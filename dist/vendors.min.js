(window["webpackJsonp"] = window["webpackJsonp"] || []).push([["vendors"],{

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\index.js":
/*!**********************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/index.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

module.exports.SummarizerManager = __webpack_require__(/*! ./src/SummarizerManager */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\src\\SummarizerManager.js");

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\classifier\\bayes_classifier.js":
/*!*********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/apparatus/lib/apparatus/classifier/bayes_classifier.js ***!
  \*********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
Classifier = __webpack_require__(/*! ./classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\classifier\\classifier.js");

var BayesClassifier = function(smoothing) {
    Classifier.call(this);
    this.classFeatures = {};
    this.classTotals = {};
    this.totalExamples = 1; // start at one to smooth
    this.smoothing = smoothing === undefined ? 1.0 : smoothing;
};

util.inherits(BayesClassifier, Classifier);

function addExample(observation, label) {
    if(!this.classFeatures[label]) {
        this.classFeatures[label] = {};
        this.classTotals[label] = 1; // give an extra for smoothing
    }

    if(observation instanceof Array) {
        var i = observation.length;
        this.totalExamples++;
        this.classTotals[label]++;

        while(i--) {
            if(observation[i]) {
                if(this.classFeatures[label][i]) {
                    this.classFeatures[label][i]++;
                } else {
                    // give an extra for smoothing
                    this.classFeatures[label][i] = 1 + this.smoothing;
                }
            }
        }
    } else {
        // sparse observation
        for(var key in observation){
            value = observation[key];

            if(this.classFeatures[label][value]) {
               this.classFeatures[label][value]++;
            } else {
                // give an extra for smoothing
               this.classFeatures[label][value] = 1 + this.smoothing;
            }
        }
    }
}

function train() {

}

function probabilityOfClass(observation, label) {
    var prob = 0;

    if(observation instanceof Array){
        var i = observation.length;

        while(i--) {
            if(observation[i]) {
                var count = this.classFeatures[label][i] || this.smoothing;
                // numbers are tiny, add logs rather than take product
                prob += Math.log(count / this.classTotals[label]);
            }
        }
    } else {
        // sparse observation
        for(var key in observation){
            var count = this.classFeatures[label][observation[key]] || this.smoothing;
            // numbers are tiny, add logs rather than take product
            prob += Math.log(count / this.classTotals[label]);
        }
    }

    // p(C) * unlogging the above calculation P(X|C)
    prob = (this.classTotals[label] / this.totalExamples) * Math.exp(prob);

    return prob;
}

function getClassifications(observation) {
    var classifier = this;
    var labels = [];

    for(var className in this.classFeatures) {
        labels.push({label: className,
        value: classifier.probabilityOfClass(observation, className)});
    }

    return labels.sort(function(x, y) {
        return y.value - x.value;
    });
}

function restore(classifier) {
     classifier = Classifier.restore(classifier);
     classifier.__proto__ = BayesClassifier.prototype;

     return classifier;
}

BayesClassifier.prototype.addExample = addExample;
BayesClassifier.prototype.train = train;
BayesClassifier.prototype.getClassifications = getClassifications;
BayesClassifier.prototype.probabilityOfClass = probabilityOfClass;

BayesClassifier.restore = restore;

module.exports = BayesClassifier;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\classifier\\classifier.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/apparatus/lib/apparatus/classifier/classifier.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

function Classifier() {
}

function restore(classifier) {
    classifier = typeof classifier == 'string' ?  JSON.parse(classifier) : classifier;

    return classifier;
}

function addExample(observation, classification) {
    throw 'Not implemented';
}

function classify(observation) {
	var classifications = this.getClassifications(observation);
	if(!classifications || classifications.length === 0) {
		throw "Not Trained";
	} 
    return classifications[0].label;
}

function train() {
    throw 'Not implemented';
}

Classifier.prototype.addExample = addExample;
Classifier.prototype.train = train;
Classifier.prototype.classify = classify;

Classifier.restore = restore;

module.exports = Classifier;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\classifier\\logistic_regression_classifier.js":
/*!***********************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/apparatus/lib/apparatus/classifier/logistic_regression_classifier.js ***!
  \***********************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
     Classifier = __webpack_require__(/*! ./classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\classifier\\classifier.js");

var sylvester = __webpack_require__(/*! sylvester */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\index.js"),
Matrix = sylvester.Matrix,
Vector = sylvester.Vector;

function sigmoid(z) {
    return 1 / (1 + Math.exp(0 - z));
}

function hypothesis(theta, Observations) {
    return Observations.x(theta).map(sigmoid);
}

function cost(theta, Examples, classifications) {
    var hypothesisResult = hypothesis(theta, Examples);

    var ones = Vector.One(Examples.rows());
    var cost_1 = Vector.Zero(Examples.rows()).subtract(classifications).elementMultiply(hypothesisResult.log());
    var cost_0 = ones.subtract(classifications).elementMultiply(ones.subtract(hypothesisResult).log());

    return (1 / Examples.rows()) * cost_1.subtract(cost_0).sum();
}

function descendGradient(theta, Examples, classifications) {
    var maxIt = 500 * Examples.rows();
    var last;
    var current;
    var learningRate = 3;
    var learningRateFound = false;

    Examples = Matrix.One(Examples.rows(), 1).augment(Examples);
    theta = theta.augment([0]);

    while(!learningRateFound && learningRate !== 0) {
        var i = 0;
        last = null;

        while(true) {
            var hypothesisResult = hypothesis(theta, Examples);
            theta = theta.subtract(Examples.transpose().x(
            hypothesisResult.subtract(classifications)).x(1 / Examples.rows()).x(learningRate));
            current = cost(theta, Examples, classifications);

            i++;

            if(last) {
            if(current < last)
                learningRateFound = true;
            else
                break;

            if(last - current < 0.0001)
                break;
            }

            if(i >= maxIt) {
                throw 'unable to find minimum';
            }

            last = current;
        }

        learningRate /= 3;
    }

    return theta.chomp(1);
}

var LogisticRegressionClassifier = function() {
    Classifier.call(this);
    this.examples = {};
    this.features = [];
    this.featurePositions = {};
    this.maxFeaturePosition = 0;
    this.classifications = [];
    this.exampleCount = 0;
};

util.inherits(LogisticRegressionClassifier, Classifier);

function createClassifications() {
    var classifications = [];

    for(var i = 0; i < this.exampleCount; i++) {
        var classification = [];

        for(var _ in this.examples) {
            classification.push(0);
        }

       classifications.push(classification);
    }

    return classifications;
}

function computeThetas(Examples, Classifications) {
    this.theta = [];

    // each class will have it's own theta.
    var zero = function() { return 0; };
    for(var i = 1; i <= this.classifications.length; i++) {
        var theta = Examples.row(1).map(zero);
        this.theta.push(descendGradient(theta, Examples, Classifications.column(i)));
    }
}

function train() {
    var examples = [];
    var classifications = this.createClassifications();
    var d = 0, c = 0;

    for(var classification in this.examples) {
        for(var i = 0; i < this.examples[classification].length; i++) {
            var doc = this.examples[classification][i];
            var example = doc;

            examples.push(example);
            classifications[d][c] = 1;
            d++;
        }

        c++;
    }

    this.computeThetas($M(examples), $M(classifications));
}

function addExample(data, classification) {
    if(!this.examples[classification]) {
	this.examples[classification] = [];
	this.classifications.push(classification);
    }

    this.examples[classification].push(data);
    this.exampleCount++;
}

function getClassifications(observation) {
    observation = $V(observation);
    var classifications = [];

    for(var i = 0; i < this.theta.length; i++) {
        classifications.push({label: this.classifications[i], value: sigmoid(observation.dot(this.theta[i])) });
    }

    return classifications.sort(function(x, y) {
        return y.value - x.value;
    });
}

function restore(classifier) {
    classifier = Classifier.restore(classifier);
    classifier.__proto__ = LogisticRegressionClassifier.prototype;

    return classifier;
}

LogisticRegressionClassifier.prototype.addExample = addExample;
LogisticRegressionClassifier.prototype.restore = restore;
LogisticRegressionClassifier.prototype.train = train;
LogisticRegressionClassifier.prototype.createClassifications = createClassifications;
LogisticRegressionClassifier.prototype.computeThetas = computeThetas;
LogisticRegressionClassifier.prototype.getClassifications = getClassifications;

LogisticRegressionClassifier.restore = restore;

module.exports = LogisticRegressionClassifier;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\clusterer\\kmeans.js":
/*!**********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/apparatus/lib/apparatus/clusterer/kmeans.js ***!
  \**********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Sylvester = __webpack_require__(/*! sylvester */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\index.js"),
Matrix = Sylvester.Matrix,
Vector = Sylvester.Vector;

function KMeans(Observations) {
    if(!Observations.elements)
    Observations = $M(Observations);

    this.Observations = Observations;
}

// create an initial centroid matrix with initial values between
// 0 and the max of feature data X.
function createCentroids(k) {
    var Centroid = [];
    var maxes = this.Observations.maxColumns();
    //console.log(maxes);

    for(var i = 1; i <= k; i++) {
        var centroid = [];
        for(var j = 1; j <= this.Observations.cols(); j++) {
            centroid.push(Math.random() * maxes.e(j));
        }

        Centroid.push(centroid);
    }

    //console.log(centroid)

    return $M(Centroid);
}

// get the euclidian distance between the feature data X and
// a given centroid matrix C.
function distanceFrom(Centroids) {
    var distances = [];

    for(var i = 1; i <= this.Observations.rows(); i++) {
        var distance = [];

        for(var j = 1; j <= Centroids.rows(); j++) {
            distance.push(this.Observations.row(i).distanceFrom(Centroids.row(j)));
        }

        distances.push(distance);
    }

    return $M(distances);
}

// categorize the feature data X into k clusters. return a vector
// containing the results.
function cluster(k) {
    var Centroids = this.createCentroids(k);
    var LastDistances = Matrix.Zero(this.Observations.rows(), this.Observations.cols());
    var Distances = this.distanceFrom(Centroids);
    var Groups;

    while(!(LastDistances.eql(Distances))) {
    Groups = Distances.minColumnIndexes();
    LastDistances = Distances;

    var newCentroids = [];

    for(var i = 1; i <= Centroids.rows(); i++) {
        var centroid = [];

        for(var j = 1; j <= Centroids.cols(); j++) {
        var sum = 0;
        var count = 0;

        for(var l = 1; l <= this.Observations.rows(); l++) {
            if(Groups.e(l) == i) {
            count++;
            sum += this.Observations.e(l, j);
            }
        }

        centroid.push(sum / count);
        }

        newCentroids.push(centroid);
    }

    Centroids = $M(newCentroids);
    Distances = this.distanceFrom(Centroids);
    }

    return Groups;
}

KMeans.prototype.createCentroids = createCentroids;
KMeans.prototype.distanceFrom = distanceFrom;
KMeans.prototype.cluster = cluster;

module.exports = KMeans;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\index.js":
/*!***********************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/apparatus/lib/apparatus/index.js ***!
  \***********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {


exports.BayesClassifier = __webpack_require__(/*! ./classifier/bayes_classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\classifier\\bayes_classifier.js");
exports.LogisticRegressionClassifier = __webpack_require__(/*! ./classifier/logistic_regression_classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\classifier\\logistic_regression_classifier.js");
exports.KMeans = __webpack_require__(/*! ./clusterer/kmeans */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\clusterer\\kmeans.js");


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\json-stable-stringify\\index.js":
/*!*********************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/json-stable-stringify/index.js ***!
  \*********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var json = typeof JSON !== 'undefined' ? JSON : __webpack_require__(/*! jsonify */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\jsonify\\index.js");

module.exports = function (obj, opts) {
    if (!opts) opts = {};
    if (typeof opts === 'function') opts = { cmp: opts };
    var space = opts.space || '';
    if (typeof space === 'number') space = Array(space+1).join(' ');
    var cycles = (typeof opts.cycles === 'boolean') ? opts.cycles : false;
    var replacer = opts.replacer || function(key, value) { return value; };

    var cmp = opts.cmp && (function (f) {
        return function (node) {
            return function (a, b) {
                var aobj = { key: a, value: node[a] };
                var bobj = { key: b, value: node[b] };
                return f(aobj, bobj);
            };
        };
    })(opts.cmp);

    var seen = [];
    return (function stringify (parent, key, node, level) {
        var indent = space ? ('\n' + new Array(level + 1).join(space)) : '';
        var colonSeparator = space ? ': ' : ':';

        if (node && node.toJSON && typeof node.toJSON === 'function') {
            node = node.toJSON();
        }

        node = replacer.call(parent, key, node);

        if (node === undefined) {
            return;
        }
        if (typeof node !== 'object' || node === null) {
            return json.stringify(node);
        }
        if (isArray(node)) {
            var out = [];
            for (var i = 0; i < node.length; i++) {
                var item = stringify(node, i, node[i], level+1) || json.stringify(null);
                out.push(indent + space + item);
            }
            return '[' + out.join(',') + indent + ']';
        }
        else {
            if (seen.indexOf(node) !== -1) {
                if (cycles) return json.stringify('__cycle__');
                throw new TypeError('Converting circular structure to JSON');
            }
            else seen.push(node);

            var keys = objectKeys(node).sort(cmp && cmp(node));
            var out = [];
            for (var i = 0; i < keys.length; i++) {
                var key = keys[i];
                var value = stringify(node, key, node[key], level+1);

                if(!value) continue;

                var keyValue = json.stringify(key)
                    + colonSeparator
                    + value;
                ;
                out.push(indent + space + keyValue);
            }
            seen.splice(seen.indexOf(node), 1);
            return '{' + out.join(',') + indent + '}';
        }
    })({ '': obj }, '', obj, 0);
};

var isArray = Array.isArray || function (x) {
    return {}.toString.call(x) === '[object Array]';
};

var objectKeys = Object.keys || function (obj) {
    var has = Object.prototype.hasOwnProperty || function () { return true };
    var keys = [];
    for (var key in obj) {
        if (has.call(obj, key)) keys.push(key);
    }
    return keys;
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\jsonify\\index.js":
/*!*******************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/jsonify/index.js ***!
  \*******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

exports.parse = __webpack_require__(/*! ./lib/parse */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\jsonify\\lib\\parse.js");
exports.stringify = __webpack_require__(/*! ./lib/stringify */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\jsonify\\lib\\stringify.js");


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\jsonify\\lib\\parse.js":
/*!***********************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/jsonify/lib/parse.js ***!
  \***********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

var at, // The index of the current character
    ch, // The current character
    escapee = {
        '"':  '"',
        '\\': '\\',
        '/':  '/',
        b:    '\b',
        f:    '\f',
        n:    '\n',
        r:    '\r',
        t:    '\t'
    },
    text,

    error = function (m) {
        // Call error when something is wrong.
        throw {
            name:    'SyntaxError',
            message: m,
            at:      at,
            text:    text
        };
    },
    
    next = function (c) {
        // If a c parameter is provided, verify that it matches the current character.
        if (c && c !== ch) {
            error("Expected '" + c + "' instead of '" + ch + "'");
        }
        
        // Get the next character. When there are no more characters,
        // return the empty string.
        
        ch = text.charAt(at);
        at += 1;
        return ch;
    },
    
    number = function () {
        // Parse a number value.
        var number,
            string = '';
        
        if (ch === '-') {
            string = '-';
            next('-');
        }
        while (ch >= '0' && ch <= '9') {
            string += ch;
            next();
        }
        if (ch === '.') {
            string += '.';
            while (next() && ch >= '0' && ch <= '9') {
                string += ch;
            }
        }
        if (ch === 'e' || ch === 'E') {
            string += ch;
            next();
            if (ch === '-' || ch === '+') {
                string += ch;
                next();
            }
            while (ch >= '0' && ch <= '9') {
                string += ch;
                next();
            }
        }
        number = +string;
        if (!isFinite(number)) {
            error("Bad number");
        } else {
            return number;
        }
    },
    
    string = function () {
        // Parse a string value.
        var hex,
            i,
            string = '',
            uffff;
        
        // When parsing for string values, we must look for " and \ characters.
        if (ch === '"') {
            while (next()) {
                if (ch === '"') {
                    next();
                    return string;
                } else if (ch === '\\') {
                    next();
                    if (ch === 'u') {
                        uffff = 0;
                        for (i = 0; i < 4; i += 1) {
                            hex = parseInt(next(), 16);
                            if (!isFinite(hex)) {
                                break;
                            }
                            uffff = uffff * 16 + hex;
                        }
                        string += String.fromCharCode(uffff);
                    } else if (typeof escapee[ch] === 'string') {
                        string += escapee[ch];
                    } else {
                        break;
                    }
                } else {
                    string += ch;
                }
            }
        }
        error("Bad string");
    },

    white = function () {

// Skip whitespace.

        while (ch && ch <= ' ') {
            next();
        }
    },

    word = function () {

// true, false, or null.

        switch (ch) {
        case 't':
            next('t');
            next('r');
            next('u');
            next('e');
            return true;
        case 'f':
            next('f');
            next('a');
            next('l');
            next('s');
            next('e');
            return false;
        case 'n':
            next('n');
            next('u');
            next('l');
            next('l');
            return null;
        }
        error("Unexpected '" + ch + "'");
    },

    value,  // Place holder for the value function.

    array = function () {

// Parse an array value.

        var array = [];

        if (ch === '[') {
            next('[');
            white();
            if (ch === ']') {
                next(']');
                return array;   // empty array
            }
            while (ch) {
                array.push(value());
                white();
                if (ch === ']') {
                    next(']');
                    return array;
                }
                next(',');
                white();
            }
        }
        error("Bad array");
    },

    object = function () {

// Parse an object value.

        var key,
            object = {};

        if (ch === '{') {
            next('{');
            white();
            if (ch === '}') {
                next('}');
                return object;   // empty object
            }
            while (ch) {
                key = string();
                white();
                next(':');
                if (Object.hasOwnProperty.call(object, key)) {
                    error('Duplicate key "' + key + '"');
                }
                object[key] = value();
                white();
                if (ch === '}') {
                    next('}');
                    return object;
                }
                next(',');
                white();
            }
        }
        error("Bad object");
    };

value = function () {

// Parse a JSON value. It could be an object, an array, a string, a number,
// or a word.

    white();
    switch (ch) {
    case '{':
        return object();
    case '[':
        return array();
    case '"':
        return string();
    case '-':
        return number();
    default:
        return ch >= '0' && ch <= '9' ? number() : word();
    }
};

// Return the json_parse function. It will have access to all of the above
// functions and variables.

module.exports = function (source, reviver) {
    var result;
    
    text = source;
    at = 0;
    ch = ' ';
    result = value();
    white();
    if (ch) {
        error("Syntax error");
    }

    // If there is a reviver function, we recursively walk the new structure,
    // passing each name/value pair to the reviver function for possible
    // transformation, starting with a temporary root object that holds the result
    // in an empty key. If there is not a reviver function, we simply return the
    // result.

    return typeof reviver === 'function' ? (function walk(holder, key) {
        var k, v, value = holder[key];
        if (value && typeof value === 'object') {
            for (k in value) {
                if (Object.prototype.hasOwnProperty.call(value, k)) {
                    v = walk(value, k);
                    if (v !== undefined) {
                        value[k] = v;
                    } else {
                        delete value[k];
                    }
                }
            }
        }
        return reviver.call(holder, key, value);
    }({'': result}, '')) : result;
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\jsonify\\lib\\stringify.js":
/*!***************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/jsonify/lib/stringify.js ***!
  \***************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

var cx = /[\u0000\u00ad\u0600-\u0604\u070f\u17b4\u17b5\u200c-\u200f\u2028-\u202f\u2060-\u206f\ufeff\ufff0-\uffff]/g,
    escapable = /[\\\"\x00-\x1f\x7f-\x9f\u00ad\u0600-\u0604\u070f\u17b4\u17b5\u200c-\u200f\u2028-\u202f\u2060-\u206f\ufeff\ufff0-\uffff]/g,
    gap,
    indent,
    meta = {    // table of character substitutions
        '\b': '\\b',
        '\t': '\\t',
        '\n': '\\n',
        '\f': '\\f',
        '\r': '\\r',
        '"' : '\\"',
        '\\': '\\\\'
    },
    rep;

function quote(string) {
    // If the string contains no control characters, no quote characters, and no
    // backslash characters, then we can safely slap some quotes around it.
    // Otherwise we must also replace the offending characters with safe escape
    // sequences.
    
    escapable.lastIndex = 0;
    return escapable.test(string) ? '"' + string.replace(escapable, function (a) {
        var c = meta[a];
        return typeof c === 'string' ? c :
            '\\u' + ('0000' + a.charCodeAt(0).toString(16)).slice(-4);
    }) + '"' : '"' + string + '"';
}

function str(key, holder) {
    // Produce a string from holder[key].
    var i,          // The loop counter.
        k,          // The member key.
        v,          // The member value.
        length,
        mind = gap,
        partial,
        value = holder[key];
    
    // If the value has a toJSON method, call it to obtain a replacement value.
    if (value && typeof value === 'object' &&
            typeof value.toJSON === 'function') {
        value = value.toJSON(key);
    }
    
    // If we were called with a replacer function, then call the replacer to
    // obtain a replacement value.
    if (typeof rep === 'function') {
        value = rep.call(holder, key, value);
    }
    
    // What happens next depends on the value's type.
    switch (typeof value) {
        case 'string':
            return quote(value);
        
        case 'number':
            // JSON numbers must be finite. Encode non-finite numbers as null.
            return isFinite(value) ? String(value) : 'null';
        
        case 'boolean':
        case 'null':
            // If the value is a boolean or null, convert it to a string. Note:
            // typeof null does not produce 'null'. The case is included here in
            // the remote chance that this gets fixed someday.
            return String(value);
            
        case 'object':
            if (!value) return 'null';
            gap += indent;
            partial = [];
            
            // Array.isArray
            if (Object.prototype.toString.apply(value) === '[object Array]') {
                length = value.length;
                for (i = 0; i < length; i += 1) {
                    partial[i] = str(i, value) || 'null';
                }
                
                // Join all of the elements together, separated with commas, and
                // wrap them in brackets.
                v = partial.length === 0 ? '[]' : gap ?
                    '[\n' + gap + partial.join(',\n' + gap) + '\n' + mind + ']' :
                    '[' + partial.join(',') + ']';
                gap = mind;
                return v;
            }
            
            // If the replacer is an array, use it to select the members to be
            // stringified.
            if (rep && typeof rep === 'object') {
                length = rep.length;
                for (i = 0; i < length; i += 1) {
                    k = rep[i];
                    if (typeof k === 'string') {
                        v = str(k, value);
                        if (v) {
                            partial.push(quote(k) + (gap ? ': ' : ':') + v);
                        }
                    }
                }
            }
            else {
                // Otherwise, iterate through all of the keys in the object.
                for (k in value) {
                    if (Object.prototype.hasOwnProperty.call(value, k)) {
                        v = str(k, value);
                        if (v) {
                            partial.push(quote(k) + (gap ? ': ' : ':') + v);
                        }
                    }
                }
            }
            
        // Join all of the member texts together, separated with commas,
        // and wrap them in braces.

        v = partial.length === 0 ? '{}' : gap ?
            '{\n' + gap + partial.join(',\n' + gap) + '\n' + mind + '}' :
            '{' + partial.join(',') + '}';
        gap = mind;
        return v;
    }
}

module.exports = function (value, replacer, space) {
    var i;
    gap = '';
    indent = '';
    
    // If the space parameter is a number, make an indent string containing that
    // many spaces.
    if (typeof space === 'number') {
        for (i = 0; i < space; i += 1) {
            indent += ' ';
        }
    }
    // If the space parameter is a string, it will be used as the indent string.
    else if (typeof space === 'string') {
        indent = space;
    }

    // If there is a replacer, it must be a function or an array.
    // Otherwise, throw an error.
    rep = replacer;
    if (replacer && typeof replacer !== 'function'
    && (typeof replacer !== 'object' || typeof replacer.length !== 'number')) {
        throw new Error('JSON.stringify');
    }
    
    // Make a fake root object containing our value under the key of ''.
    // Return the result of stringifying the value.
    return str('', {'': value});
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\analyzers\\sentence_analyzer.js":
/*!*****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/analyzers/sentence_analyzer.js ***!
  \*****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Rob Ellis, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._;

/*
 Sentences Analizer Class
 From http://www.writingcentre.uottawa.ca/hypergrammar/sntpurps.html

 Take a POS input and analyse it for
  - Type of Sentense
     - Interrogative
       - Tag Questions
       - 
     - Declarative
     - Exclamatory 
     - Imperative

  - Parts of a Sentense
     - Subject
     - Predicate

  - Show Preposition Phrases
*/

var Sentences = function(pos, callback) {
    this.posObj = pos;
    this.senType = null;
    callback(this);
};

Sentences.prototype.part = function(callback) {
    var subject = [],
	predicat = [],
	verbFound = false;
	
    this.prepositionPhrases();
	
    for (var i = 0; i < this.posObj.tags.length; i++) {
        if (this.posObj.tags[i].pos == "VB") {
            if (i === 0) {
                verbFound = true;
            } else {
                // We need to Test for any EX before the VB
                if (this.posObj.tags[i - 1].pos != "EX") {
                    verbFound = true;
                } else {
                    predicat.push(this.posObj.tags[i].token);
                }					
            }
        }

        // Add Pronoun Phrase (pp) Or Subject Phrase (sp)
        if (!verbFound) {
            if (this.posObj.tags[i].pp != true)
                this.posObj.tags[i].spos = "SP";
            
            subject.push(this.posObj.tags[i].token);
        } else {
            if (this.posObj.tags[i].pp != true)
                this.posObj.tags[i].spos = "PP";
            
            predicat.push(this.posObj.tags[i].token)
        }
    }
	
    if (subject.length == 0) {
	this.posObj.tags.push({token:"You",spos:"SP",pos:"PRP",added:true});
    }
    
    callback(this);	
};

// Takes POS and removes IN to NN or NNS
// Adds a PP for each prepositionPhrases
Sentences.prototype.prepositionPhrases = function() {
    var remove = false;

    for (var i = 0; i < this.posObj.tags.length; i++) {
        if (this.posObj.tags[i].pos.match("IN")) {
            remove = true;
        }
    
        if (remove) {
            this.posObj.tags[i].pp = true;
        }
    
        if (this.posObj.tags[i].pos.match("NN")) {
            remove = false;
        }
    }	
};

Sentences.prototype.subjectToString = function() {
    return this.posObj.tags.map(function(t){ if (t.spos == "SP" || t.spos == "S" ) return t.token }).join(' ');
};

Sentences.prototype.predicateToString = function() {
    return this.posObj.tags.map(function(t){ if (t.spos == "PP" || t.spos == "P" ) return t.token }).join(' ');
};

Sentences.prototype.implicitYou = function() {
    for (var i = 0; i < this.posObj.tags.length;i++) {
        if (this.posObj.tags[i].added) {
            return true;
        }
    }
    
    return false;
};

Sentences.prototype.toString = function() {
    return this.posObj.tags.map(function(t){return t.token}).join(' ');
};

// This is quick and incomplete.
Sentences.prototype.type = function(callback) {
    var callback = callback || false;

    // Check for implicit you before popping a tag.
    var implicitYou = this.implicitYou();

    // FIXME - punct seems useless
    var lastElement = this.posObj.punct();
    lastElement = (lastElement.length != 0) ? lastElement.pop() : this.posObj.tags.pop();

    if (lastElement.pos !== ".") {
        if (implicitYou) {
            this.senType = "COMMAND";
        } else if (_(["WDT","WP","WP$","WRB"]).contains(this.posObj.tags[0].pos)) {
            // Sentences that start with: who, what where when why and how, then they are questions
            this.senType = "INTERROGATIVE";
        } else if (_(["PRP"]).contains(lastElement.pos)) {
            // Sentences that end in a Personal pronoun are most likely questions
            // eg. We should run away, should we [?]
            // eg. You want to see that again, do you [?]
            this.senType = "INTERROGATIVE";
        } else {
            this.senType = "UNKNOWN";
        }
            
    } else {
        switch(lastElement.token) {
            case "?": this.senType = "INTERROGATIVE"; break;
            case "!": this.senType = (implicitYou) ? "COMMAND":"EXCLAMATORY"; break;
            case ".": this.senType = (implicitYou) ? "COMMAND":"DECLARATIVE";	break;
        }
    }
    
    if (callback && _(callback).isFunction()) {
        callback(this);
    } else {
        return this.senType;
    }
};

module.exports = Sentences;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Brill_POS_Tagger.js":
/*!***************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/Brill_POS_Tagger.js ***!
  \***************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Brill's POS Tagger
  Copyright (C) 2016 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");

var TF_Parser = __webpack_require__(/*! ./TF_Parser */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\TF_Parser.js");
var Sentence = __webpack_require__(/*! ./Sentence */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Sentence.js");

function Brill_POS_Tagger(lexicon, ruleSet) {
  this.lexicon = lexicon;
  this.ruleSet = ruleSet;
}

// Tags a sentence, sentence is an array of words
// Returns an array of tagged words; a tagged words is an array consisting of
// the word itself followed by its lexical category
Brill_POS_Tagger.prototype.tag = function(sentence) {
  var taggedSentence = this.tagWithLexicon(sentence);
  //console.log(taggedSentence);
  return this.applyRules(taggedSentence);
};

Brill_POS_Tagger.prototype.tagWithLexicon = function(sentence) {
  var taggedSentence = new Sentence();

  var that = this;
  sentence.forEach(function(word, index) {
    var categories = that.lexicon.tagWord(word);
    taggedSentence.addTaggedWord(word, categories[0]);
  });
  return(taggedSentence);
};

// Applies the transformation rules to an initially tagged sentence.
// taggedSentence is an array of tagged words.
// A tagged word is an array consisting of the word itself followed by its lexical category.
// Returns an array of tagged words as well
Brill_POS_Tagger.prototype.applyRules = function(sentence) {
  for (var i = 0, size = sentence.taggedWords.length; i < size; i++) {
    this.ruleSet.getRules().forEach(function(rule) {
      rule.apply(sentence, i);
    });
  }
  return sentence;
};

module.exports = Brill_POS_Tagger;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Brill_POS_Tester.js":
/*!***************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/Brill_POS_Tester.js ***!
  \***************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
  Brill's POS Testing class
  Copyright (C) 2017 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

function Brill_POS_Tester() {

}

Brill_POS_Tester.prototype.test = function(corpus, tagger) {
  var totalWords = 0;
  var correctTagsLexicon = 0;
  var correctTagsAfterRules = 0;

  // Tag the corpus using the tagger
  corpus.sentences.forEach(function(sentence) {
    var s = sentence.taggedWords.map(function(token) {
      return token.token;
    });

    // Use the lexicon to tag the sentence
    var taggedSentence = tagger.tagWithLexicon(s);
    // Count the right tags
    sentence.taggedWords.forEach(function(token, i) {
      totalWords++;
      if (token.tag === taggedSentence.taggedWords[i].tag) {
        correctTagsLexicon++;
      }
    });

    // Use the rule set to tag the sentence
    var taggedSentenceAfterRules = tagger.applyRules(taggedSentence);
    // Count the right tags
    sentence.taggedWords.forEach(function(token, i) {
      if (token.tag === taggedSentenceAfterRules.taggedWords[i].tag) {
        correctTagsAfterRules++;
      }
    });
  });

  // Return percentage right
  return [100 * correctTagsLexicon/ totalWords, 100 * correctTagsAfterRules / totalWords];
};

module.exports = Brill_POS_Tester;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Brill_POS_Trainer.js":
/*!****************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/Brill_POS_Trainer.js ***!
  \****************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Brill POS Trainer class
  Copyright (C) 2017 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

// Algorithm is based on:
// Exploring the Statistical Derivation of Transformational Rule Sequences
// for Part-of-Speech Tagging, Lance A. Ramshaw and Mitchell P. Marcus
// http://acl-arc.comp.nus.edu.sg/archives/acl-arc-090501d4/data/pdf/anthology-PDF/W/W94/W94-0111.pdf

//var log4js = require('log4js');
//var logger = log4js.getLogger('Brill_POS_Trainer');
//logger.setLevel('OFF');

var TransformationRule = __webpack_require__(/*! ./TransformationRule */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\TransformationRule.js");
var RuleSet = __webpack_require__(/*! ./RuleSet */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\RuleSet.js");
var Sentence = __webpack_require__(/*! ./Sentence */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Sentence.js");

// Training continues as long as there are rules with a positive score
// that have not been selected before
var minScore = 0;

// After training rules with a score below scoreThreshold are pruned
function Brill_POS_Trainer(ruleScoreThreshold) {
  if (ruleScoreThreshold) {
    this.ruleScoreThreshold = ruleScoreThreshold;
  }
  else {
    this.ruleScoreThreshold = 1;
  }
}

// Return the highest scoring rule from the rule set
Brill_POS_Trainer.prototype.selectHighRule = function() {
  var highestRule = null;

  // Walk through the map and find the rule with highest score
  this.positiveRules.getRules().forEach(function(rule){
    if (highestRule === null) {
      if (!rule.hasBeenSelectedAsHighRuleBefore) {
        highestRule = rule;
      }
    }
    else {
      if ((rule.score() > highestRule.score()) &&
        !rule.hasBeenSelectedAsHighRuleBefore) {
        highestRule = rule;
      }
    }
  });

  if (highestRule !== null) {
    highestRule.hasBeenSelectedAsHighRuleBefore = true;
  }
  // Return the rule with the highest score
  return highestRule;
};

Brill_POS_Trainer.prototype.mapRuleToSite = function(rule, i, j) {
  if (!this.mapRuleToSites[rule.key()]) {
    this.mapRuleToSites[rule.key()] = {};
  }
  if (!this.mapRuleToSites[rule.key()][i]) {
    this.mapRuleToSites[rule.key()][i] = {};
  }
  this.mapRuleToSites[rule.key()][i][j] = true;
};

Brill_POS_Trainer.prototype.mapSiteToRule = function(i, j, rule) {
  if (!this.mapSiteToRules[i]) {
    this.mapSiteToRules[i] = {};
  }
  if (!this.mapSiteToRules[i][j]) {
    this.mapSiteToRules[i][j] = {};
  }
  this.mapSiteToRules[i][j][rule.key()] = rule;
};

Brill_POS_Trainer.prototype.associateSiteWithRule = function(i, j, rule) {
  this.mapRuleToSite(rule, i, j);
  this.mapSiteToRule(i, j, rule);
};

Brill_POS_Trainer.prototype.siteIsAssociatedWithRule = function(i, j, rule) {
  if (this.mapSiteToRules[i]) {
    if (this.mapSiteToRules[i][j]) {
      if (this.mapSiteToRules[i][j][rule.key()]) {
        return true;
      }
    }
  }
  return false;
};

// Returns an array of all sites associated with rule
Brill_POS_Trainer.prototype.getSites = function(rule) {
  var that = this;
  var result = [];
  Object.keys(this.mapRuleToSites[rule.key()]).forEach(function(i) {
    Object.keys(that.mapRuleToSites[rule.key()][i]).forEach(function(j) {
      // Unary plus the convert hash keys i and j to integer
      result.push([+i, +j]);
    });
  });
  //logger.debug("Brill_POS_Trainer.prototype.getSites: sites " + JSON.stringify(result));
  return(result);
};

// Returns an array of all rules associated with the site
Brill_POS_Trainer.prototype.getRules = function(i, j) {
  var result = [];
  var that = this;

  if (this.mapSiteToRules[i]) {
    if (this.mapSiteToRules[i][j]) {
      result = Object.keys(this.mapSiteToRules[i][j]).map(function(key) {
        return that.mapSiteToRules[i][j][key];
      });
    }
  }
  return result;
};

Brill_POS_Trainer.prototype.disconnectSiteFromRule = function(i, j, rule) {
  // mapRuleToSites
  if (this.mapRuleToSites[rule.key()]) {
    if (this.mapRuleToSites[rule.key()][i]) {
      if (this.mapRuleToSites[rule.key()][i][j]) {
        delete this.mapRuleToSites[rule.key()][i][j];
      }
    }
  }

  // mapSiteToRules
  if (this.mapSiteToRules[i]) {
    if (this.mapSiteToRules[i][j]) {
      if (this.mapSiteToRules[i][j][rule.key()]) {
        delete this.mapSiteToRules[i][j][rule.key()];
      }
    }
  }
};

// Adjusts the score of the rule at position i, j of the corpus
Brill_POS_Trainer.prototype.scoreRule = function(rule, i, j) {
  //logger.debug("Brill_POS_Trainer.prototype.scoreRule: entry");
  var token = this.corpus.sentences[i].taggedWords[j];
  var rightTag = token.tag;
  var oldTag = token.testTag;
  var newTag = token.newTag;
  if (rightTag !== oldTag) {
    // Old tag is wrong
    if (newTag === rightTag) {
      // New tag is right
      rule.positive++;
      // If the score changes, it may be selected again as highest scoring rule
      rule.hasBeenSelectedAsHighRuleBefore = false;
      //logger.debug("Brill_POS_Trainer.prototype.scoreRule: positive: " + rule.key() + "\t score: " + rule.positive);
    }
    else {
      // New tag is wrong as well --> neutral
      rule.neutral++;
      //logger.debug("Brill_POS_Trainer.prototype.scoreRule: neutral: " + rule.key() + "\t score: " + rule.neutral);
    }
  }
  else {
    // Old tag is right
    if (newTag === rightTag) {
      // New tag is right --> neutral
      rule.neutral++;
      //logger.debug("Brill_POS_Trainer.prototype.scoreRule: neutral: " + rule.key() + "\t score: " + rule.neutral);


    }
    else {
      // New tag is false
      rule.negative++;
      // If the score changes, it may be selected again as highest scoring rule
      rule.hasBeenSelectedAsHighRuleBefore = false;
      //logger.debug("Brill_POS_Trainer.prototype.scoreRule: negative: " + rule.key() + "\t score: " + rule.negative);
    }
  }
  //logger.debug("Brill_POS_Trainer.prototype.scoreRule: exit");
};

// Generate positive rules for this given site using templates
Brill_POS_Trainer.prototype.generatePositiveRules = function(i, j) {
  var sentence = this.corpus.sentences[i];
  var token = sentence.taggedWords[j];
  // A positive rule should trigger on the currently assigned testTag
  var oldTag = token.testTag;
  //logger.debug("Brill_POS_Trainer.prototype.generatePositiveRules: oldTag " + oldTag);
  // It should assign the right tag as given by the corpus
  var newTag = token.tag;
  //logger.debug("Brill_POS_Trainer.prototype.generatePositiveRules: newTag " + newTag);

  var newRules = new RuleSet();
  // Exit if testTag already is the right tag --> will not result in positive rules
  if (oldTag === newTag) {
    return newRules;
  }

  this.templates.forEach(function(template) {
    if (template.windowFitsSite(sentence, j)) {
      if (template.meta.nrParameters === 1) {
        template.meta.parameter1Values(sentence, j).forEach(function (value) {
          newRules.addRule(new TransformationRule(oldTag, newTag, template.predicateName, value));
        });
      }
      else {
        if (template.meta.nrParameters === 2) {
          template.meta.parameter1Values(sentence, j).forEach(function (value1) {
            template.meta.parameter2Values(sentence, j).forEach(function (value2) {
              newRules.addRule(new TransformationRule(oldTag, newTag, template.predicateName, value1, value2));
            });
          });
        }
        else {
          // 0 paramaters
          newRules.addRule(new TransformationRule(oldTag, newTag, template.predicateName));
        }
      }
    }
  });
  return newRules;
};

// Finds all rules that are applicable at some site
Brill_POS_Trainer.prototype.scanForPositiveRules = function() {
  //logger.debug("Brill_POS_Trainer.prototype.scanForPositiveRules: entry");
  var that = this;
  this.corpus.sentences.forEach(function(sentence, i) {
    sentence.taggedWords.forEach(function(token, j) {
      //logger.debug("Brill_POS_Trainer.prototype.scanForPositiveRules: sentence no " + i);
      var newRules = that.generatePositiveRules(i, j);
      newRules.getRules().forEach(function(rule) {
        that.positiveRules.addRule(rule);
        //logger.debug("Brill_POS_Trainer.prototype.scanForPositiveRules: nrRules " + that.positiveRules.nrRules());
      });
    });
  });
  //logger.debug("Brill_POS_Trainer.prototype.scanForPositiveRules: exit, number of rules: " + this.positiveRules.nrRules());
};

// Find all sites where the rules can be applied, register these sites and
// update the scores
Brill_POS_Trainer.prototype.scanForSites = function() {
  //logger.debug("Brill_POS_Trainer.prototype.scanForSites: entry");
  var that = this;

  // Scan the corpus
  this.corpus.sentences.forEach(function(sentence, i) {
    if (i % 100 === 0) {
      //logger.info("Brill_POS_Trainer.prototype.scanForSites: sentence " + i);
    }

    var taggedSentence = new Sentence();
    sentence.taggedWords.forEach(function(wordObject) {
      taggedSentence.addTaggedWord(wordObject.token, wordObject.testTag);
    });

    sentence.taggedWords.forEach(function(token, j) {
      that.positiveRules.getRules().forEach(function(rule) {
        if (rule.isApplicableAt(sentence, taggedSentence, j)) {
          that.associateSiteWithRule(i, j, rule);
          that.scoreRule(rule, i, j);
          //logger.debug("Brill_POS_Trainer.prototype.scanForSites: (sentence, token, rule): (" + i + ", " + j + ", " + rule.prettyPrint() + ")");
        }
      });
    });
  });

  //logger.debug("Brill_POS_Trainer.prototype.scanForSites: exit");
};

// Returns a list of sites that may have been touched by a changing tag
Brill_POS_Trainer.prototype.neighbourhood = function(i, j) {
  var sentenceLength = this.corpus.sentences[i].length;
  var list = [];

  if (this.index > 2) {
    list.push([i, j - 3]);
  }
  if (this.index > 1) {
    list.push([i, j - 2]);
  }
  if (this.index > 0) {
    list.push([i, j - 1]);
  }
  if (this.index < sentenceLength - 1) {
    list.push([i, j + 1]);
  }
  if (this.index < sentenceLength - 2) {
    list.push([i, j + 2]);
  }
  if (this.index > sentenceLength - 3) {
    list.push([i, j + 3]);
  }
  return list;
};

// corpus: an array of token arrays
// templates: an array of rule templates
// lexicon: lexicon that provides method tagWord(word)
Brill_POS_Trainer.prototype.train = function(corpus, templates, lexicon) {
  this.corpus = corpus;
  this.templates = templates;
  this.positiveRules = new RuleSet();
  this.mapRuleToSites = {};
  this.mapSiteToRules = {};

  //logger.debug("Brill_POS_Trainer.prototype.train: entry");
  this.corpus.tag(lexicon);
  this.scanForPositiveRules();
  //logger.info("Brill_POS_Trainer.prototype.train: initial number of rules: " + this.positiveRules.nrRules());
  this.scanForSites();

  var highRule = this.selectHighRule();
  var iterationNumber = 0;
  var that = this;
  while ((highRule !== null) && (highRule.score() > minScore)) {
    if ((iterationNumber % 5) === 0) {
      //logger.info("Brill_POS_Trainer.prototype.train: training iteration: " + iterationNumber);
    }
    //logger.debug("Brill_POS_Trainer.prototype.train: highRule selected: " + highRule.key());
    //logger.debug("Brill_POS_Trainer.prototype.train: number of rules: " + this.positiveRules.nrRules());
    //logger.debug("Brill_POS_Trainer.prototype.train: score of highRule: " + highRule.score());

    // Apply the high rule to each change site on its site list
    this.getSites(highRule).forEach(function(site) {
      //logger.debug("Brill_POS_Trainer.prototype.train: apply highRule to: " + site);
      //logger.debug("Brill_POS_Trainer.prototype.train: sentence length: " + that.corpus.sentences[site[0]].length);
      highRule.applyAt(that.corpus.sentences[site[0]], site[1]);
    });

    var unseenRules = new RuleSet();
    this.getSites(highRule).forEach(function(site) {
      that.neighbourhood(site[0], site[1]).forEach(function(testSite) {
        // Generate positive rules for testSite
        var newRules = that.generatePositiveRules(testSite[0], testSite[1]);

        // Disconnect test site from its rules
        // because highrule has been applied
        that.getRules(testSite[0], testSite[1]).forEach(function(rule) {
          if (!newRules.hasRule(rule)) {
            that.disconnectSiteFromRule(testSite[0], testSite[1], rule);
          }
        });

        // Connect new rules not already connected to the test site
        newRules.getRules().forEach(function(rule) {
          if (!that.siteIsAssociatedWithRule(testSite[0]. testSite[1], rule)) {
            if (that.positiveRules.hasRule(rule)) {
              that.associateSiteWithRule(testSite[0], testSite[1], rule);
            }
            else {
              unseenRules.addRule(rule);
            }
          }
        });

        // Process unseen rules
        if (unseenRules.nrRules() > 0) {
          unseenRules.getRules().forEach(function(rule) {
            that.positiveRules.addRule(rule);
          });
          that.corpus.sentences.forEach(function (sentence, i) {
            var taggedSentence = sentence.map(function(token) {
              return [token.token, token.testTag];
            });
            sentence.forEach(function(token, j) {
              unseenRules.getRules().forEach(function(rule) {
                if (rule.isApplicableAt(sentence, taggedSentence, j)) {
                  that.associateSiteWithRule(i, j, rule);
                  that.scoreRule(rule, i, j);
                }
              });
            });
          });
        }

      });
    });

    // Select next highest scoring rule
    highRule = this.selectHighRule();
    iterationNumber++;
  }
  //logger.info("Brill_POS_Trainer.prototype.train: number of iterations: " + iterationNumber);
  //logger.info("Brill_POS_Trainer.prototype.train: number of rules: " + this.positiveRules.nrRules());

  // Remove rules having a non-positive score
  this.positiveRules.getRules().forEach(function(rule) {
    if (rule.score() < that.ruleScoreThreshold) {
      that.positiveRules.removeRule(rule);
    }
  });

  //logger.info("Brill_POS_Trainer.prototype.train: number of rules after pruning: " + this.positiveRules.nrRules());
  //logger.debug("Brill_POS_Trainer.prototype.train: exit");
  return this.positiveRules;
};

Brill_POS_Trainer.prototype.printRulesWithScores = function() {
  var that = this;
  var result = "";

  function compareRules(a, b) {
    if (a.score() > b.score()) {
      return -1;
    }
    else {
      if (a.score() < b.score()) {
        return 1;
      }
      else {
        return 0;
      }
    }
  }

  var rules = this.positiveRules.getRules();
  var sortedRules = rules.sort(compareRules);

  sortedRules.forEach(function(rule) {
    //if (rule.score() > 0) {
      result += rule.score() + '\t' + rule.positive + '\t' + rule.negative + '\t' + rule.neutral + '\t' + rule.prettyPrint() + "\n";
    //}
  });
  return result;
};

module.exports = Brill_POS_Trainer;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Corpus.js":
/*!*****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/Corpus.js ***!
  \*****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Corpus class for parsing and analysing corpora
  Copyright (C) 2018 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var Sample = __webpack_require__(/*! ../../classifiers/maxent/Sample */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Sample.js");
var ElementClass = __webpack_require__(/*! ../../classifiers/maxent/POS/POS_Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\POS\\POS_Element.js");
var Lexicon = __webpack_require__(/*! ./Lexicon */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Lexicon.js");

const BROWN = 1;

// sentences: an array of annotated sentences
// A sentence is an array of annotated tokens
// A token is an object with (token, tag, testTag, ruleList)
function Corpus(data, typeOfCorpus, SentenceClass) {
  this.wordCount = 0;
  this.sentences = [];
  if (data && typeOfCorpus) {
    // For other types of corpora add a case here and supply a parsing method
    switch (typeOfCorpus) {
      case BROWN:
        this.parseBrownCorpus(data, SentenceClass);
        break;
      default:
        // Assume it is an array of tagged sentences
        this.sentences = data;
    }
  }
}

// data is raw text
// A corpus parsing method should split the corpus in sentences each of which
// consist of an array of tokens.
Corpus.prototype.parseBrownCorpus = function(data, SentenceClass) {
  var that = this;

  var lines = data.split('\n');
  lines.forEach(function(line) {
    var trimmedLine = line.trim();
    // Only parse lines that contain characters
    if (trimmedLine != "") {
      var taggedSentence = new SentenceClass();
      var tokens = line.trim().split(/\s+/);
      tokens.forEach(function (token) {
        that.wordCount++;
        // Create a tagged sentences consisting of tokens
        var wordPlusTag = token.split('_');
        taggedSentence.addTaggedWord(wordPlusTag[0], wordPlusTag[1]);
      });

      // Add the sentence to the corpus
      that.sentences.push(taggedSentence);
    }
  });
};

// Returns an array of all POS tags used in the corpus
Corpus.prototype.getTags = function() {
  return Object.keys(this.posTags);
};

// Splits the corpus in a training and testing set.
// percentageTrain is the size of the training corpus in percent
// Returns an array with two elements: training corpus, testing corpus
Corpus.prototype.splitInTrainAndTest = function(percentageTrain) {
  var corpusTrain = new Corpus();
  var corpusTest = new Corpus();

  var p = percentageTrain / 100;
  this.sentences.forEach(function(sentence, i) {
    if (Math.random() < p) {
      corpusTrain.sentences.push(sentence);
    }
    else {
      corpusTest.sentences.push(sentence);
    }
  });
  return [corpusTrain, corpusTest];
};

// Analyses the corpus:
// - registers used POS tags
// - records the frequency of POS tag for each word
Corpus.prototype.analyse = function() {
  this.tagFrequencies = {};
  this.posTags = {};
  this.wordCount = 0;

  var that = this;
  this.sentences.forEach(function(sentence) {
    sentence.taggedWords.forEach(function(token) {
      that.wordCount++;

      // Register the tags used in the corpus
      that.posTags[token.tag] = true;

      // Register the frequency of the tag
      if (!that.tagFrequencies[token.token]) {
        that.tagFrequencies[token.token] = {};
      }
      if (!that.tagFrequencies[token.token][token.tag]) {
        that.tagFrequencies[token.token][token.tag] = 0;
      }
      that.tagFrequencies[token.token][token.tag]++;
    });
  });
};

// Creates a lexicon by taking the most frequently occurring tag of a word
// as the right tag
Corpus.prototype.buildLexicon = function() {
  var lexicon = new Lexicon();
  var that = this;

  this.analyse();
  Object.keys(this.tagFrequencies).forEach(function(token) {
    var catToFreq = that.tagFrequencies[token];
    var categories = Object.keys(catToFreq);

    function compareByFrequency(a, b) {
      if (catToFreq[a] > catToFreq[b]) {
        return -1;
      }
      else {
        if (catToFreq[a] < catToFreq[b]) {
          return 1;
        }
        else {
          return 0;
        }
      }
    }

    var sortedCategories = categories.sort(compareByFrequency);
    lexicon.addWord(token, sortedCategories);
  });
  return lexicon;
};

Corpus.prototype.tag = function(lexicon) {
  this.sentences.forEach(function(sentence) {
    sentence.taggedWords.forEach(function(token) {
      // tagWord returns a list of categories, take the first category
      token.testTag = lexicon.tagWord(token.token)[0];
    });
  });
};

Corpus.prototype.nrSentences = function() {
  return this.sentences.length;
};

Corpus.prototype.nrWords = function() {
  return this.wordCount;
};

Corpus.prototype.generateFeatures = function() {
  var features = [];
  this.sentences.forEach(function(sentence) {
    features = sentence.generateFeatures(features);
  });
  //console.log(JSON.stringify(features));
  return features;
};

Corpus.prototype.prettyPrint = function() {
  this.sentences.forEach(function(sentence, index) {
    //logger.debug("sentence no " + index + "\n" +
    //  JSON.stringify(sentence, null, 2));
  });
};

module.exports = Corpus;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Lexicon.js":
/*!******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/Lexicon.js ***!
  \******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Lexicon class
  Copyright (C) 2016 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");

// Parses a lexicon in JSON or text format
function Lexicon(filename, defaultCategory, defaultCategoryCapitalised) {
  this.lexicon = {}; //Object.create(null);

  if (filename) {
    this.defaultCategory = defaultCategory;
    // Read lexicon
    try {
      var data = fs.readFileSync(filename, 'utf8');
      if (data[0] === "{") {
        // Lexicon is in JSON format
        this.lexicon = JSON.parse(data);
      }
      else {
        // Lexicon is plain text
        this.parseLexicon(data);
      }
      //console.log('Brill_POS_Tagger.read_lexicon: number of lexicon entries read: ' + Object.keys(this.lexicon).length);
    }
    catch (error) {
      console.error(error);
    }
    if (defaultCategory) {
      this.defaultCategory = defaultCategory;
      if (defaultCategoryCapitalised) {
        this.defaultCategoryCapitalised = defaultCategoryCapitalised;
      }
    }
  }
}

// Parses a lexicon in text format: word cat1 cat2 ... catn
Lexicon.prototype.parseLexicon = function(data) {
  // Split into an array of non-empty lines
  var arrayOfLines = data.match(/[^\r\n]+/g);
  this.lexicon = {}; //Object.create(null);
  var that = this;
  arrayOfLines.forEach(function(line) {
    // Split line by whitespace
    var elements = line.trim().split(/\s+/);
    if (elements.length > 0) {
      that.lexicon[elements[0]] = elements.slice(1);
    }
  });
};

Lexicon.prototype.tagWordWithDefaults = function(word) {
  if (/[A-Z]/.test(word[0]) && this.defaultCategoryCapitalised) {
    // Capitalised
    return this.defaultCategoryCapitalised;
  }
  else {
    // If not found assign default_category
    return this.defaultCategory;
  }
};

// Returns a list of categories for word
Lexicon.prototype.tagWord = function(word) {
  var categories = this.lexicon[word];
  //console.log(categories);
  if (!categories || (typeof categories == "function")) {
    categories = this.lexicon[word.toLowerCase()];
  }
  if (!categories || (typeof categories == "function")) {
    categories = [this.tagWordWithDefaults(word)];
  }
  return(categories);
};

// Adds a word to the lexicon. NB simply replaces the entry
Lexicon.prototype.addWord = function(word, categories) {
  this.lexicon[word] = categories;
};

Lexicon.prototype.prettyPrint = function() {
  var result = "";
  var that = this;
  Object.keys(this.lexicon).forEach(function(token) {
    result += token + "\t";
    that.lexicon[token].forEach(function(cat) {
      result += cat + "\t";
    });
    result += "\n";
  });
  return result;
};

Lexicon.prototype.nrEntries = function() {
  return Object.keys(this.lexicon).length;
};

Lexicon.prototype.size = function() {
  return this.nrEntries();
};

Lexicon.prototype.setDefaultCategories = function(category, categoryCapitalised) {
  this.defaultCategory = category;
  if (categoryCapitalised) {
    this.defaultCategoryCapitalised = categoryCapitalised;
  }
};

module.exports = Lexicon;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Predicate.js":
/*!********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/Predicate.js ***!
  \********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Predicates for the Brill tagger
  Copyright (C) 2017 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

//var log4js = require('log4js');
//var logger = log4js.getLogger();
//logger.setLevel('INFO');

var predicates = __webpack_require__(/*! ./RuleTemplates */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\RuleTemplates.js");
//logger.debug(predicates);

function Predicate(name, parameter1, parameter2) {
  this.name = name;
  this.meta = predicates[name];
  if (!this.meta) {
    this.meta = predicates["DEFAULT"];
  }
  //if (this.meta.nrParameters > 0) {
    this.parameter1 = parameter1;
  //}
  //if (this.meta.nrParameters > 1) {
    this.parameter2 = parameter2;
  //}
  //logger.debug('Predicate\n' + JSON.toString(this.meta, null, 2));
}

Predicate.prototype.evaluate = function(sentence, position) {
  //logger.debug('Predicate.evalute ' + this.name);
  var predicate = this.meta.function;
  return (predicate(sentence, position, this.parameter1, this.parameter2));
};

module.exports = Predicate;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\RuleSet.js":
/*!******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/RuleSet.js ***!
  \******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
   Set of transformation rules
   Copyright (C) 2017 Hugo W.L. ter Doest

   This program is free software: you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by
   the Free Software Foundation, either version 3 of the License, or
   (at your option) any later version.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.

   You should have received a copy of the GNU General Public License
   along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");
var TF_Parser = __webpack_require__(/*! ./TF_Parser */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\TF_Parser.js");

function RuleSet(filename) {
  //this.rules = [];
  this.rules = {};

  if (filename) {
    // Read transformation rules
    try {
      var data = fs.readFileSync(filename, 'utf8');
      this.rules = TF_Parser.parse(data);
      // console.log(this.rules);
      // console.log('Brill_POS_Tagger.read_transformation_rules: number of transformation rules read: ' + this.rules.length);
    }
    catch (error) {
      console.error(error);
    }
  }
}

RuleSet.prototype.addRule = function(rule) {
  //this.rules.push(rule);
  if (!this.rules[rule.key()]) {
    this.rules[rule.key()] = rule;
    return true;
  }
  else {
    return false;
  }
};

RuleSet.prototype.removeRule = function(rule) {
  if (this.rules[rule.key()]) {
    delete this.rules[rule.key()];
  }
};

RuleSet.prototype.getRules = function() {
  var that = this;
  return Object.keys(this.rules).map(function(key) {
    return that.rules[key];
  });
};

RuleSet.prototype.nrRules = function() {
  return Object.keys(this.rules).length;
};

RuleSet.prototype.hasRule = function(rule) {
  if (this.rules[rule.key()]) {
    return true;
  }
  else {
    return false;
  }
};

RuleSet.prototype.prettyPrint = function() {
  var result = "";
  //this.rules.forEach(function(rule) {
  var that = this;
  Object.keys(this.rules).forEach(function(key) {
    var rule = that.rules[key];
    result += rule.prettyPrint() + "\n";
  });
  return result;
};

module.exports = RuleSet;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\RuleTemplate.js":
/*!***********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/RuleTemplate.js ***!
  \***********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
  Rule Template class for deriving transformation rules.
  Copyright (C) 2017 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

function RuleTemplate(templateName, metadata) {
  this.predicateName = templateName;
  this.meta = metadata;
}

RuleTemplate.prototype.windowFitsSite = function(sentence, i) {
  return ((i + this.meta.window[0] >= 0) &&
    (i + this.meta.window[0] < sentence.taggedWords.length) &&
    (i + this.meta.window[1] >= 0) &&
    (i + this.meta.window[1] < sentence.taggedWords.length));
};

module.exports = RuleTemplate;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\RuleTemplates.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/RuleTemplates.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
  Rule templates that provide metadata for generating transformation rules
  Copyright (C) 2017 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var ruleTemplates = {
  // Predicates as used in the English rules in data/English/tr_from_posjs.txt
  "NEXT-TAG": {
    // maps to the predicate function
    "function": next_tag_is,
    // Minimum required space before or after current position to be a relevant predicate
    "window": [0, 1],
    // The number of parameters the predicate takes
    "nrParameters": 1,
    // Function that returns relevant values for parameter 1
    "parameter1Values": nextTagParameterValues
  },
  "NEXT-WORD-IS-CAP": {
    "function": next_word_is_cap,
    "window": [0, 1],
    "nrParameters" : 0
  },
  "PREV-1-OR-2-OR-3-TAG": {
    "function": prev_1_or_2_or_3_tag,
    "window" : [-1, 0],
    "nrParameters" : 1,
    "parameter1Values": prev1Or2Or3TagParameterValues
  },
  "PREV-1-OR-2-TAG": {
    "function": prev_1_or_2_tag,
    "window": [-1, 0],
    "nrParameters": 1,
    "parameter1Values": prev1Or2TagParameterValues
  },
  "NEXT-WORD-IS-TAG": {
    "function": next_tag_is,
    "window": [0, 1],
    "nrParameters": 1,
    "parameter1Values": nextTagParameterValues
  },
  "PREV-TAG": {
    "function": prev_tag_is,
    "window": [-1, 0],
    "nrParameters": 1,
    "parameter1Values": prevTagParameterValues
  },
  /*
 "CURRENT-WORD-IS-TAG": {
   "function": current_word_is_tag,
   "window": [0],
   "nrParameter": 1,
   "parameter1Values": currentTagParameterValues
   },
  */
  "PREV-WORD-IS-CAP": {
    "function": prev_word_is_cap,
    "window": [-1, 0],
    "nrParameters": 0
  },
  "CURRENT-WORD-IS-CAP": {
    "function": current_word_is_cap,
    "window": [0, 0],
    "nrParameters": 0
  },
  "CURRENT-WORD-IS-NUMBER": {
    "function": current_word_is_number,
    "window": [0, 0],
    "nrParameters": 0
  },
  "CURRENT-WORD-IS-URL": {
    "function": current_word_is_url,
    "window": [0, 0],
    "nrParameters": 0
  },
  "CURRENT-WORD-ENDS-WITH": {
    "function": current_word_ends_with,
    "window": [0, 0],
    "nrParameters": 1,
    "parameter1Values": currentWordEndsWithParameterValues
  },
  "PREV-WORD-IS": {
    "function": prev_word_is,
    "window": [-1, 0],
    "nrParameters": 1,
    "parameter1Values": prevWordParameterValues
  },

  // Predicates as used in the Dutch rules in data/Dutch/brill_CONTEXTRULES.jg
  "PREVTAG": {
    "function": prev_tag_is,
    "window": [-1, 0],
    "nrParameters": 1,
    "parameter1Values": prevTagParameterValues
  },
  "NEXT1OR2TAG": {
    "function": next_1_or_2_tag_is,
    "window": [0, 1],
    "nrParameters": 1,
    "parameter1Values": next1Or2TagIsParameterValues
  },
  "NEXTTAG": {
    "function": next_tag_is,
    "window": [0, 1],
    "nrParameters": 1,
    "parameter1Values": nextTagParameterValues
  },
  "PREV1OR2TAG": {
    "function": prev_1_or_2_tag,
    "window": [-1, 0],
    "nrParameters": 1,
    "parameter1Values": prev1Or2TagParameterValues
  },
  "WDAND2TAGAFT": {
    "function": current_word_and_2_tag_after_are,
    "window": [0, 2],
    "nrParameters": 2,
    "parameter1Values": currentWordParameterValues,
    "parameter2Values": twoTagAfterParameterValues
  },
  "NEXT1OR2OR3TAG": {
    "function": next_1_or_2_or_3_tag,
    // Minimum required window to apply this template is one tag to the right
    "window": [0, 1],
    "nrParameters": 1,
    "parameter1Values": next1Or2Or3TagParameterValues
  },
  "CURWD": {
    "function": current_word_is,
    "window": [0, 0],
    "nrParameters": 1,
    "parameter1Values": currentWordParameterValues
  },
  "SURROUNDTAG": {
    "function": surrounded_by_tags,
    "window": [-1, 1],
    "nrParameters": 2,
    "parameter1Values": prevTagParameterValues,
    "parameter2Values": nextTagParameterValues
  },
  "PREV1OR2OR3TAG": {
    "function": prev_1_or_2_or_3_tag,
    // Minimum required window to apply this template is one tag to the left
    "window": [-1, 0],
    "nrParameters": 1,
    "parameter1Values": prev1Or2Or3TagParameterValues
  },
  "WDNEXTTAG": {
    "function": current_word_and_next_tag_are,
    "window": [0, 1],
    "nrParameters": 2,
    "parameter1Values": currentWordParameterValues,
    "parameter2Values": nextTagParameterValues
  },
  "PREV1OR2WD": {
    "function": prev_1_or_2_word_is,
    "window": [-1, 0],
    "nrParameters": 1,
    "parameter1Values": prev1Or2WordParameterValues
  },
  "NEXTWD": {
    "function": next_word_is,
    "window": [0, 1],
    "nrParameters": 1,
    "parameter1Values": nextWordParameterValues
  },
  "PREVWD": {
    "function": prev_word_is,
    "window": [-1, 0],
    "nrParameters": 1,
    "parameter1Values": prevWordParameterValues
  },
  "NEXT2TAG": {
    "function": next_2_tag_is,
    "window": [0, 2],
    "nrParameters": 1,
    "parameter1Values": next2TagParameterValues
  },
  "WDAND2TAGBFR": {
    "function": current_word_and_2_tag_before_are,
    "window": [-2, 0],
    "nrParameters": 2,
    "parameter1Values": currentWordParameterValues,
    "parameter2Values": twoTagBeforeParameterValues
  },
  "WDAND2AFT": {
    "function": current_word_and_2_after_are,
    "window": [0, 2],
    "nrParameters": 2,
    "parameter1Values": currentWordParameterValues,
    "parameter2Values": twoTagAfterParameterValues
  },
  "WDPREVTAG": {
    "function": current_word_and_prev_tag_are,
    "window": [-1, 0],
    "nrParameters": 2,
    "parameter1Values": currentWordParameterValues,
    "parameter2Values": prevTagParameterValues
  },
  "RBIGRAM": {
    "function": right_bigram_is,
    "window": [0, 1],
    "nrParameters": 2,
    "parameter1Values": currentWordParameterValues,
    "parameter2Values": nextWordParameterValues
  },
  "LBIGRAM": {
    "function": left_bigram_is,
    "window": [-1, 0],
    "nrParameters": 2,
    "parameter1Values": prevWordParameterValues,
    "parameter2Values": currentWordParameterValues
  },
  "NEXTBIGRAM": {
    "function": next_bigram_is,
    "window": [0, 2],
    "nrParameters": 2,
    "parameter1Values": nextWordParameterValues,
    "parameter2Values": twoWordAfterParameterValues
  },
  "PREVBIGRAM": {
    "function": prev_bigram_is,
    "window": [-2, 0],
    "nrParameters": 2,
    "parameter1Values": twoWordBeforeParameterValues,
    "parameter2Values": prevWordParameterValues
  },
  "PREV2TAG": {
    "function": prev_2_tag_is,
    "window": [-2, 0],
    "nrParameters": 2,
    "parameter1Values": twoTagBeforeParameterValues,
    "parameter2Values": prevTagParameterValues
  },
  "NEXT1OR2WD": {
    "function": next_1_or_2_word_is,
    "window": [0, 1],
    "nrParameters": 1,
    "parameter1Values": next1Or2WordParameterValues
  },
  "DEFAULT": {
    "function": default_predicate,
    "window": [0, 0],
    "nrParameters": 0
  }
};


// ==================================
// Predicates that start with words
// ==================================
function next_word_is_cap(sentence, i, parameter) {
  if (i < sentence.taggedWords.length - 1) {
    var next_word = sentence.taggedWords[i+1].token;
    return(next_word[0] === next_word[0].toUpperCase());
  }
  return(false);
}

function next_word_is(sentence, i, parameter) {
  if (i < sentence.taggedWords.length - 1) {
    return(sentence.taggedWords[i + 1].token === parameter);
  }
}

function nextWordParameterValues(sentence, i) {
  if (i < sentence.taggedWords.length - 1) {
    return [sentence.taggedWords[i + 1].token];
  }
  else {
    return [];
  }
}

function prev_word_is_cap(sentence, i, parameter) {
  var prev_word = null;
  if (i > 0) {
    prev_word = sentence.taggedWords[i-1].token;
    return(prev_word[0] === prev_word[0].toUpperCase());
  }
  return(false);
}

function current_word_is_cap(sentence, i, parameter) {
  var current_word = sentence.taggedWords[i].token;
  return(current_word[0] === current_word[0].toUpperCase());
}

function currentWordParameterValues(sentence, i) {
  return [sentence[i].token];
}

function current_word_is(sentence, i, parameter) {
  return(sentence.taggedWords[i].token === parameter);
}

function isNumeric(num) {
  return (!isNaN(num));
}

function current_word_is_number(sentence, i, parameter) {
  var is_number = isNumeric(sentence.taggedWords[i].token);
  // Attempt to parse it as a float
  if (!is_number) {
    is_number = parseFloat(sentence.taggedWords[i].token);
  }
  return((parameter === "YES") ? is_number : !is_number);
}

// Checks if the current word is a url
// Adapted from the original Javascript Brill tagger
function current_word_is_url(sentence, i, parameter) {
  var is_url = false;
  if (sentence.taggedWords[i].token.indexOf(".") > -1) {
    // url if there are two contiguous alpha characters
    if (/[a-zA-Z]{2}/.test(sentence.taggedWords[i].token)) {
      is_url = true;
    }
  }
  return((parameter === "YES") ? is_url : !is_url);
}

function current_word_and_2_tag_after_are(sentence, i, parameter1, parameter2) {
  if (i < sentence.taggedWords.length - 2) {
    if (sentence.taggedWords[i + 2][1] === parameter2) {
      return(sentence.taggedWords[i].token === parameter1);
    }
    else {
      return(false);
    }
  }
  else {
    return(false);
  }
}

function twoTagAfterParameterValues(sentence, i) {
  if (i < sentence.taggedWords.length - 2) {
    return [sentence.taggedWords[i + 2].tag];
  }
  else {
    return [];
  }
}

function current_word_and_next_tag_are(sentence, i, parameter1, parameter2) {
  var next_tag = false;
  // check current word
  var current_word = (sentence.taggedWords[i].token === parameter1);
  // check next tag
  if (i < sentence.taggedWords.length - 1) {
    next_tag = (sentence.taggedWords[i+1].tag === parameter2);
  }
  return(current_word && next_tag);
}

function current_word_and_prev_tag_are(sentence, i, parameter1, parameter2) {
  var prev_tag = false;
  // check current word
  var current_word = (sentence.taggedWords[i].token === parameter2);
  // check prev tag
  if (i > 0) {
    prev_tag = (sentence.taggedWords[i-1].tag === parameter1);
  }
  return(current_word && prev_tag);
}

function current_word_and_2_tag_before_are(sentence, i, parameter1, parameter2) {
  var two_tags_before = false;
  // check current word
  var current_word = (sentence.taggedWords[i].token === parameter2);
  if (i > 1) {
    // check two tags before
    two_tags_before = (sentence.taggedWords[i - 2].tag === parameter1);
  }
  return(current_word && two_tags_before);
}

function twoTagBeforeParameterValues(sentence, i) {
  if (i > 1) {
    return [sentence.taggedWords[i - 2].tag];
  }
  else {
    return [];
  }
}

function current_word_and_2_after_are(sentence, i, parameter1, parameter2) {
  var two_words_after = false;
  // check current word
  var current_word = (sentence.taggedWords[i].token === parameter1);
  if (i < sentence.taggedWords.length - 2) {
    two_words_after = (sentence.taggedWords[i+2].token === parameter2);
  }
  return(current_word && two_words_after);
}

function prev_word_is(sentence, i, parameter) {
  if (i > 0) {
    return(sentence.taggedWords[i - 1].token.toLowerCase() === parameter.toLowerCase());
  }
  else {
    return(false);
  }
}

// Returns the right value for parameter 1 of prev_word_is
function prevWordParameterValues(sentence, i) {
  if (i > 0) {
    return [sentence.taggedWords[i - 1].token];
  }
  else {
    return [];
  }
}

function prev_1_or_2_word_is(sentence, i, parameter) {
  var prev_1 = false;
  var prev_2 = false;
  if (i > 0) {
    prev_1 = (sentence.taggedWords[i-1].token.toLowerCase() === parameter.toLowerCase());
  }
  if (i > 1) {
    prev_2 = (sentence.taggedWords[i-2].token.toLowerCase() === parameter.toLowerCase());
  }
  return(prev_1 || prev_2);
}

function prev1Or2WordParameterValues(sentence, i) {
  var values = [];
  if (i > 0) {
    values.push(sentence[i - 1].token);
  }
  if (i > 1) {
    values.push(sentence[i - 2].token);
  }
  return values;
}

// Indicates whether or not this string ends with the specified string.
// Adapted from the original Javascript Brill tagger
function current_word_ends_with(sentence, i, parameter) {
  var word = sentence.taggedWords[i].token;
  if (!parameter || (parameter.length > word.length)) {
    return false;
  }
  return(word.indexOf(parameter) === (word.length - parameter.length));
}

// sentence is an array of token records
function currentWordEndsWithParameterValues(sentence, i) {
  var values = ["ing"];

  return values;
}

function right_bigram_is(sentence, i, parameter1, parameter2) {
  var word_1 = (sentence.taggedWords[i].token === parameter1);
  var word_2 = false;
  if (i < sentence.taggedWords.length - 1) {
    word_2 = (sentence.taggedWords[i+1].token === parameter2);
  }
  return(word_1 && word_2);
}

function left_bigram_is(sentence, i, parameter1, parameter2) {
  var word_1 = false;
  var word_2 = (sentence.taggedWords[i].token === parameter2);
  if (i > 0) {
    word_1 = (sentence.taggedWords[i-1].token === parameter1);
  }
  return(word_1 && word_2);
}

function next_bigram_is(sentence, i, parameter1, parameter2) {
  var word_1 = false;
  var word_2 = false;
  if (i < sentence.taggedWords.length - 1) {
    word_1 = (sentence.taggedWords[i + 1].token === parameter1);
  }
  if (i < sentence.taggedWords.length - 2) {
    word_2 = (sentence.taggedWords[i + 2].token === parameter2);
  }
  return(word_1 && word_2);
}

function twoWordAfterParameterValues(sentence, i) {
  if (i < sentence.taggedWords.length - 2) {
    return [sentence.taggedWords[i + 2].token];
  }
  else {
    return [];
  }
}

function prev_bigram_is(sentence, i, parameter1, parameter2) {
  var word_1 = false;
  var word_2 = false;
  if (i >  1) {
    word_1 = (sentence.taggedWords[i-2].token === parameter1);
  }
  if (i > 0) {
    word_2 = (sentence.taggedWords[i-1].token === parameter2);
  }
  return(word_1 && word_2);
}

function twoWordBeforeParameterValues(sentence, i) {
  if (i >  1) {
    return [sentence.taggedWords[i - 2].token];
  }
  else {
    return [];
  }
}

function next_1_or_2_word_is(sentence, i, parameter1, parameter2) {
  next_1 = false;
  next_2 = false;
  if (i < sentence.taggedWords.length - 1) {
    next_1 = (sentence.taggedWords[i+1].token === parameter1);
  }
  if (i < sentence.taggedWords.length - 2) {
    next_2 = (sentence.taggedWords[i+2].token === parameter2);
  }
  return(next_1 || next_2);
}

function next1Or2WordParameterValues(sentence, i) {
  var values = [];
  if (i < sentence.taggedWords.length - 1) {
    values.push(sentence.taggedWords[i + 1].token);
  }
  if (i < sentence.taggedWords.length - 2) {
    values.push(sentence.taggedWords[i + 2].token);
  }
  return values;
}

// ==================================
// Predicates about tags
// ==================================
function next_tag_is(sentence, i, parameter) {
  if (i < sentence.taggedWords.length - 1) {
    return(sentence.taggedWords[i + 1].tag === parameter);
  }
  else {
    return(false);
  }
}

function nextTagParameterValues(sentence, i) {
  if (i < sentence.taggedWords.length - 1) {
    return [sentence.taggedWords[i + 1].tag];
  }
  else {
    return [];
  }
}

function next_2_tag_is(sentence, i, parameter) {
  if (i < sentence.taggedWords.length - 2) {
    return(sentence.taggedWords[i+2].tag === parameter);
  }
  else {
    return(false);
  }
}

function next2TagParameterValues(sentence, i) {
  if (i < sentence.taggedWords.length - 2) {
    return [sentence.taggedWords[i+2].tag];
  }
  else {
    return [];
  }
}

function next_1_or_2_tag_is(sentence, i, parameter) {
  var next_1 = false;
  var next_2 = false;
  if (i < sentence.taggedWords.length - 1) {
    next_1 = (sentence.taggedWords[i+1].tag === parameter);
  }
  if (i < sentence.taggedWords.length - 2) {
    next_2 = (sentence.taggedWords[i+2].tag === parameter);
  }
  return(next_1 || next_2);
}

function next1Or2TagIsParameterValues(sentence, i) {
  var values = [];
  if (i < sentence.taggedWords.length - 1) {
    values.push(sentence.taggedWords[i + 1].tag);
  }
  if (i < sentence.taggedWords.length - 2) {
    values.push(sentence.taggedWords[i + 2].tag);
  }
  return values;
}

function next_1_or_2_or_3_tag(sentence, i, parameter) {
  var next_1 = false;
  var next_2 = false;
  var next_3 = false;
  if (i < sentence.taggedWords.length - 1) {
    next_1 = (sentence.taggedWords[i+1].tag === parameter);
  }
  if (i < sentence.taggedWords.length - 2) {
    next_2 = (sentence.taggedWords[i+2].tag === parameter);
  }
  if (i < sentence.taggedWords.length - 3) {
    next_3 = (sentence.taggedWords[i+3].tag === parameter);
  }
  return(next_1 || next_2 || next_3);
}

function next1Or2Or3TagParameterValues(sentence, i) {
  var values = [];
  if (i < sentence.taggedWords.length - 1) {
    values.push(sentence.taggedWords[i + 1].tag);
  }
  if (i < sentence.taggedWords.length - 2) {
    values.push(sentence.taggedWords[i + 2].tag);
  }
  if (i < sentence.taggedWords.length - 3) {
    values.push(sentence.taggedWords[i + 3].tag);
  }
  return values;
}

function surrounded_by_tags(sentence, i, parameter1, parameter2) {
  if (i < sentence.taggedWords.length - 1) {
    // check next tag
    if (sentence.taggedWords[i+1].tag === parameter2) {
      // check previous tag
      if (i > 0) {
        return(sentence.taggedWords[i-1].tag === parameter1)
      }
      else {
        return(false);
      }
    }
    else {
      return(false);
    }
  }
  else {
    return(false);
  }
}

function prev_1_or_2_or_3_tag(sentence, i, parameter) {
  var prev_1 = null;
  if (i > 0) {
    prev_1 = sentence.taggedWords[i-1].tag;
  }
  var prev_2 = null;
  if (i > 1) {
    prev_2 = sentence.taggedWords[i-2].tag;
  }
  var prev_3 = null;
  if (i > 2) {
    prev_3 = sentence.taggedWords[i-3].tag;
  }
  return((prev_1 === parameter) || (prev_2 === parameter) || (prev_3 === parameter));
}

function prev1Or2Or3TagParameterValues(sentence, i) {
  var values = [];
  if (i > 0) {
    values.push(sentence.taggedWords[i - 1].tag);
  }
  if (i > 1) {
    values.push(sentence.taggedWords[i - 2].tag);
  }
  if (i > 2) {
    values.push(sentence.taggedWords[i - 3].tag);
  }
  return values;
}

function prev_1_or_2_tag(sentence, i, parameter) {
  var prev_1 = null;
  if (i > 0) {
    prev_1 = sentence.taggedWords[i - 1].tag;
  }
  var prev_2 = null;
  if (i > 1) {
    prev_2 = sentence.taggedWords[i - 2].tag;
  }
  return((prev_1 === parameter) || (prev_2 === parameter));
}

function prev1Or2TagParameterValues(sentence, i) {
  values = [];
  if (i > 0) {
    values.push(sentence.taggedWords[i - 1].tag);
  }
  if (i > 1) {
    values.push(sentence.taggedWords[i - 2].tag);
  }
  return values;
}

function prev_tag_is(sentence, i, parameter) {
  var prev = false;
  if (i > 0) {
    prev = (sentence.taggedWords[i-1].tag === parameter);
  }
  return(prev);
}

function prevTagParameterValues(sentence, i) {
  if (i > 0) {
    return [sentence.taggedWords[i - 1].tag];
  }
  else {
    return [];
  }
}

// Looks like a useless predicate because transformation already take the
// current tag into account
function current_word_is_tag(sentence, i, parameter) {
  return(sentence.taggedWords[i].tag === parameter);
}

function prev_2_tag_is(sentence, i, parameter) {
  var prev_2 = false;
  if (i > 1) {
    prev_2 = (sentence.taggedWords[i-2].tag === parameter);
  }
  return(prev_2);
}

function default_predicate(sentence, i, parameter) {
  return(false);
}

module.exports = ruleTemplates;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Sentence.js":
/*!*******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/Sentence.js ***!
  \*******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Sentence class that generates sample elements from sentences
  Copyright (C) 2018 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/


var Context = __webpack_require__(/*! ../../classifiers/maxent/Context */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Context.js");

function Sentence() {
  this.taggedWords = [];
}

Sentence.prototype.addTaggedWord = function(token, tag) {
  this.taggedWords.push({
    "token": token,
    "tag": tag
  });
};

Sentence.prototype.clone = function() {
  var s = new Sentence();
  this.taggedWords.forEach(function(wordObject) {
    s.addTaggedWord(wordObject.token, wordObject.tag);
  });
  return s;
};

module.exports = Sentence;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\TF_Parser.js":
/*!********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/TF_Parser.js ***!
  \********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

module.exports = (function() {
  /*
   * Generated by PEG.js 0.8.0.
   *
   * http://pegjs.majda.cz/
   */

  function peg$subclass(child, parent) {
    function ctor() { this.constructor = child; }
    ctor.prototype = parent.prototype;
    child.prototype = new ctor();
  }

  function SyntaxError(message, expected, found, offset, line, column) {
    this.message  = message;
    this.expected = expected;
    this.found    = found;
    this.offset   = offset;
    this.line     = line;
    this.column   = column;

    this.name     = "SyntaxError";
  }

  peg$subclass(SyntaxError, Error);

  function parse(input) {
    var options = arguments.length > 1 ? arguments[1] : {},

        peg$FAILED = {},

        peg$startRuleFunctions = { transformation_rules: peg$parsetransformation_rules },
        peg$startRuleFunction  = peg$parsetransformation_rules,

        peg$c0 = [],
        peg$c1 = peg$FAILED,
        peg$c2 = function(rules) {
          var result = {};

          for (var i = 0; i < rules.length; i++) {
            var rule = rules[i][1];
            result[rule.key()] = rule;
          }
          return(result);
        },
        peg$c3 = function(c1, c2, pred, pars) {
          var result = null;

          // Construct rule
          if (pars.length === 1) {
            result = new TransformationRule(c1, c2, pred, pars[0]);
          }
          else {
            if (pars.length === 2) {
              result = new TransformationRule(c1, c2, pred, pars[0], pars[1]);
            }
            else {
              result = new TransformationRule(c1, c2, pred);
            }
          }
          return(result);
        },
        peg$c4 = /^[!-~\xA1-\xFF]/,
        peg$c5 = { type: "class", value: "[!-~\\xA1-\\xFF]", description: "[!-~\\xA1-\\xFF]" },
        peg$c6 = function(characters) {
           var s = "";
           for (var i = 0; i < characters.length; i++) {
             s += characters[i];
           }
           return(s);
          },
        peg$c7 = "*",
        peg$c8 = { type: "literal", value: "*", description: "\"*\"" },
        peg$c9 = function(wc) {
           return(wc)
          },
        peg$c10 = "\r\n",
        peg$c11 = { type: "literal", value: "\r\n", description: "\"\\r\\n\"" },
        peg$c12 = "\n",
        peg$c13 = { type: "literal", value: "\n", description: "\"\\n\"" },
        peg$c14 = "\r",
        peg$c15 = { type: "literal", value: "\r", description: "\"\\r\"" },
        peg$c16 = "//",
        peg$c17 = { type: "literal", value: "//", description: "\"//\"" },
        peg$c18 = void 0,
        peg$c19 = { type: "any", description: "any character" },
        peg$c20 = " ",
        peg$c21 = { type: "literal", value: " ", description: "\" \"" },
        peg$c22 = "\t",
        peg$c23 = { type: "literal", value: "\t", description: "\"\\t\"" },

        peg$currPos          = 0,
        peg$reportedPos      = 0,
        peg$cachedPos        = 0,
        peg$cachedPosDetails = { line: 1, column: 1, seenCR: false },
        peg$maxFailPos       = 0,
        peg$maxFailExpected  = [],
        peg$silentFails      = 0,

        peg$result;

    if ("startRule" in options) {
      if (!(options.startRule in peg$startRuleFunctions)) {
        throw new Error("Can't start parsing from rule \"" + options.startRule + "\".");
      }

      peg$startRuleFunction = peg$startRuleFunctions[options.startRule];
    }

    function text() {
      return input.substring(peg$reportedPos, peg$currPos);
    }

    function offset() {
      return peg$reportedPos;
    }

    function line() {
      return peg$computePosDetails(peg$reportedPos).line;
    }

    function column() {
      return peg$computePosDetails(peg$reportedPos).column;
    }

    function expected(description) {
      throw peg$buildException(
        null,
        [{ type: "other", description: description }],
        peg$reportedPos
      );
    }

    function error(message) {
      throw peg$buildException(message, null, peg$reportedPos);
    }

    function peg$computePosDetails(pos) {
      function advance(details, startPos, endPos) {
        var p, ch;

        for (p = startPos; p < endPos; p++) {
          ch = input.charAt(p);
          if (ch === "\n") {
            if (!details.seenCR) { details.line++; }
            details.column = 1;
            details.seenCR = false;
          } else if (ch === "\r" || ch === "\u2028" || ch === "\u2029") {
            details.line++;
            details.column = 1;
            details.seenCR = true;
          } else {
            details.column++;
            details.seenCR = false;
          }
        }
      }

      if (peg$cachedPos !== pos) {
        if (peg$cachedPos > pos) {
          peg$cachedPos = 0;
          peg$cachedPosDetails = { line: 1, column: 1, seenCR: false };
        }
        advance(peg$cachedPosDetails, peg$cachedPos, pos);
        peg$cachedPos = pos;
      }

      return peg$cachedPosDetails;
    }

    function peg$fail(expected) {
      if (peg$currPos < peg$maxFailPos) { return; }

      if (peg$currPos > peg$maxFailPos) {
        peg$maxFailPos = peg$currPos;
        peg$maxFailExpected = [];
      }

      peg$maxFailExpected.push(expected);
    }

    function peg$buildException(message, expected, pos) {
      function cleanupExpected(expected) {
        var i = 1;

        expected.sort(function(a, b) {
          if (a.description < b.description) {
            return -1;
          } else if (a.description > b.description) {
            return 1;
          } else {
            return 0;
          }
        });

        while (i < expected.length) {
          if (expected[i - 1] === expected[i]) {
            expected.splice(i, 1);
          } else {
            i++;
          }
        }
      }

      function buildMessage(expected, found) {
        function stringEscape(s) {
          function hex(ch) { return ch.charCodeAt(0).toString(16).toUpperCase(); }

          return s
            .replace(/\\/g,   '\\\\')
            .replace(/"/g,    '\\"')
            .replace(/\x08/g, '\\b')
            .replace(/\t/g,   '\\t')
            .replace(/\n/g,   '\\n')
            .replace(/\f/g,   '\\f')
            .replace(/\r/g,   '\\r')
            .replace(/[\x00-\x07\x0B\x0E\x0F]/g, function(ch) { return '\\x0' + hex(ch); })
            .replace(/[\x10-\x1F\x80-\xFF]/g,    function(ch) { return '\\x'  + hex(ch); })
            .replace(/[\u0180-\u0FFF]/g,         function(ch) { return '\\u0' + hex(ch); })
            .replace(/[\u1080-\uFFFF]/g,         function(ch) { return '\\u'  + hex(ch); });
        }

        var expectedDescs = new Array(expected.length),
            expectedDesc, foundDesc, i;

        for (i = 0; i < expected.length; i++) {
          expectedDescs[i] = expected[i].description;
        }

        expectedDesc = expected.length > 1
          ? expectedDescs.slice(0, -1).join(", ")
              + " or "
              + expectedDescs[expected.length - 1]
          : expectedDescs[0];

        foundDesc = found ? "\"" + stringEscape(found) + "\"" : "end of input";

        return "Expected " + expectedDesc + " but " + foundDesc + " found.";
      }

      var posDetails = peg$computePosDetails(pos),
          found      = pos < input.length ? input.charAt(pos) : null;

      if (expected !== null) {
        cleanupExpected(expected);
      }

      return new SyntaxError(
        message !== null ? message : buildMessage(expected, found),
        expected,
        found,
        pos,
        posDetails.line,
        posDetails.column
      );
    }

    function peg$parsetransformation_rules() {
      var s0, s1, s2, s3, s4, s5;

      s0 = peg$currPos;
      s1 = [];
      s2 = peg$currPos;
      s3 = peg$parseS();
      if (s3 !== peg$FAILED) {
        s4 = peg$parsetransformation_rule();
        if (s4 !== peg$FAILED) {
          s5 = peg$parseS();
          if (s5 !== peg$FAILED) {
            s3 = [s3, s4, s5];
            s2 = s3;
          } else {
            peg$currPos = s2;
            s2 = peg$c1;
          }
        } else {
          peg$currPos = s2;
          s2 = peg$c1;
        }
      } else {
        peg$currPos = s2;
        s2 = peg$c1;
      }
      if (s2 !== peg$FAILED) {
        while (s2 !== peg$FAILED) {
          s1.push(s2);
          s2 = peg$currPos;
          s3 = peg$parseS();
          if (s3 !== peg$FAILED) {
            s4 = peg$parsetransformation_rule();
            if (s4 !== peg$FAILED) {
              s5 = peg$parseS();
              if (s5 !== peg$FAILED) {
                s3 = [s3, s4, s5];
                s2 = s3;
              } else {
                peg$currPos = s2;
                s2 = peg$c1;
              }
            } else {
              peg$currPos = s2;
              s2 = peg$c1;
            }
          } else {
            peg$currPos = s2;
            s2 = peg$c1;
          }
        }
      } else {
        s1 = peg$c1;
      }
      if (s1 !== peg$FAILED) {
        peg$reportedPos = s0;
        s1 = peg$c2(s1);
      }
      s0 = s1;

      return s0;
    }

    function peg$parsetransformation_rule() {
      var s0, s1, s2, s3, s4, s5;

      s0 = peg$currPos;
      s1 = peg$parsecategory1();
      if (s1 !== peg$FAILED) {
        s2 = peg$parseidentifier();
        if (s2 !== peg$FAILED) {
          s3 = peg$parseidentifier();
          if (s3 !== peg$FAILED) {
            s4 = [];
            s5 = peg$parseidentifier();
            while (s5 !== peg$FAILED) {
              s4.push(s5);
              s5 = peg$parseidentifier();
            }
            if (s4 !== peg$FAILED) {
              peg$reportedPos = s0;
              s1 = peg$c3(s1, s2, s3, s4);
              s0 = s1;
            } else {
              peg$currPos = s0;
              s0 = peg$c1;
            }
          } else {
            peg$currPos = s0;
            s0 = peg$c1;
          }
        } else {
          peg$currPos = s0;
          s0 = peg$c1;
        }
      } else {
        peg$currPos = s0;
        s0 = peg$c1;
      }

      return s0;
    }

    function peg$parsecategory1() {
      var s0;

      s0 = peg$parsewild_card();
      if (s0 === peg$FAILED) {
        s0 = peg$parseidentifier();
      }

      return s0;
    }

    function peg$parseidentifier() {
      var s0, s1, s2;

      s0 = peg$currPos;
      s1 = [];
      if (peg$c4.test(input.charAt(peg$currPos))) {
        s2 = input.charAt(peg$currPos);
        peg$currPos++;
      } else {
        s2 = peg$FAILED;
        if (peg$silentFails === 0) { peg$fail(peg$c5); }
      }
      if (s2 !== peg$FAILED) {
        while (s2 !== peg$FAILED) {
          s1.push(s2);
          if (peg$c4.test(input.charAt(peg$currPos))) {
            s2 = input.charAt(peg$currPos);
            peg$currPos++;
          } else {
            s2 = peg$FAILED;
            if (peg$silentFails === 0) { peg$fail(peg$c5); }
          }
        }
      } else {
        s1 = peg$c1;
      }
      if (s1 !== peg$FAILED) {
        s2 = peg$parseS_no_eol();
        if (s2 !== peg$FAILED) {
          peg$reportedPos = s0;
          s1 = peg$c6(s1);
          s0 = s1;
        } else {
          peg$currPos = s0;
          s0 = peg$c1;
        }
      } else {
        peg$currPos = s0;
        s0 = peg$c1;
      }

      return s0;
    }

    function peg$parsewild_card() {
      var s0, s1, s2;

      s0 = peg$currPos;
      if (input.charCodeAt(peg$currPos) === 42) {
        s1 = peg$c7;
        peg$currPos++;
      } else {
        s1 = peg$FAILED;
        if (peg$silentFails === 0) { peg$fail(peg$c8); }
      }
      if (s1 !== peg$FAILED) {
        s2 = peg$parseS_no_eol();
        if (s2 !== peg$FAILED) {
          peg$reportedPos = s0;
          s1 = peg$c9(s1);
          s0 = s1;
        } else {
          peg$currPos = s0;
          s0 = peg$c1;
        }
      } else {
        peg$currPos = s0;
        s0 = peg$c1;
      }

      return s0;
    }

    function peg$parseEOL() {
      var s0;

      if (input.substr(peg$currPos, 2) === peg$c10) {
        s0 = peg$c10;
        peg$currPos += 2;
      } else {
        s0 = peg$FAILED;
        if (peg$silentFails === 0) { peg$fail(peg$c11); }
      }
      if (s0 === peg$FAILED) {
        if (input.charCodeAt(peg$currPos) === 10) {
          s0 = peg$c12;
          peg$currPos++;
        } else {
          s0 = peg$FAILED;
          if (peg$silentFails === 0) { peg$fail(peg$c13); }
        }
        if (s0 === peg$FAILED) {
          if (input.charCodeAt(peg$currPos) === 13) {
            s0 = peg$c14;
            peg$currPos++;
          } else {
            s0 = peg$FAILED;
            if (peg$silentFails === 0) { peg$fail(peg$c15); }
          }
        }
      }

      return s0;
    }

    function peg$parseComment() {
      var s0, s1, s2, s3, s4, s5;

      s0 = peg$currPos;
      if (input.substr(peg$currPos, 2) === peg$c16) {
        s1 = peg$c16;
        peg$currPos += 2;
      } else {
        s1 = peg$FAILED;
        if (peg$silentFails === 0) { peg$fail(peg$c17); }
      }
      if (s1 !== peg$FAILED) {
        s2 = [];
        s3 = peg$currPos;
        s4 = peg$currPos;
        peg$silentFails++;
        s5 = peg$parseEOL();
        peg$silentFails--;
        if (s5 === peg$FAILED) {
          s4 = peg$c18;
        } else {
          peg$currPos = s4;
          s4 = peg$c1;
        }
        if (s4 !== peg$FAILED) {
          if (input.length > peg$currPos) {
            s5 = input.charAt(peg$currPos);
            peg$currPos++;
          } else {
            s5 = peg$FAILED;
            if (peg$silentFails === 0) { peg$fail(peg$c19); }
          }
          if (s5 !== peg$FAILED) {
            s4 = [s4, s5];
            s3 = s4;
          } else {
            peg$currPos = s3;
            s3 = peg$c1;
          }
        } else {
          peg$currPos = s3;
          s3 = peg$c1;
        }
        while (s3 !== peg$FAILED) {
          s2.push(s3);
          s3 = peg$currPos;
          s4 = peg$currPos;
          peg$silentFails++;
          s5 = peg$parseEOL();
          peg$silentFails--;
          if (s5 === peg$FAILED) {
            s4 = peg$c18;
          } else {
            peg$currPos = s4;
            s4 = peg$c1;
          }
          if (s4 !== peg$FAILED) {
            if (input.length > peg$currPos) {
              s5 = input.charAt(peg$currPos);
              peg$currPos++;
            } else {
              s5 = peg$FAILED;
              if (peg$silentFails === 0) { peg$fail(peg$c19); }
            }
            if (s5 !== peg$FAILED) {
              s4 = [s4, s5];
              s3 = s4;
            } else {
              peg$currPos = s3;
              s3 = peg$c1;
            }
          } else {
            peg$currPos = s3;
            s3 = peg$c1;
          }
        }
        if (s2 !== peg$FAILED) {
          s3 = peg$parseEOL();
          if (s3 === peg$FAILED) {
            s3 = peg$parseEOI();
          }
          if (s3 !== peg$FAILED) {
            s1 = [s1, s2, s3];
            s0 = s1;
          } else {
            peg$currPos = s0;
            s0 = peg$c1;
          }
        } else {
          peg$currPos = s0;
          s0 = peg$c1;
        }
      } else {
        peg$currPos = s0;
        s0 = peg$c1;
      }

      return s0;
    }

    function peg$parseS() {
      var s0, s1;

      s0 = [];
      if (input.charCodeAt(peg$currPos) === 32) {
        s1 = peg$c20;
        peg$currPos++;
      } else {
        s1 = peg$FAILED;
        if (peg$silentFails === 0) { peg$fail(peg$c21); }
      }
      if (s1 === peg$FAILED) {
        if (input.charCodeAt(peg$currPos) === 9) {
          s1 = peg$c22;
          peg$currPos++;
        } else {
          s1 = peg$FAILED;
          if (peg$silentFails === 0) { peg$fail(peg$c23); }
        }
        if (s1 === peg$FAILED) {
          s1 = peg$parseEOL();
          if (s1 === peg$FAILED) {
            s1 = peg$parseComment();
          }
        }
      }
      while (s1 !== peg$FAILED) {
        s0.push(s1);
        if (input.charCodeAt(peg$currPos) === 32) {
          s1 = peg$c20;
          peg$currPos++;
        } else {
          s1 = peg$FAILED;
          if (peg$silentFails === 0) { peg$fail(peg$c21); }
        }
        if (s1 === peg$FAILED) {
          if (input.charCodeAt(peg$currPos) === 9) {
            s1 = peg$c22;
            peg$currPos++;
          } else {
            s1 = peg$FAILED;
            if (peg$silentFails === 0) { peg$fail(peg$c23); }
          }
          if (s1 === peg$FAILED) {
            s1 = peg$parseEOL();
            if (s1 === peg$FAILED) {
              s1 = peg$parseComment();
            }
          }
        }
      }

      return s0;
    }

    function peg$parseS_no_eol() {
      var s0, s1;

      s0 = [];
      if (input.charCodeAt(peg$currPos) === 32) {
        s1 = peg$c20;
        peg$currPos++;
      } else {
        s1 = peg$FAILED;
        if (peg$silentFails === 0) { peg$fail(peg$c21); }
      }
      if (s1 === peg$FAILED) {
        if (input.charCodeAt(peg$currPos) === 9) {
          s1 = peg$c22;
          peg$currPos++;
        } else {
          s1 = peg$FAILED;
          if (peg$silentFails === 0) { peg$fail(peg$c23); }
        }
        if (s1 === peg$FAILED) {
          s1 = peg$parseComment();
        }
      }
      while (s1 !== peg$FAILED) {
        s0.push(s1);
        if (input.charCodeAt(peg$currPos) === 32) {
          s1 = peg$c20;
          peg$currPos++;
        } else {
          s1 = peg$FAILED;
          if (peg$silentFails === 0) { peg$fail(peg$c21); }
        }
        if (s1 === peg$FAILED) {
          if (input.charCodeAt(peg$currPos) === 9) {
            s1 = peg$c22;
            peg$currPos++;
          } else {
            s1 = peg$FAILED;
            if (peg$silentFails === 0) { peg$fail(peg$c23); }
          }
          if (s1 === peg$FAILED) {
            s1 = peg$parseComment();
          }
        }
      }

      return s0;
    }

    function peg$parseEOI() {
      var s0, s1;

      s0 = peg$currPos;
      peg$silentFails++;
      if (input.length > peg$currPos) {
        s1 = input.charAt(peg$currPos);
        peg$currPos++;
      } else {
        s1 = peg$FAILED;
        if (peg$silentFails === 0) { peg$fail(peg$c19); }
      }
      peg$silentFails--;
      if (s1 === peg$FAILED) {
        s0 = peg$c18;
      } else {
        peg$currPos = s0;
        s0 = peg$c1;
      }

      return s0;
    }


      var TransformationRule = __webpack_require__(/*! ./TransformationRule */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\TransformationRule.js");


    peg$result = peg$startRuleFunction();

    if (peg$result !== peg$FAILED && peg$currPos === input.length) {
      return peg$result;
    } else {
      if (peg$result !== peg$FAILED && peg$currPos < input.length) {
        peg$fail({ type: "end", description: "end of input" });
      }

      throw peg$buildException(null, peg$maxFailExpected, peg$maxFailPos);
    }
  }

  return {
    SyntaxError: SyntaxError,
    parse:       parse
  };
})();


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\TransformationRule.js":
/*!*****************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/brill_pos_tagger/lib/TransformationRule.js ***!
  \*****************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Transformation rules for the Brill tagger
  Copyright (C) 2017 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

//var log4js = require('log4js');
//var logger = log4js.getLogger();

var Predicate = __webpack_require__(/*! ./Predicate */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Predicate.js");
var Sentence = __webpack_require__(/*! ./Sentence */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Sentence.js");

//logger.setLevel('INFO');

var category_wild_card = "*";

function TransformationRule(c1, c2, predicate, parameter1, parameter2) {
  this.literal = [c1, c2, predicate, parameter1, parameter2];
  this.predicate = new Predicate(predicate, parameter1, parameter2);
  this.old_category = c1;
  this.new_category = c2;
  // These members are for the learning algorithm
  this.neutral = 0;
  this.negative = 0;
  this.positive = 0;
  this.hasBeenSelectedAsHighRuleBefore = false;
  //logger.debug('TransformationRule constructor: ' + this.literal);
}

TransformationRule.prototype.key = function() {
  return(this.literal.toString());
};

TransformationRule.prototype.apply = function(sentence, position) {
  if ((sentence.taggedWords[position].tag === this.old_category) ||
      (this.old_category === category_wild_card)) {
    if (this.predicate.evaluate(sentence, position)) {
      sentence.taggedWords[position].tag = this.new_category;
      //logger.debug('TransformationRule.apply: changed category ' +
        //this.old_category + ' to ' + this.new_category +
        //' at position ' + position);
    }
  }
};

//
// Methods for processing sentences from a corpus that consist of an array of tokens
//

// Returns true if the rule applies at site. As a side effect it assigns the new
// category to newTag
TransformationRule.prototype.isApplicableAt = function(sentence, taggedSentence, i) {
  //logger.debug("TransformationRule.prototype.isApplicableAt: " + taggedSentence);
  var applies = (taggedSentence.taggedWords[i].tag === this.old_category) &&
    this.predicate.evaluate(taggedSentence, i);
  //logger.debug("TransformationRule.prototype.isApplicableAt: " + applies);

  // Set newTag to let the trainer know what the new tag would become
  if (applies) {
    sentence.taggedWords[i].newTag = this.new_category;
  }
  return(applies);
};

TransformationRule.prototype.prettyPrint = function() {
  var result = "";
  // Old category and new category
  result += this.old_category + " " + this.new_category;
  // Predicate name
  result += " " + this.predicate.name;
  // Parameter 1 and 2
  if (this.predicate.parameter1) {
    result += " " + this.predicate.parameter1;
    if (this.predicate.parameter2) {
      result += " " + this.predicate.parameter2;
    }
  }
  return result;
};


// Applies the rule the given location (if it applies)
TransformationRule.prototype.applyAt = function(sentence, i) {
  var taggedSentence = sentence.clone();

  //logger.debug("TransformationRule.prototype.applyAt: input sentence length: " + sentence.length);
  //logger.debug("TransformationRule.prototype.applyAt: tagged sentence length: " + taggedSentence.length);

  this.apply(sentence, i);
  // Assign the new tag to the corpus site
  sentence.taggedWords[i].testTag = taggedSentence.taggedWords[i].tag;
};

// Calculate the net score of this rule
TransformationRule.prototype.score = function() {
  return (this.positive - this.negative);
};

module.exports = TransformationRule;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\bayes_classifier.js":
/*!******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/bayes_classifier.js ***!
  \******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    Classifier = __webpack_require__(/*! ./classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\classifier.js"),
    ApparatusBayesClassifier = __webpack_require__(/*! apparatus */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\index.js").BayesClassifier;

var BayesClassifier = function(stemmer, smoothing) {
    var abc = new ApparatusBayesClassifier();
    if (smoothing && isFinite(smoothing)) {
        abc = new ApparatusBayesClassifier(smoothing);
    }
    Classifier.call(this, abc, stemmer);
};

util.inherits(BayesClassifier, Classifier);

function restore(classifier, stemmer) {
    classifier = Classifier.restore(classifier, stemmer);
    classifier.__proto__ = BayesClassifier.prototype;
    classifier.classifier = ApparatusBayesClassifier.restore(classifier.classifier);

    return classifier;
}

function load(filename, stemmer, callback) {
    Classifier.load(filename, function(err, classifier) {
        if (err) {
            return callback(err);
        }
        else {
            callback(err, restore(classifier, stemmer));
        }
    });
}

BayesClassifier.restore = restore;
BayesClassifier.load = load;

module.exports = BayesClassifier;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\classifier.js":
/*!************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/classifier.js ***!
  \************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var PorterStemmer = __webpack_require__(/*! ../stemmers/porter_stemmer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer.js"),
util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
events = __webpack_require__(/*! events */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\events\\events.js"),
os = __webpack_require__(/*! os */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\os-browserify\\browser.js");

try {
    var Threads = __webpack_require__(/*! webworker-threads */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webworker-threads\\index.js");
} catch (e) {
    // Since webworker-threads are optional, only thow if the module is found
    if (e.code !== 'MODULE_NOT_FOUND') throw e;
}

function checkThreadSupport() {
    if (typeof Threads === 'undefined') {
        throw new Error('parallel classification requires the optional dependency webworker-threads');
    }
}

var Classifier = function(classifier, stemmer) {
    this.classifier = classifier;
    this.docs = [];
    this.features = {};
    this.stemmer = stemmer || PorterStemmer;
    this.lastAdded = 0;
    this.events = new events.EventEmitter();
};

function addDocument(text, classification) {

    // Ignore further processing if classification is undefined
    if(typeof classification === 'undefined') return;

    // If classification is type of string then make sure it's dosen't have blank space at both end
    if(typeof classification === 'string'){
      classification = classification.trim();
    }

    if(typeof text === 'string')
	text = this.stemmer.tokenizeAndStem(text, this.keepStops);

    if(text.length === 0) {
        // ignore empty documents
        return;
    }

    this.docs.push({
	label: classification,
	text: text
    });

    for (var i = 0; i < text.length; i++) {
        var token = text[i];
        this.features[token] = (this.features[token] || 0) + 1;
    }
}

function removeDocument(text, classification) {
  var docs = this.docs
    , doc
    , pos;

  if (typeof text === 'string') {
    text = this.stemmer.tokenizeAndStem(text, this.keepStops);
  }

  for (var i = 0, ii = docs.length; i < ii; i++) {
    doc = docs[i];
    if (doc.text.join(' ') == text.join(' ') &&
        doc.label == classification) {
      pos = i;
    }
  }

  // Remove if there's a match
  if (!isNaN(pos)) {
    this.docs.splice(pos, 1);

    for (var i = 0, ii = text.length; i < ii; i++) {
      delete this.features[text[i]];
    }
  }
}

function textToFeatures(observation) {
    var features = [];

    if(typeof observation === 'string')
	observation = this.stemmer.tokenizeAndStem(observation, this.keepStops);

    for(var feature in this.features) {
        if(observation.indexOf(feature) > -1)
            features.push(1);
        else
            features.push(0);
    }

    return features;
}

function docsToFeatures(docs) {
    var parsedDocs = [];

    for (var i = 0; i < docs.length; i++) {
        var features = [];

        for (var feature in FEATURES) {
            if (docs[i].observation.indexOf(feature) > -1)
                features.push(1);
            else
                features.push(0);
        }

        parsedDocs.push({
            index: docs[i].index,
            features: features
        });
    }

    return JSON.stringify(parsedDocs);
}

function train() {
    var totalDocs = this.docs.length;
    for(var i = this.lastAdded; i < totalDocs; i++) {
        var features = this.textToFeatures(this.docs[i].text);
        this.classifier.addExample(features, this.docs[i].label);
        this.events.emit('trainedWithDocument', {index: i, total: totalDocs, doc: this.docs[i]});
        this.lastAdded++;
    }
    this.events.emit('doneTraining', true);
    this.classifier.train();
}

function trainParallel(numThreads, callback) {
    checkThreadSupport();

    if (!callback) {
        callback = numThreads;
        numThreads = undefined;
    }

    if (isNaN(numThreads)) {
        numThreads = os.cpus().length;
    }

    var totalDocs = this.docs.length;
    var threadPool = Threads.createPool(numThreads);
    var docFeatures = {};
    var finished = 0;
    var self = this;

    // Init pool; send the features array and the parsing function
    threadPool.all.eval('var FEATURES = ' + JSON.stringify(this.features));
    threadPool.all.eval(docsToFeatures);

    // Convert docs to observation objects
    var obsDocs = [];
    for (var i = this.lastAdded; i < totalDocs; i++) {
        var observation = this.docs[i].text;
        if (typeof observation === 'string')
            observation = this.stemmer.tokenizeAndStem(observation, this.keepStops);
        obsDocs.push({
            index: i,
            observation: observation
        });
    }

    // Called when a batch completes processing
    var onFeaturesResult = function(docs) {
        setTimeout(function() {
            self.events.emit('processedBatch', {
                size: docs.length,
                docs: totalDocs,
                batches: numThreads,
                index: finished
            });
        });

        for (var j = 0; j < docs.length; j++) {
            docFeatures[docs[j].index] = docs[j].features;
        }
    };

    // Called when all batches finish processing
    var onFinished = function(err) {
        if (err) {
            threadPool.destroy();
            return callback(err);
        }

        for (var j = self.lastAdded; j < totalDocs; j++) {
            self.classifier.addExample(docFeatures[j], self.docs[j].label);
            self.events.emit('trainedWithDocument', {
                index: j,
                total: totalDocs,
                doc: self.docs[j]
            });
            self.lastAdded++;
        }

        self.events.emit('doneTraining', true);
        self.classifier.train();

        threadPool.destroy();
        callback(null);
    };

    // Split the docs and start processing
    var batchSize = Math.ceil(obsDocs.length / numThreads);
    var lastError;

    for (var i = 0; i < numThreads; i++) {
        var batchDocs = obsDocs.slice(i * batchSize, (i+1) * batchSize);
        var batchJson = JSON.stringify(batchDocs);

        threadPool.any.eval('docsToFeatures(' + batchJson + ')', function(err, docs) {
            lastError = err || lastError;
            finished++;

            if (docs) {
                docs = JSON.parse(docs);
                onFeaturesResult(docs);
            }

            if (finished >= numThreads) {
                onFinished(lastError);
            }
        });
    }
}

function trainParallelBatches(options) {
    checkThreadSupport();

    var numThreads = options && options.numThreads;
    var batchSize = options && options.batchSize;

    if (isNaN(numThreads)) {
        numThreads = os.cpus().length;
    }

    if (isNaN(batchSize)) {
        batchSize = 2500;
    }

    var totalDocs = this.docs.length;
    var threadPool = Threads.createPool(numThreads);
    var docFeatures = {};
    var finished = 0;
    var self = this;

    var abort = false;
    var onError = function(err) {
        if (!err || abort) return;
        abort = true;
        threadPool.destroy(true);
        self.events.emit('doneTrainingError', err);
    };

    // Init pool; send the features array and the parsing function
    var str = JSON.stringify(this.features);
    threadPool.all.eval('var FEATURES = ' + str + ';', onError);
    threadPool.all.eval(docsToFeatures, onError);

    // Convert docs to observation objects
    var obsDocs = [];
    for (var i = this.lastAdded; i < totalDocs; i++) {
        var observation = this.docs[i].text;
        if (typeof observation === 'string')
            observation = this.stemmer.tokenizeAndStem(observation, this.keepStops);
        obsDocs.push({
            index: i,
            observation: observation
        });
    }

    // Split the docs in batches
    var obsBatches = [];
    var i = 0;
    while (true) {
        var batch = obsDocs.slice(i * batchSize, (i+1) * batchSize);
        if (!batch || !batch.length) break;
        obsBatches.push(batch);
        i++;
    }
    obsDocs = null;
    self.events.emit('startedTraining', {
        docs: totalDocs,
        batches: obsBatches.length
    });

    // Called when a batch completes processing
    var onFeaturesResult = function(docs) {
        self.events.emit('processedBatch', {
            size: docs.length,
            docs: totalDocs,
            batches: obsBatches.length,
            index: finished
        });

        for (var j = 0; j < docs.length; j++) {
            docFeatures[docs[j].index] = docs[j].features;
        }
    };

    // Called when all batches finish processing
    var onFinished = function() {
        threadPool.destroy(true);
        abort = true;

        for (var j = self.lastAdded; j < totalDocs; j++) {
            self.classifier.addExample(docFeatures[j], self.docs[j].label);
            self.events.emit('trainedWithDocument', {
                index: j,
                total: totalDocs,
                doc: self.docs[j]
            });
            self.lastAdded++;
        }

        self.events.emit('doneTraining', true);
        self.classifier.train();
    };

    // Called to send the next batch to be processed
    var batchIndex = 0;
    var sendNext = function() {
        if (abort) return;
        if (batchIndex >= obsBatches.length) {
            return;
        }

        sendBatch(JSON.stringify(obsBatches[batchIndex]));
        batchIndex++;
    };

    // Called to send a batch of docs to the threads
    var sendBatch = function(batchJson) {
        if (abort) return;
        threadPool.any.eval('docsToFeatures(' + batchJson + ');', function(err, docs) {
            if (err) {
                return onError(err);
            }

            finished++;

            if (docs) {
                docs = JSON.parse(docs);
                setTimeout(onFeaturesResult.bind(null, docs));
            }

            if (finished >= obsBatches.length) {
                setTimeout(onFinished);
            }

            setTimeout(sendNext);
        });
    };

    // Start processing
    for (var i = 0; i < numThreads; i++) {
        sendNext();
    }
}

function retrain() {
  this.classifier = new (this.classifier.constructor)();
  this.lastAdded = 0;
  this.train();
}

function retrainParallel(numThreads, callback) {
  this.classifier = new (this.classifier.constructor)();
  this.lastAdded = 0;
  this.trainParallel(numThreads, callback);
}

function getClassifications(observation) {
    return this.classifier.getClassifications(this.textToFeatures(observation));
}

function classify(observation) {
    return this.classifier.classify(this.textToFeatures(observation));
}

function restore(classifier, stemmer) {
    classifier.stemmer = stemmer || PorterStemmer;
    classifier.events = new events.EventEmitter();
    return classifier;
}

function save(filename, callback) {
    var data = JSON.stringify(this);
    var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");
    var classifier = this;
    fs.writeFile(filename, data, 'utf8', function(err) {
        if(callback) {
            callback(err, err ? null : classifier);
        }
    });
}

function load(filename, callback) {
    var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");

    fs.readFile(filename, 'utf8', function(err, data) {
        var classifier;

        if(!err) {
            classifier = JSON.parse(data);
        }

        if(callback)
            callback(err, classifier);
    });
}

function setOptions(options){
    this.keepStops = (options.keepStops) ? true : false;
}

Classifier.prototype.addDocument = addDocument;
Classifier.prototype.removeDocument = removeDocument;
Classifier.prototype.train = train;
if (Threads) {
  Classifier.prototype.trainParallel = trainParallel;
  Classifier.prototype.trainParallelBatches = trainParallelBatches;
  Classifier.prototype.retrainParallel = retrainParallel;
}
Classifier.prototype.retrain = retrain;
Classifier.prototype.classify = classify;
Classifier.prototype.textToFeatures = textToFeatures;
Classifier.prototype.save = save;
Classifier.prototype.getClassifications = getClassifications;
Classifier.prototype.setOptions = setOptions;
Classifier.restore = restore;
Classifier.load = load;

module.exports = Classifier;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\logistic_regression_classifier.js":
/*!********************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/logistic_regression_classifier.js ***!
  \********************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    Classifier = __webpack_require__(/*! ./classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\classifier.js"),
    ApparatusLogisticRegressionClassifier = __webpack_require__(/*! apparatus */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\apparatus\\lib\\apparatus\\index.js").LogisticRegressionClassifier;

var LogisticRegressionClassifier = function(stemmer) {
    Classifier.call(this, new ApparatusLogisticRegressionClassifier(), stemmer);
};

util.inherits(LogisticRegressionClassifier, Classifier);

function restore(classifier, stemmer) {
    classifier = Classifier.restore(classifier, stemmer);
    classifier.__proto__ = LogisticRegressionClassifier.prototype;
    classifier.classifier = ApparatusLogisticRegressionClassifier.restore(classifier.classifier);

    return classifier;
}

function load(filename, stemmer, callback) {
    Classifier.load(filename, function(err, classifier) {
        if (err) {
            callback(err);
        }
        else {
            callback(err, restore(classifier, stemmer));
        }
    });
}

function train() {
    // we need to reset the traning state because logistic regression
    // needs its matricies to have their widths synced, etc.
    this.lastAdded = 0;
    this.classifier = new ApparatusLogisticRegressionClassifier();
    Classifier.prototype.train.call(this);
}

LogisticRegressionClassifier.prototype.train = train;
LogisticRegressionClassifier.restore = restore;
LogisticRegressionClassifier.load = load;

module.exports = LogisticRegressionClassifier;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Classifier.js":
/*!*******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/Classifier.js ***!
  \*******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
    Classifier class that provides functionality for training and
    classification
    Copyright (C) 2017 Hugo W.L. ter Doest

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");

var Context = __webpack_require__(/*! ./Context */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Context.js");
var Element = __webpack_require__(/*! ./Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Element.js");
var Sample = __webpack_require__(/*! ./Sample */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Sample.js");
var Scaler = __webpack_require__(/*! ./GISScaler */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\GISScaler.js");
var FeatureSet = __webpack_require__(/*! ./FeatureSet */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\FeatureSet.js");

function Classifier(features, sample) {
  if (features) {
    this.features = features;
  }
  else {
    this.features = new featureSet();
  }
  this.features = features;
  if (sample) {
    this.sample = sample;
  }
  else {
    this.sample = new Sample();
  }
}

// Loads a classifier from file.
// Caveat: feature functions are generated from the sample elements. You need
// to create your own specialisation of the Element class that can generate
// your own specific feature functions
Classifier.prototype.load = function(filename, elementClass, callback) {
  fs.readFile(filename, 'utf8', function(err, data) {

    if(!err) {
        classifierData = JSON.parse(data);
        var sample = new Sample();
        classifierData.sample.elements.forEach(function(elementData) {
          var elt = new elementClass(elementData.a, new Context(elementData.b.data));
          sample.addElement(elt);
        });
        var featureSet = new FeatureSet();
        sample.generateFeatures(featureSet);
        var classifier = new Classifier(featureSet, sample);
        callback(err, classifier);
    }
    else {
      if(callback) {
        callback(err);
      }
    }
  });
};

Classifier.prototype.save = function(filename, callback) {
  var data = JSON.stringify(this, null, 2);
  var classifier = this;
  fs.writeFile(filename, data, 'utf8', function(err) {
      if(callback) {
          callback(err, err ? null : classifier);
      }
  });
};

Classifier.prototype.addElement = function(x) {
  this.sample.addElement(x);
};

Classifier.prototype.addDocument = function(context, classification, elementClass) {
  Classifier.prototype.addElement(new elementClass(classification, context));
};

Classifier.prototype.train = function(maxIterations, minImprovement, approxExpectation) {
  this.scaler = new Scaler(this.features, this.sample);
  this.p = this.scaler.run(maxIterations, minImprovement, approxExpectation);
};

Classifier.prototype.getClassifications = function(b) {
  var scores = [];
  var that = this;
  this.sample.getClasses().forEach(function(a) {
    var x = new Element(a, b);
    scores.push({
      "label": a,
      "value": that.p.calculateAPriori(x)
    });
  });
  return scores;
};

Classifier.prototype.classify = function(b) {
  var scores = this.getClassifications(b);
  // Sort the scores in an array
  scores.sort(function(a, b) {
    return b.value - a.value;
  });
  // Check if the classifier discriminates
  var min = scores[scores.length - 1].value;
  var max = scores[0].value;
  if (min === max) {
      return "";
  }
  else {
    // Return the highest scoring classes
    return scores[0].label;
  }
};

module.exports = Classifier;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Context.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/Context.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Context class
  Copyright (C) 2017 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var stringify = __webpack_require__(/*! json-stable-stringify */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\json-stable-stringify\\index.js");

function Context(data) {
  this.data = data;
}

// Create a predictable key string for looking up in a hash
Context.prototype.toString = function() {
  if (!this.key) {
    this.key = stringify(this.data);
  }
  return this.key;
};

module.exports = Context;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Distribution.js":
/*!*********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/Distribution.js ***!
  \*********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
    Distribution class for probability distributions
    Copyright (C) 2017 Hugo W.L. ter Doest

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var Element = __webpack_require__(/*! ./Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Element.js");

function Distribution(alpha, featureSet, sample) {
  this.alpha = alpha;
  this.featureSet = featureSet;
  this.sample = sample;
}

// Returns the distribution as a string that can be stored for later usage
Distribution.prototype.toString = function() {

}

Distribution.prototype.weight = function(x) {
  var product = 1;
  var that = this;

  this.alpha.forEach(function(alpha_j, j) {
    product *= Math.pow(alpha_j, that.featureSet.getFeatures()[j].apply(x));
  });
  return product;
};

Distribution.prototype.calculateAPriori = function(x) {
  if (!this.aPriorisBeforeNormalisation[x.toString()]) {
    this.aPriorisBeforeNormalisation[x.toString()] = this.weight(x);
  }
  return this.aPriorisBeforeNormalisation[x.toString()];// / this.aPrioriNormalisationConstant;
};

// Memoize a priori probabilities of sample elements
Distribution.prototype.prepareWeights = function() {
  this.aPriorisBeforeNormalisation = {};
  this.aPrioriNormalisationConstant = 0;
  var sum = 0;
  var that = this;
  this.sample.elements.forEach(function(x) {
    that.aPriorisBeforeNormalisation[x.toString()] = that.weight(x);
    sum += that.aPriorisBeforeNormalisation[x.toString()];
  });
  this.aPrioriNormalisationConstant = sum;
};

Distribution.prototype.calculateAPosteriori = function(x) {
  if (!this.aPriorisBeforeNormalisation[x.toString()]) {
    this.aPriorisBeforeNormalisation[x.toString()] = this.weight(x);
  }
  if (!this.aPosterioriNormalisationConstants[x.b.toString()]) {
    this.aPosterioriNormalisationConstants[x.b.toString()] = this.aPosterioriNormalisation(x.b);
  }
  return this.aPriorisBeforeNormalisation[x] / this.aPosterioriNormalisationConstants[x.b.toString()];
};

Distribution.prototype.aPosterioriNormalisation = function(b) {
  var sum = 0;

  var that = this;
  this.sample.getClasses().forEach(function(a) {
    sum += that.weight(new Element(a, b));
  });

  return(sum);
};

// Memoize a posteriori probabilities of sample elements
Distribution.prototype.prepareAPosterioris = function() {
  this.aPosterioriNormalisationConstants = {};

  var contextSeen = {};
  var that = this;
  this.sample.elements.forEach(function(sampleElement) {
    var context = sampleElement.b;
    if (!contextSeen[context]) {
      contextSeen[context] = true;
      that.aPosterioriNormalisationConstants[context] =
        that.aPosterioriNormalisation(context);
    }
  });
};

// Memoize all probabilities of sample elements
Distribution.prototype.prepare = function() {
  this.prepareWeights();
  //console.log("Weights prepared");
  this.prepareAPosterioris();
};

// Relative entropy between observered distribution and derived distribution
Distribution.prototype.KullbackLieblerDistance = function() {
  var sum = 0;
  var that = this;
  this.sample.elements.forEach(function(x) {
    sum += that.sample.observedProbability(x) * Math.log(that.sample.observedProbability(x) / that.calculateAPriori(x));
  });
  return sum;
};

Distribution.prototype.logLikelihood = function() {
  var sum = 0;
  var that = this;
  this.sample.elements.forEach(function(x) {
    sum += that.sample.observedProbability(x) * Math.log(that.calculateAPriori(x));
  });
  return sum;
};

Distribution.prototype.entropy = function() {
  var sum = 0;
  var that = this;
  this.sample.elements.forEach(function(x) {
    var p = that.calculateAPriori(x);
    sum += p * Math.log(p);
  });
  return sum;
};

Distribution.prototype.checkSum = function() {
  var sum = 0;
  var that = this;
  this.sample.elements.forEach(function(x) {
      sum += that.calculateAPriori(x);
  });
  //console.log("Distribution.checkSum is " + sum);
  return sum;
}

module.exports = Distribution;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Element.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/Element.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
    Element class for elements in the event space
    Copyright (C) 2017 Hugo W.L. ter Doest

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var Feature = __webpack_require__(/*! ./Feature */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Feature.js");

// a is class and b is context
function Element(a, b) {
  this.a = a;
  this.b = b;
}

Element.prototype.toString = function() {
  if (!this.key) {
    this.key =  this.a + this.b.toString();
  }
  return this.key;
};

module.exports = Element;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Feature.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/Feature.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
    Feature class for features that fire (or don't) on combinations of context
    and class
    Copyright (C) 2017 Hugo W.L. ter Doest

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/


function Feature(f, name, parameters) {
  this.evaluate = f;
  this.name = name;
  this.parameters = parameters;

  var tmp = "";
  parameters.forEach(function(par) {
    tmp += par + "|";
  });
  this.parametersKey = tmp.substr(0, tmp.length - 1);
}

Feature.prototype.apply = function(x) {
  return this.evaluate(x);
};

Feature.prototype.expectationApprox = function(p, sample) {
  var totalSum = 0;
  var that = this;
  var sum = 0;
  var seen = {};
  var A = sample.getClasses();
  sample.elements.forEach(function(sampleElement) {
    var b_i = sampleElement.b;

    if (!seen[b_i.toString()]) {
      seen[b_i.toString()] = true;
      var Element = __webpack_require__(/*! ./Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Element.js");

      A.forEach(function(a) {
        var x = new Element(a, b_i);
        sum += sample.observedProbabilityOfContext(b_i) * p.calculateAPosteriori(x) * that.apply(x);
      });
    }
  });
  return sum;
};

// Diect calculation of expected value of this feature according to distribution p
// In real-life applications with a lot of features this is not tractable
Feature.prototype.expectation = function(p, A, B) {
  var sum = 0;
  var that = this;
  A.forEach(function(a) {
    B.forEach(function(b) {
        var x = new Element(a, b);
        sum += (p.calculateAPriori(x) * that.apply(x));
    });
  });
  return sum;
};

// Observed expectation of this feature in the sample
Feature.prototype.observedExpectation = function(sample) {
  if (this.observedExpect) {
    return this.observedExpect;
  }
  var N = sample.size();
  var sum = 0;
  var that = this;
  sample.elements.forEach(function(x) {
    sum += that.apply(x);
  });
  this.observedExpect = sum / N;
  return this.observedExpect;
};

module.exports = Feature;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\FeatureSet.js":
/*!*******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/FeatureSet.js ***!
  \*******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
  Feature set class for administrating a set of unique feature
  Copyright (C) 2017 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/


function FeatureSet() {
  this.features = [];
  this.map = {};
}

// Returns true if the feature did not exist and was added
FeatureSet.prototype.addFeature = function(feature) {
  if (!this.featureExists(feature)) {
    this.map[feature.name +" | " + feature.parametersKey] = true;
    this.features.push(feature);
    //console.log("FeatureSet.addFeature: feature added: " + feature.name + " - " + feature.parametersKey);
    return true;
  }
  else {
    return false;
  }
};

FeatureSet.prototype.featureExists = function(feature) {
  if (this.map[feature.name +" | " + feature.parametersKey]) {
    //console.log("FeatureSet.featureExists: feature already exists: " +
    //  feature.name + " - " + feature.parameters);
    return true;
  }
  else {
    return false;
  }
};

// Returns an array of features
// If the available array this.features is up to date it is returned immediately
FeatureSet.prototype.getFeatures = function() {
  return this.features;
};

FeatureSet.prototype.size = function() {
  return this.features.length;
};

FeatureSet.prototype.prettyPrint = function() {
  var s = "";
  Object.keys(this.map).forEach(function(key) {
    s += key + "\n";
  });
  return s;
};

module.exports = FeatureSet;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\GISScaler.js":
/*!******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/GISScaler.js ***!
  \******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
    GISScaler class that finds parameters of features
    Copyright (C) 2017 Hugo W.L. ter Doest

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var Element = __webpack_require__(/*! ./Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Element.js");
var Feature = __webpack_require__(/*! ./Feature */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Feature.js");
var Distribution = __webpack_require__(/*! ./Distribution */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Distribution.js");

// classes is an array of classes
// features is an array of feature functions
function GISScaler(featureSet, sample) {
    this.featureSet = featureSet;
    this.sample = sample;
}

// Returns true if a correction feature is necessary
GISScaler.prototype.calculateMaxSumOfFeatures = function() {
  var that = this;
  this.C = 0;
  this.featureSums = {};
  var listOfSumValues = [];

  // Since feature functions are derived from the sample
  // we can use the sample to calculate the max sum
  // We look at each sample element only once
  this.sample.elements.forEach(function(x) {
    if (!that.featureSums[x.toString()]) {
      var sum = 0;
      that.featureSet.getFeatures().forEach(function(f) {
        sum += f.apply(x);
      });
      if (sum > that.C) {
        that.C = sum;
      }
      that.featureSums[x.toString()] = sum;
      listOfSumValues.push(sum);
    }
  });
  //console.log("GISScaler:calculateMaxSumOfFeatures:maxSum is " + this.C);

  // Check if a correction feature is necessary
  listOfSumValues.sort(function(a, b) {
    return a - b;
  });
  return(listOfSumValues[0] !== listOfSumValues[listOfSumValues.length - 1]);
};

GISScaler.prototype.addCorrectionFeature = function() {
  if (this.calculateMaxSumOfFeatures()) {
    //console.log("GISScaler:addCorrectionFeature:C is " + this.C);
    var that = this;

    function f(x) {
      if (that.featureSums[x.toString()] !== undefined) {
        return that.C - that.featureSums[x.toString()];
      }
      return 0;
    }

    var correctionFeature = new Feature(f, "Correction feature", []);
    //console.log("GISScaler:addCorrectionFeature:correctionFeature " + JSON.stringify(correctionFeature));
    this.featureSet.addFeature(correctionFeature);
  }
  else {
    //console.log("Correction feature not needed");
  }
};

// This is the Generalised Iterative Scaling algorithm
// It ends if the improvement in likelihood of the distribution does not
// improve more than minImprovement or if the maximum number of iterations is
// reached.
GISScaler.prototype.run = function(maxIterations, minImprovement) {
  this.iteration = 0;
  this.improvement = 0;

  this.addCorrectionFeature();
  // Build up the distribution p
  var alpha = new Array(this.featureSet.size());
  for (var i = 0; i < alpha.length; i++) {
    alpha[i] = 1;
  }
  var p = new Distribution(alpha, this.featureSet, this.sample);
  //console.log("Distribution created");
  p.prepare();
  //console.log("Distribution prepared");
  var likelihood = p.logLikelihood();
  var KLDistance = p.KullbackLieblerDistance();

  var newAlpha = new Array(this.featureSet.size());
  var observedExpectation = 0;
  var expectationApprox = 0;
  do {
    //console.log("Iteration " + this.iteration + " - Log likelihood of sample: " + likelihood + " - Entropy: " + p.entropy());
    for (var i = 0; i < this.featureSet.size(); i++) {
      observedExpectation = this.featureSet.getFeatures()[i].observedExpectation(this.sample);
      expectationApprox = this.featureSet.getFeatures()[i].expectationApprox(p, this.sample);
      //console.log("Iteration " + this.iteration + " - Feature " + i);
      newAlpha[i] = p.alpha[i] * Math.pow(observedExpectation / expectationApprox, 1 / this.C);

      //console.log("GISScaler.run: old alpha[" + i + "]: " + p.alpha[i]);
      //console.log("GISScaler.run: new alpha[" + i + "]: " + newAlpha[i]);
    }

    // Make the newly calculated parameters current parameters
    newAlpha.forEach(function(newAlpha_j, j) {
      p.alpha[j] = newAlpha_j;
    });
    // Recalculate a priori and a posteriori probabilities
    p.prepare();

    this.iteration++;
    var newLikelihood = p.logLikelihood();
    var newKLDistance = p.KullbackLieblerDistance();
    this.improvement = KLDistance - newKLDistance;
    //console.log("Iteration " + this.iteration + " - Old likelihood: " + likelihood + " - New likelihood: " + newLikelihood);
    //console.log("Iteration " + this.iteration + " - Old KL: " + KLDistance + " - New KL: " + newKLDistance);

    likelihood = newLikelihood;
    KLDistance = newKLDistance;
  } while ((this.iteration < maxIterations) && (this.improvement > minImprovement));
  //} while (iteration < maxIterations);
  /*
  var that = this;
  this.featureSet.getFeatures().forEach(function(f, j) {
    console.log("Observed expectation of feature " + j + ": " + f.observedExpectation(that.sample) +
      " - Expection of feature according to p: " + f.expectationApprox(p, that.sample));
  });
  */

  return p;
};

module.exports = GISScaler;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\POS\\ME_Corpus.js":
/*!**********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/POS/ME_Corpus.js ***!
  \**********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Corpus class specific for MaxEnt modeling
  Copyright (C) 2018 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");
var Sample = __webpack_require__(/*! ../Sample */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Sample.js");
var Corpus = __webpack_require__(/*! ../../../brill_pos_tagger/lib/Corpus */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Corpus.js");

function ME_Corpus(data, BROWN, SentenceClass) {
   ME_Corpus.super_.call(this, data, BROWN, SentenceClass);
}

util.inherits(ME_Corpus, Corpus);

ME_Corpus.prototype.generateSample = function() {
  var sample = new Sample([]);
  this.sentences.forEach(function(sentence) {
    sentence.generateSampleElements(sample);
  });
  return sample;
};

// Splits the corpus in a training and testing set.
// percentageTrain is the size of the training corpus in percent
// Returns an array with two elements: training corpus, testing corpus
ME_Corpus.prototype.splitInTrainAndTest = function(percentageTrain) {
  var corpusTrain = new ME_Corpus();
  var corpusTest = new ME_Corpus();

  var p = percentageTrain / 100;
  this.sentences.forEach(function(sentence, i) {
    if (Math.random() < p) {
      corpusTrain.sentences.push(sentence);
    }
    else {
      corpusTest.sentences.push(sentence);
    }
  });
  return [corpusTrain, corpusTest];
};

module.exports = ME_Corpus;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\POS\\ME_Sentence.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/POS/ME_Sentence.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Sentence class specific for MaxEnt modeling
  Copyright (C) 2018 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");
var Context = __webpack_require__(/*! ../Context */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Context.js");
var Sentence = __webpack_require__(/*! ../../../brill_pos_tagger/lib/Sentence */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Sentence.js");
var Element = __webpack_require__(/*! ./POS_Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\POS\\POS_Element.js");

function ME_Sentence() {
   ME_Sentence.super_.call(this);
}

util.inherits(ME_Sentence, Sentence);

ME_Sentence.prototype.generateSampleElements = function(sample) {
  var sentence = this.taggedWords;
  sentence.forEach(function(token, index) {
    var x = new Element(
      token.tag,
      new Context({
        wordWindow: {},
        tagWindow: {}
      })
    );

    // Current word and tag
    x.b.data.wordWindow["0"] = token.token;
    x.b.data.tagWindow["0"] = sentence[index].tag;

    // Previous bigram
    if (index > 1) {
      x.b.data.tagWindow["-2"] = sentence[index - 2].tag;
      x.b.data.wordWindow["-2"] = sentence[index - 2].token;
    }

    // Left bigram
    if (index > 0) {
      x.b.data.tagWindow["-1"] = sentence[index - 1].tag;
      x.b.data.wordWindow["-1"] = sentence[index - 1].token;
    }

    // Right bigram
    if (index < sentence.length - 1) {
      x.b.data.tagWindow["1"] = sentence[index + 1].tag;
      x.b.data.wordWindow["1"] = sentence[index + 1].token;
    }

    // Next bigram
    if (index < sentence.length - 2) {
      x.b.data.tagWindow["2"] = sentence[index + 2].tag;
      x.b.data.wordWindow["2"] = sentence[index + 2].token;
    }

    sample.addElement(x);
  });
};

module.exports = ME_Sentence;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\POS\\POS_Element.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/POS/POS_Element.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Element class for POS tagging
  Copyright (C) 2018 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/


var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");
var Element = __webpack_require__(/*! ../Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Element.js");
var Feature = __webpack_require__(/*! ../Feature */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Feature.js");

function POS_Element(a, b) {
   POS_Element.super_.call(this, a, b);
}

util.inherits(POS_Element, Element);

POS_Element.prototype.generateFeatures = function(featureSet) {
  var context = this.b.data;
  var tag = this.a;
  var token = context.wordWindow["0"];


  // Feature for the current word
  function currentWord(x) {
    if ((x.b.data.wordWindow["0"] === token) &&
        (x.a === tag)) {
        return 1;
    }
    return 0;
  }
  featureSet.addFeature(new Feature(currentWord, "wordFeature", ["0", token, "0", tag]));


  // Feature for previous bigram (previous two tags), positions -2, -1
  if (context.tagWindow["-2"]) {
    var prevPrevTag = context.tagWindow["-2"];
    var prevTag = context.tagWindow["-1"];
    function prevBigram(x) {
      if ((x.a === tag) &&
          (x.b.data.tagWindow["-2"] === prevPrevTag) &&
          (x.b.data.tagWindow["-1"] === prevTag)) {
          return 1;
        }
      return 0;
    }
    featureSet.addFeature(new Feature(prevBigram, "prevBigram", ["0", tag, "-2", prevPrevTag, "-1", prevTag]));
  }


/*
  // Feature for left bigram, positions -1, 0
  if (context.tagWindow["-1"]) {
    var prevTag = context.tagWindow["-1"];
    function leftBigram(x) {
      if ((x.b.data.tagWindow["-1"] === prevTag) &&
          (x.a === tag)) {
          return 1;
        }
      return 0;
    }
    featureSet.addFeature(new Feature(leftBigram, "leftBigram", ["0", tag, "-1", prevTag]));
  }
*/

/*

  // Feature for right bigram, positions 0, 1
  if (context.tagWindow["1"]) {
    var nextTag = context.tagWindow["1"];
    function rightBigram(x) {
      if ((x.a === tag) &&
          (x.b.data.tagWindow["1"] === nextTag)) {
          return 1;
        }
      return 0;
    }
    featureSet.addFeature(new Feature(rightBigram, "rightBigram", ["0", tag, "1", nextTag]));
  }
*/
/*
  // Feature for next bigram (next two tags), positions 1 and 2
  if (context.tagWindow["2"]) {
    var nextTag = context.tagWindow["1"];
    var nextNextTag = context.tagWindow["2"];
    function nextBigram(x) {
      if ((x.a === tag) &&
          (x.b.data.tagWindow["1"] === nextTag) &&
          (x.b.data.tagWindow["2"] === nextNextTag)) {
          return 1;
        }
      return 0;
    }
    featureSet.addFeature(new Feature(nextBigram, "nextBigram", ["0", tag, "1", nextTag, "2", nextNextTag]));
  }

  // Feature that looks at the left bigram words
  if (context.wordWindow["-1"]) {
    var prevWord = context.wordWindow["-1"];
    function leftBigramWords(x) {
      if ((x.a === tag) &&
          (x.b.data.wordWindow["0"] === token) &&
          (x.b.data.wordWindow["-1"] === prevWord)) {
          return 1;
        }
      return 0;
    }
    featureSet.addFeature(new Feature(leftBigramWords, "leftBigramWords", ["0", tag, "0", token, "-1", prevWord]));
  }

  // Feature that looks at the right bigram words
  if (context.wordWindow["1"]) {
    var nextWord = context.wordWindow["1"];
    function rightBigramWords(x) {
      if ((x.a === tag) &&
          (x.b.data.wordWindow["0"] === token) &&
          (x.b.data.wordWindow["1"] === nextWord)) {
          return 1;
        }
      return 0;
    }
    featureSet.addFeature(new Feature(rightBigramWords, "rightBigramWords", ["0", tag, "0", token, "1", nextWord]));
  }
*/

  // Feature that looks at the previous word and its category
  if (context.wordWindow["-1"]) {
    var prevWord = context.wordWindow["-1"];
    var prevTag = context.tagWindow["-1"];
    function prevWordAndCat(x) {
      if ((x.a === tag) &&
          (x.b.data.wordWindow["-1"] === prevWord) &&
          (x.b.data.tagWindow["-1"] === prevTag)) {
          return 1;
        }
      return 0;
    }
    featureSet.addFeature(new Feature(prevWordAndCat, "prevWordAndCat", ["0", tag, "-1", prevWord, "-1", prevTag]));
  }


/*
  // Feature that looks at the next word and its category
  if (context.wordWindow["1"]) {
    var nextWord = context.wordWindow["1"];
    var nextTag = context.tagWindow["1"];
    function nextWordAndCat(x) {
      if ((x.a === tag) &&
          (x.b.data.wordWindow["1"] === nextWord) &&
          (x.b.data.tagWindow["1"] === nextTag)) {
          return 1;
        }
      return 0;
    }
    featureSet.addFeature(new Feature(nextWordAndCat, "nextWordAndCat", ["0", tag, "1", nextWord, "1", nextTag]));
  }
*/
};

module.exports = POS_Element;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Sample.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/Sample.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
    Sample space of observed events
    Copyright (C) 2018 Hugo W.L. ter Doest

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var Context = __webpack_require__(/*! ./Context */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Context.js");

var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");

function Sample(elements) {
  this.frequencyOfContext = {};
  this.frequency = {};
  this.classes = [];
  if (elements) {
    this.elements = elements;
    this.analyse();
  }
  else {
    this.elements = [];
  }
}

// Extracts classes and frequencies
Sample.prototype.analyse = function() {
  var that = this;
  this.elements.forEach(function(x) {
    if (this.classes.indexOf(x.a) === -1) {
      this.classes.push(x.a);
    }
    if (!that.frequencyOfContext[x.b.toString()]) {
      that.frequencyOfContext[x.b.toString()] = 0;
    }
    that.frequencyOfContext[x.b.toString()]++;
    if (!that.frequency[x.toString()]) {
      that.frequency[x.toString()] = 0;
    }
    that.frequency[x.toString()]++;
  });
};

Sample.prototype.addElement = function(x) {
  this.elements.push(x);
  // Update frequencies
  if (!this.frequencyOfContext[x.b.toString()]) {
    this.frequencyOfContext[x.b.toString()] = 0;
  }
  this.frequencyOfContext[x.b.toString()]++;
  if (!this.frequency[x.toString()]) {
    this.frequency[x.toString()] = 0;
  }
  this.frequency[x.toString()]++;
  // Update classes
  if (this.classes.indexOf(x.a) === -1) {
    this.classes.push(x.a);
  }
};

Sample.prototype.observedProbabilityOfContext = function(context) {
  if (this.frequencyOfContext[context.toString()]) {
    return this.frequencyOfContext[context.toString()] / this.elements.length;
  }
  else {
    return 0;
  }
};

Sample.prototype.observedProbability = function(x) {
  if (this.frequency[x.toString()]) {
    return this.frequency[x.toString()] / this.elements.length;
  }
  else {
    return 0;
  }
};

Sample.prototype.size = function() {
  return this.elements.length;
};

Sample.prototype.getClasses = function() {
  return this.classes;
};

Sample.prototype.generateFeatures = function(featureSet) {
  this.elements.forEach(function(x) {
    x.generateFeatures(featureSet);
  });
};

Sample.prototype.save = function(filename, callback) {
  var sample = this;
  var data = JSON.stringify(this, null, 2);
  fs.writeFile(filename, data, 'utf8', function(err) {
      //console.log('Sample written')
      if(callback) {
          callback(err, err ? null : sample);
      }
  });
};

// Loads a sample from file and revives the right classes, i.e. Sample and
// Element classes.
Sample.prototype.load = function(filename, elementClass, callback) {
  fs.readFile(filename, 'utf8', function(err, data) {

    if(!err) {
        var sampleData = JSON.parse(data);
        var sample = new Sample();
        sampleData.elements.forEach(function(elementData) {
          var elt = new elementClass(elementData.a, new Context(elementData.b.data));
          sample.addElement(elt);
        });
        if (!sample.frequency || !sample.frequencyOfContext) {
          sample.analyse();
        }
        if (callback) {
          callback(err, sample);
        }
    }
    else {
      if (callback) {
        callback(err);
      }
    }
  });
};

module.exports = Sample;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\SimpleExample\\SE_Element.js":
/*!*********************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/classifiers/maxent/SimpleExample/SE_Element.js ***!
  \*********************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Simple Example Element class
  Copyright (C) 2018 Hugo W.L. ter Doest

  This program is free software: you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation, either version 3 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License
  along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var Element = __webpack_require__(/*! ../Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Element.js");
var Feature = __webpack_require__(/*! ../Feature */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Feature.js");

function SE_Element(a, b) {
   SE_Element.super_.call(this, a, b);
}

util.inherits(SE_Element, Element);

SE_Element.prototype.generateFeatures = function(featureSet) {

  function isZero(x) {
    if ((x.a === "x") && (x.b.data === "0")) {
      return 1;
    }
    return 0;
  }
  featureSet.addFeature(new Feature(isZero, "isZero", ["0"]));

  function isOne(x) {
    if ((x.a === "y") && (x.b.data === "1")) {
      return 1;
    }
    return 0;
  }
  featureSet.addFeature(new Feature(isOne, "isOne", ["1"]));
};

module.exports = SE_Element;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\dice_coefficient.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/distance/dice_coefficient.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, John Crepezzi, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// Get all of the pairs of letters for a string
var letterPairs = function (str) {
  var numPairs = str.length - 1;
  var pairs = new Array(numPairs);
  for (var i = 0; i < numPairs; i++) {
    pairs[i] = str.substring(i, i + 2);
  }
  return pairs;
};

// Get all of the pairs in all of the words for a string
var wordLetterPairs = function (str) {
  var allPairs = [], pairs;
  var words = str.split(/\s+/);
  for (var i = 0; i < words.length; i++) {
    pairs = letterPairs(words[i]);
    allPairs.push.apply(allPairs, pairs);
  }
  return allPairs;
};

// Perform some sanitization steps
var sanitize = function (str) {
  return str.toLowerCase().replace(/^\s+|\s+$/g, '');
};

// Compare two strings, and spit out a number from 0-1
var compare = function (str1, str2) {
  var sanitized_str1 = sanitize(str1);
  var sanitized_str2 = sanitize(str2);
  var pairs1 = wordLetterPairs(sanitized_str1);
  var pairs2 = wordLetterPairs(sanitized_str2);
  var intersection = 0, union = pairs1.length + pairs2.length;
  if (union === 0) {
      if (sanitized_str1 === sanitized_str2) {
          return 1;
      } else {
          return 0;
      }
  } else {
    var i, j, pair1, pair2;
    for (i = 0; i < pairs1.length; i++) {
      pair1 = pairs1[i];
      for (j = 0; j < pairs2.length; j++) {
        pair2 = pairs2[j];
        if (pair1 == pair2) {
          intersection ++;
          delete pairs2[j];
          break;
        }
      }
    }
    return 2 * intersection / union;
  }
};

module.exports = compare;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\hamming_distance.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/distance/hamming_distance.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
	Copyright (c) 2018, Shane Caldwell, Hugo ter Doest

	Permission is hereby granted, free of charge, to any person obtaining a copy
	of this software and associated documentation files (the "Software"), to deal
	in the Software without restriction, including without limitation the rights
	to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
	copies of the Software, and to permit persons to whom the Software is
	furnished to do so, subject to the following conditions:

	The above copyright notice and this permission notice shall be included in
	all copies or substantial portions of the Software.

	THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
	IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
	FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
	AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
	LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
	OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
	THE SOFTWARE.
*/

// Computes the Hamming distance between two string -- intrepreted from:
// https://en.wikipedia.org/wiki/Hamming_distance
// s1 is the first string to compare
// s2 is the second string to compare
// Strings should have equal length
function HammingDistance(s1, s2, ignoreCase) {
	// Return -1 if one of the parameters is not a string
	if (typeof(s1) != "string" || typeof(s2) != "string") {
		return -1;
	}
	// Return -1 the lengths of the strings differ
	if (s1.length != s2.length) {
		return -1;
	}

	if (ignoreCase) {
		s1 = s1.toLowerCase();
		s2 = s2.toLowerCase();
	}

  var diffs = 0;
  for (var i = 0; i < s1.length; i++) {
  	if (s1[i] != s2[i]) {
  		diffs++;
		}
  }
  return diffs;
}

module.exports = HammingDistance;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\jaro-winkler_distance.js":
/*!********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/distance/jaro-winkler_distance.js ***!
  \********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2012, Adam Phillabaum, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

Unless otherwise stated by a specific section of code

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// Computes the Jaro distance between two string -- intrepreted from:
// http://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance
// s1 is the first string to compare
// s2 is the second string to compare
function distance(s1, s2) {
    if (typeof(s1) !== "string" || typeof(s2) !== "string") {
        return 0;
    }

    if (s1.length === 0 || s2.length === 0) {
        return 0;
    }

    var matchWindow = (Math.floor(Math.max(s1.length, s2.length) / 2.0)) - 1;
    var matches1 = new Array(s1.length);
    var matches2 = new Array(s2.length);
    var m = 0; // number of matches
    var t = 0; // number of transpositions
    var i = 0; // index for string 1
    var k = 0; // index for string 2

    //debug helpers
    //console.log("s1: " + s1 + "; s2: " + s2);
    //console.log(" - matchWindow: " + matchWindow);

    for (i = 0; i < s1.length; i++) { // loop to find matched characters
        var start = Math.max(0, (i - matchWindow)); // use the higher of the window diff
        var end = Math.min((i + matchWindow + 1), s2.length); // use the min of the window and string 2 length

        for (k = start; k < end; k++) { // iterate second string index
            if (matches2[k]) { // if second string character already matched
                continue;
            }
            if (s1[i] !== s2[k]) { // characters don't match
                continue;
            }

            // assume match if the above 2 checks don't continue
            matches1[i] = true;
            matches2[k] = true;
            m++;
            break;
        }
    }

    // nothing matched
    if (m === 0) {
        return 0.0;
    }

    k = 0; // reset string 2 index
    for(i = 0; i < s1.length; i++) { // loop to find transpositions
        if (!matches1[i]) { // non-matching character
            continue;
        }
        while(!matches2[k]) { // move k index to the next match
            k++;
        }
        if (s1[i] !== s2[k]) { // if the characters don't match, increase transposition
          // HtD: t is always less than the number of matches m, because transpositions are a subset of matches
            t++;
        }
        k++; // iterate k index normally
    }

    // transpositions divided by 2
    t = t / 2.0;

    return ((m / s1.length) + (m / s2.length) + ((m - t) / m)) / 3.0; // HtD: therefore, m - t > 0, and m - t < m
    // HtD: => return value is between 0 and 1
}

// Computes the Winkler distance between two string -- intrepreted from:
// http://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance
// s1 is the first string to compare
// s2 is the second string to compare
// dj is the Jaro Distance (if you've already computed it), leave blank and the method handles it
// ignoreCase: if true strings are first converted to lower case before comparison
function JaroWinklerDistance(s1, s2, dj, ignoreCase) {
    if (s1 === s2) {
        return 1;
    } else {
        if (ignoreCase) {
          s1 = s1.toLowerCase();
          s2 = s2.toLowerCase();
        }

        //console.log(news1);
        //console.log(news2);

        var jaro = (typeof(dj) === 'undefined') ? distance(s1, s2) : dj;
        var p = 0.1; // default scaling factor
        var l = 0 // length of the matching prefix
        while(s1[l] === s2[l] && l < 4) {
            l++;
        }

        // HtD: 1 - jaro >= 0
        return jaro + l * p * (1 - jaro);
    }
}

module.exports = JaroWinklerDistance;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\levenshtein_distance.js":
/*!*******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/distance/levenshtein_distance.js ***!
  \*******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2012, Sid Nallu, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

/*
 * contribution by sidred123
 */

/*
 * Compute the Levenshtein distance between two strings.
 * Algorithm based from Speech and Language Processing - Daniel Jurafsky and James H. Martin.
 */

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js");

// Walk the path back from the matchEnd to the beginning of the match.
// Do this by traversing the distanceMatrix as you would a linked list,
// following going from cell child to parent until reach row 0.
function _getMatchStart(distanceMatrix, matchEnd, sourceLength) {
  var row = sourceLength;
  var column = matchEnd;
  var tmpRow;
  var tmpColumn;

  // match will be empty string
  if (matchEnd === 0) { return 0; }

  while(row > 1 && column > 1) {
   tmpRow = row;
   tmpColumn = column;
   row = distanceMatrix[tmpRow][tmpColumn].parentCell.row;
   column = distanceMatrix[tmpRow][tmpColumn].parentCell.column;
  }

  return column-1;
}

function getMinCostSubstring(distanceMatrix, source, target) {
  var sourceLength = source.length;
  var targetLength = target.length;
  var minDistance = sourceLength + targetLength;
  var matchEnd = targetLength;

  // Find minimum value in last row of the cost matrix. This cell marks the
  // end of the match string.
  for (var column = 0; column <= targetLength; column++) {
    if (minDistance > distanceMatrix[sourceLength][column].cost) {
      minDistance = distanceMatrix[sourceLength][column].cost;
      matchEnd = column;
    }
  }

  matchStart = _getMatchStart(distanceMatrix, matchEnd, sourceLength);
  return {substring: target.slice(matchStart, matchEnd), distance: minDistance};
}

/*
* Returns the Damerau-Levenshtein distance between strings. Counts the distance
* between two strings by returning the number of edit operations required to
* convert `source` into `target`.
*
* Valid edit operations are:
*  - transposition, insertion, deletion, and substitution
*
* Options:
*  insertion_cost: (default: 1)
*  deletion_cost: number (default: 1)
*  substitution_cost: number (default: 1)
*  transposition_cost: number (default: 1)
*  search: boolean (default: false)
*  restricted: boolean (default: false)
*/
function DamerauLevenshteinDistance(source, target, options) {
    var damLevOptions = _.extend(
        { transposition_cost: 1, restricted: false },
        options || {},
        { damerau: true }
    );
    return levenshteinDistance(source, target, damLevOptions);
}

function LevenshteinDistance(source, target, options) {
    var levOptions = _.extend({}, options || {}, { damerau: false });
    return levenshteinDistance(source, target, levOptions);
}


function levenshteinDistance (source, target, options) {
    if(isNaN(options.insertion_cost)) options.insertion_cost = 1;
    if(isNaN(options.deletion_cost)) options.deletion_cost = 1;
    if(isNaN(options.substitution_cost)) options.substitution_cost = 1;

    if(typeof options.search !== 'boolean') options.search = false;

    var isUnrestrictedDamerau = options.damerau && !options.restricted;
    var isRestrictedDamerau = options.damerau && options.restricted;

    if (isUnrestrictedDamerau) {
        var lastRowMap = {};
    }

    var sourceLength = source.length;
    var targetLength = target.length;
    var distanceMatrix = [[{cost: 0}]]; //the root, has no parent cell

    for (var row =  1; row <= sourceLength; row++) {
        distanceMatrix[row] = [];
        distanceMatrix[row][0] = {cost: distanceMatrix[row-1][0].cost + options.deletion_cost, parentCell: {row: row-1, column: 0}};
    }

    for (var column = 1; column <= targetLength; column++) {
        if (options.search) {
          distanceMatrix[0][column] = {cost: 0};
        } else {
          distanceMatrix[0][column] = {cost: distanceMatrix[0][column-1].cost + options.insertion_cost, parentCell: {row: 0, column: column-1}};
        }
    }

    for (var row = 1; row <= sourceLength; row++) {
        if (isUnrestrictedDamerau) {
            var lastColMatch = null;
        }
        for (var column = 1; column <= targetLength; column++) {
            var costToInsert = distanceMatrix[row][column-1].cost + options.insertion_cost;
            var costToDelete = distanceMatrix[row-1][column].cost + options.deletion_cost;

            var sourceElement = source[row-1];
            var targetElement = target[column-1];
            var costToSubstitute = distanceMatrix[row-1][column-1].cost;
            if (sourceElement !== targetElement) {
                costToSubstitute = costToSubstitute + options.substitution_cost;
            }

            var possibleParents = [
              {cost: costToInsert, coordinates: {row: row, column: column-1}},
              {cost: costToDelete, coordinates: {row: row-1, column: column}},
              {cost: costToSubstitute, coordinates: {row: row-1, column: column-1}}
            ];

            // We can add damerau to the possibleParents if the current
            // target-letter has been encountered in our lastRowMap,
            // and if there exists a previous column in this row where the
            // row & column letters matched
            var canDamerau = isUnrestrictedDamerau
                && row > 1 && column > 1
                && lastColMatch
                && targetElement in lastRowMap;

            if (canDamerau) {
                var lastRowMatch = lastRowMap[targetElement];
                var costBeforeTransposition =
                    distanceMatrix[lastRowMatch - 1][lastColMatch - 1].cost;
                var costToTranspose = costBeforeTransposition
                    + ((row - lastRowMatch - 1) * options.deletion_cost)
                    + ((column - lastColMatch - 1) * options.insertion_cost)
                    + options.transposition_cost;
                possibleParents.push({
                    cost: costToTranspose,
                    coordinates: {
                        row: lastRowMatch - 1,
                        column: lastColMatch - 1,
                    },
                });
            }
            // Source and target chars are 1-indexed in the distanceMatrix so previous
            // source/target element is (col/row - 2)
            var canDoRestrictedDamerau = isRestrictedDamerau
                && row > 1 && column > 1
                && sourceElement === target[column - 2]
                && source[row - 2] === targetElement;

            if (canDoRestrictedDamerau) {
                var costBeforeTransposition = distanceMatrix[row - 2][column - 2].cost;
                possibleParents.push({
                    cost: costBeforeTransposition + options.transposition_cost,
                    coordinates: { row: row - 2, column: column - 2 },
                });
            }

            var minCostParent = _.min(possibleParents, function(p) { return p.cost; });

            distanceMatrix[row][column] = {cost: minCostParent.cost, parentCell: minCostParent.coordinates};

            if (isUnrestrictedDamerau) {
                lastRowMap[sourceElement] = row;
                if (sourceElement === targetElement) {
                    lastColMatch = column;
                }
            }
        }
    }

    if (!options.search) {
        return distanceMatrix[sourceLength][targetLength].cost;
    }

    return getMinCostSubstring(distanceMatrix, source, target);
}

module.exports = {
    LevenshteinDistance: LevenshteinDistance,
    DamerauLevenshteinDistance: DamerauLevenshteinDistance,
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\index.js":
/*!*******************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/index.js ***!
  \*******************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

exports.SoundEx = __webpack_require__(/*! ./phonetics/soundex */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\soundex.js");
exports.Metaphone = __webpack_require__(/*! ./phonetics/metaphone */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\metaphone.js");
exports.DoubleMetaphone = __webpack_require__(/*! ./phonetics/double_metaphone */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\double_metaphone.js");
exports.SoundExDM = __webpack_require__(/*! ./phonetics/dm_soundex */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\dm_soundex.js");
exports.PorterStemmer = __webpack_require__(/*! ./stemmers/porter_stemmer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer.js");
exports.PorterStemmerFa = __webpack_require__(/*! ./stemmers/porter_stemmer_fa */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_fa.js");
exports.PorterStemmerFr = __webpack_require__(/*! ./stemmers/porter_stemmer_fr */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_fr.js");
exports.PorterStemmerRu = __webpack_require__(/*! ./stemmers/porter_stemmer_ru */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_ru.js");
exports.PorterStemmerEs = __webpack_require__(/*! ./stemmers/porter_stemmer_es */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_es.js");
exports.PorterStemmerIt = __webpack_require__(/*! ./stemmers/porter_stemmer_it */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_it.js");
exports.PorterStemmerNo = __webpack_require__(/*! ./stemmers/porter_stemmer_no */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_no.js");
exports.PorterStemmerSv = __webpack_require__(/*! ./stemmers/porter_stemmer_sv */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_sv.js");
exports.PorterStemmerPt = __webpack_require__(/*! ./stemmers/porter_stemmer_pt */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_pt.js");
exports.PorterStemmerNl = __webpack_require__(/*! ./stemmers/porter_stemmer_nl */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_nl.js");
exports.LancasterStemmer = __webpack_require__(/*! ./stemmers/lancaster_stemmer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\lancaster_stemmer.js");
// StemmerFr and StemmerPl are not stemmers. A Polish stemmer is
// not available, and for French PorterStemmerFr should be used.
//exports.StemmerFr = require('./stemmers/stemmer_fr');
//exports.StemmerPl = require('./stemmers/stemmer_pl');
exports.StemmerJa = __webpack_require__(/*! ./stemmers/stemmer_ja */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_ja.js");
exports.StemmerId = __webpack_require__(/*! ./stemmers/indonesian/stemmer_id */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\stemmer_id.js");
exports.AggressiveTokenizerNl = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_nl */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_nl.js");
exports.AggressiveTokenizerFa = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_fa */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_fa.js");
exports.AggressiveTokenizerFr = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_fr */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_fr.js");
exports.AggressiveTokenizerRu = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_ru */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_ru.js");
exports.AggressiveTokenizerEs = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_es */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_es.js");
exports.AggressiveTokenizerIt = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_it */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_it.js");
exports.AggressiveTokenizerPl = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_pl */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_pl.js");
exports.AggressiveTokenizerPt = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_pt */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_pt.js");
exports.AggressiveTokenizerNo = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_no */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_no.js");
exports.AggressiveTokenizerSv = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_sv */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_sv.js");
exports.AggressiveTokenizerVi = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer_vi */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_vi.js");
exports.AggressiveTokenizer = __webpack_require__(/*! ./tokenizers/aggressive_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer.js");
exports.CaseTokenizer = __webpack_require__(/*! ./tokenizers/tokenizer_case */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer_case.js");
exports.RegexpTokenizer = __webpack_require__(/*! ./tokenizers/regexp_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\regexp_tokenizer.js").RegexpTokenizer;
exports.OrthographyTokenizer = __webpack_require__(/*! ./tokenizers/regexp_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\regexp_tokenizer.js").OrthographyTokenizer;
exports.WordTokenizer = __webpack_require__(/*! ./tokenizers/regexp_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\regexp_tokenizer.js").WordTokenizer;
exports.WordPunctTokenizer = __webpack_require__(/*! ./tokenizers/regexp_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\regexp_tokenizer.js").WordPunctTokenizer;
exports.TreebankWordTokenizer = __webpack_require__(/*! ./tokenizers/treebank_word_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\treebank_word_tokenizer.js");
exports.TokenizerJa = __webpack_require__(/*! ./tokenizers/tokenizer_ja */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer_ja.js");
exports.SentenceTokenizer = __webpack_require__(/*! ./tokenizers/sentence_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\sentence_tokenizer.js");
exports.BayesClassifier = __webpack_require__(/*! ./classifiers/bayes_classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\bayes_classifier.js");
exports.LogisticRegressionClassifier = __webpack_require__(/*! ./classifiers/logistic_regression_classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\logistic_regression_classifier.js");
exports.NounInflector = __webpack_require__(/*! ./inflectors/noun_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\noun_inflector.js");
exports.NounInflectorFr = __webpack_require__(/*! ./inflectors/fr/noun_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\fr\\noun_inflector.js");
exports.NounInflectorJa = __webpack_require__(/*! ./inflectors/ja/noun_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\ja\\noun_inflector.js");
exports.PresentVerbInflector = __webpack_require__(/*! ./inflectors/present_verb_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\present_verb_inflector.js");
exports.CountInflector = __webpack_require__(/*! ./inflectors/count_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\count_inflector.js");
exports.WordNet = __webpack_require__(/*! ./wordnet/wordnet */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\wordnet.js");
exports.TfIdf = __webpack_require__(/*! ./tfidf/tfidf */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tfidf\\tfidf.js");
exports.Trie = __webpack_require__(/*! ./trie/trie */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\trie\\trie.js");
exports.SentenceAnalyzer = __webpack_require__(/*! ./analyzers/sentence_analyzer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\analyzers\\sentence_analyzer.js");
exports.stopwords = __webpack_require__(/*! ./util/stopwords */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords.js").words;
exports.ShortestPathTree = __webpack_require__(/*! ./util/shortest_path_tree */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\shortest_path_tree.js");
exports.Spellcheck = __webpack_require__(/*! ./spellcheck/spellcheck */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\spellcheck\\spellcheck.js");
exports.LongestPathTree = __webpack_require__(/*! ./util/longest_path_tree */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\longest_path_tree.js");
exports.EdgeWeightedDigraph = __webpack_require__(/*! ./util/edge_weighted_digraph */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\edge_weighted_digraph.js");
exports.NGrams = __webpack_require__(/*! ./ngrams/ngrams */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\ngrams\\ngrams.js");
exports.NGramsZH = __webpack_require__(/*! ./ngrams/ngrams_zh */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\ngrams\\ngrams_zh.js");
exports.JaroWinklerDistance = __webpack_require__(/*! ./distance/jaro-winkler_distance */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\jaro-winkler_distance.js");
exports.LevenshteinDistance = __webpack_require__(/*! ./distance/levenshtein_distance */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\levenshtein_distance.js").LevenshteinDistance;
exports.DamerauLevenshteinDistance = __webpack_require__(/*! ./distance/levenshtein_distance */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\levenshtein_distance.js").DamerauLevenshteinDistance;
exports.DiceCoefficient = __webpack_require__(/*! ./distance/dice_coefficient */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\dice_coefficient.js");
exports.HammingDistance = __webpack_require__(/*! ./distance/hamming_distance */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\distance\\hamming_distance.js");
exports.normalize = __webpack_require__(/*! ./normalizers/normalizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer.js").normalize_tokens;
exports.normalize_ja = __webpack_require__(/*! ./normalizers/normalizer_ja */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer_ja.js").normalize_ja;
exports.removeDiacritics = __webpack_require__(/*! ./normalizers/remove_diacritics */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\remove_diacritics.js");
exports.transliterate_ja = __webpack_require__(/*! ./transliterators/ja */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\transliterators\\ja\\index.js");
exports.BrillPOSTagger = __webpack_require__(/*! ./brill_pos_tagger/lib/Brill_POS_Tagger */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Brill_POS_Tagger.js");
exports.BrillPOSTrainer = __webpack_require__(/*! ./brill_pos_tagger/lib/Brill_POS_Trainer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Brill_POS_Trainer.js");
exports.BrillPOSTester = __webpack_require__(/*! ./brill_pos_tagger/lib/Brill_POS_Tester */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Brill_POS_Tester.js");
exports.Lexicon = __webpack_require__(/*! ./brill_pos_tagger/lib/Lexicon */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Lexicon.js");
exports.RuleSet = __webpack_require__(/*! ./brill_pos_tagger/lib/RuleSet */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\RuleSet.js");
exports.RuleTemplates = __webpack_require__(/*! ./brill_pos_tagger/lib/RuleTemplates */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\RuleTemplates.js");
exports.RuleTemplate = __webpack_require__(/*! ./brill_pos_tagger/lib/RuleTemplate */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\RuleTemplate.js");
exports.Corpus = __webpack_require__(/*! ./brill_pos_tagger/lib/Corpus */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Corpus.js");
exports.MaxEntClassifier = __webpack_require__(/*! ./classifiers/maxent/Classifier */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Classifier.js");
exports.Context = __webpack_require__(/*! ./classifiers/maxent/Context */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Context.js");
exports.Feature = __webpack_require__(/*! ./classifiers/maxent/Feature */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Feature.js");
exports.FeatureSet = __webpack_require__(/*! ./classifiers/maxent/FeatureSet */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\FeatureSet.js");
exports.Sample = __webpack_require__(/*! ./classifiers/maxent/Sample */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Sample.js");
exports.Element = __webpack_require__(/*! ./classifiers/maxent/Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\Element.js");
exports.SE_Element = __webpack_require__(/*! ./classifiers/maxent/SimpleExample/SE_Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\SimpleExample\\SE_Element.js");
exports.Sentence = __webpack_require__(/*! ./brill_pos_tagger/lib/Sentence */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\brill_pos_tagger\\lib\\Sentence.js");
exports.GISScaler = __webpack_require__(/*! ./classifiers/maxent/GISScaler */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\GISScaler.js");
exports.POS_Element = __webpack_require__(/*! ./classifiers/maxent/POS/POS_Element */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\POS\\POS_Element.js");
exports.ME_Sentence = __webpack_require__(/*! ./classifiers/maxent/POS/ME_Sentence */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\POS\\ME_Sentence.js");
exports.ME_Corpus = __webpack_require__(/*! ./classifiers/maxent/POS/ME_Corpus */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\classifiers\\maxent\\POS\\ME_Corpus.js");
exports.SentimentAnalyzer = __webpack_require__(/*! ./sentiment/SentimentAnalyzer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\sentiment\\SentimentAnalyzer.js");

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\count_inflector.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/inflectors/count_inflector.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

function nthForm(i) {
    var teenth = (i % 100);

    if(teenth > 10 && teenth < 14)
        return 'th';
    else {
        switch(i % 10) {
            case 1:
                return 'st';
                break;
            case 2:
                return 'nd';
                break;            
            case 3:
                return 'rd';
                break;
            default:
                return 'th';
        }
    }
}

function nth(i) {
    return i.toString() + nthForm(i);
}

var CountInflector = function() {
};

CountInflector.nth = nth;

module.exports = CountInflector;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\form_set.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/inflectors/form_set.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var FormSet = function() {
    this.regularForms = [];
    this.irregularForms = {};
}

module.exports = FormSet;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\fr\\noun_inflector.js":
/*!******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/inflectors/fr/noun_inflector.js ***!
  \******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
 Copyright (c) 2012, Guillaume Marty

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * A noun inflector for French.
 * Compiled from:
 * \@see http://fr.wiktionary.org/wiki/Annexe:Pluriels_irr%C3%A9guliers_en_fran%C3%A7ais
 * \@see http://fr.wikipedia.org/wiki/Pluriels_irr%C3%A9guliers_en_fran%C3%A7ais
 *
 * \@todo Take compounded noun into account (eaux-fortes, pique-nique...).
 * \@todo General note: French also requires AdjectiveInflector (femininize...).
 */

var SingularPluralInflector = __webpack_require__(/*! ../singular_plural_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\singular_plural_inflector.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    FormSet = __webpack_require__(/*! ../form_set */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\form_set.js");

function attach() {
  var inflector = this;

  String.prototype.singularizeNoun = function() {
    return inflector.singularize(this);
  };

  String.prototype.pluralizeNoun = function() {
    return inflector.pluralize(this);
  };
}



/**
 * @constructor
 */
var NounInflector = function() {
  // Ambiguous a.k.a. invariant.
  // \@todo Expand this list to be as comprehensive as possible.
  this.ambiguous = [
    // Nouns ending by -s
    'à-peu-près', 'à-propos', 'abattis', 'abcès', 'abois', 'abribus', 'abus',
    'accès', 'acquis', 'adénovirus', 'adonis', 'ados', 'agrès', 'aguets',
    'ailleurs', 'ais', 'albatros', 'albinos', 'alias', 'aloès', 'amaryllis',
    'amas', 'ampélopsis', 'ananas', 'anchois', 'angélus', 'anis', 'anticorps',
    'antihéros', 'antirides', 'anus', 'appas', 'appentis', 'appui-bras',
    'appuie-bras', 'arcanes', 'argus', 'arrérages', 'arrière-pays', 'as',
    'ascaris', 'asparagus', 'atlas', 'atours', 'aurochs', 'autobus',
    'autofocus', 'avant-bras', 'avant-corps', 'avant-propos', 'avers', 'avis',
    'axis', 'barbouillis', 'bas', 'beaujolais', 'beaux-arts', 'biais',
    'bibliobus', 'biceps', 'bicross', 'bien-fonds', 'bloc-notes', 'blockhaus',
    'blocus', 'blues', 'bois', 'bonus', 'bout-dehors', 'bouts-rimés',
    'branle-bas', 'bras', 'brebis', 'bris', 'brise-lames', 'brise-mottes',
    'brûlis', 'buis', 'burnous', 'bus', 'business', 'cabas', 'cacatoès',
    'cacatois', 'cactus', 'cadenas', 'cafouillis', 'caillebotis', 'calvados',
    'cambouis', 'campus', 'canevas', 'cannabis', 'carquois', 'cas',
    'casse-noisettes', 'casse-pieds', 'cassis', 'caucus', 'cens', 'cervelas',
    'chablis', 'chamois', 'chaos', 'chas', 'chasselas', 'châssis',
    'chatouillis', 'chauffe-assiettes', 'chauve-souris', 'chorus', 'choucas',
    'circoncis', 'cirrus', 'clafoutis', 'clapotis', 'cliquetis', 'clos',
    'cochylis', 'colis', 'coloris', 'commis', 'compas', 'compromis',
    'compte-chèques', 'compte-gouttes', 'compte-tours', 'concours', 'confins',
    'congrès', 'consensus', 'contrepoids', 'contresens', 'contretemps',
    'corn flakes', 'corps', 'corps-à-corps', 'corpus', 'cosinus', 'cosmos',
    'coulis', 'coupe-ongles', 'cours', 'court-jus', 'couscous', 'coutelas',
    'crocus', 'croquis', 'cross', 'cubitus', 'cumulus', 'cure-dents',
    'cure-ongles', 'cure-pipes', 'cursus', 'cyclo-cross', 'cyprès', 'dais',
    'damas', 'débarras', 'débours', 'débris', 'décès', 'dedans', 'dehors',
    'delirium tremens', 'demi-gros', 'dépens', 'dessous', 'dessus', 'détritus',
    'deux-mâts', 'deux-pièces', 'deux-points', 'deux-roues', 'deux-temps',
    'dévers', 'devis', 'diplodocus', 'discours', 'dos', 'ébats', 'éboulis',
    'échalas', 'edelweiss', 'élaeis', 'éleis', 'éléphantiasis', 'embarras',
    'empois', 'en-cas', 'encens', 'enclos', 'endos', 'engrais', 'entrelacs',
    'entremets', 'envers', 'épluche-légumes', 'ers', 'espace-temps',
    'essuie-mains', 'eucalyptus', 'ex-libris', 'excès', 'express', 'extrados',
    'faciès', 'fait-divers', 'fatras', 'faux-sens', 'favoris', 'ficus',
    'fier-à-bras', 'finnois', 'florès', 'focus', 'fœtus', 'fois', 'forceps',
    'fouillis', 'fracas', 'frais', 'français', 'franglais', 'frimas',
    'friselis', 'frisottis', 'froncis', 'frottis', 'fucus', 'gâchis', 'galetas',
    'galimatias', 'garde-à-vous', 'garde-corps', 'gargouillis', 'gars',
    'gâte-bois', 'gazouillis', 'génois', 'gibus', 'glacis', 'glas', 'gneiss',
    'gobe-mouches', 'grès', 'gribouillis', 'guet-apens', 'habeas corpus',
    'hachis', 'haras', 'hardes', 'harnais', 'haut-le-corps', 'hautbois',
    'herbe-aux-chats', 'héros', 'herpès', 'hiatus', 'hibiscus', 'hors-concours',
    'hors-pistes', 'hourdis', 'huis-clos', 'humérus', 'humus', 'ibis', 'iléus',
    'indique-fuites', 'infarctus', 'inlandsis', 'insuccès', 'intercours',
    'intrados', 'intrus', 'iris', 'isatis', 'jais', 'jars', 'jeans',
    'jeuconcours', 'judas', 'juliénas', 'jus', 'justaucorps', 'kakatoès',
    'kermès', 'kriss', 'lacis', 'laïus', 'lambris', 'lapis', 'laps', 'lapsus',
    'laquais', 'las', 'lattis', 'lave-mains', 'lavis', 'lèche-bottes',
    'lèche-vitrines', 'legs', 'lias', 'liégeois', 'lilas', 'lis', 'lœss',
    'logis', 'loris', 'lotus', 'louis', 'lupus', 'lys', 'mâchicoulis', 'madras',
    'maïs', 'malappris', 'malus', 'mânes', 'maquis', 'marais', 'maroilles',
    'marquis', 'mas', 'mass-médias', 'matelas', 'matois', 'médius', 'mépris',
    'mérinos', 'mess', 'mets', 'mi-bas', 'micro-ondes', 'mille-pattes',
    'millepertuis', 'minibus', 'minois', 'minus', 'mirabilis', 'mois',
    'monocorps', 'monte-plats', 'mors', 'motocross', 'mots-croisés', 'motus',
    'mouchetis', 'mucus', 'myosotis', 'nævus', 'négus', 'niais',
    'nimbo-stratus', 'nimbus', 'norois', 'nounours', 'nu-pieds', 'oasis',
    'obus', 'olibrius', 'omnibus', 'opus', 'os', 'ours', 'ouvre-boîtes',
    'ouvre-bouteilles', 'palais', 'palis', 'palmarès', 'palus', 'panais',
    'panaris', 'pancréas', 'papyrus', 'par-dehors', 'paradis', 'parcours',
    'pardessus', 'pare-balles', 'pare-chocs', 'parvis', 'pas', 'passe-temps',
    'pataquès', 'pathos', 'patois', 'pavois', 'pays', 'permis',
    'petit-bourgeois', 'petit-gris', 'petit-pois', 'phallus', 'phimosis',
    'pickles', 'pilotis', 'pique-fleurs', 'pis', 'pithiviers', 'pityriasis',
    'plateau-repas', 'plâtras', 'plein-temps', 'plexiglas', 'plexus', 'plus',
    'poids', 'pois', 'pont-levis', 'porte-avions', 'porte-bagages',
    'porte-billets', 'porte-bouteilles', 'porte-clés', 'porte-hélicoptères',
    'porte-jarretelles', 'porte-revues', 'pouls', 'préavis', 'presse-fruits',
    'presse-papiers', 'princeps', 'printemps', 'procès', 'processus', 'progrès',
    'propos', 'prospectus', 'protège-dents', 'psoriasis', 'pubis', 'puits',
    'pus', 'putois', 'quatre-épices', 'quatre-feuilles', 'quatre-heures',
    'quatre-mâts', 'quatre-quarts', 'quatre-temps', 'quitus', 'rabais',
    'rachis', 'radis', 'radius', 'raïs', 'ramassis', 'rébus', 'reclus',
    'recours', 'refus', 'relais', 'remords', 'remous', 'remue-méninges',
    'rendez-vous', 'repas', 'répons', 'repos', 'repris', 'reps', 'rétrovirus',
    'revers', 'rhinocéros', 'rictus', 'rince-doigts', 'ris', 'rollmops',
    'rosé-des-prés', 'roulis', 'rubis', 'salmigondis', 'salsifis', 'sans-logis',
    'sas', 'sassafras', 'sauternes', 'schnaps', 'schuss', 'secours', 'semis',
    'sens', 'serre-fils', 'serre-livres', 'sévices', 'sinus', 'skunks',
    'souris', 'sournois', 'sous-bois', 'stradivarius', 'stras', 'strass',
    'strato-cumulus', 'stratus', 'stress', 'succès', 'surdos', 'surplus',
    'surpoids', 'sursis', 'suspens', 'synopsis', 'syphilis', 'taffetas',
    'taillis', 'talus', 'tamaris', 'tamis', 'tapis', 'tas', 'taudis', 'temps',
    'tennis', 'terminus', 'terre-neuvas', 'tétanos', 'tétras', 'thalamus',
    'thermos', 'thesaurus', 'thésaurus', 'thymus', 'tire-fesses', 'tonus',
    'torchis', 'torticolis', 'tournedos', 'tournevis', 'tournis', 'tracas',
    'traîne-savates', 'travers', 'tréfonds', 'treillis', 'trépas', 'trias',
    'triceps', 'trichomonas', 'trois-étoiles', 'trois-mâts', 'trois-quarts',
    'trolleybus', 'tumulus', 'typhus', 'univers', 'us', 'utérus', 'vasistas',
    'vélocross', 'velours', 'verglas', 'verjus', 'vernis', 'vers',
    'vert-de-gris', 'vide-ordures', 'vide-poches', 'villageois', 'virus',
    'vis-à-vis', 'volubilis', 'vulgum pecus', 'waters', 'williams', 'xérès',

    // Nouns ending by -x
    'abat-voix', 'afflux', 'alpax', 'anthrax', 'apex', 'aptéryx',
    'archéoptéryx', 'arrière-faix', 'bombyx', 'borax', 'bordeaux', 'bouseux',
    'box', 'carex', 'casse-noix', 'cedex', 'céphalothorax', 'cérambyx', 'chaux',
    'choix', 'coccyx', 'codex', 'contumax', 'coqueleux', 'cortex', 'courroux',
    'croix', 'crucifix', 'culex', 'demodex', 'duplex', 'entre-deux', 'époux',
    'équivaux', 'eux', 'ex', 'faix', 'faucheux', 'faux', 'fax', 'ferreux',
    'flux', 'fox', 'freux', 'furax', 'hapax', 'harengueux', 'hélix',
    'horse-pox', 'houx', 'index', 'influx', 'inox', 'juke-box', 'kleenex',
    'lagothrix', 'larynx', 'lastex', 'latex', 'lux', 'lynx', 'macareux', 'max',
    'mésothorax', 'mi-voix', 'mirepoix', 'motteux', 'multiplex', 'murex',
    'narthex', 'noix', 'onyx', 'opopanax', 'oropharynx', 'paix', 'panax',
    'perdrix', 'pharynx', 'phénix', 'phlox', 'phoenix', 'pneumothorax', 'poix',
    'portefaix', 'pousse-cailloux', 'preux', 'prix', 'prothorax', 'pucheux',
    'pyrex', 'pyroligneux', 'quadruplex', 'queux', 'redoux', 'reflex', 'reflux',
    'relax', 'rhinopharynx', 'rose-croix', 'rouvieux', 'roux', 'rumex',
    'saindoux', 'sardonyx', 'scolex', 'sèche-cheveux', 'silex', 'simplex',
    'sioux', 'sirex', 'smilax', 'solex', 'songe-creux', 'spalax', 'sphex',
    'sphinx', 'storax', 'strix', 'styrax', 'surfaix', 'surtaux', 'syrinx',
    'tamarix', 'taux', 'télex', 'thorax', 'tord-boyaux', 'toux', 'trionyx',
    'tripoux', 'tubifex', 'vertex', 'vidéotex', 'vielleux', 'vieux',
    'violoneux', 'voix', 'volvox', 'vortex',

    // Nouns ending by -z
    'allume-gaz', 'assez', 'biogaz', 'cache-nez', 'camping-gaz', 'chez',
    'chintz', 'ersatz', 'fez', 'free-jazz', 'fritz', 'gaz', 'gin-fizz', 'hertz',
    'jazz', 'jerez', 'kibboutz', 'kilohertz', 'kolkhoz', 'kronprinz', 'lapiaz',
    'lez', 'mégahertz', 'merguez', 'nez', 'pince-nez', 'quartz', 'quiz', 'ranz',
    'raz', 'recez', 'rémiz', 'rez', 'riz', 'ruolz', 'seltz', 'serre-nez'
  ];

  this.customPluralForms = [];
  this.customSingularForms = [];
  this.singularForms = new FormSet();
  this.pluralForms = new FormSet();

  this.attach = attach;

  this.addIrregular('ail', 'aulx');
  this.addIrregular('bétail', 'bestiaux');
  this.addIrregular('bonhomme', 'bonshommes');
  this.addIrregular('ciel', 'cieux');
  this.addIrregular('monsieur', 'messieurs');
  this.addIrregular('mafioso', 'mafiosi');
  this.addIrregular('œil', 'yeux');
  this.addIrregular('putto', 'putti');
  this.addIrregular('targui', 'touareg'); // touareg -> touaregs is also OK.

  // Pluralize
  this.pluralForms.regularForms.push([/^(av|b|c|carnav|cérémoni|chac|corr|emment|emmenth|festiv|fut|gavi|gra|narv|p|récit|rég|rit|rorqu|st)al$/i, '$1als']);
  this.pluralForms.regularForms.push([/^(aspir|b|cor|ém|ferm|gemm|soupir|trav|vant|vent|vitr)ail$/i, '$1aux']);
  this.pluralForms.regularForms.push([/^(bij|caill|ch|gen|hib|jouj|p|rip|chouch)ou$/i, '$1oux']);
  this.pluralForms.regularForms.push([/^(gr|berimb|don|karb|land|pil|rest|sarr|un)au$/i, '$1aus']);
  this.pluralForms.regularForms.push([/^(bl|ém|enf|pn)eu$/i, '$1eus']);
  this.pluralForms.regularForms.push([/(au|eau|eu|œu)$/i, '$1x']);
  this.pluralForms.regularForms.push([/al$/i, 'aux']);
  this.pluralForms.regularForms.push([/(s|x)$/i, '$1']);
  this.pluralForms.regularForms.push([/(.*)$/i, '$1s']);

  // Singularize
  this.singularForms.regularForms.push([/^(aspir|b|cor|ém|ferm|gemm|soupir|trav|vant|vent|vitr)aux$/i, '$1ail']);
  this.singularForms.regularForms.push([/^(aloy|b|bouc|boy|burg|conoy|coy|cr|esquim|ét|fabli|flé|flûti|glu|gr|gru|hoy|joy|kérab|matéri|nobli|noy|pré|sen|sén|t|touch|tuss|tuy|v|ypré)aux$/i, '$1au']);
  this.singularForms.regularForms.push([/^(bij|caill|ch|gen|hib|jouj|p|rip|chouch)oux$/i, '$1ou']);
  this.singularForms.regularForms.push([/^(bis)?aïeux$/i, '$1aïeul']);
  this.singularForms.regularForms.push([/^apparaux$/i, 'appareil']); // One way transform, don't put on irregular list.
  this.singularForms.regularForms.push([/^ciels$/i, 'ciel']);
  this.singularForms.regularForms.push([/^œils$/i, 'œil']);
  this.singularForms.regularForms.push([/(eau|eu|œu)x$/i, '$1']);
  this.singularForms.regularForms.push([/aux$/i, 'al']);
  this.singularForms.regularForms.push([/(.*)s$/i, '$1']);

  this.pluralize = function(token) {
    return this.ize(token, this.pluralForms, this.customPluralForms);
  };

  this.singularize = function(token) {
    return this.ize(token, this.singularForms, this.customSingularForms);
  };
};

util.inherits(NounInflector, SingularPluralInflector);

module.exports = NounInflector;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\ja\\noun_inflector.js":
/*!******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/inflectors/ja/noun_inflector.js ***!
  \******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
 Copyright (c) 2012, Guillaume Marty

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * A noun inflector for Japanese.
 * Compiled from several sources including:
 * \@see http://answers.yahoo.com/question/index?qid=20080528201740AASBWy6
 * \@see http://www.excite.co.jp/dictionary/english_japanese/
 *
 * This script assumes input is normalized using normalizer_ja().
 * Pluralizing Japanese has a very limited interest.
 * Japanese don't usually distinct plural from singular, so even a word looking
 * like a singular might actually be a plural.
 *
 * Singularization of nouns ending by -tachi or -ra is achieved using a
 * comprehensive black list, while nouns ending by -domo or -gata use a white
 * list because there are too many exceptions.
 *
 * \@todo Singularize nouns ending by -ら, but there are too many exceptions.
 * \@todo Expand the list of common plurals ending by -domo and -gata.
 */

var SingularPluralInflector = __webpack_require__(/*! ../singular_plural_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\singular_plural_inflector.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    FormSet = __webpack_require__(/*! ../form_set */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\form_set.js");

function attach() {
  var inflector = this;

  String.prototype.singularizeNoun = function() {
    return inflector.singularize(this);
  };

  String.prototype.pluralizeNoun = function() {
    return inflector.pluralize(this);
  };
}



/**
 * @constructor
 */
var NounInflector = function() {
  // Ambiguous a.k.a. invariant.
  this.ambiguous = [
    'ともだち', '友だち', '友達', '遊び友達', '飲み友達', '酒飲み友達', '茶飲み友達',
    '学校友達', '女友達', '男友達', '幼友達'
  ];

  this.customPluralForms = [];
  this.customSingularForms = [];
  this.singularForms = new FormSet();
  this.pluralForms = new FormSet();

  this.attach = attach;

  this.addIrregular('神', '神神');
  this.addIrregular('人', '人人');
  this.addIrregular('年', '年年');
  this.addIrregular('月', '月月');
  this.addIrregular('日', '日日');
  this.addIrregular('星', '星星');
  this.addIrregular('島', '島島');
  this.addIrregular('我', '我我');
  this.addIrregular('山', '山山');
  this.addIrregular('国', '国国');
  this.addIrregular('所', '所所');
  this.addIrregular('隅', '隅隅');

  /**
   * Notes:
   * -たち exceptions: いたち, おいたち, ついたち, かたち, かおかたち, なりかたち, いでたち, はたち, からたち, なりたち
   * -達 exceptions: 伊達, 男伊達, 栄達, 上意下達, 熟達, 上達, 下意上達, 先達, 送達, 速達, 即日速達, 書留速達, 調達, 通達, 伝達, 到達, 配達, 牛乳配達, 新聞配達, 無料配達, 四通八達, 発達, 未発達, 御用達, 宮内庁御用達, 練達, 闊達
   * -等 exceptions: 一等, 下等, 何等, 均等, 勲等, 高等, 三等, 初等, 上等, 親等, 二親等, 数等, 対等, 中等, 同等, 特等, 二等, 品等, 不等, 平等, 悪平等, 男女平等, 不平等, 優等, 劣等
   */

  // Pluralize
  this.pluralForms.regularForms.push([/^(.+)$/i, '$1たち']);

  // Singularize
  this.singularForms.regularForms.push([/^(.+)たち$/i, function(a, mask) {
    if (['い', 'おい', 'つい', 'か', 'かおか', 'なりか', 'いで', 'は', 'から',
      'なり'].indexOf(mask) >= 0)
      return mask + 'たち';
    return mask;
  }]);
  this.singularForms.regularForms.push([/^(.+)達$/i, function(a, mask) {
    if (['伊', '伊', '栄', '上意下', '熟', '上', '下意上', '先', '送', '速',
      '即日速', '書留速', '調', '通', '伝', '到', '配', '牛乳配', '新聞配', '無料配',
      '四通八', '発', '未発', '御用', '宮内庁御用', '練', '闊'].indexOf(mask) >= 0)
      return mask + '達';
    return mask;
  }]);  // Singularize nouns ending by -等, but not exceptions.
  this.singularForms.regularForms.push([/^(.+)等$/i, function(a, mask) {
    if (['一', '下', '何', '均', '勲', '高', '三', '初', '親', '二親', '数', '対',
      '中', '同', '特', '二', '品', '不', '平', '悪平', '男女平', '不平', '優',
      '劣'].indexOf(mask) >= 0)
      return mask + '等';
    return mask;
  }]);
  this.singularForms.regularForms.push([/^(人間|わたくし|私|てまえ|手前|野郎|やろう|勇者|がき|ガキ|餓鬼|あくとう|悪党|猫|家来)(共|ども)$/i, '$1']);
  this.singularForms.regularForms.push([/^(神様|先生|あなた|大名|女中|奥様)(方|がた)$/i, '$1']);

  this.pluralize = function(token) {
    return this.ize(token, this.pluralForms, this.customPluralForms);
  };

  this.singularize = function(token) {
    return this.ize(token, this.singularForms, this.customSingularForms);
  };
};

util.inherits(NounInflector, SingularPluralInflector);

module.exports = NounInflector;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\noun_inflector.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/inflectors/noun_inflector.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var SingularPluralInflector = __webpack_require__(/*! ./singular_plural_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\singular_plural_inflector.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    FormSet = __webpack_require__(/*! ./form_set */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\form_set.js");

function attach() {
    var inflector = this;

    String.prototype.singularizeNoun = function() {
        return inflector.singularize(this);
    }

    String.prototype.pluralizeNoun = function() {
        return inflector.pluralize(this);
    }
}

var NounInflector = function() {
    this.ambiguous = [
        'bison', 'bream', 'carp', 'chassis', 'christmas', 'cod', 'corps', 'debris', 'deer',
        'diabetes', 'equipment', 'elk', 'fish', 'flounder', 'gallows', 'graffiti',
        'headquarters', 'herpes', 'highjinks', 'homework', 'information',
        'mackerel', 'mews', 'money', 'news', 'rice', 'rabies', 'salmon', 'series',
        'sheep', 'shrimp', 'species', 'swine', 'trout', 'tuna', 'whiting', 'wildebeest'
    ];

    this.customPluralForms = [];
    this.customSingularForms = [];
    this.singularForms = new FormSet();
    this.pluralForms = new FormSet();

    this.attach = attach;

    this.addIrregular("child", "children");
    this.addIrregular("man", "men");
    this.addIrregular("person", "people");
    this.addIrregular("sex", "sexes");
    this.addIrregular("mouse", "mice");
    this.addIrregular("ox", "oxen");
    this.addIrregular("foot", "feet");
    this.addIrregular("tooth", "teeth");
    this.addIrregular("goose", "geese");
    this.addIrregular("ephemeris", "ephemerides");
    this.addIrregular("cloth", "clothes");
    this.addIrregular("hero", "heroes");
    this.addIrregular("torso", "torsi");

    // see if it is possible to unify the creation of both the singular and
    // plural regexes or maybe even just have one list. with a complete list
    // of rules it may only be possible for some regular forms, but worth a shot
    this.pluralForms.regularForms.push([/([aeiou]y)$/i, '$1s']);
    this.pluralForms.regularForms.push([/y$/i, 'ies']);
    this.pluralForms.regularForms.push([/ife$/i, 'ives']);
    this.pluralForms.regularForms.push([/(antenn|formul|nebul|vertebr|vit)a$/i, '$1ae']);
    this.pluralForms.regularForms.push([/(octop|vir|radi|nucle|fung|cact|stimul|alumn|calcul|hippopotam|macrofung|phoet|syllab|troph)us$/i, '$1i']);
    this.pluralForms.regularForms.push([/(buffal|tomat|tornad)o$/i, '$1oes']);
    this.pluralForms.regularForms.push([/(sis)$/i, 'ses']);
    this.pluralForms.regularForms.push([/(matr|vert|ind|cort)(ix|ex)$/i, '$1ices']);
    this.pluralForms.regularForms.push([/sses$/i, 'sses']);
    this.pluralForms.regularForms.push([/(x|ch|ss|sh|s|z)$/i, '$1es']);
    this.pluralForms.regularForms.push([/^(?!talis|.*hu)(.*)man$/i, '$1men']);
    this.pluralForms.regularForms.push([/(.*)/i, '$1s']);

    this.singularForms.regularForms.push([/([^v])ies$/i, '$1y']);
    this.singularForms.regularForms.push([/ives$/i, 'ife']);
    this.singularForms.regularForms.push([/(antenn|formul|nebul|vertebr|vit)ae$/i, '$1a']);
    this.singularForms.regularForms.push([/(octop|vir|radi|nucle|fung|cact|stimul|alumn|calcul|hippopotam|macrofung|phoet|syllab|troph)(i)$/i, '$1us']);
    this.singularForms.regularForms.push([/(buffal|tomat|tornad)(oes)$/i, '$1o']);
    this.singularForms.regularForms.push([/(analy|naly|synop|parenthe|diagno|the)ses$/i, '$1sis']);
    this.singularForms.regularForms.push([/(vert|ind|cort)(ices)$/i, '$1ex']);
    // our pluralizer won''t cause this form of appendix (appendicies)
    // but we should handle it
    this.singularForms.regularForms.push([/(matr|append)(ices)$/i, '$1ix']);
    this.singularForms.regularForms.push([/(x|ch|ss|sh|s|z)es$/i, '$1']);
    this.singularForms.regularForms.push([/men$/i, 'man']);
    this.singularForms.regularForms.push([/ss$/i, 'ss']);
    this.singularForms.regularForms.push([/s$/i, '']);

    this.pluralize = function (token) {
        return this.ize(token, this.pluralForms, this.customPluralForms);
    };

    this.singularize = function(token) {
        return this.ize(token, this.singularForms, this.customSingularForms);
    };
};

util.inherits(NounInflector, SingularPluralInflector);

module.exports = NounInflector;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\present_verb_inflector.js":
/*!***********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/inflectors/present_verb_inflector.js ***!
  \***********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    SingularPluralInflector = __webpack_require__(/*! ./singular_plural_inflector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\singular_plural_inflector.js"),
    FormSet = __webpack_require__(/*! ./form_set */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\form_set.js");

function attach() {
    var inflector = this;
    
    String.prototype.singularizePresentVerb = function() {
        return inflector.singularize(this);
    }
    
    String.prototype.pluralizePresentVerb = function() {
        return inflector.pluralize(this);
    }
}

var VerbInflector = function() {
    this.ambiguous = [
        'will'
    ];
    
    this.attach = attach;
        
    this.customPluralForms = [];
    this.customSingularForms = [];    
    this.singularForms = new FormSet();
    this.pluralForms = new FormSet();

    this.addIrregular("am", "are");    
    this.addIrregular("is", "are");
    this.addIrregular("was", "were");
    this.addIrregular("has", "have");
    
    this.singularForms.regularForms.push([/ed$/i, 'ed']);
    this.singularForms.regularForms.push([/ss$/i, 'sses']);
    this.singularForms.regularForms.push([/x$/i, 'xes']);    
    this.singularForms.regularForms.push([/(h|z|o)$/i, '$1es']);
    this.singularForms.regularForms.push([/$zz/i, 'zzes']);
    this.singularForms.regularForms.push([/([^a|e|i|o|u])y$/i, '$1ies']);
    this.singularForms.regularForms.push([/$/i, 's']);

    this.pluralForms.regularForms.push([/sses$/i, 'ss']);
    this.pluralForms.regularForms.push([/xes$/i, 'x']);
    this.pluralForms.regularForms.push([/([cs])hes$/i, '$1h']);
    this.pluralForms.regularForms.push([/zzes$/i, 'zz']);
    this.pluralForms.regularForms.push([/([^h|z|o|i])es$/i, '$1e']);
    this.pluralForms.regularForms.push([/ies$/i, 'y']);//flies->fly
    this.pluralForms.regularForms.push([/e?s$/i, '']); 
};

util.inherits(VerbInflector, SingularPluralInflector);

module.exports = VerbInflector;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\inflectors\\singular_plural_inflector.js":
/*!**************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/inflectors/singular_plural_inflector.js ***!
  \**************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var TenseInflector = function () {
};

TenseInflector.prototype.addSingular = function(pattern, replacement) {
    this.customSingularForms.push([pattern, replacement]);    
};

TenseInflector.prototype.addPlural = function(pattern, replacement) {
    this.customPluralForms.push([pattern, replacement]);
};

TenseInflector.prototype.ize = function (token, formSet, customForms) {
    var restoreCase = this.restoreCase(token);
    return restoreCase(this.izeRegExps(token, customForms) || this.izeAbiguous(token) ||
        this.izeRegulars(token, formSet) || this.izeRegExps(token, formSet.regularForms) ||
        token);
}

TenseInflector.prototype.izeAbiguous = function (token) {
    if(this.ambiguous.indexOf(token.toLowerCase()) > -1)
        return token.toLowerCase();

    return false;
}

TenseInflector.prototype.pluralize = function (token) {
    return this.ize(token, this.pluralForms, this.customPluralForms);
};

TenseInflector.prototype.singularize = function(token) {
    return this.ize(token, this.singularForms, this.customSingularForms);
};    

var uppercaseify = function(token) {
    return token.toUpperCase();
}
var capitalize = function(token) {
    return token[0].toUpperCase() + token.slice(1);
}
var lowercaseify = function(token) {
    return token.toLowerCase();
}

TenseInflector.prototype.restoreCase = function(token) {
    if (token[0] === token[0].toUpperCase()) {
        if (token[1] && token[1] === token[1].toLowerCase()) {
            return capitalize;
        } else {
            return uppercaseify;
        }
    } else {
        return lowercaseify;
    }
}

TenseInflector.prototype.izeRegulars = function(token, formSet) {
    token = token.toLowerCase();
    if(formSet.irregularForms.hasOwnProperty(token) && formSet.irregularForms[token])
        return formSet.irregularForms[token];

    return false;
}

TenseInflector.prototype.addForm = function(singularTable, pluralTable, singular, plural) {
    singular = singular.toLowerCase();
    plural = plural.toLowerCase();
    pluralTable[singular] = plural;
    singularTable[plural] = singular;
};

TenseInflector.prototype.addIrregular = function(singular, plural) {
    this.addForm(this.singularForms.irregularForms, this.pluralForms.irregularForms, singular, plural);
};

TenseInflector.prototype.izeRegExps = function(token, forms) {
        var i, form;
        for(i = 0; i < forms.length; i++) {
            form = forms[i];
            
            if(token.match(form[0]))
                return token.replace(form[0], form[1]);
        }
        
        return false;
    }

module.exports = TenseInflector;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\ngrams\\ngrams.js":
/*!***************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/ngrams/ngrams.js ***!
  \***************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, 2018 Rob Ellis, Chris Umbel, Hugo W.L. ter Doest

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._,
    Tokenizer = __webpack_require__(/*! ../tokenizers/regexp_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\regexp_tokenizer.js").WordTokenizer,
    tokenizer = new Tokenizer(),
    frequencies = {},
    nrOfNgrams = 0;

exports.setTokenizer = function(t) {
    if(!_.isFunction(t.tokenize))
        throw new Error('Expected a valid Tokenizer');
    tokenizer = t;
};

exports.ngrams = function(sequence, n, startSymbol, endSymbol, stats) {
    return ngrams(sequence, n, startSymbol, endSymbol, stats);
};

exports.bigrams = function(sequence, startSymbol, endSymbol, stats) {
    return ngrams(sequence, 2, startSymbol, endSymbol, stats);
};

exports.trigrams = function(sequence, startSymbol, endSymbol, stats) {
    return ngrams(sequence, 3, startSymbol, endSymbol, stats);
};

exports.multrigrams = function(sequence, n, startSymbol, endSymbol, stats) {
    return ngrams(sequence, n, startSymbol, endSymbol, stats);
};

// Calculates a key (string) that can be used for a map
function arrayToKey(arr) {
  result = "(";
  arr.forEach(function(x) {
    result += x + ", ";
  });
  result = result.substr(0, result.length - 2) + ")";
  return result;
};

// Updates the statistics for the new ngram
function countNgrams(ngram) {
  nrOfNgrams++;
  var key = arrayToKey(ngram);
  if (!frequencies[key]) {
    frequencies[key] = 0;
  }
  frequencies[key]++;
}

// If stats is true, statistics will be returned
var ngrams = function(sequence, n, startSymbol, endSymbol, stats) {
    var result = [];
    frequencies = {};
    nrOfNgrams = 0;
    
    if (!_(sequence).isArray()) {
        sequence = tokenizer.tokenize(sequence);
    }

    var count = _.max([0, sequence.length - n + 1]);

    // Check for left padding    
    if(typeof startSymbol !== "undefined" && startSymbol !== null) {
        // Create an array of (n) start symbols
        var blanks = [];
        for(var i = 0 ; i < n ; i++) {
            blanks.push(startSymbol);
        }

        // Create the left padding
        for(var p = n - 1 ; p > 0 ; p--) {
            // Create a tuple of (p) start symbols and (n - p) words
          var ngram = blanks.slice(0, p).concat(sequence.slice(0, n - p));
          result.push(ngram);
          if (stats) {
            countNgrams(ngram);
          }
        }
    }

    // Build the complete ngrams
    for (var i = 0; i < count; i++) {
        var ngram = sequence.slice(i, i + n);
        result.push(ngram);
        if (stats) { 
          countNgrams(ngram);
        }
    }

    // Check for right padding
    if(typeof endSymbol !== "undefined" && endSymbol !== null) {
        // Create an array of (n) end symbols
        var blanks = [];
        for(var i = 0 ; i < n ; i++) {
            blanks.push(endSymbol);
        }

        // create the right padding
        for(var p = n - 1 ; p > 0 ; p--) {
            // Create a tuple of (p) start symbols and (n - p) words
          var ngram = sequence.slice(sequence.length - p, sequence.length).concat(blanks.slice(0, n - p));
          result.push(ngram);
          if (stats) {
            countNgrams(ngram);
          }
        }
    }
    
    if (stats) {
      
      // Count frequencies
      var Nr = {};
      Object.keys(frequencies).forEach(function(key) {
        if (!Nr[frequencies[key]]) {
          Nr[frequencies[key]] = 0;
        }
        Nr[frequencies[key]]++;
      });
      
      // Return the ngrams AND statistics
      return {
        "ngrams": result,
        "frequencies": frequencies,
        "Nr": Nr,
        "numberOfNgrams": nrOfNgrams
      };
      
    }
    else { // Do not break existing API of this module 
      return result;
    }
};

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\ngrams\\ngrams_zh.js":
/*!******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/ngrams/ngrams_zh.js ***!
  \******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2014, Lee Wenzhu

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._;

exports.ngrams = function(sequence, n, startSymbol, endSymbol) {
    return ngrams(sequence, n, startSymbol, endSymbol);
}

exports.bigrams = function(sequence, startSymbol, endSymbol) {
    return ngrams(sequence, 2, startSymbol, endSymbol);
}

exports.trigrams = function(sequence, startSymbol, endSymbol) {
    return ngrams(sequence, 3, startSymbol, endSymbol);
}

var ngrams = function(sequence, n, startSymbol, endSymbol) {
    var result = [], i;
    
    if (!_(sequence).isArray()) {
        sequence = sequence.split('');
    }

    var count = _.max([0, sequence.length - n + 1]);

    // Check for left padding    
    if(typeof startSymbol !== "undefined" && startSymbol !== null) {
        // Create an array of (n) start symbols
        var blanks = [];
        for(i = 0 ; i < n ; i++) {
            blanks.push(startSymbol);
        }

        // Create the left padding
        for(var p = n - 1 ; p > 0 ; p--) {
            // Create a tuple of (p) start symbols and (n - p) words
            result.push(blanks.slice(0, p).concat(sequence.slice(0, n - p)));
        }
    }

    // Build the complete ngrams
    for (i = 0; i < count; i++) {
        result.push(sequence.slice(i, i + n));
    }

    // Check for right padding
    if(typeof endSymbol !== "undefined" && endSymbol !== null) {
        // Create an array of (n) end symbols
        var blanks = [];
        for(var i = 0 ; i < n ; i++) {
            blanks.push(endSymbol);
        }

        // create the right padding
        for(var p = n - 1 ; p > 0 ; p--) {
            // Create a tuple of (p) start symbols and (n - p) words
            result.push(sequence.slice(sequence.length - p, sequence.length).concat(blanks.slice(0, n - p)));
        }
    }
    
    return result;
};



/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer.js":
/*!************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/normalizers/normalizer.js ***!
  \************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
 Copyright (c) 2013, Kenneth Koch

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * The english normalizer will create a string in which all contractions are expanded to their 
 * full meaning (i.e. "we'll" becomes "we will"). 
 *
 * It currently works off a conversion table and falls back to a set of rules.
 * Since it is applied first, the conversion table provides an "override" for the rules.
 **/
var replacer = __webpack_require__(/*! ../util/utils */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\utils.js").replacer;

var conversionTable = {
	"can't":"can not",
	"won't":"will not",
	"couldn't've":"could not have",
	"i'm":"I am",
	"how'd":"how did"
};

var rules = [
	{ regex: /([azAZ]*)n\'[tT]/g, output: "$1 not" },
	{ regex: /([azAZ]*)\'[sS]/g, output: "$1 is" },
	{ regex: /([azAZ]*)\'[lL][lL]/g, output: "$1 will" },
	{ regex: /([azAZ]*)\'[rR][eE]/g, output: "$1 are" },
	{ regex: /([azAZ]*)\'[vV][eE]/g, output: "$1 have" },
	{ regex: /([azAZ]*)\'[dD]/g, output: "$1 would" }
];

// Accepts a list of tokens to expand.
var normalize_tokens = function(tokens) {
	if(typeof tokens === "string") {
		tokens = [tokens];
	}
        var results = [];
	var rule_count = rules.length;
	var num_tokens = tokens.length;
        var i, token, r, rule;
    
        for (i = 0; i < num_tokens; i++) {
            token = tokens[i];
            // Check the conversion table
            if (conversionTable[token.toLowerCase()]) {
                results = results.concat(conversionTable[token.toLowerCase()].split(/\W+/));
            }
            
            // Apply the rules
            else {
                var matched = false;
                for ( r = 0; r < rule_count; r++) {
                    rule = rules[r];
                    if (token.match(rule.regex)) {
                        results = results.concat(token.replace(rule.regex, rule.output).split(/\W+/));
                        matched = true;
                        break;
                    }
                }
                if (!matched) {
                    results.push(token);
                }
            }
        }

	return results;
};





// export the relevant stuff.
exports.normalize_tokens = normalize_tokens;






/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer_ja.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/normalizers/normalizer_ja.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
 Copyright (c) 2012, Guillaume Marty

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * Normalize Japanese inputs and expose function to perform several conversions.
 *
 * Note: The space character is treated like a roman character as it usually
 *   has the same width as them in Japanese texts.
 *
 * \@todo Replace characters range from ㈠ to ㉃, ㊀ to ㊰ and ㇰ to ㇿ.
 * \@todo Lazy initializations of conversionTables and converters.
 * \@todo Would fixHalfwidthKana be useful?
 *
 * Descriptions of functions exposed:
 * normalizeJapanese 「全角」英字・数字を「半角」、「半角」記・カタカナを「全角」に変換
 * converters.fullwidthToHalfwidth.alphabet    「全角」英字を「半角」に変換
 * converters.halfwidthToFullwidth.alphabet    「半角」英字を「全角」に変換
 * converters.fullwidthToHalfwidth.numbers     「全角」数字を「半角」に変換
 * converters.halfwidthToFullwidth.numbers     「半角」数字を「全角」に変換 「全角」スペースを「半角」
 * converters.fullwidthToHalfwidth.punctuation 「全角」記号を「半角」に変換 「半角」スペースを「全角」
 * converters.halfwidthToFullwidth.punctuation 「半角」記号を「全角」に変換
 * converters.fullwidthToHalfwidth.katakana    「全角カタカナ」を「半角カタカナ」に変換
 * converters.halfwidthToFullwidth.katakana    「半角カタカナ」を「全角カタカナ」に変換
 * converters.hiraganaToKatakana               「カタカナ」を「ひらがな」に変換
 * converters.katakanaToHiragana               「ひらがな」を「カタカナ」に変換
 */

var flip = __webpack_require__(/*! ../util/utils.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\utils.js").flip;
var merge = __webpack_require__(/*! ../util/utils.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\utils.js").merge;
var replacer = __webpack_require__(/*! ../util/utils */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\utils.js").replacer;

// From http://fernweh.jp/b/mb_convert_kana_js/
var conversionTables = {
  fullwidthToHalfwidth: {
    alphabet: {
      'ａ': 'a',
      'ｂ': 'b',
      'ｃ': 'c',
      'ｄ': 'd',
      'ｅ': 'e',
      'ｆ': 'f',
      'ｇ': 'g',
      'ｈ': 'h',
      'ｉ': 'i',
      'ｊ': 'j',
      'ｋ': 'k',
      'ｌ': 'l',
      'ｍ': 'm',
      'ｎ': 'n',
      'ｏ': 'o',
      'ｐ': 'p',
      'ｑ': 'q',
      'ｒ': 'r',
      'ｓ': 's',
      'ｔ': 't',
      'ｕ': 'u',
      'ｖ': 'v',
      'ｗ': 'w',
      'ｘ': 'x',
      'ｙ': 'y',
      'ｚ': 'z',
      'Ａ': 'A',
      'Ｂ': 'B',
      'Ｃ': 'C',
      'Ｄ': 'D',
      'Ｅ': 'E',
      'Ｆ': 'F',
      'Ｇ': 'G',
      'Ｈ': 'H',
      'Ｉ': 'I',
      'Ｊ': 'J',
      'Ｋ': 'K',
      'Ｌ': 'L',
      'Ｍ': 'M',
      'Ｎ': 'N',
      'Ｏ': 'O',
      'Ｐ': 'P',
      'Ｑ': 'Q',
      'Ｒ': 'R',
      'Ｓ': 'S',
      'Ｔ': 'T',
      'Ｕ': 'U',
      'Ｖ': 'V',
      'Ｗ': 'W',
      'Ｘ': 'X',
      'Ｙ': 'Y',
      'Ｚ': 'Z',
      '　': ' ' // Fullwidth space
    },

    numbers: {
      '０': '0',
      '１': '1',
      '２': '2',
      '３': '3',
      '４': '4',
      '５': '5',
      '６': '6',
      '７': '7',
      '８': '8',
      '９': '9'
    },

    symbol: {
      '＿': '_',
      '－': '-',
      '，': ',',
      '；': ';',
      '：': ':',
      '！': '!',
      '？': '?',
      '．': '.',
      '（': '(',
      '）': ')',
      '［': '[',
      '］': ']',
      '｛': '{',
      '｝': '}',
      '＠': '@',
      '＊': '*',
      '＼': '\\',
      '／': '/',
      '＆': '&',
      '＃': '#',
      '％': '%',
      '｀': '`',
      '＾': '^',
      '＋': '+',
      '＜': '<',
      '＝': '=',
      '＞': '>',
      '｜': '|',
      // Never converted: '～': '~',
      '≪': '«',
      '≫': '»',
      '─': '-',
      '＄': '$',
      '＂': '"'
    },

    purePunctuation: {
      '、': '､',
      '。': '｡',
      '・': '･',
      '「': '｢',
      '」': '｣'
    },

    punctuation: {},

    katakana: {
      '゛': 'ﾞ',
      '゜': 'ﾟ',
      'ー': 'ｰ',

      'ヴ': 'ｳﾞ',
      'ガ': 'ｶﾞ',
      'ギ': 'ｷﾞ',
      'グ': 'ｸﾞ',
      'ゲ': 'ｹﾞ',
      'ゴ': 'ｺﾞ',
      'ザ': 'ｻﾞ',
      'ジ': 'ｼﾞ',
      'ズ': 'ｽﾞ',
      'ゼ': 'ｾﾞ',
      'ゾ': 'ｿﾞ',
      'ダ': 'ﾀﾞ',
      'ヂ': 'ﾁﾞ',
      'ヅ': 'ﾂﾞ',
      'デ': 'ﾃﾞ',
      'ド': 'ﾄﾞ',
      'バ': 'ﾊﾞ',
      'パ': 'ﾊﾟ',
      'ビ': 'ﾋﾞ',
      'ピ': 'ﾋﾟ',
      'ブ': 'ﾌﾞ',
      'プ': 'ﾌﾟ',
      'ベ': 'ﾍﾞ',
      'ペ': 'ﾍﾟ',
      'ボ': 'ﾎﾞ',
      'ポ': 'ﾎﾟ',

      'ァ': 'ｧ',
      'ア': 'ｱ',
      'ィ': 'ｨ',
      'イ': 'ｲ',
      'ゥ': 'ｩ',
      'ウ': 'ｳ',
      'ェ': 'ｪ',
      'エ': 'ｴ',
      'ォ': 'ｫ',
      'オ': 'ｵ',
      'カ': 'ｶ',
      'キ': 'ｷ',
      'ク': 'ｸ',
      'ケ': 'ｹ',
      'コ': 'ｺ',
      'サ': 'ｻ',
      'シ': 'ｼ',
      'ス': 'ｽ',
      'セ': 'ｾ',
      'ソ': 'ｿ',
      'タ': 'ﾀ',
      'チ': 'ﾁ',
      'ッ': 'ｯ',
      'ツ': 'ﾂ',
      'テ': 'ﾃ',
      'ト': 'ﾄ',
      'ナ': 'ﾅ',
      'ニ': 'ﾆ',
      'ヌ': 'ﾇ',
      'ネ': 'ﾈ',
      'ノ': 'ﾉ',
      'ハ': 'ﾊ',
      'ヒ': 'ﾋ',
      'フ': 'ﾌ',
      'ヘ': 'ﾍ',
      'ホ': 'ﾎ',
      'マ': 'ﾏ',
      'ミ': 'ﾐ',
      'ム': 'ﾑ',
      'メ': 'ﾒ',
      'モ': 'ﾓ',
      'ャ': 'ｬ',
      'ヤ': 'ﾔ',
      'ュ': 'ｭ',
      'ユ': 'ﾕ',
      'ョ': 'ｮ',
      'ヨ': 'ﾖ',
      'ラ': 'ﾗ',
      'リ': 'ﾘ',
      'ル': 'ﾙ',
      'レ': 'ﾚ',
      'ロ': 'ﾛ',
      'ワ': 'ﾜ',
      'ヲ': 'ｦ',
      'ン': 'ﾝ'
    }
  },

  halfwidthToFullwidth: {}
};

var fixFullwidthKana = {
  'ゝ゛': 'ゞ',
  'ヽ゛': 'ヾ',

  'う゛': 'ゔ',
  'か゛': 'が',
  'き゛': 'ぎ',
  'く゛': 'ぐ',
  'け゛': 'げ',
  'こ゛': 'ご',
  'さ゛': 'ざ',
  'し゛': 'じ',
  'す゛': 'ず',
  'せ゛': 'ぜ',
  'そ゛': 'ぞ',
  'た゛': 'だ',
  'ち゛': 'ぢ',
  'つ゛': 'づ',
  'て゛': 'で',
  'と゛': 'ど',
  'は゛': 'ば',
  'は゜': 'ぱ',
  'ひ゛': 'び',
  'ひ゜': 'ぴ',
  'ふ゛': 'ぶ',
  'ふ゜': 'ぷ',
  'へ゛': 'べ',
  'へ゜': 'ぺ',
  'ほ゛': 'ぼ',
  'ほ゜': 'ぽ',
  'っな': 'んな',
  'っに': 'んに',
  'っぬ': 'んぬ',
  'っね': 'んね',
  'っの': 'んの',

  'ウ゛': 'ヴ',
  'カ゛': 'ガ',
  'キ゛': 'ギ',
  'ク゛': 'グ',
  'ケ゛': 'ゲ',
  'コ゛': 'ゴ',
  'サ゛': 'ザ',
  'シ゛': 'ジ',
  'ス゛': 'ズ',
  'セ゛': 'ゼ',
  'ソ゛': 'ゾ',
  'タ゛': 'ダ',
  'チ゛': 'ヂ',
  'ツ゛': 'ヅ',
  'テ゛': 'デ',
  'ト゛': 'ド',
  'ハ゛': 'バ',
  'ハ゜': 'パ',
  'ヒ゛': 'ビ',
  'ヒ゜': 'ピ',
  'フ゛': 'ブ',
  'フ゜': 'プ',
  'ヘ゛': 'ベ',
  'ヘ゜': 'ペ',
  'ホ゛': 'ボ',
  'ホ゜': 'ポ',
  'ッナ': 'ンナ',
  'ッニ': 'ンニ',
  'ッヌ': 'ンヌ',
  'ッネ': 'ンネ',
  'ッノ': 'ンノ'
};

var fixCompositeSymbolsTable = {
  '㋀': '1月',
  '㋁': '2月',
  '㋂': '3月',
  '㋃': '4月',
  '㋄': '5月',
  '㋅': '6月',
  '㋆': '7月',
  '㋇': '8月',
  '㋈': '9月',
  '㋉': '10月',
  '㋊': '11月',
  '㋋': '12月',

  '㏠': '1日',
  '㏡': '2日',
  '㏢': '3日',
  '㏣': '4日',
  '㏤': '5日',
  '㏥': '6日',
  '㏦': '7日',
  '㏧': '8日',
  '㏨': '9日',
  '㏩': '10日',
  '㏪': '11日',
  '㏫': '12日',
  '㏬': '13日',
  '㏭': '14日',
  '㏮': '15日',
  '㏯': '16日',
  '㏰': '17日',
  '㏱': '18日',
  '㏲': '19日',
  '㏳': '20日',
  '㏴': '21日',
  '㏵': '22日',
  '㏶': '23日',
  '㏷': '24日',
  '㏸': '25日',
  '㏹': '26日',
  '㏺': '27日',
  '㏻': '28日',
  '㏼': '29日',
  '㏽': '30日',
  '㏾': '31日',

  '㍘': '0点',
  '㍙': '1点',
  '㍚': '2点',
  '㍛': '3点',
  '㍜': '4点',
  '㍝': '5点',
  '㍞': '6点',
  '㍟': '7点',
  '㍠': '8点',
  '㍡': '9点',
  '㍢': '10点',
  '㍣': '11点',
  '㍤': '12点',
  '㍥': '13点',
  '㍦': '14点',
  '㍧': '15点',
  '㍨': '16点',
  '㍩': '17点',
  '㍪': '18点',
  '㍫': '19点',
  '㍬': '20点',
  '㍭': '21点',
  '㍮': '22点',
  '㍯': '23点',
  '㍰': '24点',

  '㍻': '平成',
  '㍼': '昭和',
  '㍽': '大正',
  '㍾': '明治',
  '㍿': '株式会社',

  '㌀': 'アパート',
  '㌁': 'アルファ',
  '㌂': 'アンペア',
  '㌃': 'アール',
  '㌄': 'イニング',
  '㌅': 'インチ',
  '㌆': 'ウオン',
  '㌇': 'エスクード',
  '㌈': 'エーカー',
  '㌉': 'オンス',
  '㌊': 'オーム',
  '㌋': 'カイリ', //海里
  '㌌': 'カラット',
  '㌍': 'カロリー',
  '㌎': 'ガロン',
  '㌏': 'ガンマ',
  '㌐': 'ギガ',
  '㌑': 'ギニー',
  '㌒': 'キュリー',
  '㌓': 'ギルダー',
  '㌔': 'キロ',
  '㌕': 'キログラム',
  '㌖': 'キロメートル',
  '㌗': 'キロワット',
  '㌘': 'グラム',
  '㌙': 'グラムトン',
  '㌚': 'クルゼイロ',
  '㌛': 'クローネ',
  '㌜': 'ケース',
  '㌝': 'コルナ',
  '㌞': 'コーポ',
  '㌟': 'サイクル',
  '㌠': 'サンチーム',
  '㌡': 'シリング',
  '㌢': 'センチ',
  '㌣': 'セント',
  '㌤': 'ダース',
  '㌥': 'デシ',
  '㌦': 'ドル',
  '㌧': 'トン',
  '㌨': 'ナノ',
  '㌩': 'ノット',
  '㌪': 'ハイツ',
  '㌫': 'パーセント',
  '㌬': 'パーツ',
  '㌭': 'バーレル',
  '㌮': 'ピアストル',
  '㌯': 'ピクル',
  '㌰': 'ピコ',
  '㌱': 'ビル',
  '㌲': 'ファラッド',
  '㌳': 'フィート',
  '㌴': 'ブッシェル',
  '㌵': 'フラン',
  '㌶': 'ヘクタール',
  '㌷': 'ペソ',
  '㌸': 'ペニヒ',
  '㌹': 'ヘルツ',
  '㌺': 'ペンス',
  '㌻': 'ページ',
  '㌼': 'ベータ',
  '㌽': 'ポイント',
  '㌾': 'ボルト',
  '㌿': 'ホン',
  '㍀': 'ポンド',
  '㍁': 'ホール',
  '㍂': 'ホーン',
  '㍃': 'マイクロ',
  '㍄': 'マイル',
  '㍅': 'マッハ',
  '㍆': 'マルク',
  '㍇': 'マンション',
  '㍈': 'ミクロン',
  '㍉': 'ミリ',
  '㍊': 'ミリバール',
  '㍋': 'メガ',
  '㍌': 'メガトン',
  '㍍': 'メートル',
  '㍎': 'ヤード',
  '㍏': 'ヤール',
  '㍐': 'ユアン',
  '㍑': 'リットル',
  '㍒': 'リラ',
  '㍓': 'ルピー',
  '㍔': 'ルーブル',
  '㍕': 'レム',
  '㍖': 'レントゲン',
  '㍗': 'ワット'
};

// punctuation is pure_punctuation
conversionTables.fullwidthToHalfwidth.punctuation = merge(
    conversionTables.fullwidthToHalfwidth.symbol,
    conversionTables.fullwidthToHalfwidth.purePunctuation
)

// Fill in the conversion tables with the flipped tables.
conversionTables.halfwidthToFullwidth.alphabet = flip(conversionTables.fullwidthToHalfwidth.alphabet);
conversionTables.halfwidthToFullwidth.numbers = flip(conversionTables.fullwidthToHalfwidth.numbers);
conversionTables.halfwidthToFullwidth.symbol = flip(conversionTables.fullwidthToHalfwidth.symbol);
conversionTables.halfwidthToFullwidth.purePunctuation = flip(conversionTables.fullwidthToHalfwidth.purePunctuation);
conversionTables.halfwidthToFullwidth.punctuation = flip(conversionTables.fullwidthToHalfwidth.punctuation);
conversionTables.halfwidthToFullwidth.katakana = flip(conversionTables.fullwidthToHalfwidth.katakana);

// Build the normalization table.
conversionTables.normalize = merge(
    conversionTables.fullwidthToHalfwidth.alphabet,
    conversionTables.fullwidthToHalfwidth.numbers,
    conversionTables.fullwidthToHalfwidth.symbol,
    conversionTables.halfwidthToFullwidth.purePunctuation,
    conversionTables.halfwidthToFullwidth.katakana
    );

var converters = {
  fullwidthToHalfwidth: {
    alphabet: replacer(conversionTables.fullwidthToHalfwidth.alphabet),
    numbers: replacer(conversionTables.fullwidthToHalfwidth.numbers),
    symbol: replacer(conversionTables.fullwidthToHalfwidth.symbol),
    purePunctuation: replacer(conversionTables.fullwidthToHalfwidth.purePunctuation),
    punctuation: replacer(conversionTables.fullwidthToHalfwidth.punctuation),
    katakana: replacer(conversionTables.fullwidthToHalfwidth.katakana)
  },

  halfwidthToFullwidth: {
    alphabet: replacer(conversionTables.halfwidthToFullwidth.alphabet),
    numbers: replacer(conversionTables.halfwidthToFullwidth.numbers),
    symbol: replacer(conversionTables.halfwidthToFullwidth.symbol),
    purePunctuation: replacer(conversionTables.halfwidthToFullwidth.purePunctuation),
    punctuation: replacer(conversionTables.halfwidthToFullwidth.punctuation),
    katakana: replacer(conversionTables.halfwidthToFullwidth.katakana)
  },

  fixFullwidthKana: replacer(fixFullwidthKana),
  normalize: replacer(conversionTables.normalize)
};

var fixCompositeSymbols = replacer(fixCompositeSymbolsTable);


/**
 * Convert hiragana to fullwidth katakana.
 * According to http://jsperf.com/converting-japanese, these implementations are
 * faster than using lookup tables.
 *
 * @param {string} str A string.
 * @return {string} A string not containing hiragana.
 */
converters.hiraganaToKatakana = function(str) {
  str = converters.halfwidthToFullwidth.katakana(str);
  str = converters.fixFullwidthKana(str);

  str = str.replace(/ゝ/g, 'ヽ');
  str = str.replace(/ゞ/g, 'ヾ');
  //str = str.replace(/?/g, '𛀀'); // Letter archaic E

  str = str.replace(/[ぁ-ゖ]/g, function(str) {
    return String.fromCharCode(str.charCodeAt(0) + 96);
  });

  return str;
};


/**
 * Convert katakana to hiragana.
 *
 * @param {string} str A string.
 * @return {string} A string not containing katakana.
 */
converters.katakanaToHiragana = function(str) {
  str = converters.halfwidthToFullwidth.katakana(str);
  str = converters.fixFullwidthKana(str);

  str = str.replace(/ヽ/g, 'ゝ');
  str = str.replace(/ヾ/g, 'ゞ');
  //str = str.replace(/?/g, '𛀁'); // Letter archaic E

  str = str.replace(/[ァ-ヶ]/g, function(str) {
    return String.fromCharCode(str.charCodeAt(0) - 96);
  });

  return str;
};


/**
 * Fix kana and apply the following processes;
 * * Replace repeat characters
 * * Alphabet to halfwidth
 * * Numbers to halfwidth
 * * Punctuation to fullwidth
 * * Katakana to fullwidth
 * * Fix fullwidth kana
 * * Replace composite symbols
 *
 * @param {string} str
 * @return {string}
 */
var normalize_ja = function(str) {
  // Replace repeat characters.
  str = str
    .replace(/(..)々々/g, '$1$1')
    .replace(/(.)々/g, '$1$1');

  str = converters.normalize(str);
  str = converters.fixFullwidthKana(str);

  // Replace composite symbols.
  str = fixCompositeSymbols(str);

  return str;
};

exports.normalize_ja = normalize_ja;
exports.converters = converters;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer_no.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/normalizers/normalizer_no.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
 Copyright (c) 2014, Kristoffer Brabrand

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * Remove commonly used diacritic marks from a string as these
 * are not used in a consistent manner. Leave only ä, ö, ü.
 */
var remove_diacritics = function(text) {
    text = text.replace('à', 'a');
    text = text.replace('À', 'A');
    text = text.replace('á', 'a');
    text = text.replace('Á', 'A');
    text = text.replace('â', 'a');
    text = text.replace('Â', 'A');
    text = text.replace('ç', 'c');
    text = text.replace('Ç', 'C');
    text = text.replace('è', 'e');
    text = text.replace('È', 'E');
    text = text.replace('é', 'e');
    text = text.replace('É', 'E');
    text = text.replace('ê', 'e');
    text = text.replace('Ê', 'E');
    text = text.replace('î', 'i');
    text = text.replace('Î', 'I');
    text = text.replace('ñ', 'n');
    text = text.replace('Ñ', 'N');
    text = text.replace('ó', 'o');
    text = text.replace('Ó', 'O');
    text = text.replace('ô', 'o');
    text = text.replace('Ô', 'O');
    text = text.replace('û', 'u');
    text = text.replace('Û', 'U');
    text = text.replace('š', 's');
    text = text.replace('Š', 'S');

    return text;
};

// export the relevant stuff.
exports.remove_diacritics = remove_diacritics;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer_sv.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/normalizers/normalizer_sv.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
 Copyright (c) 2017, Dogan Yazar

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * Remove commonly used diacritic marks from a string as these
 * are not used in a consistent manner. Leave only ä, ö, å.
 */
var remove_diacritics = function(text) {
    text = text.replace('à', 'a');
    text = text.replace('À', 'A');
    text = text.replace('á', 'a');
    text = text.replace('Á', 'A');
    text = text.replace('è', 'e');
    text = text.replace('È', 'E');
    text = text.replace('é', 'e');
    text = text.replace('É', 'E');

    return text;
};

// export the relevant stuff.
exports.remove_diacritics = remove_diacritics;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\remove_diacritics.js":
/*!*******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/normalizers/remove_diacritics.js ***!
  \*******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
 Copyright (c) 2012, Alexy Maslennikov

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * Script to remove diacritics. Original source was taken from
 * http://lehelk.com/2011/05/06/script-to-remove-diacritics/
 */
var diacriticsRemovalMap = [
    {'base':'A', 'letters':/[\u0041\u24B6\uFF21\u00C0\u00C1\u00C2\u1EA6\u1EA4\u1EAA\u1EA8\u00C3\u0100\u0102\u1EB0\u1EAE\u1EB4\u1EB2\u0226\u01E0\u00C4\u01DE\u1EA2\u00C5\u01FA\u01CD\u0200\u0202\u1EA0\u1EAC\u1EB6\u1E00\u0104\u023A\u2C6F]/g},
    {'base':'AA','letters':/[\uA732]/g},
    {'base':'AE','letters':/[\u00C6\u01FC\u01E2]/g},
    {'base':'AO','letters':/[\uA734]/g},
    {'base':'AU','letters':/[\uA736]/g},
    {'base':'AV','letters':/[\uA738\uA73A]/g},
    {'base':'AY','letters':/[\uA73C]/g},
    {'base':'B', 'letters':/[\u0042\u24B7\uFF22\u1E02\u1E04\u1E06\u0243\u0182\u0181]/g},
    {'base':'C', 'letters':/[\u0043\u24B8\uFF23\u0106\u0108\u010A\u010C\u00C7\u1E08\u0187\u023B\uA73E]/g},
    {'base':'D', 'letters':/[\u0044\u24B9\uFF24\u1E0A\u010E\u1E0C\u1E10\u1E12\u1E0E\u0110\u018B\u018A\u0189\uA779]/g},
    {'base':'DZ','letters':/[\u01F1\u01C4]/g},
    {'base':'Dz','letters':/[\u01F2\u01C5]/g},
    {'base':'E', 'letters':/[\u0045\u24BA\uFF25\u00C8\u00C9\u00CA\u1EC0\u1EBE\u1EC4\u1EC2\u1EBC\u0112\u1E14\u1E16\u0114\u0116\u00CB\u1EBA\u011A\u0204\u0206\u1EB8\u1EC6\u0228\u1E1C\u0118\u1E18\u1E1A\u0190\u018E]/g},
    {'base':'F', 'letters':/[\u0046\u24BB\uFF26\u1E1E\u0191\uA77B]/g},
    {'base':'G', 'letters':/[\u0047\u24BC\uFF27\u01F4\u011C\u1E20\u011E\u0120\u01E6\u0122\u01E4\u0193\uA7A0\uA77D\uA77E]/g},
    {'base':'H', 'letters':/[\u0048\u24BD\uFF28\u0124\u1E22\u1E26\u021E\u1E24\u1E28\u1E2A\u0126\u2C67\u2C75\uA78D]/g},
    {'base':'I', 'letters':/[\u0049\u24BE\uFF29\u00CC\u00CD\u00CE\u0128\u012A\u012C\u0130\u00CF\u1E2E\u1EC8\u01CF\u0208\u020A\u1ECA\u012E\u1E2C\u0197]/g},
    {'base':'J', 'letters':/[\u004A\u24BF\uFF2A\u0134\u0248]/g},
    {'base':'K', 'letters':/[\u004B\u24C0\uFF2B\u1E30\u01E8\u1E32\u0136\u1E34\u0198\u2C69\uA740\uA742\uA744\uA7A2]/g},
    {'base':'L', 'letters':/[\u004C\u24C1\uFF2C\u013F\u0139\u013D\u1E36\u1E38\u013B\u1E3C\u1E3A\u0141\u023D\u2C62\u2C60\uA748\uA746\uA780]/g},
    {'base':'LJ','letters':/[\u01C7]/g},
    {'base':'Lj','letters':/[\u01C8]/g},
    {'base':'M', 'letters':/[\u004D\u24C2\uFF2D\u1E3E\u1E40\u1E42\u2C6E\u019C]/g},
    {'base':'N', 'letters':/[\u004E\u24C3\uFF2E\u01F8\u0143\u00D1\u1E44\u0147\u1E46\u0145\u1E4A\u1E48\u0220\u019D\uA790\uA7A4]/g},
    {'base':'NJ','letters':/[\u01CA]/g},
    {'base':'Nj','letters':/[\u01CB]/g},
    {'base':'O', 'letters':/[\u004F\u24C4\uFF2F\u00D2\u00D3\u00D4\u1ED2\u1ED0\u1ED6\u1ED4\u00D5\u1E4C\u022C\u1E4E\u014C\u1E50\u1E52\u014E\u022E\u0230\u00D6\u022A\u1ECE\u0150\u01D1\u020C\u020E\u01A0\u1EDC\u1EDA\u1EE0\u1EDE\u1EE2\u1ECC\u1ED8\u01EA\u01EC\u00D8\u01FE\u0186\u019F\uA74A\uA74C]/g},
    {'base':'OE','letters':/[\u0152]/g},
    {'base':'OI','letters':/[\u01A2]/g},
    {'base':'OO','letters':/[\uA74E]/g},
    {'base':'OU','letters':/[\u0222]/g},
    {'base':'P', 'letters':/[\u0050\u24C5\uFF30\u1E54\u1E56\u01A4\u2C63\uA750\uA752\uA754]/g},
    {'base':'Q', 'letters':/[\u0051\u24C6\uFF31\uA756\uA758\u024A]/g},
    {'base':'R', 'letters':/[\u0052\u24C7\uFF32\u0154\u1E58\u0158\u0210\u0212\u1E5A\u1E5C\u0156\u1E5E\u024C\u2C64\uA75A\uA7A6\uA782]/g},
    {'base':'S', 'letters':/[\u0053\u24C8\uFF33\u1E9E\u015A\u1E64\u015C\u1E60\u0160\u1E66\u1E62\u1E68\u0218\u015E\u2C7E\uA7A8\uA784]/g},
    {'base':'T', 'letters':/[\u0054\u24C9\uFF34\u1E6A\u0164\u1E6C\u021A\u0162\u1E70\u1E6E\u0166\u01AC\u01AE\u023E\uA786]/g},
    {'base':'TZ','letters':/[\uA728]/g},
    {'base':'U', 'letters':/[\u0055\u24CA\uFF35\u00D9\u00DA\u00DB\u0168\u1E78\u016A\u1E7A\u016C\u00DC\u01DB\u01D7\u01D5\u01D9\u1EE6\u016E\u0170\u01D3\u0214\u0216\u01AF\u1EEA\u1EE8\u1EEE\u1EEC\u1EF0\u1EE4\u1E72\u0172\u1E76\u1E74\u0244]/g},
    {'base':'V', 'letters':/[\u0056\u24CB\uFF36\u1E7C\u1E7E\u01B2\uA75E\u0245]/g},
    {'base':'VY','letters':/[\uA760]/g},
    {'base':'W', 'letters':/[\u0057\u24CC\uFF37\u1E80\u1E82\u0174\u1E86\u1E84\u1E88\u2C72]/g},
    {'base':'X', 'letters':/[\u0058\u24CD\uFF38\u1E8A\u1E8C]/g},
    {'base':'Y', 'letters':/[\u0059\u24CE\uFF39\u1EF2\u00DD\u0176\u1EF8\u0232\u1E8E\u0178\u1EF6\u1EF4\u01B3\u024E\u1EFE]/g},
    {'base':'Z', 'letters':/[\u005A\u24CF\uFF3A\u0179\u1E90\u017B\u017D\u1E92\u1E94\u01B5\u0224\u2C7F\u2C6B\uA762]/g},
    {'base':'a', 'letters':/[\u0061\u24D0\uFF41\u1E9A\u00E0\u00E1\u00E2\u1EA7\u1EA5\u1EAB\u1EA9\u00E3\u0101\u0103\u1EB1\u1EAF\u1EB5\u1EB3\u0227\u01E1\u00E4\u01DF\u1EA3\u00E5\u01FB\u01CE\u0201\u0203\u1EA1\u1EAD\u1EB7\u1E01\u0105\u2C65\u0250]/g},
    {'base':'aa','letters':/[\uA733]/g},
    {'base':'ae','letters':/[\u00E6\u01FD\u01E3]/g},
    {'base':'ao','letters':/[\uA735]/g},
    {'base':'au','letters':/[\uA737]/g},
    {'base':'av','letters':/[\uA739\uA73B]/g},
    {'base':'ay','letters':/[\uA73D]/g},
    {'base':'b', 'letters':/[\u0062\u24D1\uFF42\u1E03\u1E05\u1E07\u0180\u0183\u0253]/g},
    {'base':'c', 'letters':/[\u0063\u24D2\uFF43\u0107\u0109\u010B\u010D\u00E7\u1E09\u0188\u023C\uA73F\u2184]/g},
    {'base':'d', 'letters':/[\u0064\u24D3\uFF44\u1E0B\u010F\u1E0D\u1E11\u1E13\u1E0F\u0111\u018C\u0256\u0257\uA77A]/g},
    {'base':'dz','letters':/[\u01F3\u01C6]/g},
    {'base':'e', 'letters':/[\u0065\u24D4\uFF45\u00E8\u00E9\u00EA\u1EC1\u1EBF\u1EC5\u1EC3\u1EBD\u0113\u1E15\u1E17\u0115\u0117\u00EB\u1EBB\u011B\u0205\u0207\u1EB9\u1EC7\u0229\u1E1D\u0119\u1E19\u1E1B\u0247\u025B\u01DD]/g},
    {'base':'f', 'letters':/[\u0066\u24D5\uFF46\u1E1F\u0192\uA77C]/g},
    {'base':'g', 'letters':/[\u0067\u24D6\uFF47\u01F5\u011D\u1E21\u011F\u0121\u01E7\u0123\u01E5\u0260\uA7A1\u1D79\uA77F]/g},
    {'base':'h', 'letters':/[\u0068\u24D7\uFF48\u0125\u1E23\u1E27\u021F\u1E25\u1E29\u1E2B\u1E96\u0127\u2C68\u2C76\u0265]/g},
    {'base':'hv','letters':/[\u0195]/g},
    {'base':'i', 'letters':/[\u0069\u24D8\uFF49\u00EC\u00ED\u00EE\u0129\u012B\u012D\u00EF\u1E2F\u1EC9\u01D0\u0209\u020B\u1ECB\u012F\u1E2D\u0268\u0131]/g},
    {'base':'j', 'letters':/[\u006A\u24D9\uFF4A\u0135\u01F0\u0249]/g},
    {'base':'k', 'letters':/[\u006B\u24DA\uFF4B\u1E31\u01E9\u1E33\u0137\u1E35\u0199\u2C6A\uA741\uA743\uA745\uA7A3]/g},
    {'base':'l', 'letters':/[\u006C\u24DB\uFF4C\u0140\u013A\u013E\u1E37\u1E39\u013C\u1E3D\u1E3B\u017F\u0142\u019A\u026B\u2C61\uA749\uA781\uA747]/g},
    {'base':'lj','letters':/[\u01C9]/g},
    {'base':'m', 'letters':/[\u006D\u24DC\uFF4D\u1E3F\u1E41\u1E43\u0271\u026F]/g},
    {'base':'n', 'letters':/[\u006E\u24DD\uFF4E\u01F9\u0144\u00F1\u1E45\u0148\u1E47\u0146\u1E4B\u1E49\u019E\u0272\u0149\uA791\uA7A5]/g},
    {'base':'nj','letters':/[\u01CC]/g},
    {'base':'o', 'letters':/[\u006F\u24DE\uFF4F\u00F2\u00F3\u00F4\u1ED3\u1ED1\u1ED7\u1ED5\u00F5\u1E4D\u022D\u1E4F\u014D\u1E51\u1E53\u014F\u022F\u0231\u00F6\u022B\u1ECF\u0151\u01D2\u020D\u020F\u01A1\u1EDD\u1EDB\u1EE1\u1EDF\u1EE3\u1ECD\u1ED9\u01EB\u01ED\u00F8\u01FF\u0254\uA74B\uA74D\u0275]/g},
    {'base':'oe','letters':/[\u0153]/g},
    {'base':'oi','letters':/[\u01A3]/g},
    {'base':'ou','letters':/[\u0223]/g},
    {'base':'oo','letters':/[\uA74F]/g},
    {'base':'p','letters':/[\u0070\u24DF\uFF50\u1E55\u1E57\u01A5\u1D7D\uA751\uA753\uA755]/g},
    {'base':'q','letters':/[\u0071\u24E0\uFF51\u024B\uA757\uA759]/g},
    {'base':'r','letters':/[\u0072\u24E1\uFF52\u0155\u1E59\u0159\u0211\u0213\u1E5B\u1E5D\u0157\u1E5F\u024D\u027D\uA75B\uA7A7\uA783]/g},
    {'base':'s','letters':/[\u0073\u24E2\uFF53\u00DF\u015B\u1E65\u015D\u1E61\u0161\u1E67\u1E63\u1E69\u0219\u015F\u023F\uA7A9\uA785\u1E9B]/g},
    {'base':'t','letters':/[\u0074\u24E3\uFF54\u1E6B\u1E97\u0165\u1E6D\u021B\u0163\u1E71\u1E6F\u0167\u01AD\u0288\u2C66\uA787]/g},
    {'base':'tz','letters':/[\uA729]/g},
    {'base':'u','letters':/[\u0075\u24E4\uFF55\u00F9\u00FA\u00FB\u0169\u1E79\u016B\u1E7B\u016D\u00FC\u01DC\u01D8\u01D6\u01DA\u1EE7\u016F\u0171\u01D4\u0215\u0217\u01B0\u1EEB\u1EE9\u1EEF\u1EED\u1EF1\u1EE5\u1E73\u0173\u1E77\u1E75\u0289]/g},
    {'base':'v','letters':/[\u0076\u24E5\uFF56\u1E7D\u1E7F\u028B\uA75F\u028C]/g},
    {'base':'vy','letters':/[\uA761]/g},
    {'base':'w','letters':/[\u0077\u24E6\uFF57\u1E81\u1E83\u0175\u1E87\u1E85\u1E98\u1E89\u2C73]/g},
    {'base':'x','letters':/[\u0078\u24E7\uFF58\u1E8B\u1E8D]/g},
    {'base':'y','letters':/[\u0079\u24E8\uFF59\u1EF3\u00FD\u0177\u1EF9\u0233\u1E8F\u00FF\u1EF7\u1E99\u1EF5\u01B4\u024F\u1EFF]/g},
    {'base':'z','letters':/[\u007A\u24E9\uFF5A\u017A\u1E91\u017C\u017E\u1E93\u1E95\u01B6\u0225\u0240\u2C6C\uA763]/g}
];


module.exports = function(str) {
	var rules = diacriticsRemovalMap;
	for (var i = 0; i < rules.length; i++) {
		str = str.replace(rules[i].letters, rules[i].base);
	}
	return str;
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\dm_soundex.js":
/*!**********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/phonetics/dm_soundex.js ***!
  \**********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2012, Alexy Maslenninkov

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

/*
 * Daitch-Mokotoff Soundex Coding
 *
 * The Daitch-Mokotoff Soundex System was created by Randy Daitch and Gary
 * Mokotoff of the Jewish Genealogical Society because they concluded the system
 * developed by Robert Russell in 1918, and in use today by the U.S. National
 * Archives and Records Administration (NARA) does not apply well to many Slavic
 * and Yiddish surnames.  It also includes refinements that are independent of
 * ethnic considerations.
 *
 * The rules for converting surnames into D-M Code numbers are listed below.
 * They are followed by the coding chart.
 *
 * 1. Names are coded to six digits, each digit representing a sound listed in
 * the coding chart (below).
 *
 * 2. When a name lacks enough coded sounds for six digits, use zeros to fill to
 * six digits. GOLDEN which has only four coded sounds [G-L-D-N] is coded as
 * 583600.
 *
 * 3. The letters A, E, I, O, U, J, and Y are always coded at the beginning of a
 * name as in Alpert 087930. In any other situation, they are ignored except
 * when two of them form a pair and the pair comes before a vowel, as in Breuer
 * 791900 but not Freud.
 *
 * 4. The letter H is coded at the beginning of a name, as in Haber 579000, or
 * preceding a vowel, as in Manheim 665600, otherwise it is not coded.
 *
 * 5. When adjacent sounds can combine to form a larger sound, they are given
 * the code number of the larger sound.  Mintz which is not coded MIN-T-Z but
 * MIN-TZ 664000.
 *
 * 6. When adjacent letters have the same code number, they are coded as one
 * sound, as in TOPF, which is not coded TO-P-F 377000 but TO-PF 370000.
 * Exceptions to this rule are the letter combinations MN and NM, whose letters
 * are coded separately, as in Kleinman, which is coded 586660 not 586600.
 *
 * 7. When a surname consists or more than one word, it is coded as if one word,
 * such as Ben Aron which is treated as Benaron.
 *
 * 8. Several letter and letter combinations pose the problem that they may
 * sound in one of two ways.  The letter and letter combinations CH, CK, C, J,
 * and RS are assigned two possible code numbers.
 *
 * For more info, see http://www.jewishgen.org/InfoFiles/soundex.html
 */

/**
 * D-M transformation table in the form of finite-state machine.
 * Every element of the table having member with zero index represents
 * legal FSM state; every non-zero key is the transition rule.
 *
 * Every legal state comprises tree values chosen according to the position
 * of the letter combination in the word:
 *   0: start of a word;
 *   1: before a vowel;
 *   2: any other situation.
 */
var codes = {
    A: {
        0: [0, -1, -1],
        I: [[0, 1, -1]],
        J: [[0, 1, -1]],
        Y: [[0, 1, -1]],
        U: [[0, 7, -1]]},
    B: [[7, 7, 7]],
    C: {
        0: [5, 5, 5],
        Z: {0: [4, 4, 4], S: [[4, 4, 4]]},
        S: {0: [4, 4, 4], Z: [[4, 4, 4]]},
        K: [[5, 5, 5], [45, 45, 45]],
        H: {0: [5, 5, 5], S: [[5, 54, 54]]}},
    D: {
        0: [3, 3, 3],
        T: [[3, 3, 3]],
        Z: {0: [4, 4, 4], H: [[4, 4, 4]], S: [[4, 4, 4]]},
        S: {0: [4, 4, 4], H: [[4, 4, 4]], Z: [[4, 4, 4]]},
        R: {S: [[4, 4, 4]], Z: [[4, 4, 4]]}},
    E: {
        0: [0, -1, -1],
        I: [[0, 1, -1]],
        J: [[0, 1, -1]],
        Y: [[0, 1, -1]],
        U: [[1, 1, -1]],
        W: [[1, 1, -1]]},
    F: {
        0: [7, 7, 7],
        B: [[7, 7, 7]]},
    G: [[5, 5, 5]],
    H: [[5, 5, -1]],
    I: {
        0: [0, -1, -1],
        A: [[1, -1, -1]],
        E: [[1, -1, -1]],
        O: [[1, -1, -1]],
        U: [[1, -1, -1]]},
    J: [[4, 4, 4]],
    K: {
        0: [5, 5, 5],
        H: [[5, 5, 5]],
        S: [[5, 54, 54]]},
    L: [[8, 8, 8]],
    M: {
        0: [6, 6, 6],
        N: [[66, 66, 66]]},
    N: {
        0: [6, 6, 6],
        M: [[66, 66, 66]]},
    O: {
        0: [0, -1, -1],
        I: [[0, 1, -1]],
        J: [[0, 1, -1]],
        Y: [[0, 1, -1]]},
    P: {
        0: [7, 7, 7],
        F: [[7, 7, 7]],
        H: [[7, 7, 7]]},
    Q: [[5, 5, 5]],
    R: {
        0: [9, 9, 9],
        Z: [[94, 94, 94], [94, 94, 94]],
        S: [[94, 94, 94], [94, 94, 94]]},
    S: {
        0: [4, 4, 4],
        Z: {0: [4, 4, 4], T: [[2, 43, 43]], C: {Z: [[2, 4, 4]], S: [[2, 4, 4]]}, D: [[2, 43, 43]]},
        D: [[2, 43, 43]],
        T: {0: [2, 43, 43], R: {Z: [[2, 4, 4]], S: [[2, 4, 4]]}, C: {H: [[2, 4, 4]]}, S: {H: [[2, 4, 4]], C: {H: [[2, 4, 4]]}}},
        C: {0: [2, 4, 4], H: {0: [4, 4, 4], T: {0: [2, 43, 43], S: {C: {H: [[2, 4, 4]]}, H: [[2, 4, 4]]}, C: {H: [[2, 4, 4]]}}, D: [[2, 43, 43]]}},
        H: {0: [4, 4, 4], T: {0: [2, 43, 43], C: {H: [[2, 4, 4]]}, S: {H: [[2, 4, 4]]}}, C: {H: [[2, 4, 4]]}, D: [[2, 43, 43]]}},
    T: {
        0: [3, 3, 3],
        C: {0: [4, 4, 4], H: [[4, 4, 4]]},
        Z: {0: [4, 4, 4], S: [[4, 4, 4]]},
        S: {0: [4, 4, 4], Z: [[4, 4, 4]], H: [[4, 4, 4]], C: {H: [[4, 4, 4]]}},
        T: {S: {0: [4, 4, 4], Z: [[4, 4, 4]], C: {H: [[4, 4, 4]]}}, C: {H: [[4, 4, 4]]}, Z: [[4, 4, 4]]},
        H: [[3, 3, 3]],
        R: {Z: [[4, 4, 4]], S: [[4, 4, 4]]}},
    U: {
        0: [0, -1, -1],
        E: [[0, -1, -1]],
        I: [[0, 1, -1]],
        J: [[0, 1, -1]],
        Y: [[0, 1, -1]]},
    V: [[7, 7, 7]],
    W: [[7, 7, 7]],
    X: [[5, 54, 54]],
    Y: [[1, -1, -1]],
    Z: {
        0: [4, 4, 4],
        D: {0: [2, 43, 43], Z: {0: [2, 4, 4], H: [[2, 4, 4]]}},
        H: {0: [4, 4, 4], D: {0: [2, 43, 43], Z: {H: [[2, 4, 4]]}}},
        S: {0: [4, 4, 4], H: [[4, 4, 4]], C: {H: [[4, 4, 4]]}}}
};


function process(word, codeLength) {
	codeLength = codeLength || 6;
    word = word.toUpperCase();
    var output = '';

    var pos = 0, lastCode = -1;
    while (pos < word.length) {
        var substr = word.slice(pos);
        var rules = findRules(substr);

        var code;
        if (pos == 0) {
            // at the beginning of the word
            code = rules.mapping[0];
        } else if (substr[rules.length] && findRules(substr[rules.length]).mapping[0] == 0) {
            // before a vowel
            code = rules.mapping[1];
        } else {
            // any other situation
            code = rules.mapping[2];
        }

        if ((code != -1) && (code != lastCode)) output += code;
        lastCode = code;
        pos += rules.length;

    }

    return normalizeLength(output, codeLength);
}


function findRules(str) {
    var state = codes[str[0]];
    var legalState = state || [[-1,-1,-1]],
        charsInvolved = 1;

    for (var offs = 1; offs < str.length; offs++) {
        if (!state || !state[str[offs]]) break;

        state = state[str[offs]];
        if (state[0]) {
            legalState = state;
            charsInvolved = offs + 1;
        }
    }

    return {
        length: charsInvolved,
        mapping: legalState[0]
    };
}


/**
 * Pad right with zeroes or cut excess symbols to fit length
 */
function normalizeLength(token, length) {
	length = length || 6;
	if (token.length < length) {
		token += (new Array(length - token.length + 1)).join('0');
	}
    return token.slice(0, length);
}

var Phonetic = __webpack_require__(/*! ./phonetic */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\phonetic.js");
var soundex = new Phonetic();
soundex.process = process;
module.exports = soundex;



/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\double_metaphone.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/phonetics/double_metaphone.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Phonetic = __webpack_require__(/*! ./phonetic */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\phonetic.js");

var DoubleMetaphone = new Phonetic();
module.exports = DoubleMetaphone;

function isVowel(c) {
	return c && c.match(/[aeiouy]/i);
}

function truncate(string, length) {
    if(string.length >= length)
        string = string.substring(0, length);

    return string;
}

function process(token, maxLength) {
	token = token.toUpperCase();
	var primary = '', secondary = '';
    var pos = 0;
    maxLength == maxLength || 32;

    function subMatch(startOffset, stopOffset, terms) {
        return subMatchAbsolute(pos + startOffset, pos + stopOffset, terms);
    }

    function subMatchAbsolute(startOffset, stopOffset, terms) {
        return terms.indexOf(token.substring(startOffset, stopOffset)) > -1;
    }

    function addSecondary(primaryAppendage, secondaryAppendage) {
    	primary += primaryAppendage;
    	secondary += secondaryAppendage;
    }

    function add(primaryAppendage) {
    	addSecondary(primaryAppendage, primaryAppendage);
    }

    function addCompressedDouble(c, encoded) {
    	if(token[pos + 1] == c)
    		pos++;
    	add(encoded || c);
    }

    function handleC() {

        if(pos >= 1 && !isVowel(token[pos - 2])
                && token[pos - 1] == 'A' && token[pos + 1] == 'H'
                    && token[pos + 2] != 'I'
                        || subMatch(-2, 4, ['BACHER', 'MACHER'])) {
            add('K');
            pos++;
        } else if(pos == 0 && token.substring(1, 6) == 'EASAR') {
            add('S');
            add('S');
            add('R');
            pos += 6;
        } else if(token.substring(pos + 1, pos + 4) == 'HIA') {
            add('K');
            pos++;
        } else if(token[pos + 1] == 'H') {
            if(pos > 0 && token.substring(pos + 2, pos + 4) == 'AE') {
                addSecondary('K', 'X');
                pos++;
            } else if(pos == 0
                        && (subMatch(1, 6, ['HARAC', 'HARIS'])
                            || subMatch(1, 4, ['HOR', 'HUM', 'HIA', 'HEM']))
                        && token.substring(pos + 1, pos + 5) != 'HORE') {
                add('K');
                pos++;
            } else {
                if((subMatchAbsolute(0, 3, ['VAN', 'VON']) || token.substring(0,  3) == 'SCH')
                    || subMatch(-2, 4, ['ORCHES', 'ARCHIT', 'ORCHID'])
                    || subMatch(2, 3, ['T', 'S'])
                    || ((subMatch(-1, 0, ['A', 'O', 'U', 'E']) || pos == 0)
                        && subMatch(2, 3, ['B', 'F', 'H', 'L', 'M', 'N', 'R', 'V', 'W']))) {
                    add('K');
                } else if(pos > 0) {

                    if(token.substring(0, 2) == 'MC') {
                        add('K');
                    } else {
                        addSecondary('X', 'K');
                    }
                } else {
                    add('X');
                }

                pos++;
            }
        } else if(token.substring(pos, pos + 2) == 'CZ'
                && token.substring(pos - 2, pos + 1) != 'WICZ') {
            addSecondary('S', 'X');
            pos++;
        } else if(token.substring(pos, pos + 3) == 'CIA') {
            add('X');
            pos += 2;
        } else if(token[pos + 1] == 'C' && pos != 1 && token[0] != 'M') {
            if(['I', 'E', 'H'].indexOf(token[pos + 2]) > -1
                    && token.substring(pos + 2, pos + 4) != 'HU') {
                if(pos == 1 && token[pos - 1] == 'A'
                        || subMatch(-1, 4, ['UCCEE', 'UCCES'])) {
                    add('KS');
                } else {
                   add('X');
                }

               pos +=2;
            } else {
                add('K');
                pos++;
            }
        } else if(['K', 'G', 'Q'].indexOf(token[pos + 1]) > -1) {
            add('K');
            pos++;
        } else if(['E', 'I', 'Y'].indexOf(token[pos + 1]) > -1) {
            if(subMatch(1, 3, ['IA', 'IE', 'IO'])) {
                addSecondary('S', 'X');
            } else {
                add('S');
            }
            pos++;
        } else {
            add('K');
            if(token[pos + 1] == ' ' && ['C', 'Q', 'G'].indexOf(token[pos + 2])) {
                pos += 2;
            } else if(['C', 'K', 'Q'].indexOf(token[pos + 1]) > -1
                    && !subMatch(1, 3, ['CE', 'CI'])) {
                pos++;
            }
        }
    }

    function handleD() {
    	if(token[pos + 1] == 'G') {
    		if(['I', 'E', 'Y'].indexOf(token[pos + 2]) > -1)  {
    			add('J');
    			pos += 2;
    		} else {
    			add('TK');
    			pos++;
    		}
	    } else if(token[pos + 1] == 'T') {
    		add('T');
	    	pos++;
    	} else
    		addCompressedDouble('D', 'T');
    }

    function handleG() {
        if(token[pos + 1] == 'H') {
            if(pos > 0 && !isVowel(token[pos - 1])) {
                add('K');
                pos++;
            } else if(pos == 0) {
                if(token[pos + 2] == 'I') {
                    add('J');
                } else {
                    add('K');
                }
                pos++;
            } else if(pos > 1
                && (['B', 'H', 'D'].indexOf(token[pos - 2]) > -1
                    || ['B', 'H', 'D'].indexOf(token[pos - 3]) > -1
                    || ['B', 'H'].indexOf(token[pos - 4]) > -1)) {
                pos++;
            } else {
                if(pos > 2
                        && token[pos - 1] == 'U'
                        && ['C', 'G', 'L', 'R', 'T'].indexOf(token[pos - 3]) > -1) {
                    add('F');
                } else if(token[pos - 1] != 'I') {
                    add('K');
                }

                pos++;
            }
        } else if(token[pos + 1] == 'N') {
            if(pos == 1 && startsWithVowel && !slavoGermanic) {
                addSecondary('KN', 'N');
            } else {
                if(token.substring(pos + 2, pos + 4) != 'EY'
                        && (token[pos + 1] != 'Y'
                            && !slavoGermanic)) {
                    addSecondary('N', 'KN');
                } else
                    add('KN');
            }
            pos++;
        } else if(token.substring(pos + 1, pos + 3) == 'LI' && !slavoGermanic) {
            addSecondary('KL', 'L');
            pos++;
        } else if(pos == 0 && (token[pos + 1] == 'Y'
                || subMatch(1, 3, ['ES', 'EP', 'EB', 'EL', 'EY', 'IB', 'IL', 'IN', 'IE', 'EI', 'ER']))) {
            addSecondary('K', 'J')
        } else {
            addCompressedDouble('G', 'K');
        }
    }

    function handleH() {
		// keep if starts a word or is surrounded by vowels
		if((pos == 0 || isVowel(token[pos - 1])) && isVowel(token[pos + 1])) {
			add('H');
			pos++;
		}
    }

    function handleJ() {
        var jose = (token.substring(pos + 1, pos + 4) == 'OSE');

        if(san || jose) {
            if((pos == 0 && token[pos + 4] == ' ')
                    || san) {
                add('H');
            } else
                add('J', 'H');
        } else {
            if(pos == 0/* && !jose*/) {
                addSecondary('J', 'A');
            } else if(isVowel(token[pos - 1]) && !slavoGermanic
                    && (token[pos + 1] == 'A' || token[pos + 1] == 'O')) {
                addSecondary('J', 'H');
            } else if(pos == token.length - 1) {
                addSecondary('J', ' ');
            } else
                addCompressedDouble('J');
        }
    }

    function handleL() {
    	if(token[pos + 1] == 'L') {
    		if(pos == token.length - 3 && (
    					subMatch(-1, 3, ['ILLO', 'ILLA', 'ALLE']) || (
    						token.substring(pos - 1, pos + 3) == 'ALLE' &&
    						(subMatch(-2, -1, ['AS', 'OS']) > -1 ||
    						['A', 'O'].indexOf(token[token.length - 1]) > -1)))) {
    			addSecondary('L', '');
    			pos++;
    			return;
    		}
    		pos++;
    	}
    	add('L');
    }

    function handleM() {
    	addCompressedDouble('M');
    	if(token[pos - 1] == 'U' && token[pos + 1] == 'B' &&
    			((pos == token.length - 2  || token.substring(pos + 2, pos + 4) == 'ER')))
    		pos++;
    }

    function handleP() {
    	if(token[pos + 1] == 'H') {
    		add('F');
    		pos++;
    	} else {
    		addCompressedDouble('P');

			if(token[pos + 1] == 'B')
    			pos++;
    	}
    }

    function handleR() {
    	if(pos == token.length - 1 && !slavoGermanic
    			&& token.substring(pos - 2, pos) == 'IE'
    			&& !subMatch(-4, -3, ['ME', 'MA'])) {
    		addSecondary('', 'R');
    	} else
	    	addCompressedDouble('R');
    }

    function handleS() {
        if(pos == 0 && token.substring(0, 5) == 'SUGAR') {
            addSecondary('X', 'S');
        } else if(token[pos + 1] == 'H') {
            if(subMatch(2, 5, ['EIM', 'OEK', 'OLM', 'OLZ'])) {
                add('S');
            } else {
                add('X');
            }
            pos++;
        } else if(subMatch(1, 3, ['IO', 'IA'])) {
            if(slavoGermanic) {
                add('S');
            } else {
                addSecondary('S', 'X');
            }
            pos++;
        } else if((pos == 0 && ['M', 'N', 'L', 'W'].indexOf(token[pos + 1]) > -1)
                || token[pos + 1] == 'Z') {
            addSecondary('S', 'X');
            if(token[pos + 1] == 'Z')
                pos++;
        } else if(token.substring(pos, pos + 2) == 'SC') {
            if(token[pos + 2] == 'H') {
                if(subMatch(3, 5, ['ER', 'EN'])) {
                    addSecondary('X', 'SK');
                } else if(subMatch(3, 5, ['OO', 'UY', 'ED', 'EM'])) {
                    add('SK');
                } else if(pos == 0 && !isVowel(token[3]) && token[3] != 'W') {
                    addSecondary('X', 'S');
                } else {
                    add('X');
                }
            } else if(['I', 'E', 'Y'].indexOf(token[pos + 2]) > -1) {
                add('S');
            } else {
                add('SK');
            }

            pos += 2;
        } else if(pos == token.length - 1
                && subMatch(-2, 0, ['AI', 'OI'])) {
            addSecondary('', 'S');
        } else if(token[pos + 1] != 'L' && (
                token[pos - 1] != 'A' && token[pos - 1] != 'I')) {
            addCompressedDouble('S');
            if(token[pos + 1] == 'Z')
                pos++;
        }
    }

    function handleT() {
        if(token.substring(pos + 1, pos + 4) == 'ION') {
            add('XN');
            pos += 3;
        } else if(subMatch(1, 3, ['IA', 'CH'])) {
            add('X');
            pos += 2;
        } else if(token[pos + 1] == 'H'
                || token.substring(1, 2) == 'TH') {
            if(subMatch(2, 4, ['OM', 'AM'])
                    || ['VAN ', 'VON '].indexOf(token.substring(0, 4)) > -1
                    || token.substring(0, 3) == 'SCH') {
                add('T');
            } else
                addSecondary('0', 'T');
            pos++;
        } else {
            addCompressedDouble('T');

            if(token[pos + 1] == 'D')
                pos++;
        }
    }

    function handleX() {
    	if(pos == 0) {
    		add('S');
    	} else if(!(pos == token.length - 1
	    		&& (['IAU', 'EAU', 'IEU'].indexOf(token.substring(pos - 3, pos)) > -1
	    			|| ['AU', 'OU'].indexOf(token.substring(pos - 2, pos)) > -1))) {
    		add('KS');
    	}
    }

    function handleW() {
        if(pos == 0) {
            if(token[1] == 'H') {
                add('A');
            } else if (isVowel(token[1])) {
                addSecondary('A', 'F');
            }
        } else if((pos == token.length - 1 && isVowel(token[pos - 1])
                    || subMatch(-1, 4, ['EWSKI', 'EWSKY', 'OWSKI', 'OWSKY'])
                    || token.substring(0, 3) == 'SCH')) {
                addSecondary('', 'F');
                pos++;
        } else if(['ICZ', 'ITZ'].indexOf(token.substring(pos + 1, pos + 4)) > -1) {
            addSecondary('TS', 'FX');
            pos += 3;
        }
    }

    function handleZ() {
        if(token[pos + 1] == 'H') {
            add('J');
            pos++;
        } else if(subMatch(1, 3, ['ZO', 'ZI', 'ZA'])
                || (slavoGermanic && pos > 0 && token[pos - 1] != 'T')) {
            addSecondary('S', 'TS');
            pos++;
        } else
            addCompressedDouble('Z', 'S');
    }

    var san = (token.substring(0, 3) == 'SAN');
    var startsWithVowel = isVowel(token[0]);
    var slavoGermanic = token.match(/(W|K|CZ|WITZ)/);

    if(subMatch(0, 2, ['GN', 'KN', 'PN', 'WR', 'PS'])) {
    	pos++;
    }

    while(pos < token.length) {

    	switch(token[pos]) {
	        case 'A': case 'E': case 'I': case 'O': case 'U': case 'Y':
	        case 'Ê': case 'É': case 'É': case'À':
		        if(pos == 0)
		        	add('A');
		        break;
		    case 'B':
		    	addCompressedDouble('B', 'P');
		    	break;
            case 'C':
                handleC();
                break;
	        case 'Ç':
	            add("S");
	            break;
	        case 'D':
	        	handleD();
	        	break;
	        case 'F': case 'K': case 'N':
	        	addCompressedDouble(token[pos]);
	        	break;
            case 'G':
                handleG();
                break;
	        case 'H':
	        	handleH();
	        	break;
            case 'J':
                handleJ();
                break;
	        case 'L':
	        	handleL();
	        	break;
	        case 'M':
	        	handleM();
	        	break;
	        case 'Ñ':
	        	add('N');
	        	break;
	        case 'P':
	        	handleP();
	        	break;
	        case 'Q':
	        	addCompressedDouble('Q', 'K');
	        	break;
	        case 'R':
	        	handleR();
	        	break;
            case 'S':
                handleS();
                break;
            case 'T':
                handleT();
                break;
	        case 'V':
	        	addCompressedDouble('V', 'F');
	        	break;
            case 'W':
                handleW();
                break;
	        case 'X':
	        	handleX();
	        	break;
	        case 'Z':
	        	handleZ();
	        	break;
    	}

        if(primary.length >= maxLength && secondary.length >= maxLength) {
            break;
        }

    	pos++;
    }

    return [truncate(primary, maxLength), truncate(secondary, maxLength)];
}

function compare(stringA, stringB) {
    var encodingsA = process(stringA),
        encodingsB = process(stringB);

    return encodingsA[0] == encodingsB[0] ||
        encodingsA[1] == encodingsB[1];
};

DoubleMetaphone.compare = compare
DoubleMetaphone.process = process;
DoubleMetaphone.isVowel = isVowel;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\metaphone.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/phonetics/metaphone.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Phonetic = __webpack_require__(/*! ./phonetic */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\phonetic.js");

function dedup(token) {
    return token.replace(/([^c])\1/g, '$1');
}

function dropInitialLetters(token) {
    if(token.match(/^(kn|gn|pn|ae|wr)/))
        return token.substr(1, token.length - 1);
        
    return token;
}

function dropBafterMAtEnd(token) {
    return token.replace(/mb$/, 'm');
}

function cTransform(token) {
    

    token = token.replace(/([^s]|^)(c)(h)/g, '$1x$3').trim();


    token = token.replace(/cia/g, 'xia');
    token = token.replace(/c(i|e|y)/g, 's$1');
    token = token.replace(/c/g, 'k'); 
    
    return token;
}

function dTransform(token) {
    token = token.replace(/d(ge|gy|gi)/g, 'j$1');
    token = token.replace(/d/g, 't');
    
    return token;
}

function dropG(token) {
    token = token.replace(/gh(^$|[^aeiou])/g, 'h$1');
    token = token.replace(/g(n|ned)$/g, '$1');    
    
    return token;
}

function transformG(token) {
    token = token.replace(/gh/g, 'f'); 
    token = token.replace(/([^g]|^)(g)(i|e|y)/g, '$1j$3');
    token = token.replace(/gg/g, 'g');
    token = token.replace(/g/g, 'k');    
    
    return token;
}

function dropH(token) {
    return token.replace(/([aeiou])h([^aeiou]|$)/g, '$1$2');
}

function transformCK(token) {
    return token.replace(/ck/g, 'k');
}
function transformPH(token) {
    return token.replace(/ph/g, 'f');
}

function transformQ(token) {
    return token.replace(/q/g, 'k');
}

function transformS(token) {
    return token.replace(/s(h|io|ia)/g, 'x$1');
}

function transformT(token) {
    token = token.replace(/t(ia|io)/g, 'x$1');
    token = token.replace(/th/, '0');
    
    return token;
}

function dropT(token) {
    return token.replace(/tch/g, 'ch');
}

function transformV(token) {
    return token.replace(/v/g, 'f');
}

function transformWH(token) {
    return token.replace(/^wh/, 'w');
}

function dropW(token) {
    return token.replace(/w([^aeiou]|$)/g, '$1');
}

function transformX(token) {
    token = token.replace(/^x/, 's');
    token = token.replace(/x/g, 'ks');
    return token;
}

function dropY(token) {
    return token.replace(/y([^aeiou]|$)/g, '$1');
}

function transformZ(token) {
    return token.replace(/z/, 's');
}

function dropVowels(token) {
    return token.charAt(0) + token.substr(1, token.length).replace(/[aeiou]/g, '');
}

var Metaphone = new Phonetic();
module.exports = Metaphone;

Metaphone.process = function(token, maxLength) {
    maxLength == maxLength || 32;
    token = token.toLowerCase();
    token = dedup(token);
    token = dropInitialLetters(token);
    token = dropBafterMAtEnd(token);
    token = transformCK(token);
    token = cTransform(token);
    token = dTransform(token);
    token = dropG(token);
    token = transformG(token);
    token = dropH(token);
    token = transformPH(token);
    token = transformQ(token);
    token = transformS(token);
    token = transformX(token);    
    token = transformT(token);
    token = dropT(token);
    token = transformV(token);
    token = transformWH(token);
    token = dropW(token);
    token = dropY(token);
    token = transformZ(token);
    token = dropVowels(token);
    
    token.toUpperCase();
    if(token.length >= maxLength)
        token = token.substring(0, maxLength);        

    return token.toUpperCase();
};

// expose functions for testing    
Metaphone.dedup = dedup;
Metaphone.dropInitialLetters = dropInitialLetters;
Metaphone.dropBafterMAtEnd = dropBafterMAtEnd;
Metaphone.cTransform = cTransform;
Metaphone.dTransform = dTransform;
Metaphone.dropG = dropG;
Metaphone.transformG = transformG;
Metaphone.dropH = dropH;
Metaphone.transformCK = transformCK;
Metaphone.transformPH = transformPH;
Metaphone.transformQ = transformQ;
Metaphone.transformS = transformS;
Metaphone.transformT = transformT;
Metaphone.dropT = dropT;
Metaphone.transformV = transformV;
Metaphone.transformWH = transformWH;
Metaphone.dropW = dropW;
Metaphone.transformX = transformX;
Metaphone.dropY = dropY;
Metaphone.transformZ = transformZ;
Metaphone.dropVowels = dropVowels;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\phonetic.js":
/*!********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/phonetics/phonetic.js ***!
  \********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer.js"),
    tokenizer = new Tokenizer();

module.exports = function() {
    this.compare = function(stringA, stringB) {
        return this.process(stringA) == this.process(stringB);
    };

    this.attach = function() {
	var phonetic = this;

        String.prototype.soundsLike = function(compareTo) {
            return phonetic.compare(this, compareTo);
        }
        
        String.prototype.phonetics = function() {
            return phonetic.process(this);
        }
	
        String.prototype.tokenizeAndPhoneticize = function(keepStops) {
            var phoneticizedTokens = [];
            
            tokenizer.tokenize(this).forEach(function(token) {
                if(keepStops || stopwords.words.indexOf(token) < 0)
                    phoneticizedTokens.push(token.phonetics());
            });
            
            return phoneticizedTokens;
        }
    };
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\soundex.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/phonetics/soundex.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Phonetic = __webpack_require__(/*! ./phonetic */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\phonetics\\phonetic.js");

function transformLipps(token) {
    return token.replace(/[bfpv]/g, '1');
}

function transformThroats(token) {
    return token.replace(/[cgjkqsxz]/g, '2');
}

function transformToungue(token) {
    return token.replace(/[dt]/g, '3');
}

function transformL(token) {
    return token.replace(/l/g, '4');
}

function transformHum(token) {
    return token.replace(/[mn]/g, '5');
}

function transformR(token) {
    return token.replace(/r/g, '6');
}

function condense(token) {
    return token.replace(/(\d)?\1+/g, '$1');
}

function padRight0(token) {
    if(token.length < 4)
        return token + Array(4 - token.length).join('0');
    else
        return token;
}

function transform(token) {
    return transformLipps(transformThroats(
        transformToungue(transformL(transformHum(transformR(token))))));
}

var SoundEx = new Phonetic();
module.exports = SoundEx;

SoundEx.process = function(token, maxLength) {
    token = token.toLowerCase();    
    var transformed = condense(transform(token.substr(1, token.length - 1))); // anything that isn't a digit goes
    // deal with duplicate INITIAL consonant SOUNDS
    transformed = transformed.replace(new RegExp("^" + transform(token.charAt(0))), '');
    return token.charAt(0).toUpperCase() + padRight0(transformed.replace(/\D/g, '')).substr(0, (maxLength && maxLength - 1) || 3);
};

// export for tests;
SoundEx.transformLipps = transformLipps;
SoundEx.transformThroats = transformThroats;
SoundEx.transformToungue = transformToungue;
SoundEx.transformL = transformL;
SoundEx.transformHum = transformHum;
SoundEx.transformR = transformR;
SoundEx.condense = condense;
SoundEx.padRight0 = padRight0;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\sentiment\\SentimentAnalyzer.js":
/*!*****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/sentiment/SentimentAnalyzer.js ***!
  \*****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
  Copyright (c) 2018, Domingo Martín Mancera, Hugo W.L. ter Doest (based on https://github.com/dmarman/lorca)

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to deal
  in the Software without restriction, including without limitation the rights
  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
  copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
  THE SOFTWARE.
*/

var languageFiles = {
  "afinn" : {
    "English": ["afinn-165", "./English/negations_en.json"],
    "Spanish": ["./Spanish/afinnShortSortedSpanish", "./Spanish/negations_es.json"]
  },
  "senticon": {
    "Spanish": ["./Spanish/senticon_es.json", "./Spanish/negations_es.json"],
    "English": ["./English/senticon_en.json", "./English/negations_en.json"],
    "Galician": ["./Galician/senticon_gl.json", ""],
    "Catalan": ["./Catalan/senticon_ca.json", ""],
    "Basque": ["./Basque/senticon_eu.json", ""]
  },
  "pattern": {
    "Dutch": ["./Dutch/pattern-sentiment-nl.json", "./Dutch/negations_du.json"],
    "Italian": ["./Italian/pattern-sentiment-it.json", ""],
    "English": ["./English/pattern-sentiment-en.json", "./English/negations_en.json"],
    "French": ["./French/pattern-sentiment-fr", ""]
  }
};

class SentimentAnalyzer {

  constructor(language, stemmer, type) {
    this.language = language;
    this.stemmer = stemmer;

    //this.vocabulary = require(languageFiles[type][language][0]);
    this.vocabulary = {};
    if (type === "senticon") {
      Object.keys(this.vocabulary).forEach(word => {
        this.vocabulary[word] = this.vocabulary[word].pol;
      });
    }
    else {
      if (type == "pattern") {
        Object.keys(this.vocabulary).forEach(word => {
          this.vocabulary[word] = this.vocabulary[word].polarity;
        });
        //console.log(JSON.stringify(this.vocabulary, null, 2));
      }
    }

    this.negations = [];
    if (languageFiles[type][language][1] != "") {
      this.negations = __webpack_require__("C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\sentiment sync recursive")(languageFiles[type][language][1]).words;
    }

    if (stemmer) {
      var vocaStemmed = {};
      for(var token in this.vocabulary) {
            vocaStemmed[stemmer.stem(token)] = this.vocabulary[token];
      }
      this.vocabulary = vocaStemmed;
    }
  }

  // words is an array of words (strings)
  getSentiment(words) {
    var score = 0;
    var negator = 1;
    var nrHits = 0;

    words.forEach((token) => {
      var lowerCased = token.toLowerCase();
      if (this.negations.indexOf(lowerCased) > -1) {
        negator = -1;
        nrHits++;
      }
      else {
        // First try without stemming
        if (this.vocabulary[lowerCased] != undefined) {
          score += negator * this.vocabulary[lowerCased];
          nrHits++;
        }
        else {
          if (this.stemmer) {
            var stemmedWord = this.stemmer.stem(lowerCased);
            if(this.vocabulary[stemmedWord] != undefined) {
              score += negator * this.vocabulary[stemmedWord];
              nrHits++;
            }
          }
        }
      }
    });

    score = score / words.length;
    //console.log("Number of hits: " + nrHits);

    return score;
  }

}

module.exports = SentimentAnalyzer;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\spellcheck\\spellcheck.js":
/*!***********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/spellcheck/spellcheck.js ***!
  \***********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {


var Trie = __webpack_require__(/*! ../trie/trie */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\trie\\trie.js");

// Probabilistic spellchecker based on http://norvig.com/spell-correct.html
// The general idea is simple. Given a word, the spellchecker calculates all strings that are some user-defined edit distance away. Of those many candidates, it filters the ones that are not words and then returns an array of possible corrections in order of decreasing probability, based on the edit distance and the candidate's frequency in the input corpus
// Words that are an edit distance of n away from the mispelled word are considered infinitely more probable than words that are of an edit distance >n

// wordlist is a corpus (an array) from which word probabilities are calculated (so something like /usr/share/dict/words (on OSX) will work okay, but real world text will work better)
function Spellcheck(wordlist) {
    this.trie = new Trie();
    this.trie.addStrings(wordlist);
    this.word2frequency = {};
    for(var i in wordlist) {
        if(!this.word2frequency[wordlist[i]]) {
            this.word2frequency[wordlist[i]] = 0;
        }
        this.word2frequency[wordlist[i]]++;
    }
}

Spellcheck.prototype.isCorrect = function(word) {
    return this.trie.contains(word);
}

// Returns a list of suggested corrections, from highest to lowest probability 
// maxDistance is the maximum edit distance 
// According to Norvig, literature suggests that 80% to 95% of spelling errors are an edit distance of 1 away from the correct word. This is good, because there are roughly 54n+25 strings 1 edit distance away from any given string of length n. So after maxDistance = 2, this becomes very slow.
Spellcheck.prototype.getCorrections = function(word, maxDistance) {
    var self = this;
    if(!maxDistance) maxDistance = 1;
    var edits = this.editsWithMaxDistance(word, maxDistance);
    edits = edits.slice(1,edits.length);
    edits = edits.map(function(editList) {
       return editList.filter(function(word) { return self.isCorrect(word); })
                      .map(function(word) { return [word, self.word2frequency[word]]; })
                      .sort(function(a,b) { return a[1] > b[1] ? -1 : 1; })
                      .map(function(wordscore) { return wordscore[0]; });
    });
    var flattened = [];
    for(var i in edits) {
        if(edits[i].length) flattened = flattened.concat(edits[i]);
    }
    return flattened.filter(function (v, i, a) { return a.indexOf(v) == i });
}

// Returns all edits that are 1 edit-distance away from the input word
Spellcheck.prototype.edits = function(word) {
    var alphabet = 'abcdefghijklmnopqrstuvwxyz';
    var edits = [];
    for(var i=0; i<word.length+1; i++) {
        if(i>0) edits.push(word.slice(0,i-1)+word.slice(i,word.length)); // deletes
        if(i>0 && i<word.length+1) edits.push(word.slice(0,i-1) + word.slice(i,i+1) + word.slice(i-1, i) + word.slice(i+1,word.length)); // transposes
        for(var k=0; k<alphabet.length; k++) {
            if(i>0) edits.push(word.slice(0,i-1)+alphabet[k]+word.slice(i,word.length)); // replaces
            edits.push(word.slice(0,i)+alphabet[k]+word.slice(i,word.length)); // inserts
        }
    }
    // Deduplicate edits
    edits = edits.filter(function (v, i, a) { return a.indexOf(v) == i });
    return edits;
}

// Returns all edits that are up to "distance" edit distance away from the input word
Spellcheck.prototype.editsWithMaxDistance = function(word, distance) { 
    return this.editsWithMaxDistanceHelper(distance, [[word]]);
}

Spellcheck.prototype.editsWithMaxDistanceHelper = function(distanceCounter, distance2edits) {
    if(distanceCounter == 0) return distance2edits;
    var currentDepth = distance2edits.length-1;
    var words = distance2edits[currentDepth];
    var edits = this.edits(words[0]);
    distance2edits[currentDepth+1] = [];
    for(var i in words) {
        distance2edits[currentDepth+1] = distance2edits[currentDepth+1].concat(this.edits(words[i]));
    }
    return this.editsWithMaxDistanceHelper(distanceCounter-1, distance2edits);
}

module.exports = Spellcheck;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\base_stemmer_id.js":
/*!*************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/indonesian/base_stemmer_id.js ***!
  \*************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2017, Alif Bhaskoro, Andy Librian, R. Kukuh (Reimplemented from https://github.com/sastrawi/sastrawi)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../../util/stopwords_id */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_id.js");
var Tokenizer = __webpack_require__(/*! ../../tokenizers/aggressive_tokenizer_id */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_id.js");

module.exports = function() {
    var stemmer = this;

    stemmer.stem = function(token) {
        return token;
    };

    stemmer.addStopWord = function(stopWord) {
        stopwords.words.push(stopWord);
    };

    stemmer.addStopWords = function(moreStopWords) {
        stopwords.words = stopwords.words.concat(moreStopWords);
    };

    stemmer.removeStopWord = function(stopWord) {
        this.removeStopWords([stopWord])
    };

    stemmer.removeStopWords = function(moreStopWords) {
        moreStopWords.forEach(function(stopWord){
            var idx = stopwords.words.indexOf(stopWord);
            if (idx >= 0) {
                stopwords.words.splice(idx, 1);
            }
        });

    };


    stemmer.tokenizeAndStem = function(text, keepStops) {
        var stemmedTokens = [];
        var lowercaseText = text.toLowerCase();
        var tokens = new Tokenizer().tokenize(lowercaseText);

        if (keepStops) {
            tokens.forEach(function(token) {
                stemmedTokens.push(stemmer.stem(token));
            });
        }

        else {
            tokens.forEach(function(token) {
                if (stopwords.words.indexOf(token) == -1)
                    stemmedTokens.push(stemmer.stem(token));
            });
        }

        return stemmedTokens;
    };

    stemmer.attach = function() {
        String.prototype.stem = function() {
            return stemmer.stem(this);
        };

        String.prototype.tokenizeAndStem = function(keepStops) {
            return stemmer.tokenizeAndStem(this, keepStops);
        };
    };
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\data\\kata-dasar.json":
/*!***************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/indonesian/data/kata-dasar.json ***!
  \***************************************************************************************************************************************************/
/*! exports provided: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2860, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877, 2878, 2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921, 2922, 2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977, 2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3384, 3385, 3386, 3387, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3408, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3421, 3422, 3423, 3424, 3425, 3426, 3427, 3428, 3429, 3430, 3431, 3432, 3433, 3434, 3435, 3436, 3437, 3438, 3439, 3440, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3449, 3450, 3451, 3452, 3453, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3474, 3475, 3476, 3477, 3478, 3479, 3480, 3481, 3482, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3528, 3529, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3595, 3596, 3597, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3627, 3628, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 3640, 3641, 3642, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3711, 3712, 3713, 3714, 3715, 3716, 3717, 3718, 3719, 3720, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761, 3762, 3763, 3764, 3765, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3774, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3793, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3817, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3830, 3831, 3832, 3833, 3834, 3835, 3836, 3837, 3838, 3839, 3840, 3841, 3842, 3843, 3844, 3845, 3846, 3847, 3848, 3849, 3850, 3851, 3852, 3853, 3854, 3855, 3856, 3857, 3858, 3859, 3860, 3861, 3862, 3863, 3864, 3865, 3866, 3867, 3868, 3869, 3870, 3871, 3872, 3873, 3874, 3875, 3876, 3877, 3878, 3879, 3880, 3881, 3882, 3883, 3884, 3885, 3886, 3887, 3888, 3889, 3890, 3891, 3892, 3893, 3894, 3895, 3896, 3897, 3898, 3899, 3900, 3901, 3902, 3903, 3904, 3905, 3906, 3907, 3908, 3909, 3910, 3911, 3912, 3913, 3914, 3915, 3916, 3917, 3918, 3919, 3920, 3921, 3922, 3923, 3924, 3925, 3926, 3927, 3928, 3929, 3930, 3931, 3932, 3933, 3934, 3935, 3936, 3937, 3938, 3939, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956, 3957, 3958, 3959, 3960, 3961, 3962, 3963, 3964, 3965, 3966, 3967, 3968, 3969, 3970, 3971, 3972, 3973, 3974, 3975, 3976, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3985, 3986, 3987, 3988, 3989, 3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166, 4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4217, 4218, 4219, 4220, 4221, 4222, 4223, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4265, 4266, 4267, 4268, 4269, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4283, 4284, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4296, 4297, 4298, 4299, 4300, 4301, 4302, 4303, 4304, 4305, 4306, 4307, 4308, 4309, 4310, 4311, 4312, 4313, 4314, 4315, 4316, 4317, 4318, 4319, 4320, 4321, 4322, 4323, 4324, 4325, 4326, 4327, 4328, 4329, 4330, 4331, 4332, 4333, 4334, 4335, 4336, 4337, 4338, 4339, 4340, 4341, 4342, 4343, 4344, 4345, 4346, 4347, 4348, 4349, 4350, 4351, 4352, 4353, 4354, 4355, 4356, 4357, 4358, 4359, 4360, 4361, 4362, 4363, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 4374, 4375, 4376, 4377, 4378, 4379, 4380, 4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4401, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4441, 4442, 4443, 4444, 4445, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507, 4508, 4509, 4510, 4511, 4512, 4513, 4514, 4515, 4516, 4517, 4518, 4519, 4520, 4521, 4522, 4523, 4524, 4525, 4526, 4527, 4528, 4529, 4530, 4531, 4532, 4533, 4534, 4535, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4543, 4544, 4545, 4546, 4547, 4548, 4549, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4601, 4602, 4603, 4604, 4605, 4606, 4607, 4608, 4609, 4610, 4611, 4612, 4613, 4614, 4615, 4616, 4617, 4618, 4619, 4620, 4621, 4622, 4623, 4624, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4632, 4633, 4634, 4635, 4636, 4637, 4638, 4639, 4640, 4641, 4642, 4643, 4644, 4645, 4646, 4647, 4648, 4649, 4650, 4651, 4652, 4653, 4654, 4655, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666, 4667, 4668, 4669, 4670, 4671, 4672, 4673, 4674, 4675, 4676, 4677, 4678, 4679, 4680, 4681, 4682, 4683, 4684, 4685, 4686, 4687, 4688, 4689, 4690, 4691, 4692, 4693, 4694, 4695, 4696, 4697, 4698, 4699, 4700, 4701, 4702, 4703, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4734, 4735, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4775, 4776, 4777, 4778, 4779, 4780, 4781, 4782, 4783, 4784, 4785, 4786, 4787, 4788, 4789, 4790, 4791, 4792, 4793, 4794, 4795, 4796, 4797, 4798, 4799, 4800, 4801, 4802, 4803, 4804, 4805, 4806, 4807, 4808, 4809, 4810, 4811, 4812, 4813, 4814, 4815, 4816, 4817, 4818, 4819, 4820, 4821, 4822, 4823, 4824, 4825, 4826, 4827, 4828, 4829, 4830, 4831, 4832, 4833, 4834, 4835, 4836, 4837, 4838, 4839, 4840, 4841, 4842, 4843, 4844, 4845, 4846, 4847, 4848, 4849, 4850, 4851, 4852, 4853, 4854, 4855, 4856, 4857, 4858, 4859, 4860, 4861, 4862, 4863, 4864, 4865, 4866, 4867, 4868, 4869, 4870, 4871, 4872, 4873, 4874, 4875, 4876, 4877, 4878, 4879, 4880, 4881, 4882, 4883, 4884, 4885, 4886, 4887, 4888, 4889, 4890, 4891, 4892, 4893, 4894, 4895, 4896, 4897, 4898, 4899, 4900, 4901, 4902, 4903, 4904, 4905, 4906, 4907, 4908, 4909, 4910, 4911, 4912, 4913, 4914, 4915, 4916, 4917, 4918, 4919, 4920, 4921, 4922, 4923, 4924, 4925, 4926, 4927, 4928, 4929, 4930, 4931, 4932, 4933, 4934, 4935, 4936, 4937, 4938, 4939, 4940, 4941, 4942, 4943, 4944, 4945, 4946, 4947, 4948, 4949, 4950, 4951, 4952, 4953, 4954, 4955, 4956, 4957, 4958, 4959, 4960, 4961, 4962, 4963, 4964, 4965, 4966, 4967, 4968, 4969, 4970, 4971, 4972, 4973, 4974, 4975, 4976, 4977, 4978, 4979, 4980, 4981, 4982, 4983, 4984, 4985, 4986, 4987, 4988, 4989, 4990, 4991, 4992, 4993, 4994, 4995, 4996, 4997, 4998, 4999, 5000, 5001, 5002, 5003, 5004, 5005, 5006, 5007, 5008, 5009, 5010, 5011, 5012, 5013, 5014, 5015, 5016, 5017, 5018, 5019, 5020, 5021, 5022, 5023, 5024, 5025, 5026, 5027, 5028, 5029, 5030, 5031, 5032, 5033, 5034, 5035, 5036, 5037, 5038, 5039, 5040, 5041, 5042, 5043, 5044, 5045, 5046, 5047, 5048, 5049, 5050, 5051, 5052, 5053, 5054, 5055, 5056, 5057, 5058, 5059, 5060, 5061, 5062, 5063, 5064, 5065, 5066, 5067, 5068, 5069, 5070, 5071, 5072, 5073, 5074, 5075, 5076, 5077, 5078, 5079, 5080, 5081, 5082, 5083, 5084, 5085, 5086, 5087, 5088, 5089, 5090, 5091, 5092, 5093, 5094, 5095, 5096, 5097, 5098, 5099, 5100, 5101, 5102, 5103, 5104, 5105, 5106, 5107, 5108, 5109, 5110, 5111, 5112, 5113, 5114, 5115, 5116, 5117, 5118, 5119, 5120, 5121, 5122, 5123, 5124, 5125, 5126, 5127, 5128, 5129, 5130, 5131, 5132, 5133, 5134, 5135, 5136, 5137, 5138, 5139, 5140, 5141, 5142, 5143, 5144, 5145, 5146, 5147, 5148, 5149, 5150, 5151, 5152, 5153, 5154, 5155, 5156, 5157, 5158, 5159, 5160, 5161, 5162, 5163, 5164, 5165, 5166, 5167, 5168, 5169, 5170, 5171, 5172, 5173, 5174, 5175, 5176, 5177, 5178, 5179, 5180, 5181, 5182, 5183, 5184, 5185, 5186, 5187, 5188, 5189, 5190, 5191, 5192, 5193, 5194, 5195, 5196, 5197, 5198, 5199, 5200, 5201, 5202, 5203, 5204, 5205, 5206, 5207, 5208, 5209, 5210, 5211, 5212, 5213, 5214, 5215, 5216, 5217, 5218, 5219, 5220, 5221, 5222, 5223, 5224, 5225, 5226, 5227, 5228, 5229, 5230, 5231, 5232, 5233, 5234, 5235, 5236, 5237, 5238, 5239, 5240, 5241, 5242, 5243, 5244, 5245, 5246, 5247, 5248, 5249, 5250, 5251, 5252, 5253, 5254, 5255, 5256, 5257, 5258, 5259, 5260, 5261, 5262, 5263, 5264, 5265, 5266, 5267, 5268, 5269, 5270, 5271, 5272, 5273, 5274, 5275, 5276, 5277, 5278, 5279, 5280, 5281, 5282, 5283, 5284, 5285, 5286, 5287, 5288, 5289, 5290, 5291, 5292, 5293, 5294, 5295, 5296, 5297, 5298, 5299, 5300, 5301, 5302, 5303, 5304, 5305, 5306, 5307, 5308, 5309, 5310, 5311, 5312, 5313, 5314, 5315, 5316, 5317, 5318, 5319, 5320, 5321, 5322, 5323, 5324, 5325, 5326, 5327, 5328, 5329, 5330, 5331, 5332, 5333, 5334, 5335, 5336, 5337, 5338, 5339, 5340, 5341, 5342, 5343, 5344, 5345, 5346, 5347, 5348, 5349, 5350, 5351, 5352, 5353, 5354, 5355, 5356, 5357, 5358, 5359, 5360, 5361, 5362, 5363, 5364, 5365, 5366, 5367, 5368, 5369, 5370, 5371, 5372, 5373, 5374, 5375, 5376, 5377, 5378, 5379, 5380, 5381, 5382, 5383, 5384, 5385, 5386, 5387, 5388, 5389, 5390, 5391, 5392, 5393, 5394, 5395, 5396, 5397, 5398, 5399, 5400, 5401, 5402, 5403, 5404, 5405, 5406, 5407, 5408, 5409, 5410, 5411, 5412, 5413, 5414, 5415, 5416, 5417, 5418, 5419, 5420, 5421, 5422, 5423, 5424, 5425, 5426, 5427, 5428, 5429, 5430, 5431, 5432, 5433, 5434, 5435, 5436, 5437, 5438, 5439, 5440, 5441, 5442, 5443, 5444, 5445, 5446, 5447, 5448, 5449, 5450, 5451, 5452, 5453, 5454, 5455, 5456, 5457, 5458, 5459, 5460, 5461, 5462, 5463, 5464, 5465, 5466, 5467, 5468, 5469, 5470, 5471, 5472, 5473, 5474, 5475, 5476, 5477, 5478, 5479, 5480, 5481, 5482, 5483, 5484, 5485, 5486, 5487, 5488, 5489, 5490, 5491, 5492, 5493, 5494, 5495, 5496, 5497, 5498, 5499, 5500, 5501, 5502, 5503, 5504, 5505, 5506, 5507, 5508, 5509, 5510, 5511, 5512, 5513, 5514, 5515, 5516, 5517, 5518, 5519, 5520, 5521, 5522, 5523, 5524, 5525, 5526, 5527, 5528, 5529, 5530, 5531, 5532, 5533, 5534, 5535, 5536, 5537, 5538, 5539, 5540, 5541, 5542, 5543, 5544, 5545, 5546, 5547, 5548, 5549, 5550, 5551, 5552, 5553, 5554, 5555, 5556, 5557, 5558, 5559, 5560, 5561, 5562, 5563, 5564, 5565, 5566, 5567, 5568, 5569, 5570, 5571, 5572, 5573, 5574, 5575, 5576, 5577, 5578, 5579, 5580, 5581, 5582, 5583, 5584, 5585, 5586, 5587, 5588, 5589, 5590, 5591, 5592, 5593, 5594, 5595, 5596, 5597, 5598, 5599, 5600, 5601, 5602, 5603, 5604, 5605, 5606, 5607, 5608, 5609, 5610, 5611, 5612, 5613, 5614, 5615, 5616, 5617, 5618, 5619, 5620, 5621, 5622, 5623, 5624, 5625, 5626, 5627, 5628, 5629, 5630, 5631, 5632, 5633, 5634, 5635, 5636, 5637, 5638, 5639, 5640, 5641, 5642, 5643, 5644, 5645, 5646, 5647, 5648, 5649, 5650, 5651, 5652, 5653, 5654, 5655, 5656, 5657, 5658, 5659, 5660, 5661, 5662, 5663, 5664, 5665, 5666, 5667, 5668, 5669, 5670, 5671, 5672, 5673, 5674, 5675, 5676, 5677, 5678, 5679, 5680, 5681, 5682, 5683, 5684, 5685, 5686, 5687, 5688, 5689, 5690, 5691, 5692, 5693, 5694, 5695, 5696, 5697, 5698, 5699, 5700, 5701, 5702, 5703, 5704, 5705, 5706, 5707, 5708, 5709, 5710, 5711, 5712, 5713, 5714, 5715, 5716, 5717, 5718, 5719, 5720, 5721, 5722, 5723, 5724, 5725, 5726, 5727, 5728, 5729, 5730, 5731, 5732, 5733, 5734, 5735, 5736, 5737, 5738, 5739, 5740, 5741, 5742, 5743, 5744, 5745, 5746, 5747, 5748, 5749, 5750, 5751, 5752, 5753, 5754, 5755, 5756, 5757, 5758, 5759, 5760, 5761, 5762, 5763, 5764, 5765, 5766, 5767, 5768, 5769, 5770, 5771, 5772, 5773, 5774, 5775, 5776, 5777, 5778, 5779, 5780, 5781, 5782, 5783, 5784, 5785, 5786, 5787, 5788, 5789, 5790, 5791, 5792, 5793, 5794, 5795, 5796, 5797, 5798, 5799, 5800, 5801, 5802, 5803, 5804, 5805, 5806, 5807, 5808, 5809, 5810, 5811, 5812, 5813, 5814, 5815, 5816, 5817, 5818, 5819, 5820, 5821, 5822, 5823, 5824, 5825, 5826, 5827, 5828, 5829, 5830, 5831, 5832, 5833, 5834, 5835, 5836, 5837, 5838, 5839, 5840, 5841, 5842, 5843, 5844, 5845, 5846, 5847, 5848, 5849, 5850, 5851, 5852, 5853, 5854, 5855, 5856, 5857, 5858, 5859, 5860, 5861, 5862, 5863, 5864, 5865, 5866, 5867, 5868, 5869, 5870, 5871, 5872, 5873, 5874, 5875, 5876, 5877, 5878, 5879, 5880, 5881, 5882, 5883, 5884, 5885, 5886, 5887, 5888, 5889, 5890, 5891, 5892, 5893, 5894, 5895, 5896, 5897, 5898, 5899, 5900, 5901, 5902, 5903, 5904, 5905, 5906, 5907, 5908, 5909, 5910, 5911, 5912, 5913, 5914, 5915, 5916, 5917, 5918, 5919, 5920, 5921, 5922, 5923, 5924, 5925, 5926, 5927, 5928, 5929, 5930, 5931, 5932, 5933, 5934, 5935, 5936, 5937, 5938, 5939, 5940, 5941, 5942, 5943, 5944, 5945, 5946, 5947, 5948, 5949, 5950, 5951, 5952, 5953, 5954, 5955, 5956, 5957, 5958, 5959, 5960, 5961, 5962, 5963, 5964, 5965, 5966, 5967, 5968, 5969, 5970, 5971, 5972, 5973, 5974, 5975, 5976, 5977, 5978, 5979, 5980, 5981, 5982, 5983, 5984, 5985, 5986, 5987, 5988, 5989, 5990, 5991, 5992, 5993, 5994, 5995, 5996, 5997, 5998, 5999, 6000, 6001, 6002, 6003, 6004, 6005, 6006, 6007, 6008, 6009, 6010, 6011, 6012, 6013, 6014, 6015, 6016, 6017, 6018, 6019, 6020, 6021, 6022, 6023, 6024, 6025, 6026, 6027, 6028, 6029, 6030, 6031, 6032, 6033, 6034, 6035, 6036, 6037, 6038, 6039, 6040, 6041, 6042, 6043, 6044, 6045, 6046, 6047, 6048, 6049, 6050, 6051, 6052, 6053, 6054, 6055, 6056, 6057, 6058, 6059, 6060, 6061, 6062, 6063, 6064, 6065, 6066, 6067, 6068, 6069, 6070, 6071, 6072, 6073, 6074, 6075, 6076, 6077, 6078, 6079, 6080, 6081, 6082, 6083, 6084, 6085, 6086, 6087, 6088, 6089, 6090, 6091, 6092, 6093, 6094, 6095, 6096, 6097, 6098, 6099, 6100, 6101, 6102, 6103, 6104, 6105, 6106, 6107, 6108, 6109, 6110, 6111, 6112, 6113, 6114, 6115, 6116, 6117, 6118, 6119, 6120, 6121, 6122, 6123, 6124, 6125, 6126, 6127, 6128, 6129, 6130, 6131, 6132, 6133, 6134, 6135, 6136, 6137, 6138, 6139, 6140, 6141, 6142, 6143, 6144, 6145, 6146, 6147, 6148, 6149, 6150, 6151, 6152, 6153, 6154, 6155, 6156, 6157, 6158, 6159, 6160, 6161, 6162, 6163, 6164, 6165, 6166, 6167, 6168, 6169, 6170, 6171, 6172, 6173, 6174, 6175, 6176, 6177, 6178, 6179, 6180, 6181, 6182, 6183, 6184, 6185, 6186, 6187, 6188, 6189, 6190, 6191, 6192, 6193, 6194, 6195, 6196, 6197, 6198, 6199, 6200, 6201, 6202, 6203, 6204, 6205, 6206, 6207, 6208, 6209, 6210, 6211, 6212, 6213, 6214, 6215, 6216, 6217, 6218, 6219, 6220, 6221, 6222, 6223, 6224, 6225, 6226, 6227, 6228, 6229, 6230, 6231, 6232, 6233, 6234, 6235, 6236, 6237, 6238, 6239, 6240, 6241, 6242, 6243, 6244, 6245, 6246, 6247, 6248, 6249, 6250, 6251, 6252, 6253, 6254, 6255, 6256, 6257, 6258, 6259, 6260, 6261, 6262, 6263, 6264, 6265, 6266, 6267, 6268, 6269, 6270, 6271, 6272, 6273, 6274, 6275, 6276, 6277, 6278, 6279, 6280, 6281, 6282, 6283, 6284, 6285, 6286, 6287, 6288, 6289, 6290, 6291, 6292, 6293, 6294, 6295, 6296, 6297, 6298, 6299, 6300, 6301, 6302, 6303, 6304, 6305, 6306, 6307, 6308, 6309, 6310, 6311, 6312, 6313, 6314, 6315, 6316, 6317, 6318, 6319, 6320, 6321, 6322, 6323, 6324, 6325, 6326, 6327, 6328, 6329, 6330, 6331, 6332, 6333, 6334, 6335, 6336, 6337, 6338, 6339, 6340, 6341, 6342, 6343, 6344, 6345, 6346, 6347, 6348, 6349, 6350, 6351, 6352, 6353, 6354, 6355, 6356, 6357, 6358, 6359, 6360, 6361, 6362, 6363, 6364, 6365, 6366, 6367, 6368, 6369, 6370, 6371, 6372, 6373, 6374, 6375, 6376, 6377, 6378, 6379, 6380, 6381, 6382, 6383, 6384, 6385, 6386, 6387, 6388, 6389, 6390, 6391, 6392, 6393, 6394, 6395, 6396, 6397, 6398, 6399, 6400, 6401, 6402, 6403, 6404, 6405, 6406, 6407, 6408, 6409, 6410, 6411, 6412, 6413, 6414, 6415, 6416, 6417, 6418, 6419, 6420, 6421, 6422, 6423, 6424, 6425, 6426, 6427, 6428, 6429, 6430, 6431, 6432, 6433, 6434, 6435, 6436, 6437, 6438, 6439, 6440, 6441, 6442, 6443, 6444, 6445, 6446, 6447, 6448, 6449, 6450, 6451, 6452, 6453, 6454, 6455, 6456, 6457, 6458, 6459, 6460, 6461, 6462, 6463, 6464, 6465, 6466, 6467, 6468, 6469, 6470, 6471, 6472, 6473, 6474, 6475, 6476, 6477, 6478, 6479, 6480, 6481, 6482, 6483, 6484, 6485, 6486, 6487, 6488, 6489, 6490, 6491, 6492, 6493, 6494, 6495, 6496, 6497, 6498, 6499, 6500, 6501, 6502, 6503, 6504, 6505, 6506, 6507, 6508, 6509, 6510, 6511, 6512, 6513, 6514, 6515, 6516, 6517, 6518, 6519, 6520, 6521, 6522, 6523, 6524, 6525, 6526, 6527, 6528, 6529, 6530, 6531, 6532, 6533, 6534, 6535, 6536, 6537, 6538, 6539, 6540, 6541, 6542, 6543, 6544, 6545, 6546, 6547, 6548, 6549, 6550, 6551, 6552, 6553, 6554, 6555, 6556, 6557, 6558, 6559, 6560, 6561, 6562, 6563, 6564, 6565, 6566, 6567, 6568, 6569, 6570, 6571, 6572, 6573, 6574, 6575, 6576, 6577, 6578, 6579, 6580, 6581, 6582, 6583, 6584, 6585, 6586, 6587, 6588, 6589, 6590, 6591, 6592, 6593, 6594, 6595, 6596, 6597, 6598, 6599, 6600, 6601, 6602, 6603, 6604, 6605, 6606, 6607, 6608, 6609, 6610, 6611, 6612, 6613, 6614, 6615, 6616, 6617, 6618, 6619, 6620, 6621, 6622, 6623, 6624, 6625, 6626, 6627, 6628, 6629, 6630, 6631, 6632, 6633, 6634, 6635, 6636, 6637, 6638, 6639, 6640, 6641, 6642, 6643, 6644, 6645, 6646, 6647, 6648, 6649, 6650, 6651, 6652, 6653, 6654, 6655, 6656, 6657, 6658, 6659, 6660, 6661, 6662, 6663, 6664, 6665, 6666, 6667, 6668, 6669, 6670, 6671, 6672, 6673, 6674, 6675, 6676, 6677, 6678, 6679, 6680, 6681, 6682, 6683, 6684, 6685, 6686, 6687, 6688, 6689, 6690, 6691, 6692, 6693, 6694, 6695, 6696, 6697, 6698, 6699, 6700, 6701, 6702, 6703, 6704, 6705, 6706, 6707, 6708, 6709, 6710, 6711, 6712, 6713, 6714, 6715, 6716, 6717, 6718, 6719, 6720, 6721, 6722, 6723, 6724, 6725, 6726, 6727, 6728, 6729, 6730, 6731, 6732, 6733, 6734, 6735, 6736, 6737, 6738, 6739, 6740, 6741, 6742, 6743, 6744, 6745, 6746, 6747, 6748, 6749, 6750, 6751, 6752, 6753, 6754, 6755, 6756, 6757, 6758, 6759, 6760, 6761, 6762, 6763, 6764, 6765, 6766, 6767, 6768, 6769, 6770, 6771, 6772, 6773, 6774, 6775, 6776, 6777, 6778, 6779, 6780, 6781, 6782, 6783, 6784, 6785, 6786, 6787, 6788, 6789, 6790, 6791, 6792, 6793, 6794, 6795, 6796, 6797, 6798, 6799, 6800, 6801, 6802, 6803, 6804, 6805, 6806, 6807, 6808, 6809, 6810, 6811, 6812, 6813, 6814, 6815, 6816, 6817, 6818, 6819, 6820, 6821, 6822, 6823, 6824, 6825, 6826, 6827, 6828, 6829, 6830, 6831, 6832, 6833, 6834, 6835, 6836, 6837, 6838, 6839, 6840, 6841, 6842, 6843, 6844, 6845, 6846, 6847, 6848, 6849, 6850, 6851, 6852, 6853, 6854, 6855, 6856, 6857, 6858, 6859, 6860, 6861, 6862, 6863, 6864, 6865, 6866, 6867, 6868, 6869, 6870, 6871, 6872, 6873, 6874, 6875, 6876, 6877, 6878, 6879, 6880, 6881, 6882, 6883, 6884, 6885, 6886, 6887, 6888, 6889, 6890, 6891, 6892, 6893, 6894, 6895, 6896, 6897, 6898, 6899, 6900, 6901, 6902, 6903, 6904, 6905, 6906, 6907, 6908, 6909, 6910, 6911, 6912, 6913, 6914, 6915, 6916, 6917, 6918, 6919, 6920, 6921, 6922, 6923, 6924, 6925, 6926, 6927, 6928, 6929, 6930, 6931, 6932, 6933, 6934, 6935, 6936, 6937, 6938, 6939, 6940, 6941, 6942, 6943, 6944, 6945, 6946, 6947, 6948, 6949, 6950, 6951, 6952, 6953, 6954, 6955, 6956, 6957, 6958, 6959, 6960, 6961, 6962, 6963, 6964, 6965, 6966, 6967, 6968, 6969, 6970, 6971, 6972, 6973, 6974, 6975, 6976, 6977, 6978, 6979, 6980, 6981, 6982, 6983, 6984, 6985, 6986, 6987, 6988, 6989, 6990, 6991, 6992, 6993, 6994, 6995, 6996, 6997, 6998, 6999, 7000, 7001, 7002, 7003, 7004, 7005, 7006, 7007, 7008, 7009, 7010, 7011, 7012, 7013, 7014, 7015, 7016, 7017, 7018, 7019, 7020, 7021, 7022, 7023, 7024, 7025, 7026, 7027, 7028, 7029, 7030, 7031, 7032, 7033, 7034, 7035, 7036, 7037, 7038, 7039, 7040, 7041, 7042, 7043, 7044, 7045, 7046, 7047, 7048, 7049, 7050, 7051, 7052, 7053, 7054, 7055, 7056, 7057, 7058, 7059, 7060, 7061, 7062, 7063, 7064, 7065, 7066, 7067, 7068, 7069, 7070, 7071, 7072, 7073, 7074, 7075, 7076, 7077, 7078, 7079, 7080, 7081, 7082, 7083, 7084, 7085, 7086, 7087, 7088, 7089, 7090, 7091, 7092, 7093, 7094, 7095, 7096, 7097, 7098, 7099, 7100, 7101, 7102, 7103, 7104, 7105, 7106, 7107, 7108, 7109, 7110, 7111, 7112, 7113, 7114, 7115, 7116, 7117, 7118, 7119, 7120, 7121, 7122, 7123, 7124, 7125, 7126, 7127, 7128, 7129, 7130, 7131, 7132, 7133, 7134, 7135, 7136, 7137, 7138, 7139, 7140, 7141, 7142, 7143, 7144, 7145, 7146, 7147, 7148, 7149, 7150, 7151, 7152, 7153, 7154, 7155, 7156, 7157, 7158, 7159, 7160, 7161, 7162, 7163, 7164, 7165, 7166, 7167, 7168, 7169, 7170, 7171, 7172, 7173, 7174, 7175, 7176, 7177, 7178, 7179, 7180, 7181, 7182, 7183, 7184, 7185, 7186, 7187, 7188, 7189, 7190, 7191, 7192, 7193, 7194, 7195, 7196, 7197, 7198, 7199, 7200, 7201, 7202, 7203, 7204, 7205, 7206, 7207, 7208, 7209, 7210, 7211, 7212, 7213, 7214, 7215, 7216, 7217, 7218, 7219, 7220, 7221, 7222, 7223, 7224, 7225, 7226, 7227, 7228, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7236, 7237, 7238, 7239, 7240, 7241, 7242, 7243, 7244, 7245, 7246, 7247, 7248, 7249, 7250, 7251, 7252, 7253, 7254, 7255, 7256, 7257, 7258, 7259, 7260, 7261, 7262, 7263, 7264, 7265, 7266, 7267, 7268, 7269, 7270, 7271, 7272, 7273, 7274, 7275, 7276, 7277, 7278, 7279, 7280, 7281, 7282, 7283, 7284, 7285, 7286, 7287, 7288, 7289, 7290, 7291, 7292, 7293, 7294, 7295, 7296, 7297, 7298, 7299, 7300, 7301, 7302, 7303, 7304, 7305, 7306, 7307, 7308, 7309, 7310, 7311, 7312, 7313, 7314, 7315, 7316, 7317, 7318, 7319, 7320, 7321, 7322, 7323, 7324, 7325, 7326, 7327, 7328, 7329, 7330, 7331, 7332, 7333, 7334, 7335, 7336, 7337, 7338, 7339, 7340, 7341, 7342, 7343, 7344, 7345, 7346, 7347, 7348, 7349, 7350, 7351, 7352, 7353, 7354, 7355, 7356, 7357, 7358, 7359, 7360, 7361, 7362, 7363, 7364, 7365, 7366, 7367, 7368, 7369, 7370, 7371, 7372, 7373, 7374, 7375, 7376, 7377, 7378, 7379, 7380, 7381, 7382, 7383, 7384, 7385, 7386, 7387, 7388, 7389, 7390, 7391, 7392, 7393, 7394, 7395, 7396, 7397, 7398, 7399, 7400, 7401, 7402, 7403, 7404, 7405, 7406, 7407, 7408, 7409, 7410, 7411, 7412, 7413, 7414, 7415, 7416, 7417, 7418, 7419, 7420, 7421, 7422, 7423, 7424, 7425, 7426, 7427, 7428, 7429, 7430, 7431, 7432, 7433, 7434, 7435, 7436, 7437, 7438, 7439, 7440, 7441, 7442, 7443, 7444, 7445, 7446, 7447, 7448, 7449, 7450, 7451, 7452, 7453, 7454, 7455, 7456, 7457, 7458, 7459, 7460, 7461, 7462, 7463, 7464, 7465, 7466, 7467, 7468, 7469, 7470, 7471, 7472, 7473, 7474, 7475, 7476, 7477, 7478, 7479, 7480, 7481, 7482, 7483, 7484, 7485, 7486, 7487, 7488, 7489, 7490, 7491, 7492, 7493, 7494, 7495, 7496, 7497, 7498, 7499, 7500, 7501, 7502, 7503, 7504, 7505, 7506, 7507, 7508, 7509, 7510, 7511, 7512, 7513, 7514, 7515, 7516, 7517, 7518, 7519, 7520, 7521, 7522, 7523, 7524, 7525, 7526, 7527, 7528, 7529, 7530, 7531, 7532, 7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7543, 7544, 7545, 7546, 7547, 7548, 7549, 7550, 7551, 7552, 7553, 7554, 7555, 7556, 7557, 7558, 7559, 7560, 7561, 7562, 7563, 7564, 7565, 7566, 7567, 7568, 7569, 7570, 7571, 7572, 7573, 7574, 7575, 7576, 7577, 7578, 7579, 7580, 7581, 7582, 7583, 7584, 7585, 7586, 7587, 7588, 7589, 7590, 7591, 7592, 7593, 7594, 7595, 7596, 7597, 7598, 7599, 7600, 7601, 7602, 7603, 7604, 7605, 7606, 7607, 7608, 7609, 7610, 7611, 7612, 7613, 7614, 7615, 7616, 7617, 7618, 7619, 7620, 7621, 7622, 7623, 7624, 7625, 7626, 7627, 7628, 7629, 7630, 7631, 7632, 7633, 7634, 7635, 7636, 7637, 7638, 7639, 7640, 7641, 7642, 7643, 7644, 7645, 7646, 7647, 7648, 7649, 7650, 7651, 7652, 7653, 7654, 7655, 7656, 7657, 7658, 7659, 7660, 7661, 7662, 7663, 7664, 7665, 7666, 7667, 7668, 7669, 7670, 7671, 7672, 7673, 7674, 7675, 7676, 7677, 7678, 7679, 7680, 7681, 7682, 7683, 7684, 7685, 7686, 7687, 7688, 7689, 7690, 7691, 7692, 7693, 7694, 7695, 7696, 7697, 7698, 7699, 7700, 7701, 7702, 7703, 7704, 7705, 7706, 7707, 7708, 7709, 7710, 7711, 7712, 7713, 7714, 7715, 7716, 7717, 7718, 7719, 7720, 7721, 7722, 7723, 7724, 7725, 7726, 7727, 7728, 7729, 7730, 7731, 7732, 7733, 7734, 7735, 7736, 7737, 7738, 7739, 7740, 7741, 7742, 7743, 7744, 7745, 7746, 7747, 7748, 7749, 7750, 7751, 7752, 7753, 7754, 7755, 7756, 7757, 7758, 7759, 7760, 7761, 7762, 7763, 7764, 7765, 7766, 7767, 7768, 7769, 7770, 7771, 7772, 7773, 7774, 7775, 7776, 7777, 7778, 7779, 7780, 7781, 7782, 7783, 7784, 7785, 7786, 7787, 7788, 7789, 7790, 7791, 7792, 7793, 7794, 7795, 7796, 7797, 7798, 7799, 7800, 7801, 7802, 7803, 7804, 7805, 7806, 7807, 7808, 7809, 7810, 7811, 7812, 7813, 7814, 7815, 7816, 7817, 7818, 7819, 7820, 7821, 7822, 7823, 7824, 7825, 7826, 7827, 7828, 7829, 7830, 7831, 7832, 7833, 7834, 7835, 7836, 7837, 7838, 7839, 7840, 7841, 7842, 7843, 7844, 7845, 7846, 7847, 7848, 7849, 7850, 7851, 7852, 7853, 7854, 7855, 7856, 7857, 7858, 7859, 7860, 7861, 7862, 7863, 7864, 7865, 7866, 7867, 7868, 7869, 7870, 7871, 7872, 7873, 7874, 7875, 7876, 7877, 7878, 7879, 7880, 7881, 7882, 7883, 7884, 7885, 7886, 7887, 7888, 7889, 7890, 7891, 7892, 7893, 7894, 7895, 7896, 7897, 7898, 7899, 7900, 7901, 7902, 7903, 7904, 7905, 7906, 7907, 7908, 7909, 7910, 7911, 7912, 7913, 7914, 7915, 7916, 7917, 7918, 7919, 7920, 7921, 7922, 7923, 7924, 7925, 7926, 7927, 7928, 7929, 7930, 7931, 7932, 7933, 7934, 7935, 7936, 7937, 7938, 7939, 7940, 7941, 7942, 7943, 7944, 7945, 7946, 7947, 7948, 7949, 7950, 7951, 7952, 7953, 7954, 7955, 7956, 7957, 7958, 7959, 7960, 7961, 7962, 7963, 7964, 7965, 7966, 7967, 7968, 7969, 7970, 7971, 7972, 7973, 7974, 7975, 7976, 7977, 7978, 7979, 7980, 7981, 7982, 7983, 7984, 7985, 7986, 7987, 7988, 7989, 7990, 7991, 7992, 7993, 7994, 7995, 7996, 7997, 7998, 7999, 8000, 8001, 8002, 8003, 8004, 8005, 8006, 8007, 8008, 8009, 8010, 8011, 8012, 8013, 8014, 8015, 8016, 8017, 8018, 8019, 8020, 8021, 8022, 8023, 8024, 8025, 8026, 8027, 8028, 8029, 8030, 8031, 8032, 8033, 8034, 8035, 8036, 8037, 8038, 8039, 8040, 8041, 8042, 8043, 8044, 8045, 8046, 8047, 8048, 8049, 8050, 8051, 8052, 8053, 8054, 8055, 8056, 8057, 8058, 8059, 8060, 8061, 8062, 8063, 8064, 8065, 8066, 8067, 8068, 8069, 8070, 8071, 8072, 8073, 8074, 8075, 8076, 8077, 8078, 8079, 8080, 8081, 8082, 8083, 8084, 8085, 8086, 8087, 8088, 8089, 8090, 8091, 8092, 8093, 8094, 8095, 8096, 8097, 8098, 8099, 8100, 8101, 8102, 8103, 8104, 8105, 8106, 8107, 8108, 8109, 8110, 8111, 8112, 8113, 8114, 8115, 8116, 8117, 8118, 8119, 8120, 8121, 8122, 8123, 8124, 8125, 8126, 8127, 8128, 8129, 8130, 8131, 8132, 8133, 8134, 8135, 8136, 8137, 8138, 8139, 8140, 8141, 8142, 8143, 8144, 8145, 8146, 8147, 8148, 8149, 8150, 8151, 8152, 8153, 8154, 8155, 8156, 8157, 8158, 8159, 8160, 8161, 8162, 8163, 8164, 8165, 8166, 8167, 8168, 8169, 8170, 8171, 8172, 8173, 8174, 8175, 8176, 8177, 8178, 8179, 8180, 8181, 8182, 8183, 8184, 8185, 8186, 8187, 8188, 8189, 8190, 8191, 8192, 8193, 8194, 8195, 8196, 8197, 8198, 8199, 8200, 8201, 8202, 8203, 8204, 8205, 8206, 8207, 8208, 8209, 8210, 8211, 8212, 8213, 8214, 8215, 8216, 8217, 8218, 8219, 8220, 8221, 8222, 8223, 8224, 8225, 8226, 8227, 8228, 8229, 8230, 8231, 8232, 8233, 8234, 8235, 8236, 8237, 8238, 8239, 8240, 8241, 8242, 8243, 8244, 8245, 8246, 8247, 8248, 8249, 8250, 8251, 8252, 8253, 8254, 8255, 8256, 8257, 8258, 8259, 8260, 8261, 8262, 8263, 8264, 8265, 8266, 8267, 8268, 8269, 8270, 8271, 8272, 8273, 8274, 8275, 8276, 8277, 8278, 8279, 8280, 8281, 8282, 8283, 8284, 8285, 8286, 8287, 8288, 8289, 8290, 8291, 8292, 8293, 8294, 8295, 8296, 8297, 8298, 8299, 8300, 8301, 8302, 8303, 8304, 8305, 8306, 8307, 8308, 8309, 8310, 8311, 8312, 8313, 8314, 8315, 8316, 8317, 8318, 8319, 8320, 8321, 8322, 8323, 8324, 8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334, 8335, 8336, 8337, 8338, 8339, 8340, 8341, 8342, 8343, 8344, 8345, 8346, 8347, 8348, 8349, 8350, 8351, 8352, 8353, 8354, 8355, 8356, 8357, 8358, 8359, 8360, 8361, 8362, 8363, 8364, 8365, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8374, 8375, 8376, 8377, 8378, 8379, 8380, 8381, 8382, 8383, 8384, 8385, 8386, 8387, 8388, 8389, 8390, 8391, 8392, 8393, 8394, 8395, 8396, 8397, 8398, 8399, 8400, 8401, 8402, 8403, 8404, 8405, 8406, 8407, 8408, 8409, 8410, 8411, 8412, 8413, 8414, 8415, 8416, 8417, 8418, 8419, 8420, 8421, 8422, 8423, 8424, 8425, 8426, 8427, 8428, 8429, 8430, 8431, 8432, 8433, 8434, 8435, 8436, 8437, 8438, 8439, 8440, 8441, 8442, 8443, 8444, 8445, 8446, 8447, 8448, 8449, 8450, 8451, 8452, 8453, 8454, 8455, 8456, 8457, 8458, 8459, 8460, 8461, 8462, 8463, 8464, 8465, 8466, 8467, 8468, 8469, 8470, 8471, 8472, 8473, 8474, 8475, 8476, 8477, 8478, 8479, 8480, 8481, 8482, 8483, 8484, 8485, 8486, 8487, 8488, 8489, 8490, 8491, 8492, 8493, 8494, 8495, 8496, 8497, 8498, 8499, 8500, 8501, 8502, 8503, 8504, 8505, 8506, 8507, 8508, 8509, 8510, 8511, 8512, 8513, 8514, 8515, 8516, 8517, 8518, 8519, 8520, 8521, 8522, 8523, 8524, 8525, 8526, 8527, 8528, 8529, 8530, 8531, 8532, 8533, 8534, 8535, 8536, 8537, 8538, 8539, 8540, 8541, 8542, 8543, 8544, 8545, 8546, 8547, 8548, 8549, 8550, 8551, 8552, 8553, 8554, 8555, 8556, 8557, 8558, 8559, 8560, 8561, 8562, 8563, 8564, 8565, 8566, 8567, 8568, 8569, 8570, 8571, 8572, 8573, 8574, 8575, 8576, 8577, 8578, 8579, 8580, 8581, 8582, 8583, 8584, 8585, 8586, 8587, 8588, 8589, 8590, 8591, 8592, 8593, 8594, 8595, 8596, 8597, 8598, 8599, 8600, 8601, 8602, 8603, 8604, 8605, 8606, 8607, 8608, 8609, 8610, 8611, 8612, 8613, 8614, 8615, 8616, 8617, 8618, 8619, 8620, 8621, 8622, 8623, 8624, 8625, 8626, 8627, 8628, 8629, 8630, 8631, 8632, 8633, 8634, 8635, 8636, 8637, 8638, 8639, 8640, 8641, 8642, 8643, 8644, 8645, 8646, 8647, 8648, 8649, 8650, 8651, 8652, 8653, 8654, 8655, 8656, 8657, 8658, 8659, 8660, 8661, 8662, 8663, 8664, 8665, 8666, 8667, 8668, 8669, 8670, 8671, 8672, 8673, 8674, 8675, 8676, 8677, 8678, 8679, 8680, 8681, 8682, 8683, 8684, 8685, 8686, 8687, 8688, 8689, 8690, 8691, 8692, 8693, 8694, 8695, 8696, 8697, 8698, 8699, 8700, 8701, 8702, 8703, 8704, 8705, 8706, 8707, 8708, 8709, 8710, 8711, 8712, 8713, 8714, 8715, 8716, 8717, 8718, 8719, 8720, 8721, 8722, 8723, 8724, 8725, 8726, 8727, 8728, 8729, 8730, 8731, 8732, 8733, 8734, 8735, 8736, 8737, 8738, 8739, 8740, 8741, 8742, 8743, 8744, 8745, 8746, 8747, 8748, 8749, 8750, 8751, 8752, 8753, 8754, 8755, 8756, 8757, 8758, 8759, 8760, 8761, 8762, 8763, 8764, 8765, 8766, 8767, 8768, 8769, 8770, 8771, 8772, 8773, 8774, 8775, 8776, 8777, 8778, 8779, 8780, 8781, 8782, 8783, 8784, 8785, 8786, 8787, 8788, 8789, 8790, 8791, 8792, 8793, 8794, 8795, 8796, 8797, 8798, 8799, 8800, 8801, 8802, 8803, 8804, 8805, 8806, 8807, 8808, 8809, 8810, 8811, 8812, 8813, 8814, 8815, 8816, 8817, 8818, 8819, 8820, 8821, 8822, 8823, 8824, 8825, 8826, 8827, 8828, 8829, 8830, 8831, 8832, 8833, 8834, 8835, 8836, 8837, 8838, 8839, 8840, 8841, 8842, 8843, 8844, 8845, 8846, 8847, 8848, 8849, 8850, 8851, 8852, 8853, 8854, 8855, 8856, 8857, 8858, 8859, 8860, 8861, 8862, 8863, 8864, 8865, 8866, 8867, 8868, 8869, 8870, 8871, 8872, 8873, 8874, 8875, 8876, 8877, 8878, 8879, 8880, 8881, 8882, 8883, 8884, 8885, 8886, 8887, 8888, 8889, 8890, 8891, 8892, 8893, 8894, 8895, 8896, 8897, 8898, 8899, 8900, 8901, 8902, 8903, 8904, 8905, 8906, 8907, 8908, 8909, 8910, 8911, 8912, 8913, 8914, 8915, 8916, 8917, 8918, 8919, 8920, 8921, 8922, 8923, 8924, 8925, 8926, 8927, 8928, 8929, 8930, 8931, 8932, 8933, 8934, 8935, 8936, 8937, 8938, 8939, 8940, 8941, 8942, 8943, 8944, 8945, 8946, 8947, 8948, 8949, 8950, 8951, 8952, 8953, 8954, 8955, 8956, 8957, 8958, 8959, 8960, 8961, 8962, 8963, 8964, 8965, 8966, 8967, 8968, 8969, 8970, 8971, 8972, 8973, 8974, 8975, 8976, 8977, 8978, 8979, 8980, 8981, 8982, 8983, 8984, 8985, 8986, 8987, 8988, 8989, 8990, 8991, 8992, 8993, 8994, 8995, 8996, 8997, 8998, 8999, 9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016, 9017, 9018, 9019, 9020, 9021, 9022, 9023, 9024, 9025, 9026, 9027, 9028, 9029, 9030, 9031, 9032, 9033, 9034, 9035, 9036, 9037, 9038, 9039, 9040, 9041, 9042, 9043, 9044, 9045, 9046, 9047, 9048, 9049, 9050, 9051, 9052, 9053, 9054, 9055, 9056, 9057, 9058, 9059, 9060, 9061, 9062, 9063, 9064, 9065, 9066, 9067, 9068, 9069, 9070, 9071, 9072, 9073, 9074, 9075, 9076, 9077, 9078, 9079, 9080, 9081, 9082, 9083, 9084, 9085, 9086, 9087, 9088, 9089, 9090, 9091, 9092, 9093, 9094, 9095, 9096, 9097, 9098, 9099, 9100, 9101, 9102, 9103, 9104, 9105, 9106, 9107, 9108, 9109, 9110, 9111, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9120, 9121, 9122, 9123, 9124, 9125, 9126, 9127, 9128, 9129, 9130, 9131, 9132, 9133, 9134, 9135, 9136, 9137, 9138, 9139, 9140, 9141, 9142, 9143, 9144, 9145, 9146, 9147, 9148, 9149, 9150, 9151, 9152, 9153, 9154, 9155, 9156, 9157, 9158, 9159, 9160, 9161, 9162, 9163, 9164, 9165, 9166, 9167, 9168, 9169, 9170, 9171, 9172, 9173, 9174, 9175, 9176, 9177, 9178, 9179, 9180, 9181, 9182, 9183, 9184, 9185, 9186, 9187, 9188, 9189, 9190, 9191, 9192, 9193, 9194, 9195, 9196, 9197, 9198, 9199, 9200, 9201, 9202, 9203, 9204, 9205, 9206, 9207, 9208, 9209, 9210, 9211, 9212, 9213, 9214, 9215, 9216, 9217, 9218, 9219, 9220, 9221, 9222, 9223, 9224, 9225, 9226, 9227, 9228, 9229, 9230, 9231, 9232, 9233, 9234, 9235, 9236, 9237, 9238, 9239, 9240, 9241, 9242, 9243, 9244, 9245, 9246, 9247, 9248, 9249, 9250, 9251, 9252, 9253, 9254, 9255, 9256, 9257, 9258, 9259, 9260, 9261, 9262, 9263, 9264, 9265, 9266, 9267, 9268, 9269, 9270, 9271, 9272, 9273, 9274, 9275, 9276, 9277, 9278, 9279, 9280, 9281, 9282, 9283, 9284, 9285, 9286, 9287, 9288, 9289, 9290, 9291, 9292, 9293, 9294, 9295, 9296, 9297, 9298, 9299, 9300, 9301, 9302, 9303, 9304, 9305, 9306, 9307, 9308, 9309, 9310, 9311, 9312, 9313, 9314, 9315, 9316, 9317, 9318, 9319, 9320, 9321, 9322, 9323, 9324, 9325, 9326, 9327, 9328, 9329, 9330, 9331, 9332, 9333, 9334, 9335, 9336, 9337, 9338, 9339, 9340, 9341, 9342, 9343, 9344, 9345, 9346, 9347, 9348, 9349, 9350, 9351, 9352, 9353, 9354, 9355, 9356, 9357, 9358, 9359, 9360, 9361, 9362, 9363, 9364, 9365, 9366, 9367, 9368, 9369, 9370, 9371, 9372, 9373, 9374, 9375, 9376, 9377, 9378, 9379, 9380, 9381, 9382, 9383, 9384, 9385, 9386, 9387, 9388, 9389, 9390, 9391, 9392, 9393, 9394, 9395, 9396, 9397, 9398, 9399, 9400, 9401, 9402, 9403, 9404, 9405, 9406, 9407, 9408, 9409, 9410, 9411, 9412, 9413, 9414, 9415, 9416, 9417, 9418, 9419, 9420, 9421, 9422, 9423, 9424, 9425, 9426, 9427, 9428, 9429, 9430, 9431, 9432, 9433, 9434, 9435, 9436, 9437, 9438, 9439, 9440, 9441, 9442, 9443, 9444, 9445, 9446, 9447, 9448, 9449, 9450, 9451, 9452, 9453, 9454, 9455, 9456, 9457, 9458, 9459, 9460, 9461, 9462, 9463, 9464, 9465, 9466, 9467, 9468, 9469, 9470, 9471, 9472, 9473, 9474, 9475, 9476, 9477, 9478, 9479, 9480, 9481, 9482, 9483, 9484, 9485, 9486, 9487, 9488, 9489, 9490, 9491, 9492, 9493, 9494, 9495, 9496, 9497, 9498, 9499, 9500, 9501, 9502, 9503, 9504, 9505, 9506, 9507, 9508, 9509, 9510, 9511, 9512, 9513, 9514, 9515, 9516, 9517, 9518, 9519, 9520, 9521, 9522, 9523, 9524, 9525, 9526, 9527, 9528, 9529, 9530, 9531, 9532, 9533, 9534, 9535, 9536, 9537, 9538, 9539, 9540, 9541, 9542, 9543, 9544, 9545, 9546, 9547, 9548, 9549, 9550, 9551, 9552, 9553, 9554, 9555, 9556, 9557, 9558, 9559, 9560, 9561, 9562, 9563, 9564, 9565, 9566, 9567, 9568, 9569, 9570, 9571, 9572, 9573, 9574, 9575, 9576, 9577, 9578, 9579, 9580, 9581, 9582, 9583, 9584, 9585, 9586, 9587, 9588, 9589, 9590, 9591, 9592, 9593, 9594, 9595, 9596, 9597, 9598, 9599, 9600, 9601, 9602, 9603, 9604, 9605, 9606, 9607, 9608, 9609, 9610, 9611, 9612, 9613, 9614, 9615, 9616, 9617, 9618, 9619, 9620, 9621, 9622, 9623, 9624, 9625, 9626, 9627, 9628, 9629, 9630, 9631, 9632, 9633, 9634, 9635, 9636, 9637, 9638, 9639, 9640, 9641, 9642, 9643, 9644, 9645, 9646, 9647, 9648, 9649, 9650, 9651, 9652, 9653, 9654, 9655, 9656, 9657, 9658, 9659, 9660, 9661, 9662, 9663, 9664, 9665, 9666, 9667, 9668, 9669, 9670, 9671, 9672, 9673, 9674, 9675, 9676, 9677, 9678, 9679, 9680, 9681, 9682, 9683, 9684, 9685, 9686, 9687, 9688, 9689, 9690, 9691, 9692, 9693, 9694, 9695, 9696, 9697, 9698, 9699, 9700, 9701, 9702, 9703, 9704, 9705, 9706, 9707, 9708, 9709, 9710, 9711, 9712, 9713, 9714, 9715, 9716, 9717, 9718, 9719, 9720, 9721, 9722, 9723, 9724, 9725, 9726, 9727, 9728, 9729, 9730, 9731, 9732, 9733, 9734, 9735, 9736, 9737, 9738, 9739, 9740, 9741, 9742, 9743, 9744, 9745, 9746, 9747, 9748, 9749, 9750, 9751, 9752, 9753, 9754, 9755, 9756, 9757, 9758, 9759, 9760, 9761, 9762, 9763, 9764, 9765, 9766, 9767, 9768, 9769, 9770, 9771, 9772, 9773, 9774, 9775, 9776, 9777, 9778, 9779, 9780, 9781, 9782, 9783, 9784, 9785, 9786, 9787, 9788, 9789, 9790, 9791, 9792, 9793, 9794, 9795, 9796, 9797, 9798, 9799, 9800, 9801, 9802, 9803, 9804, 9805, 9806, 9807, 9808, 9809, 9810, 9811, 9812, 9813, 9814, 9815, 9816, 9817, 9818, 9819, 9820, 9821, 9822, 9823, 9824, 9825, 9826, 9827, 9828, 9829, 9830, 9831, 9832, 9833, 9834, 9835, 9836, 9837, 9838, 9839, 9840, 9841, 9842, 9843, 9844, 9845, 9846, 9847, 9848, 9849, 9850, 9851, 9852, 9853, 9854, 9855, 9856, 9857, 9858, 9859, 9860, 9861, 9862, 9863, 9864, 9865, 9866, 9867, 9868, 9869, 9870, 9871, 9872, 9873, 9874, 9875, 9876, 9877, 9878, 9879, 9880, 9881, 9882, 9883, 9884, 9885, 9886, 9887, 9888, 9889, 9890, 9891, 9892, 9893, 9894, 9895, 9896, 9897, 9898, 9899, 9900, 9901, 9902, 9903, 9904, 9905, 9906, 9907, 9908, 9909, 9910, 9911, 9912, 9913, 9914, 9915, 9916, 9917, 9918, 9919, 9920, 9921, 9922, 9923, 9924, 9925, 9926, 9927, 9928, 9929, 9930, 9931, 9932, 9933, 9934, 9935, 9936, 9937, 9938, 9939, 9940, 9941, 9942, 9943, 9944, 9945, 9946, 9947, 9948, 9949, 9950, 9951, 9952, 9953, 9954, 9955, 9956, 9957, 9958, 9959, 9960, 9961, 9962, 9963, 9964, 9965, 9966, 9967, 9968, 9969, 9970, 9971, 9972, 9973, 9974, 9975, 9976, 9977, 9978, 9979, 9980, 9981, 9982, 9983, 9984, 9985, 9986, 9987, 9988, 9989, 9990, 9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000, 10001, 10002, 10003, 10004, 10005, 10006, 10007, 10008, 10009, 10010, 10011, 10012, 10013, 10014, 10015, 10016, 10017, 10018, 10019, 10020, 10021, 10022, 10023, 10024, 10025, 10026, 10027, 10028, 10029, 10030, 10031, 10032, 10033, 10034, 10035, 10036, 10037, 10038, 10039, 10040, 10041, 10042, 10043, 10044, 10045, 10046, 10047, 10048, 10049, 10050, 10051, 10052, 10053, 10054, 10055, 10056, 10057, 10058, 10059, 10060, 10061, 10062, 10063, 10064, 10065, 10066, 10067, 10068, 10069, 10070, 10071, 10072, 10073, 10074, 10075, 10076, 10077, 10078, 10079, 10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088, 10089, 10090, 10091, 10092, 10093, 10094, 10095, 10096, 10097, 10098, 10099, 10100, 10101, 10102, 10103, 10104, 10105, 10106, 10107, 10108, 10109, 10110, 10111, 10112, 10113, 10114, 10115, 10116, 10117, 10118, 10119, 10120, 10121, 10122, 10123, 10124, 10125, 10126, 10127, 10128, 10129, 10130, 10131, 10132, 10133, 10134, 10135, 10136, 10137, 10138, 10139, 10140, 10141, 10142, 10143, 10144, 10145, 10146, 10147, 10148, 10149, 10150, 10151, 10152, 10153, 10154, 10155, 10156, 10157, 10158, 10159, 10160, 10161, 10162, 10163, 10164, 10165, 10166, 10167, 10168, 10169, 10170, 10171, 10172, 10173, 10174, 10175, 10176, 10177, 10178, 10179, 10180, 10181, 10182, 10183, 10184, 10185, 10186, 10187, 10188, 10189, 10190, 10191, 10192, 10193, 10194, 10195, 10196, 10197, 10198, 10199, 10200, 10201, 10202, 10203, 10204, 10205, 10206, 10207, 10208, 10209, 10210, 10211, 10212, 10213, 10214, 10215, 10216, 10217, 10218, 10219, 10220, 10221, 10222, 10223, 10224, 10225, 10226, 10227, 10228, 10229, 10230, 10231, 10232, 10233, 10234, 10235, 10236, 10237, 10238, 10239, 10240, 10241, 10242, 10243, 10244, 10245, 10246, 10247, 10248, 10249, 10250, 10251, 10252, 10253, 10254, 10255, 10256, 10257, 10258, 10259, 10260, 10261, 10262, 10263, 10264, 10265, 10266, 10267, 10268, 10269, 10270, 10271, 10272, 10273, 10274, 10275, 10276, 10277, 10278, 10279, 10280, 10281, 10282, 10283, 10284, 10285, 10286, 10287, 10288, 10289, 10290, 10291, 10292, 10293, 10294, 10295, 10296, 10297, 10298, 10299, 10300, 10301, 10302, 10303, 10304, 10305, 10306, 10307, 10308, 10309, 10310, 10311, 10312, 10313, 10314, 10315, 10316, 10317, 10318, 10319, 10320, 10321, 10322, 10323, 10324, 10325, 10326, 10327, 10328, 10329, 10330, 10331, 10332, 10333, 10334, 10335, 10336, 10337, 10338, 10339, 10340, 10341, 10342, 10343, 10344, 10345, 10346, 10347, 10348, 10349, 10350, 10351, 10352, 10353, 10354, 10355, 10356, 10357, 10358, 10359, 10360, 10361, 10362, 10363, 10364, 10365, 10366, 10367, 10368, 10369, 10370, 10371, 10372, 10373, 10374, 10375, 10376, 10377, 10378, 10379, 10380, 10381, 10382, 10383, 10384, 10385, 10386, 10387, 10388, 10389, 10390, 10391, 10392, 10393, 10394, 10395, 10396, 10397, 10398, 10399, 10400, 10401, 10402, 10403, 10404, 10405, 10406, 10407, 10408, 10409, 10410, 10411, 10412, 10413, 10414, 10415, 10416, 10417, 10418, 10419, 10420, 10421, 10422, 10423, 10424, 10425, 10426, 10427, 10428, 10429, 10430, 10431, 10432, 10433, 10434, 10435, 10436, 10437, 10438, 10439, 10440, 10441, 10442, 10443, 10444, 10445, 10446, 10447, 10448, 10449, 10450, 10451, 10452, 10453, 10454, 10455, 10456, 10457, 10458, 10459, 10460, 10461, 10462, 10463, 10464, 10465, 10466, 10467, 10468, 10469, 10470, 10471, 10472, 10473, 10474, 10475, 10476, 10477, 10478, 10479, 10480, 10481, 10482, 10483, 10484, 10485, 10486, 10487, 10488, 10489, 10490, 10491, 10492, 10493, 10494, 10495, 10496, 10497, 10498, 10499, 10500, 10501, 10502, 10503, 10504, 10505, 10506, 10507, 10508, 10509, 10510, 10511, 10512, 10513, 10514, 10515, 10516, 10517, 10518, 10519, 10520, 10521, 10522, 10523, 10524, 10525, 10526, 10527, 10528, 10529, 10530, 10531, 10532, 10533, 10534, 10535, 10536, 10537, 10538, 10539, 10540, 10541, 10542, 10543, 10544, 10545, 10546, 10547, 10548, 10549, 10550, 10551, 10552, 10553, 10554, 10555, 10556, 10557, 10558, 10559, 10560, 10561, 10562, 10563, 10564, 10565, 10566, 10567, 10568, 10569, 10570, 10571, 10572, 10573, 10574, 10575, 10576, 10577, 10578, 10579, 10580, 10581, 10582, 10583, 10584, 10585, 10586, 10587, 10588, 10589, 10590, 10591, 10592, 10593, 10594, 10595, 10596, 10597, 10598, 10599, 10600, 10601, 10602, 10603, 10604, 10605, 10606, 10607, 10608, 10609, 10610, 10611, 10612, 10613, 10614, 10615, 10616, 10617, 10618, 10619, 10620, 10621, 10622, 10623, 10624, 10625, 10626, 10627, 10628, 10629, 10630, 10631, 10632, 10633, 10634, 10635, 10636, 10637, 10638, 10639, 10640, 10641, 10642, 10643, 10644, 10645, 10646, 10647, 10648, 10649, 10650, 10651, 10652, 10653, 10654, 10655, 10656, 10657, 10658, 10659, 10660, 10661, 10662, 10663, 10664, 10665, 10666, 10667, 10668, 10669, 10670, 10671, 10672, 10673, 10674, 10675, 10676, 10677, 10678, 10679, 10680, 10681, 10682, 10683, 10684, 10685, 10686, 10687, 10688, 10689, 10690, 10691, 10692, 10693, 10694, 10695, 10696, 10697, 10698, 10699, 10700, 10701, 10702, 10703, 10704, 10705, 10706, 10707, 10708, 10709, 10710, 10711, 10712, 10713, 10714, 10715, 10716, 10717, 10718, 10719, 10720, 10721, 10722, 10723, 10724, 10725, 10726, 10727, 10728, 10729, 10730, 10731, 10732, 10733, 10734, 10735, 10736, 10737, 10738, 10739, 10740, 10741, 10742, 10743, 10744, 10745, 10746, 10747, 10748, 10749, 10750, 10751, 10752, 10753, 10754, 10755, 10756, 10757, 10758, 10759, 10760, 10761, 10762, 10763, 10764, 10765, 10766, 10767, 10768, 10769, 10770, 10771, 10772, 10773, 10774, 10775, 10776, 10777, 10778, 10779, 10780, 10781, 10782, 10783, 10784, 10785, 10786, 10787, 10788, 10789, 10790, 10791, 10792, 10793, 10794, 10795, 10796, 10797, 10798, 10799, 10800, 10801, 10802, 10803, 10804, 10805, 10806, 10807, 10808, 10809, 10810, 10811, 10812, 10813, 10814, 10815, 10816, 10817, 10818, 10819, 10820, 10821, 10822, 10823, 10824, 10825, 10826, 10827, 10828, 10829, 10830, 10831, 10832, 10833, 10834, 10835, 10836, 10837, 10838, 10839, 10840, 10841, 10842, 10843, 10844, 10845, 10846, 10847, 10848, 10849, 10850, 10851, 10852, 10853, 10854, 10855, 10856, 10857, 10858, 10859, 10860, 10861, 10862, 10863, 10864, 10865, 10866, 10867, 10868, 10869, 10870, 10871, 10872, 10873, 10874, 10875, 10876, 10877, 10878, 10879, 10880, 10881, 10882, 10883, 10884, 10885, 10886, 10887, 10888, 10889, 10890, 10891, 10892, 10893, 10894, 10895, 10896, 10897, 10898, 10899, 10900, 10901, 10902, 10903, 10904, 10905, 10906, 10907, 10908, 10909, 10910, 10911, 10912, 10913, 10914, 10915, 10916, 10917, 10918, 10919, 10920, 10921, 10922, 10923, 10924, 10925, 10926, 10927, 10928, 10929, 10930, 10931, 10932, 10933, 10934, 10935, 10936, 10937, 10938, 10939, 10940, 10941, 10942, 10943, 10944, 10945, 10946, 10947, 10948, 10949, 10950, 10951, 10952, 10953, 10954, 10955, 10956, 10957, 10958, 10959, 10960, 10961, 10962, 10963, 10964, 10965, 10966, 10967, 10968, 10969, 10970, 10971, 10972, 10973, 10974, 10975, 10976, 10977, 10978, 10979, 10980, 10981, 10982, 10983, 10984, 10985, 10986, 10987, 10988, 10989, 10990, 10991, 10992, 10993, 10994, 10995, 10996, 10997, 10998, 10999, 11000, 11001, 11002, 11003, 11004, 11005, 11006, 11007, 11008, 11009, 11010, 11011, 11012, 11013, 11014, 11015, 11016, 11017, 11018, 11019, 11020, 11021, 11022, 11023, 11024, 11025, 11026, 11027, 11028, 11029, 11030, 11031, 11032, 11033, 11034, 11035, 11036, 11037, 11038, 11039, 11040, 11041, 11042, 11043, 11044, 11045, 11046, 11047, 11048, 11049, 11050, 11051, 11052, 11053, 11054, 11055, 11056, 11057, 11058, 11059, 11060, 11061, 11062, 11063, 11064, 11065, 11066, 11067, 11068, 11069, 11070, 11071, 11072, 11073, 11074, 11075, 11076, 11077, 11078, 11079, 11080, 11081, 11082, 11083, 11084, 11085, 11086, 11087, 11088, 11089, 11090, 11091, 11092, 11093, 11094, 11095, 11096, 11097, 11098, 11099, 11100, 11101, 11102, 11103, 11104, 11105, 11106, 11107, 11108, 11109, 11110, 11111, 11112, 11113, 11114, 11115, 11116, 11117, 11118, 11119, 11120, 11121, 11122, 11123, 11124, 11125, 11126, 11127, 11128, 11129, 11130, 11131, 11132, 11133, 11134, 11135, 11136, 11137, 11138, 11139, 11140, 11141, 11142, 11143, 11144, 11145, 11146, 11147, 11148, 11149, 11150, 11151, 11152, 11153, 11154, 11155, 11156, 11157, 11158, 11159, 11160, 11161, 11162, 11163, 11164, 11165, 11166, 11167, 11168, 11169, 11170, 11171, 11172, 11173, 11174, 11175, 11176, 11177, 11178, 11179, 11180, 11181, 11182, 11183, 11184, 11185, 11186, 11187, 11188, 11189, 11190, 11191, 11192, 11193, 11194, 11195, 11196, 11197, 11198, 11199, 11200, 11201, 11202, 11203, 11204, 11205, 11206, 11207, 11208, 11209, 11210, 11211, 11212, 11213, 11214, 11215, 11216, 11217, 11218, 11219, 11220, 11221, 11222, 11223, 11224, 11225, 11226, 11227, 11228, 11229, 11230, 11231, 11232, 11233, 11234, 11235, 11236, 11237, 11238, 11239, 11240, 11241, 11242, 11243, 11244, 11245, 11246, 11247, 11248, 11249, 11250, 11251, 11252, 11253, 11254, 11255, 11256, 11257, 11258, 11259, 11260, 11261, 11262, 11263, 11264, 11265, 11266, 11267, 11268, 11269, 11270, 11271, 11272, 11273, 11274, 11275, 11276, 11277, 11278, 11279, 11280, 11281, 11282, 11283, 11284, 11285, 11286, 11287, 11288, 11289, 11290, 11291, 11292, 11293, 11294, 11295, 11296, 11297, 11298, 11299, 11300, 11301, 11302, 11303, 11304, 11305, 11306, 11307, 11308, 11309, 11310, 11311, 11312, 11313, 11314, 11315, 11316, 11317, 11318, 11319, 11320, 11321, 11322, 11323, 11324, 11325, 11326, 11327, 11328, 11329, 11330, 11331, 11332, 11333, 11334, 11335, 11336, 11337, 11338, 11339, 11340, 11341, 11342, 11343, 11344, 11345, 11346, 11347, 11348, 11349, 11350, 11351, 11352, 11353, 11354, 11355, 11356, 11357, 11358, 11359, 11360, 11361, 11362, 11363, 11364, 11365, 11366, 11367, 11368, 11369, 11370, 11371, 11372, 11373, 11374, 11375, 11376, 11377, 11378, 11379, 11380, 11381, 11382, 11383, 11384, 11385, 11386, 11387, 11388, 11389, 11390, 11391, 11392, 11393, 11394, 11395, 11396, 11397, 11398, 11399, 11400, 11401, 11402, 11403, 11404, 11405, 11406, 11407, 11408, 11409, 11410, 11411, 11412, 11413, 11414, 11415, 11416, 11417, 11418, 11419, 11420, 11421, 11422, 11423, 11424, 11425, 11426, 11427, 11428, 11429, 11430, 11431, 11432, 11433, 11434, 11435, 11436, 11437, 11438, 11439, 11440, 11441, 11442, 11443, 11444, 11445, 11446, 11447, 11448, 11449, 11450, 11451, 11452, 11453, 11454, 11455, 11456, 11457, 11458, 11459, 11460, 11461, 11462, 11463, 11464, 11465, 11466, 11467, 11468, 11469, 11470, 11471, 11472, 11473, 11474, 11475, 11476, 11477, 11478, 11479, 11480, 11481, 11482, 11483, 11484, 11485, 11486, 11487, 11488, 11489, 11490, 11491, 11492, 11493, 11494, 11495, 11496, 11497, 11498, 11499, 11500, 11501, 11502, 11503, 11504, 11505, 11506, 11507, 11508, 11509, 11510, 11511, 11512, 11513, 11514, 11515, 11516, 11517, 11518, 11519, 11520, 11521, 11522, 11523, 11524, 11525, 11526, 11527, 11528, 11529, 11530, 11531, 11532, 11533, 11534, 11535, 11536, 11537, 11538, 11539, 11540, 11541, 11542, 11543, 11544, 11545, 11546, 11547, 11548, 11549, 11550, 11551, 11552, 11553, 11554, 11555, 11556, 11557, 11558, 11559, 11560, 11561, 11562, 11563, 11564, 11565, 11566, 11567, 11568, 11569, 11570, 11571, 11572, 11573, 11574, 11575, 11576, 11577, 11578, 11579, 11580, 11581, 11582, 11583, 11584, 11585, 11586, 11587, 11588, 11589, 11590, 11591, 11592, 11593, 11594, 11595, 11596, 11597, 11598, 11599, 11600, 11601, 11602, 11603, 11604, 11605, 11606, 11607, 11608, 11609, 11610, 11611, 11612, 11613, 11614, 11615, 11616, 11617, 11618, 11619, 11620, 11621, 11622, 11623, 11624, 11625, 11626, 11627, 11628, 11629, 11630, 11631, 11632, 11633, 11634, 11635, 11636, 11637, 11638, 11639, 11640, 11641, 11642, 11643, 11644, 11645, 11646, 11647, 11648, 11649, 11650, 11651, 11652, 11653, 11654, 11655, 11656, 11657, 11658, 11659, 11660, 11661, 11662, 11663, 11664, 11665, 11666, 11667, 11668, 11669, 11670, 11671, 11672, 11673, 11674, 11675, 11676, 11677, 11678, 11679, 11680, 11681, 11682, 11683, 11684, 11685, 11686, 11687, 11688, 11689, 11690, 11691, 11692, 11693, 11694, 11695, 11696, 11697, 11698, 11699, 11700, 11701, 11702, 11703, 11704, 11705, 11706, 11707, 11708, 11709, 11710, 11711, 11712, 11713, 11714, 11715, 11716, 11717, 11718, 11719, 11720, 11721, 11722, 11723, 11724, 11725, 11726, 11727, 11728, 11729, 11730, 11731, 11732, 11733, 11734, 11735, 11736, 11737, 11738, 11739, 11740, 11741, 11742, 11743, 11744, 11745, 11746, 11747, 11748, 11749, 11750, 11751, 11752, 11753, 11754, 11755, 11756, 11757, 11758, 11759, 11760, 11761, 11762, 11763, 11764, 11765, 11766, 11767, 11768, 11769, 11770, 11771, 11772, 11773, 11774, 11775, 11776, 11777, 11778, 11779, 11780, 11781, 11782, 11783, 11784, 11785, 11786, 11787, 11788, 11789, 11790, 11791, 11792, 11793, 11794, 11795, 11796, 11797, 11798, 11799, 11800, 11801, 11802, 11803, 11804, 11805, 11806, 11807, 11808, 11809, 11810, 11811, 11812, 11813, 11814, 11815, 11816, 11817, 11818, 11819, 11820, 11821, 11822, 11823, 11824, 11825, 11826, 11827, 11828, 11829, 11830, 11831, 11832, 11833, 11834, 11835, 11836, 11837, 11838, 11839, 11840, 11841, 11842, 11843, 11844, 11845, 11846, 11847, 11848, 11849, 11850, 11851, 11852, 11853, 11854, 11855, 11856, 11857, 11858, 11859, 11860, 11861, 11862, 11863, 11864, 11865, 11866, 11867, 11868, 11869, 11870, 11871, 11872, 11873, 11874, 11875, 11876, 11877, 11878, 11879, 11880, 11881, 11882, 11883, 11884, 11885, 11886, 11887, 11888, 11889, 11890, 11891, 11892, 11893, 11894, 11895, 11896, 11897, 11898, 11899, 11900, 11901, 11902, 11903, 11904, 11905, 11906, 11907, 11908, 11909, 11910, 11911, 11912, 11913, 11914, 11915, 11916, 11917, 11918, 11919, 11920, 11921, 11922, 11923, 11924, 11925, 11926, 11927, 11928, 11929, 11930, 11931, 11932, 11933, 11934, 11935, 11936, 11937, 11938, 11939, 11940, 11941, 11942, 11943, 11944, 11945, 11946, 11947, 11948, 11949, 11950, 11951, 11952, 11953, 11954, 11955, 11956, 11957, 11958, 11959, 11960, 11961, 11962, 11963, 11964, 11965, 11966, 11967, 11968, 11969, 11970, 11971, 11972, 11973, 11974, 11975, 11976, 11977, 11978, 11979, 11980, 11981, 11982, 11983, 11984, 11985, 11986, 11987, 11988, 11989, 11990, 11991, 11992, 11993, 11994, 11995, 11996, 11997, 11998, 11999, 12000, 12001, 12002, 12003, 12004, 12005, 12006, 12007, 12008, 12009, 12010, 12011, 12012, 12013, 12014, 12015, 12016, 12017, 12018, 12019, 12020, 12021, 12022, 12023, 12024, 12025, 12026, 12027, 12028, 12029, 12030, 12031, 12032, 12033, 12034, 12035, 12036, 12037, 12038, 12039, 12040, 12041, 12042, 12043, 12044, 12045, 12046, 12047, 12048, 12049, 12050, 12051, 12052, 12053, 12054, 12055, 12056, 12057, 12058, 12059, 12060, 12061, 12062, 12063, 12064, 12065, 12066, 12067, 12068, 12069, 12070, 12071, 12072, 12073, 12074, 12075, 12076, 12077, 12078, 12079, 12080, 12081, 12082, 12083, 12084, 12085, 12086, 12087, 12088, 12089, 12090, 12091, 12092, 12093, 12094, 12095, 12096, 12097, 12098, 12099, 12100, 12101, 12102, 12103, 12104, 12105, 12106, 12107, 12108, 12109, 12110, 12111, 12112, 12113, 12114, 12115, 12116, 12117, 12118, 12119, 12120, 12121, 12122, 12123, 12124, 12125, 12126, 12127, 12128, 12129, 12130, 12131, 12132, 12133, 12134, 12135, 12136, 12137, 12138, 12139, 12140, 12141, 12142, 12143, 12144, 12145, 12146, 12147, 12148, 12149, 12150, 12151, 12152, 12153, 12154, 12155, 12156, 12157, 12158, 12159, 12160, 12161, 12162, 12163, 12164, 12165, 12166, 12167, 12168, 12169, 12170, 12171, 12172, 12173, 12174, 12175, 12176, 12177, 12178, 12179, 12180, 12181, 12182, 12183, 12184, 12185, 12186, 12187, 12188, 12189, 12190, 12191, 12192, 12193, 12194, 12195, 12196, 12197, 12198, 12199, 12200, 12201, 12202, 12203, 12204, 12205, 12206, 12207, 12208, 12209, 12210, 12211, 12212, 12213, 12214, 12215, 12216, 12217, 12218, 12219, 12220, 12221, 12222, 12223, 12224, 12225, 12226, 12227, 12228, 12229, 12230, 12231, 12232, 12233, 12234, 12235, 12236, 12237, 12238, 12239, 12240, 12241, 12242, 12243, 12244, 12245, 12246, 12247, 12248, 12249, 12250, 12251, 12252, 12253, 12254, 12255, 12256, 12257, 12258, 12259, 12260, 12261, 12262, 12263, 12264, 12265, 12266, 12267, 12268, 12269, 12270, 12271, 12272, 12273, 12274, 12275, 12276, 12277, 12278, 12279, 12280, 12281, 12282, 12283, 12284, 12285, 12286, 12287, 12288, 12289, 12290, 12291, 12292, 12293, 12294, 12295, 12296, 12297, 12298, 12299, 12300, 12301, 12302, 12303, 12304, 12305, 12306, 12307, 12308, 12309, 12310, 12311, 12312, 12313, 12314, 12315, 12316, 12317, 12318, 12319, 12320, 12321, 12322, 12323, 12324, 12325, 12326, 12327, 12328, 12329, 12330, 12331, 12332, 12333, 12334, 12335, 12336, 12337, 12338, 12339, 12340, 12341, 12342, 12343, 12344, 12345, 12346, 12347, 12348, 12349, 12350, 12351, 12352, 12353, 12354, 12355, 12356, 12357, 12358, 12359, 12360, 12361, 12362, 12363, 12364, 12365, 12366, 12367, 12368, 12369, 12370, 12371, 12372, 12373, 12374, 12375, 12376, 12377, 12378, 12379, 12380, 12381, 12382, 12383, 12384, 12385, 12386, 12387, 12388, 12389, 12390, 12391, 12392, 12393, 12394, 12395, 12396, 12397, 12398, 12399, 12400, 12401, 12402, 12403, 12404, 12405, 12406, 12407, 12408, 12409, 12410, 12411, 12412, 12413, 12414, 12415, 12416, 12417, 12418, 12419, 12420, 12421, 12422, 12423, 12424, 12425, 12426, 12427, 12428, 12429, 12430, 12431, 12432, 12433, 12434, 12435, 12436, 12437, 12438, 12439, 12440, 12441, 12442, 12443, 12444, 12445, 12446, 12447, 12448, 12449, 12450, 12451, 12452, 12453, 12454, 12455, 12456, 12457, 12458, 12459, 12460, 12461, 12462, 12463, 12464, 12465, 12466, 12467, 12468, 12469, 12470, 12471, 12472, 12473, 12474, 12475, 12476, 12477, 12478, 12479, 12480, 12481, 12482, 12483, 12484, 12485, 12486, 12487, 12488, 12489, 12490, 12491, 12492, 12493, 12494, 12495, 12496, 12497, 12498, 12499, 12500, 12501, 12502, 12503, 12504, 12505, 12506, 12507, 12508, 12509, 12510, 12511, 12512, 12513, 12514, 12515, 12516, 12517, 12518, 12519, 12520, 12521, 12522, 12523, 12524, 12525, 12526, 12527, 12528, 12529, 12530, 12531, 12532, 12533, 12534, 12535, 12536, 12537, 12538, 12539, 12540, 12541, 12542, 12543, 12544, 12545, 12546, 12547, 12548, 12549, 12550, 12551, 12552, 12553, 12554, 12555, 12556, 12557, 12558, 12559, 12560, 12561, 12562, 12563, 12564, 12565, 12566, 12567, 12568, 12569, 12570, 12571, 12572, 12573, 12574, 12575, 12576, 12577, 12578, 12579, 12580, 12581, 12582, 12583, 12584, 12585, 12586, 12587, 12588, 12589, 12590, 12591, 12592, 12593, 12594, 12595, 12596, 12597, 12598, 12599, 12600, 12601, 12602, 12603, 12604, 12605, 12606, 12607, 12608, 12609, 12610, 12611, 12612, 12613, 12614, 12615, 12616, 12617, 12618, 12619, 12620, 12621, 12622, 12623, 12624, 12625, 12626, 12627, 12628, 12629, 12630, 12631, 12632, 12633, 12634, 12635, 12636, 12637, 12638, 12639, 12640, 12641, 12642, 12643, 12644, 12645, 12646, 12647, 12648, 12649, 12650, 12651, 12652, 12653, 12654, 12655, 12656, 12657, 12658, 12659, 12660, 12661, 12662, 12663, 12664, 12665, 12666, 12667, 12668, 12669, 12670, 12671, 12672, 12673, 12674, 12675, 12676, 12677, 12678, 12679, 12680, 12681, 12682, 12683, 12684, 12685, 12686, 12687, 12688, 12689, 12690, 12691, 12692, 12693, 12694, 12695, 12696, 12697, 12698, 12699, 12700, 12701, 12702, 12703, 12704, 12705, 12706, 12707, 12708, 12709, 12710, 12711, 12712, 12713, 12714, 12715, 12716, 12717, 12718, 12719, 12720, 12721, 12722, 12723, 12724, 12725, 12726, 12727, 12728, 12729, 12730, 12731, 12732, 12733, 12734, 12735, 12736, 12737, 12738, 12739, 12740, 12741, 12742, 12743, 12744, 12745, 12746, 12747, 12748, 12749, 12750, 12751, 12752, 12753, 12754, 12755, 12756, 12757, 12758, 12759, 12760, 12761, 12762, 12763, 12764, 12765, 12766, 12767, 12768, 12769, 12770, 12771, 12772, 12773, 12774, 12775, 12776, 12777, 12778, 12779, 12780, 12781, 12782, 12783, 12784, 12785, 12786, 12787, 12788, 12789, 12790, 12791, 12792, 12793, 12794, 12795, 12796, 12797, 12798, 12799, 12800, 12801, 12802, 12803, 12804, 12805, 12806, 12807, 12808, 12809, 12810, 12811, 12812, 12813, 12814, 12815, 12816, 12817, 12818, 12819, 12820, 12821, 12822, 12823, 12824, 12825, 12826, 12827, 12828, 12829, 12830, 12831, 12832, 12833, 12834, 12835, 12836, 12837, 12838, 12839, 12840, 12841, 12842, 12843, 12844, 12845, 12846, 12847, 12848, 12849, 12850, 12851, 12852, 12853, 12854, 12855, 12856, 12857, 12858, 12859, 12860, 12861, 12862, 12863, 12864, 12865, 12866, 12867, 12868, 12869, 12870, 12871, 12872, 12873, 12874, 12875, 12876, 12877, 12878, 12879, 12880, 12881, 12882, 12883, 12884, 12885, 12886, 12887, 12888, 12889, 12890, 12891, 12892, 12893, 12894, 12895, 12896, 12897, 12898, 12899, 12900, 12901, 12902, 12903, 12904, 12905, 12906, 12907, 12908, 12909, 12910, 12911, 12912, 12913, 12914, 12915, 12916, 12917, 12918, 12919, 12920, 12921, 12922, 12923, 12924, 12925, 12926, 12927, 12928, 12929, 12930, 12931, 12932, 12933, 12934, 12935, 12936, 12937, 12938, 12939, 12940, 12941, 12942, 12943, 12944, 12945, 12946, 12947, 12948, 12949, 12950, 12951, 12952, 12953, 12954, 12955, 12956, 12957, 12958, 12959, 12960, 12961, 12962, 12963, 12964, 12965, 12966, 12967, 12968, 12969, 12970, 12971, 12972, 12973, 12974, 12975, 12976, 12977, 12978, 12979, 12980, 12981, 12982, 12983, 12984, 12985, 12986, 12987, 12988, 12989, 12990, 12991, 12992, 12993, 12994, 12995, 12996, 12997, 12998, 12999, 13000, 13001, 13002, 13003, 13004, 13005, 13006, 13007, 13008, 13009, 13010, 13011, 13012, 13013, 13014, 13015, 13016, 13017, 13018, 13019, 13020, 13021, 13022, 13023, 13024, 13025, 13026, 13027, 13028, 13029, 13030, 13031, 13032, 13033, 13034, 13035, 13036, 13037, 13038, 13039, 13040, 13041, 13042, 13043, 13044, 13045, 13046, 13047, 13048, 13049, 13050, 13051, 13052, 13053, 13054, 13055, 13056, 13057, 13058, 13059, 13060, 13061, 13062, 13063, 13064, 13065, 13066, 13067, 13068, 13069, 13070, 13071, 13072, 13073, 13074, 13075, 13076, 13077, 13078, 13079, 13080, 13081, 13082, 13083, 13084, 13085, 13086, 13087, 13088, 13089, 13090, 13091, 13092, 13093, 13094, 13095, 13096, 13097, 13098, 13099, 13100, 13101, 13102, 13103, 13104, 13105, 13106, 13107, 13108, 13109, 13110, 13111, 13112, 13113, 13114, 13115, 13116, 13117, 13118, 13119, 13120, 13121, 13122, 13123, 13124, 13125, 13126, 13127, 13128, 13129, 13130, 13131, 13132, 13133, 13134, 13135, 13136, 13137, 13138, 13139, 13140, 13141, 13142, 13143, 13144, 13145, 13146, 13147, 13148, 13149, 13150, 13151, 13152, 13153, 13154, 13155, 13156, 13157, 13158, 13159, 13160, 13161, 13162, 13163, 13164, 13165, 13166, 13167, 13168, 13169, 13170, 13171, 13172, 13173, 13174, 13175, 13176, 13177, 13178, 13179, 13180, 13181, 13182, 13183, 13184, 13185, 13186, 13187, 13188, 13189, 13190, 13191, 13192, 13193, 13194, 13195, 13196, 13197, 13198, 13199, 13200, 13201, 13202, 13203, 13204, 13205, 13206, 13207, 13208, 13209, 13210, 13211, 13212, 13213, 13214, 13215, 13216, 13217, 13218, 13219, 13220, 13221, 13222, 13223, 13224, 13225, 13226, 13227, 13228, 13229, 13230, 13231, 13232, 13233, 13234, 13235, 13236, 13237, 13238, 13239, 13240, 13241, 13242, 13243, 13244, 13245, 13246, 13247, 13248, 13249, 13250, 13251, 13252, 13253, 13254, 13255, 13256, 13257, 13258, 13259, 13260, 13261, 13262, 13263, 13264, 13265, 13266, 13267, 13268, 13269, 13270, 13271, 13272, 13273, 13274, 13275, 13276, 13277, 13278, 13279, 13280, 13281, 13282, 13283, 13284, 13285, 13286, 13287, 13288, 13289, 13290, 13291, 13292, 13293, 13294, 13295, 13296, 13297, 13298, 13299, 13300, 13301, 13302, 13303, 13304, 13305, 13306, 13307, 13308, 13309, 13310, 13311, 13312, 13313, 13314, 13315, 13316, 13317, 13318, 13319, 13320, 13321, 13322, 13323, 13324, 13325, 13326, 13327, 13328, 13329, 13330, 13331, 13332, 13333, 13334, 13335, 13336, 13337, 13338, 13339, 13340, 13341, 13342, 13343, 13344, 13345, 13346, 13347, 13348, 13349, 13350, 13351, 13352, 13353, 13354, 13355, 13356, 13357, 13358, 13359, 13360, 13361, 13362, 13363, 13364, 13365, 13366, 13367, 13368, 13369, 13370, 13371, 13372, 13373, 13374, 13375, 13376, 13377, 13378, 13379, 13380, 13381, 13382, 13383, 13384, 13385, 13386, 13387, 13388, 13389, 13390, 13391, 13392, 13393, 13394, 13395, 13396, 13397, 13398, 13399, 13400, 13401, 13402, 13403, 13404, 13405, 13406, 13407, 13408, 13409, 13410, 13411, 13412, 13413, 13414, 13415, 13416, 13417, 13418, 13419, 13420, 13421, 13422, 13423, 13424, 13425, 13426, 13427, 13428, 13429, 13430, 13431, 13432, 13433, 13434, 13435, 13436, 13437, 13438, 13439, 13440, 13441, 13442, 13443, 13444, 13445, 13446, 13447, 13448, 13449, 13450, 13451, 13452, 13453, 13454, 13455, 13456, 13457, 13458, 13459, 13460, 13461, 13462, 13463, 13464, 13465, 13466, 13467, 13468, 13469, 13470, 13471, 13472, 13473, 13474, 13475, 13476, 13477, 13478, 13479, 13480, 13481, 13482, 13483, 13484, 13485, 13486, 13487, 13488, 13489, 13490, 13491, 13492, 13493, 13494, 13495, 13496, 13497, 13498, 13499, 13500, 13501, 13502, 13503, 13504, 13505, 13506, 13507, 13508, 13509, 13510, 13511, 13512, 13513, 13514, 13515, 13516, 13517, 13518, 13519, 13520, 13521, 13522, 13523, 13524, 13525, 13526, 13527, 13528, 13529, 13530, 13531, 13532, 13533, 13534, 13535, 13536, 13537, 13538, 13539, 13540, 13541, 13542, 13543, 13544, 13545, 13546, 13547, 13548, 13549, 13550, 13551, 13552, 13553, 13554, 13555, 13556, 13557, 13558, 13559, 13560, 13561, 13562, 13563, 13564, 13565, 13566, 13567, 13568, 13569, 13570, 13571, 13572, 13573, 13574, 13575, 13576, 13577, 13578, 13579, 13580, 13581, 13582, 13583, 13584, 13585, 13586, 13587, 13588, 13589, 13590, 13591, 13592, 13593, 13594, 13595, 13596, 13597, 13598, 13599, 13600, 13601, 13602, 13603, 13604, 13605, 13606, 13607, 13608, 13609, 13610, 13611, 13612, 13613, 13614, 13615, 13616, 13617, 13618, 13619, 13620, 13621, 13622, 13623, 13624, 13625, 13626, 13627, 13628, 13629, 13630, 13631, 13632, 13633, 13634, 13635, 13636, 13637, 13638, 13639, 13640, 13641, 13642, 13643, 13644, 13645, 13646, 13647, 13648, 13649, 13650, 13651, 13652, 13653, 13654, 13655, 13656, 13657, 13658, 13659, 13660, 13661, 13662, 13663, 13664, 13665, 13666, 13667, 13668, 13669, 13670, 13671, 13672, 13673, 13674, 13675, 13676, 13677, 13678, 13679, 13680, 13681, 13682, 13683, 13684, 13685, 13686, 13687, 13688, 13689, 13690, 13691, 13692, 13693, 13694, 13695, 13696, 13697, 13698, 13699, 13700, 13701, 13702, 13703, 13704, 13705, 13706, 13707, 13708, 13709, 13710, 13711, 13712, 13713, 13714, 13715, 13716, 13717, 13718, 13719, 13720, 13721, 13722, 13723, 13724, 13725, 13726, 13727, 13728, 13729, 13730, 13731, 13732, 13733, 13734, 13735, 13736, 13737, 13738, 13739, 13740, 13741, 13742, 13743, 13744, 13745, 13746, 13747, 13748, 13749, 13750, 13751, 13752, 13753, 13754, 13755, 13756, 13757, 13758, 13759, 13760, 13761, 13762, 13763, 13764, 13765, 13766, 13767, 13768, 13769, 13770, 13771, 13772, 13773, 13774, 13775, 13776, 13777, 13778, 13779, 13780, 13781, 13782, 13783, 13784, 13785, 13786, 13787, 13788, 13789, 13790, 13791, 13792, 13793, 13794, 13795, 13796, 13797, 13798, 13799, 13800, 13801, 13802, 13803, 13804, 13805, 13806, 13807, 13808, 13809, 13810, 13811, 13812, 13813, 13814, 13815, 13816, 13817, 13818, 13819, 13820, 13821, 13822, 13823, 13824, 13825, 13826, 13827, 13828, 13829, 13830, 13831, 13832, 13833, 13834, 13835, 13836, 13837, 13838, 13839, 13840, 13841, 13842, 13843, 13844, 13845, 13846, 13847, 13848, 13849, 13850, 13851, 13852, 13853, 13854, 13855, 13856, 13857, 13858, 13859, 13860, 13861, 13862, 13863, 13864, 13865, 13866, 13867, 13868, 13869, 13870, 13871, 13872, 13873, 13874, 13875, 13876, 13877, 13878, 13879, 13880, 13881, 13882, 13883, 13884, 13885, 13886, 13887, 13888, 13889, 13890, 13891, 13892, 13893, 13894, 13895, 13896, 13897, 13898, 13899, 13900, 13901, 13902, 13903, 13904, 13905, 13906, 13907, 13908, 13909, 13910, 13911, 13912, 13913, 13914, 13915, 13916, 13917, 13918, 13919, 13920, 13921, 13922, 13923, 13924, 13925, 13926, 13927, 13928, 13929, 13930, 13931, 13932, 13933, 13934, 13935, 13936, 13937, 13938, 13939, 13940, 13941, 13942, 13943, 13944, 13945, 13946, 13947, 13948, 13949, 13950, 13951, 13952, 13953, 13954, 13955, 13956, 13957, 13958, 13959, 13960, 13961, 13962, 13963, 13964, 13965, 13966, 13967, 13968, 13969, 13970, 13971, 13972, 13973, 13974, 13975, 13976, 13977, 13978, 13979, 13980, 13981, 13982, 13983, 13984, 13985, 13986, 13987, 13988, 13989, 13990, 13991, 13992, 13993, 13994, 13995, 13996, 13997, 13998, 13999, 14000, 14001, 14002, 14003, 14004, 14005, 14006, 14007, 14008, 14009, 14010, 14011, 14012, 14013, 14014, 14015, 14016, 14017, 14018, 14019, 14020, 14021, 14022, 14023, 14024, 14025, 14026, 14027, 14028, 14029, 14030, 14031, 14032, 14033, 14034, 14035, 14036, 14037, 14038, 14039, 14040, 14041, 14042, 14043, 14044, 14045, 14046, 14047, 14048, 14049, 14050, 14051, 14052, 14053, 14054, 14055, 14056, 14057, 14058, 14059, 14060, 14061, 14062, 14063, 14064, 14065, 14066, 14067, 14068, 14069, 14070, 14071, 14072, 14073, 14074, 14075, 14076, 14077, 14078, 14079, 14080, 14081, 14082, 14083, 14084, 14085, 14086, 14087, 14088, 14089, 14090, 14091, 14092, 14093, 14094, 14095, 14096, 14097, 14098, 14099, 14100, 14101, 14102, 14103, 14104, 14105, 14106, 14107, 14108, 14109, 14110, 14111, 14112, 14113, 14114, 14115, 14116, 14117, 14118, 14119, 14120, 14121, 14122, 14123, 14124, 14125, 14126, 14127, 14128, 14129, 14130, 14131, 14132, 14133, 14134, 14135, 14136, 14137, 14138, 14139, 14140, 14141, 14142, 14143, 14144, 14145, 14146, 14147, 14148, 14149, 14150, 14151, 14152, 14153, 14154, 14155, 14156, 14157, 14158, 14159, 14160, 14161, 14162, 14163, 14164, 14165, 14166, 14167, 14168, 14169, 14170, 14171, 14172, 14173, 14174, 14175, 14176, 14177, 14178, 14179, 14180, 14181, 14182, 14183, 14184, 14185, 14186, 14187, 14188, 14189, 14190, 14191, 14192, 14193, 14194, 14195, 14196, 14197, 14198, 14199, 14200, 14201, 14202, 14203, 14204, 14205, 14206, 14207, 14208, 14209, 14210, 14211, 14212, 14213, 14214, 14215, 14216, 14217, 14218, 14219, 14220, 14221, 14222, 14223, 14224, 14225, 14226, 14227, 14228, 14229, 14230, 14231, 14232, 14233, 14234, 14235, 14236, 14237, 14238, 14239, 14240, 14241, 14242, 14243, 14244, 14245, 14246, 14247, 14248, 14249, 14250, 14251, 14252, 14253, 14254, 14255, 14256, 14257, 14258, 14259, 14260, 14261, 14262, 14263, 14264, 14265, 14266, 14267, 14268, 14269, 14270, 14271, 14272, 14273, 14274, 14275, 14276, 14277, 14278, 14279, 14280, 14281, 14282, 14283, 14284, 14285, 14286, 14287, 14288, 14289, 14290, 14291, 14292, 14293, 14294, 14295, 14296, 14297, 14298, 14299, 14300, 14301, 14302, 14303, 14304, 14305, 14306, 14307, 14308, 14309, 14310, 14311, 14312, 14313, 14314, 14315, 14316, 14317, 14318, 14319, 14320, 14321, 14322, 14323, 14324, 14325, 14326, 14327, 14328, 14329, 14330, 14331, 14332, 14333, 14334, 14335, 14336, 14337, 14338, 14339, 14340, 14341, 14342, 14343, 14344, 14345, 14346, 14347, 14348, 14349, 14350, 14351, 14352, 14353, 14354, 14355, 14356, 14357, 14358, 14359, 14360, 14361, 14362, 14363, 14364, 14365, 14366, 14367, 14368, 14369, 14370, 14371, 14372, 14373, 14374, 14375, 14376, 14377, 14378, 14379, 14380, 14381, 14382, 14383, 14384, 14385, 14386, 14387, 14388, 14389, 14390, 14391, 14392, 14393, 14394, 14395, 14396, 14397, 14398, 14399, 14400, 14401, 14402, 14403, 14404, 14405, 14406, 14407, 14408, 14409, 14410, 14411, 14412, 14413, 14414, 14415, 14416, 14417, 14418, 14419, 14420, 14421, 14422, 14423, 14424, 14425, 14426, 14427, 14428, 14429, 14430, 14431, 14432, 14433, 14434, 14435, 14436, 14437, 14438, 14439, 14440, 14441, 14442, 14443, 14444, 14445, 14446, 14447, 14448, 14449, 14450, 14451, 14452, 14453, 14454, 14455, 14456, 14457, 14458, 14459, 14460, 14461, 14462, 14463, 14464, 14465, 14466, 14467, 14468, 14469, 14470, 14471, 14472, 14473, 14474, 14475, 14476, 14477, 14478, 14479, 14480, 14481, 14482, 14483, 14484, 14485, 14486, 14487, 14488, 14489, 14490, 14491, 14492, 14493, 14494, 14495, 14496, 14497, 14498, 14499, 14500, 14501, 14502, 14503, 14504, 14505, 14506, 14507, 14508, 14509, 14510, 14511, 14512, 14513, 14514, 14515, 14516, 14517, 14518, 14519, 14520, 14521, 14522, 14523, 14524, 14525, 14526, 14527, 14528, 14529, 14530, 14531, 14532, 14533, 14534, 14535, 14536, 14537, 14538, 14539, 14540, 14541, 14542, 14543, 14544, 14545, 14546, 14547, 14548, 14549, 14550, 14551, 14552, 14553, 14554, 14555, 14556, 14557, 14558, 14559, 14560, 14561, 14562, 14563, 14564, 14565, 14566, 14567, 14568, 14569, 14570, 14571, 14572, 14573, 14574, 14575, 14576, 14577, 14578, 14579, 14580, 14581, 14582, 14583, 14584, 14585, 14586, 14587, 14588, 14589, 14590, 14591, 14592, 14593, 14594, 14595, 14596, 14597, 14598, 14599, 14600, 14601, 14602, 14603, 14604, 14605, 14606, 14607, 14608, 14609, 14610, 14611, 14612, 14613, 14614, 14615, 14616, 14617, 14618, 14619, 14620, 14621, 14622, 14623, 14624, 14625, 14626, 14627, 14628, 14629, 14630, 14631, 14632, 14633, 14634, 14635, 14636, 14637, 14638, 14639, 14640, 14641, 14642, 14643, 14644, 14645, 14646, 14647, 14648, 14649, 14650, 14651, 14652, 14653, 14654, 14655, 14656, 14657, 14658, 14659, 14660, 14661, 14662, 14663, 14664, 14665, 14666, 14667, 14668, 14669, 14670, 14671, 14672, 14673, 14674, 14675, 14676, 14677, 14678, 14679, 14680, 14681, 14682, 14683, 14684, 14685, 14686, 14687, 14688, 14689, 14690, 14691, 14692, 14693, 14694, 14695, 14696, 14697, 14698, 14699, 14700, 14701, 14702, 14703, 14704, 14705, 14706, 14707, 14708, 14709, 14710, 14711, 14712, 14713, 14714, 14715, 14716, 14717, 14718, 14719, 14720, 14721, 14722, 14723, 14724, 14725, 14726, 14727, 14728, 14729, 14730, 14731, 14732, 14733, 14734, 14735, 14736, 14737, 14738, 14739, 14740, 14741, 14742, 14743, 14744, 14745, 14746, 14747, 14748, 14749, 14750, 14751, 14752, 14753, 14754, 14755, 14756, 14757, 14758, 14759, 14760, 14761, 14762, 14763, 14764, 14765, 14766, 14767, 14768, 14769, 14770, 14771, 14772, 14773, 14774, 14775, 14776, 14777, 14778, 14779, 14780, 14781, 14782, 14783, 14784, 14785, 14786, 14787, 14788, 14789, 14790, 14791, 14792, 14793, 14794, 14795, 14796, 14797, 14798, 14799, 14800, 14801, 14802, 14803, 14804, 14805, 14806, 14807, 14808, 14809, 14810, 14811, 14812, 14813, 14814, 14815, 14816, 14817, 14818, 14819, 14820, 14821, 14822, 14823, 14824, 14825, 14826, 14827, 14828, 14829, 14830, 14831, 14832, 14833, 14834, 14835, 14836, 14837, 14838, 14839, 14840, 14841, 14842, 14843, 14844, 14845, 14846, 14847, 14848, 14849, 14850, 14851, 14852, 14853, 14854, 14855, 14856, 14857, 14858, 14859, 14860, 14861, 14862, 14863, 14864, 14865, 14866, 14867, 14868, 14869, 14870, 14871, 14872, 14873, 14874, 14875, 14876, 14877, 14878, 14879, 14880, 14881, 14882, 14883, 14884, 14885, 14886, 14887, 14888, 14889, 14890, 14891, 14892, 14893, 14894, 14895, 14896, 14897, 14898, 14899, 14900, 14901, 14902, 14903, 14904, 14905, 14906, 14907, 14908, 14909, 14910, 14911, 14912, 14913, 14914, 14915, 14916, 14917, 14918, 14919, 14920, 14921, 14922, 14923, 14924, 14925, 14926, 14927, 14928, 14929, 14930, 14931, 14932, 14933, 14934, 14935, 14936, 14937, 14938, 14939, 14940, 14941, 14942, 14943, 14944, 14945, 14946, 14947, 14948, 14949, 14950, 14951, 14952, 14953, 14954, 14955, 14956, 14957, 14958, 14959, 14960, 14961, 14962, 14963, 14964, 14965, 14966, 14967, 14968, 14969, 14970, 14971, 14972, 14973, 14974, 14975, 14976, 14977, 14978, 14979, 14980, 14981, 14982, 14983, 14984, 14985, 14986, 14987, 14988, 14989, 14990, 14991, 14992, 14993, 14994, 14995, 14996, 14997, 14998, 14999, 15000, 15001, 15002, 15003, 15004, 15005, 15006, 15007, 15008, 15009, 15010, 15011, 15012, 15013, 15014, 15015, 15016, 15017, 15018, 15019, 15020, 15021, 15022, 15023, 15024, 15025, 15026, 15027, 15028, 15029, 15030, 15031, 15032, 15033, 15034, 15035, 15036, 15037, 15038, 15039, 15040, 15041, 15042, 15043, 15044, 15045, 15046, 15047, 15048, 15049, 15050, 15051, 15052, 15053, 15054, 15055, 15056, 15057, 15058, 15059, 15060, 15061, 15062, 15063, 15064, 15065, 15066, 15067, 15068, 15069, 15070, 15071, 15072, 15073, 15074, 15075, 15076, 15077, 15078, 15079, 15080, 15081, 15082, 15083, 15084, 15085, 15086, 15087, 15088, 15089, 15090, 15091, 15092, 15093, 15094, 15095, 15096, 15097, 15098, 15099, 15100, 15101, 15102, 15103, 15104, 15105, 15106, 15107, 15108, 15109, 15110, 15111, 15112, 15113, 15114, 15115, 15116, 15117, 15118, 15119, 15120, 15121, 15122, 15123, 15124, 15125, 15126, 15127, 15128, 15129, 15130, 15131, 15132, 15133, 15134, 15135, 15136, 15137, 15138, 15139, 15140, 15141, 15142, 15143, 15144, 15145, 15146, 15147, 15148, 15149, 15150, 15151, 15152, 15153, 15154, 15155, 15156, 15157, 15158, 15159, 15160, 15161, 15162, 15163, 15164, 15165, 15166, 15167, 15168, 15169, 15170, 15171, 15172, 15173, 15174, 15175, 15176, 15177, 15178, 15179, 15180, 15181, 15182, 15183, 15184, 15185, 15186, 15187, 15188, 15189, 15190, 15191, 15192, 15193, 15194, 15195, 15196, 15197, 15198, 15199, 15200, 15201, 15202, 15203, 15204, 15205, 15206, 15207, 15208, 15209, 15210, 15211, 15212, 15213, 15214, 15215, 15216, 15217, 15218, 15219, 15220, 15221, 15222, 15223, 15224, 15225, 15226, 15227, 15228, 15229, 15230, 15231, 15232, 15233, 15234, 15235, 15236, 15237, 15238, 15239, 15240, 15241, 15242, 15243, 15244, 15245, 15246, 15247, 15248, 15249, 15250, 15251, 15252, 15253, 15254, 15255, 15256, 15257, 15258, 15259, 15260, 15261, 15262, 15263, 15264, 15265, 15266, 15267, 15268, 15269, 15270, 15271, 15272, 15273, 15274, 15275, 15276, 15277, 15278, 15279, 15280, 15281, 15282, 15283, 15284, 15285, 15286, 15287, 15288, 15289, 15290, 15291, 15292, 15293, 15294, 15295, 15296, 15297, 15298, 15299, 15300, 15301, 15302, 15303, 15304, 15305, 15306, 15307, 15308, 15309, 15310, 15311, 15312, 15313, 15314, 15315, 15316, 15317, 15318, 15319, 15320, 15321, 15322, 15323, 15324, 15325, 15326, 15327, 15328, 15329, 15330, 15331, 15332, 15333, 15334, 15335, 15336, 15337, 15338, 15339, 15340, 15341, 15342, 15343, 15344, 15345, 15346, 15347, 15348, 15349, 15350, 15351, 15352, 15353, 15354, 15355, 15356, 15357, 15358, 15359, 15360, 15361, 15362, 15363, 15364, 15365, 15366, 15367, 15368, 15369, 15370, 15371, 15372, 15373, 15374, 15375, 15376, 15377, 15378, 15379, 15380, 15381, 15382, 15383, 15384, 15385, 15386, 15387, 15388, 15389, 15390, 15391, 15392, 15393, 15394, 15395, 15396, 15397, 15398, 15399, 15400, 15401, 15402, 15403, 15404, 15405, 15406, 15407, 15408, 15409, 15410, 15411, 15412, 15413, 15414, 15415, 15416, 15417, 15418, 15419, 15420, 15421, 15422, 15423, 15424, 15425, 15426, 15427, 15428, 15429, 15430, 15431, 15432, 15433, 15434, 15435, 15436, 15437, 15438, 15439, 15440, 15441, 15442, 15443, 15444, 15445, 15446, 15447, 15448, 15449, 15450, 15451, 15452, 15453, 15454, 15455, 15456, 15457, 15458, 15459, 15460, 15461, 15462, 15463, 15464, 15465, 15466, 15467, 15468, 15469, 15470, 15471, 15472, 15473, 15474, 15475, 15476, 15477, 15478, 15479, 15480, 15481, 15482, 15483, 15484, 15485, 15486, 15487, 15488, 15489, 15490, 15491, 15492, 15493, 15494, 15495, 15496, 15497, 15498, 15499, 15500, 15501, 15502, 15503, 15504, 15505, 15506, 15507, 15508, 15509, 15510, 15511, 15512, 15513, 15514, 15515, 15516, 15517, 15518, 15519, 15520, 15521, 15522, 15523, 15524, 15525, 15526, 15527, 15528, 15529, 15530, 15531, 15532, 15533, 15534, 15535, 15536, 15537, 15538, 15539, 15540, 15541, 15542, 15543, 15544, 15545, 15546, 15547, 15548, 15549, 15550, 15551, 15552, 15553, 15554, 15555, 15556, 15557, 15558, 15559, 15560, 15561, 15562, 15563, 15564, 15565, 15566, 15567, 15568, 15569, 15570, 15571, 15572, 15573, 15574, 15575, 15576, 15577, 15578, 15579, 15580, 15581, 15582, 15583, 15584, 15585, 15586, 15587, 15588, 15589, 15590, 15591, 15592, 15593, 15594, 15595, 15596, 15597, 15598, 15599, 15600, 15601, 15602, 15603, 15604, 15605, 15606, 15607, 15608, 15609, 15610, 15611, 15612, 15613, 15614, 15615, 15616, 15617, 15618, 15619, 15620, 15621, 15622, 15623, 15624, 15625, 15626, 15627, 15628, 15629, 15630, 15631, 15632, 15633, 15634, 15635, 15636, 15637, 15638, 15639, 15640, 15641, 15642, 15643, 15644, 15645, 15646, 15647, 15648, 15649, 15650, 15651, 15652, 15653, 15654, 15655, 15656, 15657, 15658, 15659, 15660, 15661, 15662, 15663, 15664, 15665, 15666, 15667, 15668, 15669, 15670, 15671, 15672, 15673, 15674, 15675, 15676, 15677, 15678, 15679, 15680, 15681, 15682, 15683, 15684, 15685, 15686, 15687, 15688, 15689, 15690, 15691, 15692, 15693, 15694, 15695, 15696, 15697, 15698, 15699, 15700, 15701, 15702, 15703, 15704, 15705, 15706, 15707, 15708, 15709, 15710, 15711, 15712, 15713, 15714, 15715, 15716, 15717, 15718, 15719, 15720, 15721, 15722, 15723, 15724, 15725, 15726, 15727, 15728, 15729, 15730, 15731, 15732, 15733, 15734, 15735, 15736, 15737, 15738, 15739, 15740, 15741, 15742, 15743, 15744, 15745, 15746, 15747, 15748, 15749, 15750, 15751, 15752, 15753, 15754, 15755, 15756, 15757, 15758, 15759, 15760, 15761, 15762, 15763, 15764, 15765, 15766, 15767, 15768, 15769, 15770, 15771, 15772, 15773, 15774, 15775, 15776, 15777, 15778, 15779, 15780, 15781, 15782, 15783, 15784, 15785, 15786, 15787, 15788, 15789, 15790, 15791, 15792, 15793, 15794, 15795, 15796, 15797, 15798, 15799, 15800, 15801, 15802, 15803, 15804, 15805, 15806, 15807, 15808, 15809, 15810, 15811, 15812, 15813, 15814, 15815, 15816, 15817, 15818, 15819, 15820, 15821, 15822, 15823, 15824, 15825, 15826, 15827, 15828, 15829, 15830, 15831, 15832, 15833, 15834, 15835, 15836, 15837, 15838, 15839, 15840, 15841, 15842, 15843, 15844, 15845, 15846, 15847, 15848, 15849, 15850, 15851, 15852, 15853, 15854, 15855, 15856, 15857, 15858, 15859, 15860, 15861, 15862, 15863, 15864, 15865, 15866, 15867, 15868, 15869, 15870, 15871, 15872, 15873, 15874, 15875, 15876, 15877, 15878, 15879, 15880, 15881, 15882, 15883, 15884, 15885, 15886, 15887, 15888, 15889, 15890, 15891, 15892, 15893, 15894, 15895, 15896, 15897, 15898, 15899, 15900, 15901, 15902, 15903, 15904, 15905, 15906, 15907, 15908, 15909, 15910, 15911, 15912, 15913, 15914, 15915, 15916, 15917, 15918, 15919, 15920, 15921, 15922, 15923, 15924, 15925, 15926, 15927, 15928, 15929, 15930, 15931, 15932, 15933, 15934, 15935, 15936, 15937, 15938, 15939, 15940, 15941, 15942, 15943, 15944, 15945, 15946, 15947, 15948, 15949, 15950, 15951, 15952, 15953, 15954, 15955, 15956, 15957, 15958, 15959, 15960, 15961, 15962, 15963, 15964, 15965, 15966, 15967, 15968, 15969, 15970, 15971, 15972, 15973, 15974, 15975, 15976, 15977, 15978, 15979, 15980, 15981, 15982, 15983, 15984, 15985, 15986, 15987, 15988, 15989, 15990, 15991, 15992, 15993, 15994, 15995, 15996, 15997, 15998, 15999, 16000, 16001, 16002, 16003, 16004, 16005, 16006, 16007, 16008, 16009, 16010, 16011, 16012, 16013, 16014, 16015, 16016, 16017, 16018, 16019, 16020, 16021, 16022, 16023, 16024, 16025, 16026, 16027, 16028, 16029, 16030, 16031, 16032, 16033, 16034, 16035, 16036, 16037, 16038, 16039, 16040, 16041, 16042, 16043, 16044, 16045, 16046, 16047, 16048, 16049, 16050, 16051, 16052, 16053, 16054, 16055, 16056, 16057, 16058, 16059, 16060, 16061, 16062, 16063, 16064, 16065, 16066, 16067, 16068, 16069, 16070, 16071, 16072, 16073, 16074, 16075, 16076, 16077, 16078, 16079, 16080, 16081, 16082, 16083, 16084, 16085, 16086, 16087, 16088, 16089, 16090, 16091, 16092, 16093, 16094, 16095, 16096, 16097, 16098, 16099, 16100, 16101, 16102, 16103, 16104, 16105, 16106, 16107, 16108, 16109, 16110, 16111, 16112, 16113, 16114, 16115, 16116, 16117, 16118, 16119, 16120, 16121, 16122, 16123, 16124, 16125, 16126, 16127, 16128, 16129, 16130, 16131, 16132, 16133, 16134, 16135, 16136, 16137, 16138, 16139, 16140, 16141, 16142, 16143, 16144, 16145, 16146, 16147, 16148, 16149, 16150, 16151, 16152, 16153, 16154, 16155, 16156, 16157, 16158, 16159, 16160, 16161, 16162, 16163, 16164, 16165, 16166, 16167, 16168, 16169, 16170, 16171, 16172, 16173, 16174, 16175, 16176, 16177, 16178, 16179, 16180, 16181, 16182, 16183, 16184, 16185, 16186, 16187, 16188, 16189, 16190, 16191, 16192, 16193, 16194, 16195, 16196, 16197, 16198, 16199, 16200, 16201, 16202, 16203, 16204, 16205, 16206, 16207, 16208, 16209, 16210, 16211, 16212, 16213, 16214, 16215, 16216, 16217, 16218, 16219, 16220, 16221, 16222, 16223, 16224, 16225, 16226, 16227, 16228, 16229, 16230, 16231, 16232, 16233, 16234, 16235, 16236, 16237, 16238, 16239, 16240, 16241, 16242, 16243, 16244, 16245, 16246, 16247, 16248, 16249, 16250, 16251, 16252, 16253, 16254, 16255, 16256, 16257, 16258, 16259, 16260, 16261, 16262, 16263, 16264, 16265, 16266, 16267, 16268, 16269, 16270, 16271, 16272, 16273, 16274, 16275, 16276, 16277, 16278, 16279, 16280, 16281, 16282, 16283, 16284, 16285, 16286, 16287, 16288, 16289, 16290, 16291, 16292, 16293, 16294, 16295, 16296, 16297, 16298, 16299, 16300, 16301, 16302, 16303, 16304, 16305, 16306, 16307, 16308, 16309, 16310, 16311, 16312, 16313, 16314, 16315, 16316, 16317, 16318, 16319, 16320, 16321, 16322, 16323, 16324, 16325, 16326, 16327, 16328, 16329, 16330, 16331, 16332, 16333, 16334, 16335, 16336, 16337, 16338, 16339, 16340, 16341, 16342, 16343, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351, 16352, 16353, 16354, 16355, 16356, 16357, 16358, 16359, 16360, 16361, 16362, 16363, 16364, 16365, 16366, 16367, 16368, 16369, 16370, 16371, 16372, 16373, 16374, 16375, 16376, 16377, 16378, 16379, 16380, 16381, 16382, 16383, 16384, 16385, 16386, 16387, 16388, 16389, 16390, 16391, 16392, 16393, 16394, 16395, 16396, 16397, 16398, 16399, 16400, 16401, 16402, 16403, 16404, 16405, 16406, 16407, 16408, 16409, 16410, 16411, 16412, 16413, 16414, 16415, 16416, 16417, 16418, 16419, 16420, 16421, 16422, 16423, 16424, 16425, 16426, 16427, 16428, 16429, 16430, 16431, 16432, 16433, 16434, 16435, 16436, 16437, 16438, 16439, 16440, 16441, 16442, 16443, 16444, 16445, 16446, 16447, 16448, 16449, 16450, 16451, 16452, 16453, 16454, 16455, 16456, 16457, 16458, 16459, 16460, 16461, 16462, 16463, 16464, 16465, 16466, 16467, 16468, 16469, 16470, 16471, 16472, 16473, 16474, 16475, 16476, 16477, 16478, 16479, 16480, 16481, 16482, 16483, 16484, 16485, 16486, 16487, 16488, 16489, 16490, 16491, 16492, 16493, 16494, 16495, 16496, 16497, 16498, 16499, 16500, 16501, 16502, 16503, 16504, 16505, 16506, 16507, 16508, 16509, 16510, 16511, 16512, 16513, 16514, 16515, 16516, 16517, 16518, 16519, 16520, 16521, 16522, 16523, 16524, 16525, 16526, 16527, 16528, 16529, 16530, 16531, 16532, 16533, 16534, 16535, 16536, 16537, 16538, 16539, 16540, 16541, 16542, 16543, 16544, 16545, 16546, 16547, 16548, 16549, 16550, 16551, 16552, 16553, 16554, 16555, 16556, 16557, 16558, 16559, 16560, 16561, 16562, 16563, 16564, 16565, 16566, 16567, 16568, 16569, 16570, 16571, 16572, 16573, 16574, 16575, 16576, 16577, 16578, 16579, 16580, 16581, 16582, 16583, 16584, 16585, 16586, 16587, 16588, 16589, 16590, 16591, 16592, 16593, 16594, 16595, 16596, 16597, 16598, 16599, 16600, 16601, 16602, 16603, 16604, 16605, 16606, 16607, 16608, 16609, 16610, 16611, 16612, 16613, 16614, 16615, 16616, 16617, 16618, 16619, 16620, 16621, 16622, 16623, 16624, 16625, 16626, 16627, 16628, 16629, 16630, 16631, 16632, 16633, 16634, 16635, 16636, 16637, 16638, 16639, 16640, 16641, 16642, 16643, 16644, 16645, 16646, 16647, 16648, 16649, 16650, 16651, 16652, 16653, 16654, 16655, 16656, 16657, 16658, 16659, 16660, 16661, 16662, 16663, 16664, 16665, 16666, 16667, 16668, 16669, 16670, 16671, 16672, 16673, 16674, 16675, 16676, 16677, 16678, 16679, 16680, 16681, 16682, 16683, 16684, 16685, 16686, 16687, 16688, 16689, 16690, 16691, 16692, 16693, 16694, 16695, 16696, 16697, 16698, 16699, 16700, 16701, 16702, 16703, 16704, 16705, 16706, 16707, 16708, 16709, 16710, 16711, 16712, 16713, 16714, 16715, 16716, 16717, 16718, 16719, 16720, 16721, 16722, 16723, 16724, 16725, 16726, 16727, 16728, 16729, 16730, 16731, 16732, 16733, 16734, 16735, 16736, 16737, 16738, 16739, 16740, 16741, 16742, 16743, 16744, 16745, 16746, 16747, 16748, 16749, 16750, 16751, 16752, 16753, 16754, 16755, 16756, 16757, 16758, 16759, 16760, 16761, 16762, 16763, 16764, 16765, 16766, 16767, 16768, 16769, 16770, 16771, 16772, 16773, 16774, 16775, 16776, 16777, 16778, 16779, 16780, 16781, 16782, 16783, 16784, 16785, 16786, 16787, 16788, 16789, 16790, 16791, 16792, 16793, 16794, 16795, 16796, 16797, 16798, 16799, 16800, 16801, 16802, 16803, 16804, 16805, 16806, 16807, 16808, 16809, 16810, 16811, 16812, 16813, 16814, 16815, 16816, 16817, 16818, 16819, 16820, 16821, 16822, 16823, 16824, 16825, 16826, 16827, 16828, 16829, 16830, 16831, 16832, 16833, 16834, 16835, 16836, 16837, 16838, 16839, 16840, 16841, 16842, 16843, 16844, 16845, 16846, 16847, 16848, 16849, 16850, 16851, 16852, 16853, 16854, 16855, 16856, 16857, 16858, 16859, 16860, 16861, 16862, 16863, 16864, 16865, 16866, 16867, 16868, 16869, 16870, 16871, 16872, 16873, 16874, 16875, 16876, 16877, 16878, 16879, 16880, 16881, 16882, 16883, 16884, 16885, 16886, 16887, 16888, 16889, 16890, 16891, 16892, 16893, 16894, 16895, 16896, 16897, 16898, 16899, 16900, 16901, 16902, 16903, 16904, 16905, 16906, 16907, 16908, 16909, 16910, 16911, 16912, 16913, 16914, 16915, 16916, 16917, 16918, 16919, 16920, 16921, 16922, 16923, 16924, 16925, 16926, 16927, 16928, 16929, 16930, 16931, 16932, 16933, 16934, 16935, 16936, 16937, 16938, 16939, 16940, 16941, 16942, 16943, 16944, 16945, 16946, 16947, 16948, 16949, 16950, 16951, 16952, 16953, 16954, 16955, 16956, 16957, 16958, 16959, 16960, 16961, 16962, 16963, 16964, 16965, 16966, 16967, 16968, 16969, 16970, 16971, 16972, 16973, 16974, 16975, 16976, 16977, 16978, 16979, 16980, 16981, 16982, 16983, 16984, 16985, 16986, 16987, 16988, 16989, 16990, 16991, 16992, 16993, 16994, 16995, 16996, 16997, 16998, 16999, 17000, 17001, 17002, 17003, 17004, 17005, 17006, 17007, 17008, 17009, 17010, 17011, 17012, 17013, 17014, 17015, 17016, 17017, 17018, 17019, 17020, 17021, 17022, 17023, 17024, 17025, 17026, 17027, 17028, 17029, 17030, 17031, 17032, 17033, 17034, 17035, 17036, 17037, 17038, 17039, 17040, 17041, 17042, 17043, 17044, 17045, 17046, 17047, 17048, 17049, 17050, 17051, 17052, 17053, 17054, 17055, 17056, 17057, 17058, 17059, 17060, 17061, 17062, 17063, 17064, 17065, 17066, 17067, 17068, 17069, 17070, 17071, 17072, 17073, 17074, 17075, 17076, 17077, 17078, 17079, 17080, 17081, 17082, 17083, 17084, 17085, 17086, 17087, 17088, 17089, 17090, 17091, 17092, 17093, 17094, 17095, 17096, 17097, 17098, 17099, 17100, 17101, 17102, 17103, 17104, 17105, 17106, 17107, 17108, 17109, 17110, 17111, 17112, 17113, 17114, 17115, 17116, 17117, 17118, 17119, 17120, 17121, 17122, 17123, 17124, 17125, 17126, 17127, 17128, 17129, 17130, 17131, 17132, 17133, 17134, 17135, 17136, 17137, 17138, 17139, 17140, 17141, 17142, 17143, 17144, 17145, 17146, 17147, 17148, 17149, 17150, 17151, 17152, 17153, 17154, 17155, 17156, 17157, 17158, 17159, 17160, 17161, 17162, 17163, 17164, 17165, 17166, 17167, 17168, 17169, 17170, 17171, 17172, 17173, 17174, 17175, 17176, 17177, 17178, 17179, 17180, 17181, 17182, 17183, 17184, 17185, 17186, 17187, 17188, 17189, 17190, 17191, 17192, 17193, 17194, 17195, 17196, 17197, 17198, 17199, 17200, 17201, 17202, 17203, 17204, 17205, 17206, 17207, 17208, 17209, 17210, 17211, 17212, 17213, 17214, 17215, 17216, 17217, 17218, 17219, 17220, 17221, 17222, 17223, 17224, 17225, 17226, 17227, 17228, 17229, 17230, 17231, 17232, 17233, 17234, 17235, 17236, 17237, 17238, 17239, 17240, 17241, 17242, 17243, 17244, 17245, 17246, 17247, 17248, 17249, 17250, 17251, 17252, 17253, 17254, 17255, 17256, 17257, 17258, 17259, 17260, 17261, 17262, 17263, 17264, 17265, 17266, 17267, 17268, 17269, 17270, 17271, 17272, 17273, 17274, 17275, 17276, 17277, 17278, 17279, 17280, 17281, 17282, 17283, 17284, 17285, 17286, 17287, 17288, 17289, 17290, 17291, 17292, 17293, 17294, 17295, 17296, 17297, 17298, 17299, 17300, 17301, 17302, 17303, 17304, 17305, 17306, 17307, 17308, 17309, 17310, 17311, 17312, 17313, 17314, 17315, 17316, 17317, 17318, 17319, 17320, 17321, 17322, 17323, 17324, 17325, 17326, 17327, 17328, 17329, 17330, 17331, 17332, 17333, 17334, 17335, 17336, 17337, 17338, 17339, 17340, 17341, 17342, 17343, 17344, 17345, 17346, 17347, 17348, 17349, 17350, 17351, 17352, 17353, 17354, 17355, 17356, 17357, 17358, 17359, 17360, 17361, 17362, 17363, 17364, 17365, 17366, 17367, 17368, 17369, 17370, 17371, 17372, 17373, 17374, 17375, 17376, 17377, 17378, 17379, 17380, 17381, 17382, 17383, 17384, 17385, 17386, 17387, 17388, 17389, 17390, 17391, 17392, 17393, 17394, 17395, 17396, 17397, 17398, 17399, 17400, 17401, 17402, 17403, 17404, 17405, 17406, 17407, 17408, 17409, 17410, 17411, 17412, 17413, 17414, 17415, 17416, 17417, 17418, 17419, 17420, 17421, 17422, 17423, 17424, 17425, 17426, 17427, 17428, 17429, 17430, 17431, 17432, 17433, 17434, 17435, 17436, 17437, 17438, 17439, 17440, 17441, 17442, 17443, 17444, 17445, 17446, 17447, 17448, 17449, 17450, 17451, 17452, 17453, 17454, 17455, 17456, 17457, 17458, 17459, 17460, 17461, 17462, 17463, 17464, 17465, 17466, 17467, 17468, 17469, 17470, 17471, 17472, 17473, 17474, 17475, 17476, 17477, 17478, 17479, 17480, 17481, 17482, 17483, 17484, 17485, 17486, 17487, 17488, 17489, 17490, 17491, 17492, 17493, 17494, 17495, 17496, 17497, 17498, 17499, 17500, 17501, 17502, 17503, 17504, 17505, 17506, 17507, 17508, 17509, 17510, 17511, 17512, 17513, 17514, 17515, 17516, 17517, 17518, 17519, 17520, 17521, 17522, 17523, 17524, 17525, 17526, 17527, 17528, 17529, 17530, 17531, 17532, 17533, 17534, 17535, 17536, 17537, 17538, 17539, 17540, 17541, 17542, 17543, 17544, 17545, 17546, 17547, 17548, 17549, 17550, 17551, 17552, 17553, 17554, 17555, 17556, 17557, 17558, 17559, 17560, 17561, 17562, 17563, 17564, 17565, 17566, 17567, 17568, 17569, 17570, 17571, 17572, 17573, 17574, 17575, 17576, 17577, 17578, 17579, 17580, 17581, 17582, 17583, 17584, 17585, 17586, 17587, 17588, 17589, 17590, 17591, 17592, 17593, 17594, 17595, 17596, 17597, 17598, 17599, 17600, 17601, 17602, 17603, 17604, 17605, 17606, 17607, 17608, 17609, 17610, 17611, 17612, 17613, 17614, 17615, 17616, 17617, 17618, 17619, 17620, 17621, 17622, 17623, 17624, 17625, 17626, 17627, 17628, 17629, 17630, 17631, 17632, 17633, 17634, 17635, 17636, 17637, 17638, 17639, 17640, 17641, 17642, 17643, 17644, 17645, 17646, 17647, 17648, 17649, 17650, 17651, 17652, 17653, 17654, 17655, 17656, 17657, 17658, 17659, 17660, 17661, 17662, 17663, 17664, 17665, 17666, 17667, 17668, 17669, 17670, 17671, 17672, 17673, 17674, 17675, 17676, 17677, 17678, 17679, 17680, 17681, 17682, 17683, 17684, 17685, 17686, 17687, 17688, 17689, 17690, 17691, 17692, 17693, 17694, 17695, 17696, 17697, 17698, 17699, 17700, 17701, 17702, 17703, 17704, 17705, 17706, 17707, 17708, 17709, 17710, 17711, 17712, 17713, 17714, 17715, 17716, 17717, 17718, 17719, 17720, 17721, 17722, 17723, 17724, 17725, 17726, 17727, 17728, 17729, 17730, 17731, 17732, 17733, 17734, 17735, 17736, 17737, 17738, 17739, 17740, 17741, 17742, 17743, 17744, 17745, 17746, 17747, 17748, 17749, 17750, 17751, 17752, 17753, 17754, 17755, 17756, 17757, 17758, 17759, 17760, 17761, 17762, 17763, 17764, 17765, 17766, 17767, 17768, 17769, 17770, 17771, 17772, 17773, 17774, 17775, 17776, 17777, 17778, 17779, 17780, 17781, 17782, 17783, 17784, 17785, 17786, 17787, 17788, 17789, 17790, 17791, 17792, 17793, 17794, 17795, 17796, 17797, 17798, 17799, 17800, 17801, 17802, 17803, 17804, 17805, 17806, 17807, 17808, 17809, 17810, 17811, 17812, 17813, 17814, 17815, 17816, 17817, 17818, 17819, 17820, 17821, 17822, 17823, 17824, 17825, 17826, 17827, 17828, 17829, 17830, 17831, 17832, 17833, 17834, 17835, 17836, 17837, 17838, 17839, 17840, 17841, 17842, 17843, 17844, 17845, 17846, 17847, 17848, 17849, 17850, 17851, 17852, 17853, 17854, 17855, 17856, 17857, 17858, 17859, 17860, 17861, 17862, 17863, 17864, 17865, 17866, 17867, 17868, 17869, 17870, 17871, 17872, 17873, 17874, 17875, 17876, 17877, 17878, 17879, 17880, 17881, 17882, 17883, 17884, 17885, 17886, 17887, 17888, 17889, 17890, 17891, 17892, 17893, 17894, 17895, 17896, 17897, 17898, 17899, 17900, 17901, 17902, 17903, 17904, 17905, 17906, 17907, 17908, 17909, 17910, 17911, 17912, 17913, 17914, 17915, 17916, 17917, 17918, 17919, 17920, 17921, 17922, 17923, 17924, 17925, 17926, 17927, 17928, 17929, 17930, 17931, 17932, 17933, 17934, 17935, 17936, 17937, 17938, 17939, 17940, 17941, 17942, 17943, 17944, 17945, 17946, 17947, 17948, 17949, 17950, 17951, 17952, 17953, 17954, 17955, 17956, 17957, 17958, 17959, 17960, 17961, 17962, 17963, 17964, 17965, 17966, 17967, 17968, 17969, 17970, 17971, 17972, 17973, 17974, 17975, 17976, 17977, 17978, 17979, 17980, 17981, 17982, 17983, 17984, 17985, 17986, 17987, 17988, 17989, 17990, 17991, 17992, 17993, 17994, 17995, 17996, 17997, 17998, 17999, 18000, 18001, 18002, 18003, 18004, 18005, 18006, 18007, 18008, 18009, 18010, 18011, 18012, 18013, 18014, 18015, 18016, 18017, 18018, 18019, 18020, 18021, 18022, 18023, 18024, 18025, 18026, 18027, 18028, 18029, 18030, 18031, 18032, 18033, 18034, 18035, 18036, 18037, 18038, 18039, 18040, 18041, 18042, 18043, 18044, 18045, 18046, 18047, 18048, 18049, 18050, 18051, 18052, 18053, 18054, 18055, 18056, 18057, 18058, 18059, 18060, 18061, 18062, 18063, 18064, 18065, 18066, 18067, 18068, 18069, 18070, 18071, 18072, 18073, 18074, 18075, 18076, 18077, 18078, 18079, 18080, 18081, 18082, 18083, 18084, 18085, 18086, 18087, 18088, 18089, 18090, 18091, 18092, 18093, 18094, 18095, 18096, 18097, 18098, 18099, 18100, 18101, 18102, 18103, 18104, 18105, 18106, 18107, 18108, 18109, 18110, 18111, 18112, 18113, 18114, 18115, 18116, 18117, 18118, 18119, 18120, 18121, 18122, 18123, 18124, 18125, 18126, 18127, 18128, 18129, 18130, 18131, 18132, 18133, 18134, 18135, 18136, 18137, 18138, 18139, 18140, 18141, 18142, 18143, 18144, 18145, 18146, 18147, 18148, 18149, 18150, 18151, 18152, 18153, 18154, 18155, 18156, 18157, 18158, 18159, 18160, 18161, 18162, 18163, 18164, 18165, 18166, 18167, 18168, 18169, 18170, 18171, 18172, 18173, 18174, 18175, 18176, 18177, 18178, 18179, 18180, 18181, 18182, 18183, 18184, 18185, 18186, 18187, 18188, 18189, 18190, 18191, 18192, 18193, 18194, 18195, 18196, 18197, 18198, 18199, 18200, 18201, 18202, 18203, 18204, 18205, 18206, 18207, 18208, 18209, 18210, 18211, 18212, 18213, 18214, 18215, 18216, 18217, 18218, 18219, 18220, 18221, 18222, 18223, 18224, 18225, 18226, 18227, 18228, 18229, 18230, 18231, 18232, 18233, 18234, 18235, 18236, 18237, 18238, 18239, 18240, 18241, 18242, 18243, 18244, 18245, 18246, 18247, 18248, 18249, 18250, 18251, 18252, 18253, 18254, 18255, 18256, 18257, 18258, 18259, 18260, 18261, 18262, 18263, 18264, 18265, 18266, 18267, 18268, 18269, 18270, 18271, 18272, 18273, 18274, 18275, 18276, 18277, 18278, 18279, 18280, 18281, 18282, 18283, 18284, 18285, 18286, 18287, 18288, 18289, 18290, 18291, 18292, 18293, 18294, 18295, 18296, 18297, 18298, 18299, 18300, 18301, 18302, 18303, 18304, 18305, 18306, 18307, 18308, 18309, 18310, 18311, 18312, 18313, 18314, 18315, 18316, 18317, 18318, 18319, 18320, 18321, 18322, 18323, 18324, 18325, 18326, 18327, 18328, 18329, 18330, 18331, 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379, 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387, 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451, 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459, 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467, 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475, 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483, 18484, 18485, 18486, 18487, 18488, 18489, 18490, 18491, 18492, 18493, 18494, 18495, 18496, 18497, 18498, 18499, 18500, 18501, 18502, 18503, 18504, 18505, 18506, 18507, 18508, 18509, 18510, 18511, 18512, 18513, 18514, 18515, 18516, 18517, 18518, 18519, 18520, 18521, 18522, 18523, 18524, 18525, 18526, 18527, 18528, 18529, 18530, 18531, 18532, 18533, 18534, 18535, 18536, 18537, 18538, 18539, 18540, 18541, 18542, 18543, 18544, 18545, 18546, 18547, 18548, 18549, 18550, 18551, 18552, 18553, 18554, 18555, 18556, 18557, 18558, 18559, 18560, 18561, 18562, 18563, 18564, 18565, 18566, 18567, 18568, 18569, 18570, 18571, 18572, 18573, 18574, 18575, 18576, 18577, 18578, 18579, 18580, 18581, 18582, 18583, 18584, 18585, 18586, 18587, 18588, 18589, 18590, 18591, 18592, 18593, 18594, 18595, 18596, 18597, 18598, 18599, 18600, 18601, 18602, 18603, 18604, 18605, 18606, 18607, 18608, 18609, 18610, 18611, 18612, 18613, 18614, 18615, 18616, 18617, 18618, 18619, 18620, 18621, 18622, 18623, 18624, 18625, 18626, 18627, 18628, 18629, 18630, 18631, 18632, 18633, 18634, 18635, 18636, 18637, 18638, 18639, 18640, 18641, 18642, 18643, 18644, 18645, 18646, 18647, 18648, 18649, 18650, 18651, 18652, 18653, 18654, 18655, 18656, 18657, 18658, 18659, 18660, 18661, 18662, 18663, 18664, 18665, 18666, 18667, 18668, 18669, 18670, 18671, 18672, 18673, 18674, 18675, 18676, 18677, 18678, 18679, 18680, 18681, 18682, 18683, 18684, 18685, 18686, 18687, 18688, 18689, 18690, 18691, 18692, 18693, 18694, 18695, 18696, 18697, 18698, 18699, 18700, 18701, 18702, 18703, 18704, 18705, 18706, 18707, 18708, 18709, 18710, 18711, 18712, 18713, 18714, 18715, 18716, 18717, 18718, 18719, 18720, 18721, 18722, 18723, 18724, 18725, 18726, 18727, 18728, 18729, 18730, 18731, 18732, 18733, 18734, 18735, 18736, 18737, 18738, 18739, 18740, 18741, 18742, 18743, 18744, 18745, 18746, 18747, 18748, 18749, 18750, 18751, 18752, 18753, 18754, 18755, 18756, 18757, 18758, 18759, 18760, 18761, 18762, 18763, 18764, 18765, 18766, 18767, 18768, 18769, 18770, 18771, 18772, 18773, 18774, 18775, 18776, 18777, 18778, 18779, 18780, 18781, 18782, 18783, 18784, 18785, 18786, 18787, 18788, 18789, 18790, 18791, 18792, 18793, 18794, 18795, 18796, 18797, 18798, 18799, 18800, 18801, 18802, 18803, 18804, 18805, 18806, 18807, 18808, 18809, 18810, 18811, 18812, 18813, 18814, 18815, 18816, 18817, 18818, 18819, 18820, 18821, 18822, 18823, 18824, 18825, 18826, 18827, 18828, 18829, 18830, 18831, 18832, 18833, 18834, 18835, 18836, 18837, 18838, 18839, 18840, 18841, 18842, 18843, 18844, 18845, 18846, 18847, 18848, 18849, 18850, 18851, 18852, 18853, 18854, 18855, 18856, 18857, 18858, 18859, 18860, 18861, 18862, 18863, 18864, 18865, 18866, 18867, 18868, 18869, 18870, 18871, 18872, 18873, 18874, 18875, 18876, 18877, 18878, 18879, 18880, 18881, 18882, 18883, 18884, 18885, 18886, 18887, 18888, 18889, 18890, 18891, 18892, 18893, 18894, 18895, 18896, 18897, 18898, 18899, 18900, 18901, 18902, 18903, 18904, 18905, 18906, 18907, 18908, 18909, 18910, 18911, 18912, 18913, 18914, 18915, 18916, 18917, 18918, 18919, 18920, 18921, 18922, 18923, 18924, 18925, 18926, 18927, 18928, 18929, 18930, 18931, 18932, 18933, 18934, 18935, 18936, 18937, 18938, 18939, 18940, 18941, 18942, 18943, 18944, 18945, 18946, 18947, 18948, 18949, 18950, 18951, 18952, 18953, 18954, 18955, 18956, 18957, 18958, 18959, 18960, 18961, 18962, 18963, 18964, 18965, 18966, 18967, 18968, 18969, 18970, 18971, 18972, 18973, 18974, 18975, 18976, 18977, 18978, 18979, 18980, 18981, 18982, 18983, 18984, 18985, 18986, 18987, 18988, 18989, 18990, 18991, 18992, 18993, 18994, 18995, 18996, 18997, 18998, 18999, 19000, 19001, 19002, 19003, 19004, 19005, 19006, 19007, 19008, 19009, 19010, 19011, 19012, 19013, 19014, 19015, 19016, 19017, 19018, 19019, 19020, 19021, 19022, 19023, 19024, 19025, 19026, 19027, 19028, 19029, 19030, 19031, 19032, 19033, 19034, 19035, 19036, 19037, 19038, 19039, 19040, 19041, 19042, 19043, 19044, 19045, 19046, 19047, 19048, 19049, 19050, 19051, 19052, 19053, 19054, 19055, 19056, 19057, 19058, 19059, 19060, 19061, 19062, 19063, 19064, 19065, 19066, 19067, 19068, 19069, 19070, 19071, 19072, 19073, 19074, 19075, 19076, 19077, 19078, 19079, 19080, 19081, 19082, 19083, 19084, 19085, 19086, 19087, 19088, 19089, 19090, 19091, 19092, 19093, 19094, 19095, 19096, 19097, 19098, 19099, 19100, 19101, 19102, 19103, 19104, 19105, 19106, 19107, 19108, 19109, 19110, 19111, 19112, 19113, 19114, 19115, 19116, 19117, 19118, 19119, 19120, 19121, 19122, 19123, 19124, 19125, 19126, 19127, 19128, 19129, 19130, 19131, 19132, 19133, 19134, 19135, 19136, 19137, 19138, 19139, 19140, 19141, 19142, 19143, 19144, 19145, 19146, 19147, 19148, 19149, 19150, 19151, 19152, 19153, 19154, 19155, 19156, 19157, 19158, 19159, 19160, 19161, 19162, 19163, 19164, 19165, 19166, 19167, 19168, 19169, 19170, 19171, 19172, 19173, 19174, 19175, 19176, 19177, 19178, 19179, 19180, 19181, 19182, 19183, 19184, 19185, 19186, 19187, 19188, 19189, 19190, 19191, 19192, 19193, 19194, 19195, 19196, 19197, 19198, 19199, 19200, 19201, 19202, 19203, 19204, 19205, 19206, 19207, 19208, 19209, 19210, 19211, 19212, 19213, 19214, 19215, 19216, 19217, 19218, 19219, 19220, 19221, 19222, 19223, 19224, 19225, 19226, 19227, 19228, 19229, 19230, 19231, 19232, 19233, 19234, 19235, 19236, 19237, 19238, 19239, 19240, 19241, 19242, 19243, 19244, 19245, 19246, 19247, 19248, 19249, 19250, 19251, 19252, 19253, 19254, 19255, 19256, 19257, 19258, 19259, 19260, 19261, 19262, 19263, 19264, 19265, 19266, 19267, 19268, 19269, 19270, 19271, 19272, 19273, 19274, 19275, 19276, 19277, 19278, 19279, 19280, 19281, 19282, 19283, 19284, 19285, 19286, 19287, 19288, 19289, 19290, 19291, 19292, 19293, 19294, 19295, 19296, 19297, 19298, 19299, 19300, 19301, 19302, 19303, 19304, 19305, 19306, 19307, 19308, 19309, 19310, 19311, 19312, 19313, 19314, 19315, 19316, 19317, 19318, 19319, 19320, 19321, 19322, 19323, 19324, 19325, 19326, 19327, 19328, 19329, 19330, 19331, 19332, 19333, 19334, 19335, 19336, 19337, 19338, 19339, 19340, 19341, 19342, 19343, 19344, 19345, 19346, 19347, 19348, 19349, 19350, 19351, 19352, 19353, 19354, 19355, 19356, 19357, 19358, 19359, 19360, 19361, 19362, 19363, 19364, 19365, 19366, 19367, 19368, 19369, 19370, 19371, 19372, 19373, 19374, 19375, 19376, 19377, 19378, 19379, 19380, 19381, 19382, 19383, 19384, 19385, 19386, 19387, 19388, 19389, 19390, 19391, 19392, 19393, 19394, 19395, 19396, 19397, 19398, 19399, 19400, 19401, 19402, 19403, 19404, 19405, 19406, 19407, 19408, 19409, 19410, 19411, 19412, 19413, 19414, 19415, 19416, 19417, 19418, 19419, 19420, 19421, 19422, 19423, 19424, 19425, 19426, 19427, 19428, 19429, 19430, 19431, 19432, 19433, 19434, 19435, 19436, 19437, 19438, 19439, 19440, 19441, 19442, 19443, 19444, 19445, 19446, 19447, 19448, 19449, 19450, 19451, 19452, 19453, 19454, 19455, 19456, 19457, 19458, 19459, 19460, 19461, 19462, 19463, 19464, 19465, 19466, 19467, 19468, 19469, 19470, 19471, 19472, 19473, 19474, 19475, 19476, 19477, 19478, 19479, 19480, 19481, 19482, 19483, 19484, 19485, 19486, 19487, 19488, 19489, 19490, 19491, 19492, 19493, 19494, 19495, 19496, 19497, 19498, 19499, 19500, 19501, 19502, 19503, 19504, 19505, 19506, 19507, 19508, 19509, 19510, 19511, 19512, 19513, 19514, 19515, 19516, 19517, 19518, 19519, 19520, 19521, 19522, 19523, 19524, 19525, 19526, 19527, 19528, 19529, 19530, 19531, 19532, 19533, 19534, 19535, 19536, 19537, 19538, 19539, 19540, 19541, 19542, 19543, 19544, 19545, 19546, 19547, 19548, 19549, 19550, 19551, 19552, 19553, 19554, 19555, 19556, 19557, 19558, 19559, 19560, 19561, 19562, 19563, 19564, 19565, 19566, 19567, 19568, 19569, 19570, 19571, 19572, 19573, 19574, 19575, 19576, 19577, 19578, 19579, 19580, 19581, 19582, 19583, 19584, 19585, 19586, 19587, 19588, 19589, 19590, 19591, 19592, 19593, 19594, 19595, 19596, 19597, 19598, 19599, 19600, 19601, 19602, 19603, 19604, 19605, 19606, 19607, 19608, 19609, 19610, 19611, 19612, 19613, 19614, 19615, 19616, 19617, 19618, 19619, 19620, 19621, 19622, 19623, 19624, 19625, 19626, 19627, 19628, 19629, 19630, 19631, 19632, 19633, 19634, 19635, 19636, 19637, 19638, 19639, 19640, 19641, 19642, 19643, 19644, 19645, 19646, 19647, 19648, 19649, 19650, 19651, 19652, 19653, 19654, 19655, 19656, 19657, 19658, 19659, 19660, 19661, 19662, 19663, 19664, 19665, 19666, 19667, 19668, 19669, 19670, 19671, 19672, 19673, 19674, 19675, 19676, 19677, 19678, 19679, 19680, 19681, 19682, 19683, 19684, 19685, 19686, 19687, 19688, 19689, 19690, 19691, 19692, 19693, 19694, 19695, 19696, 19697, 19698, 19699, 19700, 19701, 19702, 19703, 19704, 19705, 19706, 19707, 19708, 19709, 19710, 19711, 19712, 19713, 19714, 19715, 19716, 19717, 19718, 19719, 19720, 19721, 19722, 19723, 19724, 19725, 19726, 19727, 19728, 19729, 19730, 19731, 19732, 19733, 19734, 19735, 19736, 19737, 19738, 19739, 19740, 19741, 19742, 19743, 19744, 19745, 19746, 19747, 19748, 19749, 19750, 19751, 19752, 19753, 19754, 19755, 19756, 19757, 19758, 19759, 19760, 19761, 19762, 19763, 19764, 19765, 19766, 19767, 19768, 19769, 19770, 19771, 19772, 19773, 19774, 19775, 19776, 19777, 19778, 19779, 19780, 19781, 19782, 19783, 19784, 19785, 19786, 19787, 19788, 19789, 19790, 19791, 19792, 19793, 19794, 19795, 19796, 19797, 19798, 19799, 19800, 19801, 19802, 19803, 19804, 19805, 19806, 19807, 19808, 19809, 19810, 19811, 19812, 19813, 19814, 19815, 19816, 19817, 19818, 19819, 19820, 19821, 19822, 19823, 19824, 19825, 19826, 19827, 19828, 19829, 19830, 19831, 19832, 19833, 19834, 19835, 19836, 19837, 19838, 19839, 19840, 19841, 19842, 19843, 19844, 19845, 19846, 19847, 19848, 19849, 19850, 19851, 19852, 19853, 19854, 19855, 19856, 19857, 19858, 19859, 19860, 19861, 19862, 19863, 19864, 19865, 19866, 19867, 19868, 19869, 19870, 19871, 19872, 19873, 19874, 19875, 19876, 19877, 19878, 19879, 19880, 19881, 19882, 19883, 19884, 19885, 19886, 19887, 19888, 19889, 19890, 19891, 19892, 19893, 19894, 19895, 19896, 19897, 19898, 19899, 19900, 19901, 19902, 19903, 19904, 19905, 19906, 19907, 19908, 19909, 19910, 19911, 19912, 19913, 19914, 19915, 19916, 19917, 19918, 19919, 19920, 19921, 19922, 19923, 19924, 19925, 19926, 19927, 19928, 19929, 19930, 19931, 19932, 19933, 19934, 19935, 19936, 19937, 19938, 19939, 19940, 19941, 19942, 19943, 19944, 19945, 19946, 19947, 19948, 19949, 19950, 19951, 19952, 19953, 19954, 19955, 19956, 19957, 19958, 19959, 19960, 19961, 19962, 19963, 19964, 19965, 19966, 19967, 19968, 19969, 19970, 19971, 19972, 19973, 19974, 19975, 19976, 19977, 19978, 19979, 19980, 19981, 19982, 19983, 19984, 19985, 19986, 19987, 19988, 19989, 19990, 19991, 19992, 19993, 19994, 19995, 19996, 19997, 19998, 19999, 20000, 20001, 20002, 20003, 20004, 20005, 20006, 20007, 20008, 20009, 20010, 20011, 20012, 20013, 20014, 20015, 20016, 20017, 20018, 20019, 20020, 20021, 20022, 20023, 20024, 20025, 20026, 20027, 20028, 20029, 20030, 20031, 20032, 20033, 20034, 20035, 20036, 20037, 20038, 20039, 20040, 20041, 20042, 20043, 20044, 20045, 20046, 20047, 20048, 20049, 20050, 20051, 20052, 20053, 20054, 20055, 20056, 20057, 20058, 20059, 20060, 20061, 20062, 20063, 20064, 20065, 20066, 20067, 20068, 20069, 20070, 20071, 20072, 20073, 20074, 20075, 20076, 20077, 20078, 20079, 20080, 20081, 20082, 20083, 20084, 20085, 20086, 20087, 20088, 20089, 20090, 20091, 20092, 20093, 20094, 20095, 20096, 20097, 20098, 20099, 20100, 20101, 20102, 20103, 20104, 20105, 20106, 20107, 20108, 20109, 20110, 20111, 20112, 20113, 20114, 20115, 20116, 20117, 20118, 20119, 20120, 20121, 20122, 20123, 20124, 20125, 20126, 20127, 20128, 20129, 20130, 20131, 20132, 20133, 20134, 20135, 20136, 20137, 20138, 20139, 20140, 20141, 20142, 20143, 20144, 20145, 20146, 20147, 20148, 20149, 20150, 20151, 20152, 20153, 20154, 20155, 20156, 20157, 20158, 20159, 20160, 20161, 20162, 20163, 20164, 20165, 20166, 20167, 20168, 20169, 20170, 20171, 20172, 20173, 20174, 20175, 20176, 20177, 20178, 20179, 20180, 20181, 20182, 20183, 20184, 20185, 20186, 20187, 20188, 20189, 20190, 20191, 20192, 20193, 20194, 20195, 20196, 20197, 20198, 20199, 20200, 20201, 20202, 20203, 20204, 20205, 20206, 20207, 20208, 20209, 20210, 20211, 20212, 20213, 20214, 20215, 20216, 20217, 20218, 20219, 20220, 20221, 20222, 20223, 20224, 20225, 20226, 20227, 20228, 20229, 20230, 20231, 20232, 20233, 20234, 20235, 20236, 20237, 20238, 20239, 20240, 20241, 20242, 20243, 20244, 20245, 20246, 20247, 20248, 20249, 20250, 20251, 20252, 20253, 20254, 20255, 20256, 20257, 20258, 20259, 20260, 20261, 20262, 20263, 20264, 20265, 20266, 20267, 20268, 20269, 20270, 20271, 20272, 20273, 20274, 20275, 20276, 20277, 20278, 20279, 20280, 20281, 20282, 20283, 20284, 20285, 20286, 20287, 20288, 20289, 20290, 20291, 20292, 20293, 20294, 20295, 20296, 20297, 20298, 20299, 20300, 20301, 20302, 20303, 20304, 20305, 20306, 20307, 20308, 20309, 20310, 20311, 20312, 20313, 20314, 20315, 20316, 20317, 20318, 20319, 20320, 20321, 20322, 20323, 20324, 20325, 20326, 20327, 20328, 20329, 20330, 20331, 20332, 20333, 20334, 20335, 20336, 20337, 20338, 20339, 20340, 20341, 20342, 20343, 20344, 20345, 20346, 20347, 20348, 20349, 20350, 20351, 20352, 20353, 20354, 20355, 20356, 20357, 20358, 20359, 20360, 20361, 20362, 20363, 20364, 20365, 20366, 20367, 20368, 20369, 20370, 20371, 20372, 20373, 20374, 20375, 20376, 20377, 20378, 20379, 20380, 20381, 20382, 20383, 20384, 20385, 20386, 20387, 20388, 20389, 20390, 20391, 20392, 20393, 20394, 20395, 20396, 20397, 20398, 20399, 20400, 20401, 20402, 20403, 20404, 20405, 20406, 20407, 20408, 20409, 20410, 20411, 20412, 20413, 20414, 20415, 20416, 20417, 20418, 20419, 20420, 20421, 20422, 20423, 20424, 20425, 20426, 20427, 20428, 20429, 20430, 20431, 20432, 20433, 20434, 20435, 20436, 20437, 20438, 20439, 20440, 20441, 20442, 20443, 20444, 20445, 20446, 20447, 20448, 20449, 20450, 20451, 20452, 20453, 20454, 20455, 20456, 20457, 20458, 20459, 20460, 20461, 20462, 20463, 20464, 20465, 20466, 20467, 20468, 20469, 20470, 20471, 20472, 20473, 20474, 20475, 20476, 20477, 20478, 20479, 20480, 20481, 20482, 20483, 20484, 20485, 20486, 20487, 20488, 20489, 20490, 20491, 20492, 20493, 20494, 20495, 20496, 20497, 20498, 20499, 20500, 20501, 20502, 20503, 20504, 20505, 20506, 20507, 20508, 20509, 20510, 20511, 20512, 20513, 20514, 20515, 20516, 20517, 20518, 20519, 20520, 20521, 20522, 20523, 20524, 20525, 20526, 20527, 20528, 20529, 20530, 20531, 20532, 20533, 20534, 20535, 20536, 20537, 20538, 20539, 20540, 20541, 20542, 20543, 20544, 20545, 20546, 20547, 20548, 20549, 20550, 20551, 20552, 20553, 20554, 20555, 20556, 20557, 20558, 20559, 20560, 20561, 20562, 20563, 20564, 20565, 20566, 20567, 20568, 20569, 20570, 20571, 20572, 20573, 20574, 20575, 20576, 20577, 20578, 20579, 20580, 20581, 20582, 20583, 20584, 20585, 20586, 20587, 20588, 20589, 20590, 20591, 20592, 20593, 20594, 20595, 20596, 20597, 20598, 20599, 20600, 20601, 20602, 20603, 20604, 20605, 20606, 20607, 20608, 20609, 20610, 20611, 20612, 20613, 20614, 20615, 20616, 20617, 20618, 20619, 20620, 20621, 20622, 20623, 20624, 20625, 20626, 20627, 20628, 20629, 20630, 20631, 20632, 20633, 20634, 20635, 20636, 20637, 20638, 20639, 20640, 20641, 20642, 20643, 20644, 20645, 20646, 20647, 20648, 20649, 20650, 20651, 20652, 20653, 20654, 20655, 20656, 20657, 20658, 20659, 20660, 20661, 20662, 20663, 20664, 20665, 20666, 20667, 20668, 20669, 20670, 20671, 20672, 20673, 20674, 20675, 20676, 20677, 20678, 20679, 20680, 20681, 20682, 20683, 20684, 20685, 20686, 20687, 20688, 20689, 20690, 20691, 20692, 20693, 20694, 20695, 20696, 20697, 20698, 20699, 20700, 20701, 20702, 20703, 20704, 20705, 20706, 20707, 20708, 20709, 20710, 20711, 20712, 20713, 20714, 20715, 20716, 20717, 20718, 20719, 20720, 20721, 20722, 20723, 20724, 20725, 20726, 20727, 20728, 20729, 20730, 20731, 20732, 20733, 20734, 20735, 20736, 20737, 20738, 20739, 20740, 20741, 20742, 20743, 20744, 20745, 20746, 20747, 20748, 20749, 20750, 20751, 20752, 20753, 20754, 20755, 20756, 20757, 20758, 20759, 20760, 20761, 20762, 20763, 20764, 20765, 20766, 20767, 20768, 20769, 20770, 20771, 20772, 20773, 20774, 20775, 20776, 20777, 20778, 20779, 20780, 20781, 20782, 20783, 20784, 20785, 20786, 20787, 20788, 20789, 20790, 20791, 20792, 20793, 20794, 20795, 20796, 20797, 20798, 20799, 20800, 20801, 20802, 20803, 20804, 20805, 20806, 20807, 20808, 20809, 20810, 20811, 20812, 20813, 20814, 20815, 20816, 20817, 20818, 20819, 20820, 20821, 20822, 20823, 20824, 20825, 20826, 20827, 20828, 20829, 20830, 20831, 20832, 20833, 20834, 20835, 20836, 20837, 20838, 20839, 20840, 20841, 20842, 20843, 20844, 20845, 20846, 20847, 20848, 20849, 20850, 20851, 20852, 20853, 20854, 20855, 20856, 20857, 20858, 20859, 20860, 20861, 20862, 20863, 20864, 20865, 20866, 20867, 20868, 20869, 20870, 20871, 20872, 20873, 20874, 20875, 20876, 20877, 20878, 20879, 20880, 20881, 20882, 20883, 20884, 20885, 20886, 20887, 20888, 20889, 20890, 20891, 20892, 20893, 20894, 20895, 20896, 20897, 20898, 20899, 20900, 20901, 20902, 20903, 20904, 20905, 20906, 20907, 20908, 20909, 20910, 20911, 20912, 20913, 20914, 20915, 20916, 20917, 20918, 20919, 20920, 20921, 20922, 20923, 20924, 20925, 20926, 20927, 20928, 20929, 20930, 20931, 20932, 20933, 20934, 20935, 20936, 20937, 20938, 20939, 20940, 20941, 20942, 20943, 20944, 20945, 20946, 20947, 20948, 20949, 20950, 20951, 20952, 20953, 20954, 20955, 20956, 20957, 20958, 20959, 20960, 20961, 20962, 20963, 20964, 20965, 20966, 20967, 20968, 20969, 20970, 20971, 20972, 20973, 20974, 20975, 20976, 20977, 20978, 20979, 20980, 20981, 20982, 20983, 20984, 20985, 20986, 20987, 20988, 20989, 20990, 20991, 20992, 20993, 20994, 20995, 20996, 20997, 20998, 20999, 21000, 21001, 21002, 21003, 21004, 21005, 21006, 21007, 21008, 21009, 21010, 21011, 21012, 21013, 21014, 21015, 21016, 21017, 21018, 21019, 21020, 21021, 21022, 21023, 21024, 21025, 21026, 21027, 21028, 21029, 21030, 21031, 21032, 21033, 21034, 21035, 21036, 21037, 21038, 21039, 21040, 21041, 21042, 21043, 21044, 21045, 21046, 21047, 21048, 21049, 21050, 21051, 21052, 21053, 21054, 21055, 21056, 21057, 21058, 21059, 21060, 21061, 21062, 21063, 21064, 21065, 21066, 21067, 21068, 21069, 21070, 21071, 21072, 21073, 21074, 21075, 21076, 21077, 21078, 21079, 21080, 21081, 21082, 21083, 21084, 21085, 21086, 21087, 21088, 21089, 21090, 21091, 21092, 21093, 21094, 21095, 21096, 21097, 21098, 21099, 21100, 21101, 21102, 21103, 21104, 21105, 21106, 21107, 21108, 21109, 21110, 21111, 21112, 21113, 21114, 21115, 21116, 21117, 21118, 21119, 21120, 21121, 21122, 21123, 21124, 21125, 21126, 21127, 21128, 21129, 21130, 21131, 21132, 21133, 21134, 21135, 21136, 21137, 21138, 21139, 21140, 21141, 21142, 21143, 21144, 21145, 21146, 21147, 21148, 21149, 21150, 21151, 21152, 21153, 21154, 21155, 21156, 21157, 21158, 21159, 21160, 21161, 21162, 21163, 21164, 21165, 21166, 21167, 21168, 21169, 21170, 21171, 21172, 21173, 21174, 21175, 21176, 21177, 21178, 21179, 21180, 21181, 21182, 21183, 21184, 21185, 21186, 21187, 21188, 21189, 21190, 21191, 21192, 21193, 21194, 21195, 21196, 21197, 21198, 21199, 21200, 21201, 21202, 21203, 21204, 21205, 21206, 21207, 21208, 21209, 21210, 21211, 21212, 21213, 21214, 21215, 21216, 21217, 21218, 21219, 21220, 21221, 21222, 21223, 21224, 21225, 21226, 21227, 21228, 21229, 21230, 21231, 21232, 21233, 21234, 21235, 21236, 21237, 21238, 21239, 21240, 21241, 21242, 21243, 21244, 21245, 21246, 21247, 21248, 21249, 21250, 21251, 21252, 21253, 21254, 21255, 21256, 21257, 21258, 21259, 21260, 21261, 21262, 21263, 21264, 21265, 21266, 21267, 21268, 21269, 21270, 21271, 21272, 21273, 21274, 21275, 21276, 21277, 21278, 21279, 21280, 21281, 21282, 21283, 21284, 21285, 21286, 21287, 21288, 21289, 21290, 21291, 21292, 21293, 21294, 21295, 21296, 21297, 21298, 21299, 21300, 21301, 21302, 21303, 21304, 21305, 21306, 21307, 21308, 21309, 21310, 21311, 21312, 21313, 21314, 21315, 21316, 21317, 21318, 21319, 21320, 21321, 21322, 21323, 21324, 21325, 21326, 21327, 21328, 21329, 21330, 21331, 21332, 21333, 21334, 21335, 21336, 21337, 21338, 21339, 21340, 21341, 21342, 21343, 21344, 21345, 21346, 21347, 21348, 21349, 21350, 21351, 21352, 21353, 21354, 21355, 21356, 21357, 21358, 21359, 21360, 21361, 21362, 21363, 21364, 21365, 21366, 21367, 21368, 21369, 21370, 21371, 21372, 21373, 21374, 21375, 21376, 21377, 21378, 21379, 21380, 21381, 21382, 21383, 21384, 21385, 21386, 21387, 21388, 21389, 21390, 21391, 21392, 21393, 21394, 21395, 21396, 21397, 21398, 21399, 21400, 21401, 21402, 21403, 21404, 21405, 21406, 21407, 21408, 21409, 21410, 21411, 21412, 21413, 21414, 21415, 21416, 21417, 21418, 21419, 21420, 21421, 21422, 21423, 21424, 21425, 21426, 21427, 21428, 21429, 21430, 21431, 21432, 21433, 21434, 21435, 21436, 21437, 21438, 21439, 21440, 21441, 21442, 21443, 21444, 21445, 21446, 21447, 21448, 21449, 21450, 21451, 21452, 21453, 21454, 21455, 21456, 21457, 21458, 21459, 21460, 21461, 21462, 21463, 21464, 21465, 21466, 21467, 21468, 21469, 21470, 21471, 21472, 21473, 21474, 21475, 21476, 21477, 21478, 21479, 21480, 21481, 21482, 21483, 21484, 21485, 21486, 21487, 21488, 21489, 21490, 21491, 21492, 21493, 21494, 21495, 21496, 21497, 21498, 21499, 21500, 21501, 21502, 21503, 21504, 21505, 21506, 21507, 21508, 21509, 21510, 21511, 21512, 21513, 21514, 21515, 21516, 21517, 21518, 21519, 21520, 21521, 21522, 21523, 21524, 21525, 21526, 21527, 21528, 21529, 21530, 21531, 21532, 21533, 21534, 21535, 21536, 21537, 21538, 21539, 21540, 21541, 21542, 21543, 21544, 21545, 21546, 21547, 21548, 21549, 21550, 21551, 21552, 21553, 21554, 21555, 21556, 21557, 21558, 21559, 21560, 21561, 21562, 21563, 21564, 21565, 21566, 21567, 21568, 21569, 21570, 21571, 21572, 21573, 21574, 21575, 21576, 21577, 21578, 21579, 21580, 21581, 21582, 21583, 21584, 21585, 21586, 21587, 21588, 21589, 21590, 21591, 21592, 21593, 21594, 21595, 21596, 21597, 21598, 21599, 21600, 21601, 21602, 21603, 21604, 21605, 21606, 21607, 21608, 21609, 21610, 21611, 21612, 21613, 21614, 21615, 21616, 21617, 21618, 21619, 21620, 21621, 21622, 21623, 21624, 21625, 21626, 21627, 21628, 21629, 21630, 21631, 21632, 21633, 21634, 21635, 21636, 21637, 21638, 21639, 21640, 21641, 21642, 21643, 21644, 21645, 21646, 21647, 21648, 21649, 21650, 21651, 21652, 21653, 21654, 21655, 21656, 21657, 21658, 21659, 21660, 21661, 21662, 21663, 21664, 21665, 21666, 21667, 21668, 21669, 21670, 21671, 21672, 21673, 21674, 21675, 21676, 21677, 21678, 21679, 21680, 21681, 21682, 21683, 21684, 21685, 21686, 21687, 21688, 21689, 21690, 21691, 21692, 21693, 21694, 21695, 21696, 21697, 21698, 21699, 21700, 21701, 21702, 21703, 21704, 21705, 21706, 21707, 21708, 21709, 21710, 21711, 21712, 21713, 21714, 21715, 21716, 21717, 21718, 21719, 21720, 21721, 21722, 21723, 21724, 21725, 21726, 21727, 21728, 21729, 21730, 21731, 21732, 21733, 21734, 21735, 21736, 21737, 21738, 21739, 21740, 21741, 21742, 21743, 21744, 21745, 21746, 21747, 21748, 21749, 21750, 21751, 21752, 21753, 21754, 21755, 21756, 21757, 21758, 21759, 21760, 21761, 21762, 21763, 21764, 21765, 21766, 21767, 21768, 21769, 21770, 21771, 21772, 21773, 21774, 21775, 21776, 21777, 21778, 21779, 21780, 21781, 21782, 21783, 21784, 21785, 21786, 21787, 21788, 21789, 21790, 21791, 21792, 21793, 21794, 21795, 21796, 21797, 21798, 21799, 21800, 21801, 21802, 21803, 21804, 21805, 21806, 21807, 21808, 21809, 21810, 21811, 21812, 21813, 21814, 21815, 21816, 21817, 21818, 21819, 21820, 21821, 21822, 21823, 21824, 21825, 21826, 21827, 21828, 21829, 21830, 21831, 21832, 21833, 21834, 21835, 21836, 21837, 21838, 21839, 21840, 21841, 21842, 21843, 21844, 21845, 21846, 21847, 21848, 21849, 21850, 21851, 21852, 21853, 21854, 21855, 21856, 21857, 21858, 21859, 21860, 21861, 21862, 21863, 21864, 21865, 21866, 21867, 21868, 21869, 21870, 21871, 21872, 21873, 21874, 21875, 21876, 21877, 21878, 21879, 21880, 21881, 21882, 21883, 21884, 21885, 21886, 21887, 21888, 21889, 21890, 21891, 21892, 21893, 21894, 21895, 21896, 21897, 21898, 21899, 21900, 21901, 21902, 21903, 21904, 21905, 21906, 21907, 21908, 21909, 21910, 21911, 21912, 21913, 21914, 21915, 21916, 21917, 21918, 21919, 21920, 21921, 21922, 21923, 21924, 21925, 21926, 21927, 21928, 21929, 21930, 21931, 21932, 21933, 21934, 21935, 21936, 21937, 21938, 21939, 21940, 21941, 21942, 21943, 21944, 21945, 21946, 21947, 21948, 21949, 21950, 21951, 21952, 21953, 21954, 21955, 21956, 21957, 21958, 21959, 21960, 21961, 21962, 21963, 21964, 21965, 21966, 21967, 21968, 21969, 21970, 21971, 21972, 21973, 21974, 21975, 21976, 21977, 21978, 21979, 21980, 21981, 21982, 21983, 21984, 21985, 21986, 21987, 21988, 21989, 21990, 21991, 21992, 21993, 21994, 21995, 21996, 21997, 21998, 21999, 22000, 22001, 22002, 22003, 22004, 22005, 22006, 22007, 22008, 22009, 22010, 22011, 22012, 22013, 22014, 22015, 22016, 22017, 22018, 22019, 22020, 22021, 22022, 22023, 22024, 22025, 22026, 22027, 22028, 22029, 22030, 22031, 22032, 22033, 22034, 22035, 22036, 22037, 22038, 22039, 22040, 22041, 22042, 22043, 22044, 22045, 22046, 22047, 22048, 22049, 22050, 22051, 22052, 22053, 22054, 22055, 22056, 22057, 22058, 22059, 22060, 22061, 22062, 22063, 22064, 22065, 22066, 22067, 22068, 22069, 22070, 22071, 22072, 22073, 22074, 22075, 22076, 22077, 22078, 22079, 22080, 22081, 22082, 22083, 22084, 22085, 22086, 22087, 22088, 22089, 22090, 22091, 22092, 22093, 22094, 22095, 22096, 22097, 22098, 22099, 22100, 22101, 22102, 22103, 22104, 22105, 22106, 22107, 22108, 22109, 22110, 22111, 22112, 22113, 22114, 22115, 22116, 22117, 22118, 22119, 22120, 22121, 22122, 22123, 22124, 22125, 22126, 22127, 22128, 22129, 22130, 22131, 22132, 22133, 22134, 22135, 22136, 22137, 22138, 22139, 22140, 22141, 22142, 22143, 22144, 22145, 22146, 22147, 22148, 22149, 22150, 22151, 22152, 22153, 22154, 22155, 22156, 22157, 22158, 22159, 22160, 22161, 22162, 22163, 22164, 22165, 22166, 22167, 22168, 22169, 22170, 22171, 22172, 22173, 22174, 22175, 22176, 22177, 22178, 22179, 22180, 22181, 22182, 22183, 22184, 22185, 22186, 22187, 22188, 22189, 22190, 22191, 22192, 22193, 22194, 22195, 22196, 22197, 22198, 22199, 22200, 22201, 22202, 22203, 22204, 22205, 22206, 22207, 22208, 22209, 22210, 22211, 22212, 22213, 22214, 22215, 22216, 22217, 22218, 22219, 22220, 22221, 22222, 22223, 22224, 22225, 22226, 22227, 22228, 22229, 22230, 22231, 22232, 22233, 22234, 22235, 22236, 22237, 22238, 22239, 22240, 22241, 22242, 22243, 22244, 22245, 22246, 22247, 22248, 22249, 22250, 22251, 22252, 22253, 22254, 22255, 22256, 22257, 22258, 22259, 22260, 22261, 22262, 22263, 22264, 22265, 22266, 22267, 22268, 22269, 22270, 22271, 22272, 22273, 22274, 22275, 22276, 22277, 22278, 22279, 22280, 22281, 22282, 22283, 22284, 22285, 22286, 22287, 22288, 22289, 22290, 22291, 22292, 22293, 22294, 22295, 22296, 22297, 22298, 22299, 22300, 22301, 22302, 22303, 22304, 22305, 22306, 22307, 22308, 22309, 22310, 22311, 22312, 22313, 22314, 22315, 22316, 22317, 22318, 22319, 22320, 22321, 22322, 22323, 22324, 22325, 22326, 22327, 22328, 22329, 22330, 22331, 22332, 22333, 22334, 22335, 22336, 22337, 22338, 22339, 22340, 22341, 22342, 22343, 22344, 22345, 22346, 22347, 22348, 22349, 22350, 22351, 22352, 22353, 22354, 22355, 22356, 22357, 22358, 22359, 22360, 22361, 22362, 22363, 22364, 22365, 22366, 22367, 22368, 22369, 22370, 22371, 22372, 22373, 22374, 22375, 22376, 22377, 22378, 22379, 22380, 22381, 22382, 22383, 22384, 22385, 22386, 22387, 22388, 22389, 22390, 22391, 22392, 22393, 22394, 22395, 22396, 22397, 22398, 22399, 22400, 22401, 22402, 22403, 22404, 22405, 22406, 22407, 22408, 22409, 22410, 22411, 22412, 22413, 22414, 22415, 22416, 22417, 22418, 22419, 22420, 22421, 22422, 22423, 22424, 22425, 22426, 22427, 22428, 22429, 22430, 22431, 22432, 22433, 22434, 22435, 22436, 22437, 22438, 22439, 22440, 22441, 22442, 22443, 22444, 22445, 22446, 22447, 22448, 22449, 22450, 22451, 22452, 22453, 22454, 22455, 22456, 22457, 22458, 22459, 22460, 22461, 22462, 22463, 22464, 22465, 22466, 22467, 22468, 22469, 22470, 22471, 22472, 22473, 22474, 22475, 22476, 22477, 22478, 22479, 22480, 22481, 22482, 22483, 22484, 22485, 22486, 22487, 22488, 22489, 22490, 22491, 22492, 22493, 22494, 22495, 22496, 22497, 22498, 22499, 22500, 22501, 22502, 22503, 22504, 22505, 22506, 22507, 22508, 22509, 22510, 22511, 22512, 22513, 22514, 22515, 22516, 22517, 22518, 22519, 22520, 22521, 22522, 22523, 22524, 22525, 22526, 22527, 22528, 22529, 22530, 22531, 22532, 22533, 22534, 22535, 22536, 22537, 22538, 22539, 22540, 22541, 22542, 22543, 22544, 22545, 22546, 22547, 22548, 22549, 22550, 22551, 22552, 22553, 22554, 22555, 22556, 22557, 22558, 22559, 22560, 22561, 22562, 22563, 22564, 22565, 22566, 22567, 22568, 22569, 22570, 22571, 22572, 22573, 22574, 22575, 22576, 22577, 22578, 22579, 22580, 22581, 22582, 22583, 22584, 22585, 22586, 22587, 22588, 22589, 22590, 22591, 22592, 22593, 22594, 22595, 22596, 22597, 22598, 22599, 22600, 22601, 22602, 22603, 22604, 22605, 22606, 22607, 22608, 22609, 22610, 22611, 22612, 22613, 22614, 22615, 22616, 22617, 22618, 22619, 22620, 22621, 22622, 22623, 22624, 22625, 22626, 22627, 22628, 22629, 22630, 22631, 22632, 22633, 22634, 22635, 22636, 22637, 22638, 22639, 22640, 22641, 22642, 22643, 22644, 22645, 22646, 22647, 22648, 22649, 22650, 22651, 22652, 22653, 22654, 22655, 22656, 22657, 22658, 22659, 22660, 22661, 22662, 22663, 22664, 22665, 22666, 22667, 22668, 22669, 22670, 22671, 22672, 22673, 22674, 22675, 22676, 22677, 22678, 22679, 22680, 22681, 22682, 22683, 22684, 22685, 22686, 22687, 22688, 22689, 22690, 22691, 22692, 22693, 22694, 22695, 22696, 22697, 22698, 22699, 22700, 22701, 22702, 22703, 22704, 22705, 22706, 22707, 22708, 22709, 22710, 22711, 22712, 22713, 22714, 22715, 22716, 22717, 22718, 22719, 22720, 22721, 22722, 22723, 22724, 22725, 22726, 22727, 22728, 22729, 22730, 22731, 22732, 22733, 22734, 22735, 22736, 22737, 22738, 22739, 22740, 22741, 22742, 22743, 22744, 22745, 22746, 22747, 22748, 22749, 22750, 22751, 22752, 22753, 22754, 22755, 22756, 22757, 22758, 22759, 22760, 22761, 22762, 22763, 22764, 22765, 22766, 22767, 22768, 22769, 22770, 22771, 22772, 22773, 22774, 22775, 22776, 22777, 22778, 22779, 22780, 22781, 22782, 22783, 22784, 22785, 22786, 22787, 22788, 22789, 22790, 22791, 22792, 22793, 22794, 22795, 22796, 22797, 22798, 22799, 22800, 22801, 22802, 22803, 22804, 22805, 22806, 22807, 22808, 22809, 22810, 22811, 22812, 22813, 22814, 22815, 22816, 22817, 22818, 22819, 22820, 22821, 22822, 22823, 22824, 22825, 22826, 22827, 22828, 22829, 22830, 22831, 22832, 22833, 22834, 22835, 22836, 22837, 22838, 22839, 22840, 22841, 22842, 22843, 22844, 22845, 22846, 22847, 22848, 22849, 22850, 22851, 22852, 22853, 22854, 22855, 22856, 22857, 22858, 22859, 22860, 22861, 22862, 22863, 22864, 22865, 22866, 22867, 22868, 22869, 22870, 22871, 22872, 22873, 22874, 22875, 22876, 22877, 22878, 22879, 22880, 22881, 22882, 22883, 22884, 22885, 22886, 22887, 22888, 22889, 22890, 22891, 22892, 22893, 22894, 22895, 22896, 22897, 22898, 22899, 22900, 22901, 22902, 22903, 22904, 22905, 22906, 22907, 22908, 22909, 22910, 22911, 22912, 22913, 22914, 22915, 22916, 22917, 22918, 22919, 22920, 22921, 22922, 22923, 22924, 22925, 22926, 22927, 22928, 22929, 22930, 22931, 22932, 22933, 22934, 22935, 22936, 22937, 22938, 22939, 22940, 22941, 22942, 22943, 22944, 22945, 22946, 22947, 22948, 22949, 22950, 22951, 22952, 22953, 22954, 22955, 22956, 22957, 22958, 22959, 22960, 22961, 22962, 22963, 22964, 22965, 22966, 22967, 22968, 22969, 22970, 22971, 22972, 22973, 22974, 22975, 22976, 22977, 22978, 22979, 22980, 22981, 22982, 22983, 22984, 22985, 22986, 22987, 22988, 22989, 22990, 22991, 22992, 22993, 22994, 22995, 22996, 22997, 22998, 22999, 23000, 23001, 23002, 23003, 23004, 23005, 23006, 23007, 23008, 23009, 23010, 23011, 23012, 23013, 23014, 23015, 23016, 23017, 23018, 23019, 23020, 23021, 23022, 23023, 23024, 23025, 23026, 23027, 23028, 23029, 23030, 23031, 23032, 23033, 23034, 23035, 23036, 23037, 23038, 23039, 23040, 23041, 23042, 23043, 23044, 23045, 23046, 23047, 23048, 23049, 23050, 23051, 23052, 23053, 23054, 23055, 23056, 23057, 23058, 23059, 23060, 23061, 23062, 23063, 23064, 23065, 23066, 23067, 23068, 23069, 23070, 23071, 23072, 23073, 23074, 23075, 23076, 23077, 23078, 23079, 23080, 23081, 23082, 23083, 23084, 23085, 23086, 23087, 23088, 23089, 23090, 23091, 23092, 23093, 23094, 23095, 23096, 23097, 23098, 23099, 23100, 23101, 23102, 23103, 23104, 23105, 23106, 23107, 23108, 23109, 23110, 23111, 23112, 23113, 23114, 23115, 23116, 23117, 23118, 23119, 23120, 23121, 23122, 23123, 23124, 23125, 23126, 23127, 23128, 23129, 23130, 23131, 23132, 23133, 23134, 23135, 23136, 23137, 23138, 23139, 23140, 23141, 23142, 23143, 23144, 23145, 23146, 23147, 23148, 23149, 23150, 23151, 23152, 23153, 23154, 23155, 23156, 23157, 23158, 23159, 23160, 23161, 23162, 23163, 23164, 23165, 23166, 23167, 23168, 23169, 23170, 23171, 23172, 23173, 23174, 23175, 23176, 23177, 23178, 23179, 23180, 23181, 23182, 23183, 23184, 23185, 23186, 23187, 23188, 23189, 23190, 23191, 23192, 23193, 23194, 23195, 23196, 23197, 23198, 23199, 23200, 23201, 23202, 23203, 23204, 23205, 23206, 23207, 23208, 23209, 23210, 23211, 23212, 23213, 23214, 23215, 23216, 23217, 23218, 23219, 23220, 23221, 23222, 23223, 23224, 23225, 23226, 23227, 23228, 23229, 23230, 23231, 23232, 23233, 23234, 23235, 23236, 23237, 23238, 23239, 23240, 23241, 23242, 23243, 23244, 23245, 23246, 23247, 23248, 23249, 23250, 23251, 23252, 23253, 23254, 23255, 23256, 23257, 23258, 23259, 23260, 23261, 23262, 23263, 23264, 23265, 23266, 23267, 23268, 23269, 23270, 23271, 23272, 23273, 23274, 23275, 23276, 23277, 23278, 23279, 23280, 23281, 23282, 23283, 23284, 23285, 23286, 23287, 23288, 23289, 23290, 23291, 23292, 23293, 23294, 23295, 23296, 23297, 23298, 23299, 23300, 23301, 23302, 23303, 23304, 23305, 23306, 23307, 23308, 23309, 23310, 23311, 23312, 23313, 23314, 23315, 23316, 23317, 23318, 23319, 23320, 23321, 23322, 23323, 23324, 23325, 23326, 23327, 23328, 23329, 23330, 23331, 23332, 23333, 23334, 23335, 23336, 23337, 23338, 23339, 23340, 23341, 23342, 23343, 23344, 23345, 23346, 23347, 23348, 23349, 23350, 23351, 23352, 23353, 23354, 23355, 23356, 23357, 23358, 23359, 23360, 23361, 23362, 23363, 23364, 23365, 23366, 23367, 23368, 23369, 23370, 23371, 23372, 23373, 23374, 23375, 23376, 23377, 23378, 23379, 23380, 23381, 23382, 23383, 23384, 23385, 23386, 23387, 23388, 23389, 23390, 23391, 23392, 23393, 23394, 23395, 23396, 23397, 23398, 23399, 23400, 23401, 23402, 23403, 23404, 23405, 23406, 23407, 23408, 23409, 23410, 23411, 23412, 23413, 23414, 23415, 23416, 23417, 23418, 23419, 23420, 23421, 23422, 23423, 23424, 23425, 23426, 23427, 23428, 23429, 23430, 23431, 23432, 23433, 23434, 23435, 23436, 23437, 23438, 23439, 23440, 23441, 23442, 23443, 23444, 23445, 23446, 23447, 23448, 23449, 23450, 23451, 23452, 23453, 23454, 23455, 23456, 23457, 23458, 23459, 23460, 23461, 23462, 23463, 23464, 23465, 23466, 23467, 23468, 23469, 23470, 23471, 23472, 23473, 23474, 23475, 23476, 23477, 23478, 23479, 23480, 23481, 23482, 23483, 23484, 23485, 23486, 23487, 23488, 23489, 23490, 23491, 23492, 23493, 23494, 23495, 23496, 23497, 23498, 23499, 23500, 23501, 23502, 23503, 23504, 23505, 23506, 23507, 23508, 23509, 23510, 23511, 23512, 23513, 23514, 23515, 23516, 23517, 23518, 23519, 23520, 23521, 23522, 23523, 23524, 23525, 23526, 23527, 23528, 23529, 23530, 23531, 23532, 23533, 23534, 23535, 23536, 23537, 23538, 23539, 23540, 23541, 23542, 23543, 23544, 23545, 23546, 23547, 23548, 23549, 23550, 23551, 23552, 23553, 23554, 23555, 23556, 23557, 23558, 23559, 23560, 23561, 23562, 23563, 23564, 23565, 23566, 23567, 23568, 23569, 23570, 23571, 23572, 23573, 23574, 23575, 23576, 23577, 23578, 23579, 23580, 23581, 23582, 23583, 23584, 23585, 23586, 23587, 23588, 23589, 23590, 23591, 23592, 23593, 23594, 23595, 23596, 23597, 23598, 23599, 23600, 23601, 23602, 23603, 23604, 23605, 23606, 23607, 23608, 23609, 23610, 23611, 23612, 23613, 23614, 23615, 23616, 23617, 23618, 23619, 23620, 23621, 23622, 23623, 23624, 23625, 23626, 23627, 23628, 23629, 23630, 23631, 23632, 23633, 23634, 23635, 23636, 23637, 23638, 23639, 23640, 23641, 23642, 23643, 23644, 23645, 23646, 23647, 23648, 23649, 23650, 23651, 23652, 23653, 23654, 23655, 23656, 23657, 23658, 23659, 23660, 23661, 23662, 23663, 23664, 23665, 23666, 23667, 23668, 23669, 23670, 23671, 23672, 23673, 23674, 23675, 23676, 23677, 23678, 23679, 23680, 23681, 23682, 23683, 23684, 23685, 23686, 23687, 23688, 23689, 23690, 23691, 23692, 23693, 23694, 23695, 23696, 23697, 23698, 23699, 23700, 23701, 23702, 23703, 23704, 23705, 23706, 23707, 23708, 23709, 23710, 23711, 23712, 23713, 23714, 23715, 23716, 23717, 23718, 23719, 23720, 23721, 23722, 23723, 23724, 23725, 23726, 23727, 23728, 23729, 23730, 23731, 23732, 23733, 23734, 23735, 23736, 23737, 23738, 23739, 23740, 23741, 23742, 23743, 23744, 23745, 23746, 23747, 23748, 23749, 23750, 23751, 23752, 23753, 23754, 23755, 23756, 23757, 23758, 23759, 23760, 23761, 23762, 23763, 23764, 23765, 23766, 23767, 23768, 23769, 23770, 23771, 23772, 23773, 23774, 23775, 23776, 23777, 23778, 23779, 23780, 23781, 23782, 23783, 23784, 23785, 23786, 23787, 23788, 23789, 23790, 23791, 23792, 23793, 23794, 23795, 23796, 23797, 23798, 23799, 23800, 23801, 23802, 23803, 23804, 23805, 23806, 23807, 23808, 23809, 23810, 23811, 23812, 23813, 23814, 23815, 23816, 23817, 23818, 23819, 23820, 23821, 23822, 23823, 23824, 23825, 23826, 23827, 23828, 23829, 23830, 23831, 23832, 23833, 23834, 23835, 23836, 23837, 23838, 23839, 23840, 23841, 23842, 23843, 23844, 23845, 23846, 23847, 23848, 23849, 23850, 23851, 23852, 23853, 23854, 23855, 23856, 23857, 23858, 23859, 23860, 23861, 23862, 23863, 23864, 23865, 23866, 23867, 23868, 23869, 23870, 23871, 23872, 23873, 23874, 23875, 23876, 23877, 23878, 23879, 23880, 23881, 23882, 23883, 23884, 23885, 23886, 23887, 23888, 23889, 23890, 23891, 23892, 23893, 23894, 23895, 23896, 23897, 23898, 23899, 23900, 23901, 23902, 23903, 23904, 23905, 23906, 23907, 23908, 23909, 23910, 23911, 23912, 23913, 23914, 23915, 23916, 23917, 23918, 23919, 23920, 23921, 23922, 23923, 23924, 23925, 23926, 23927, 23928, 23929, 23930, 23931, 23932, 23933, 23934, 23935, 23936, 23937, 23938, 23939, 23940, 23941, 23942, 23943, 23944, 23945, 23946, 23947, 23948, 23949, 23950, 23951, 23952, 23953, 23954, 23955, 23956, 23957, 23958, 23959, 23960, 23961, 23962, 23963, 23964, 23965, 23966, 23967, 23968, 23969, 23970, 23971, 23972, 23973, 23974, 23975, 23976, 23977, 23978, 23979, 23980, 23981, 23982, 23983, 23984, 23985, 23986, 23987, 23988, 23989, 23990, 23991, 23992, 23993, 23994, 23995, 23996, 23997, 23998, 23999, 24000, 24001, 24002, 24003, 24004, 24005, 24006, 24007, 24008, 24009, 24010, 24011, 24012, 24013, 24014, 24015, 24016, 24017, 24018, 24019, 24020, 24021, 24022, 24023, 24024, 24025, 24026, 24027, 24028, 24029, 24030, 24031, 24032, 24033, 24034, 24035, 24036, 24037, 24038, 24039, 24040, 24041, 24042, 24043, 24044, 24045, 24046, 24047, 24048, 24049, 24050, 24051, 24052, 24053, 24054, 24055, 24056, 24057, 24058, 24059, 24060, 24061, 24062, 24063, 24064, 24065, 24066, 24067, 24068, 24069, 24070, 24071, 24072, 24073, 24074, 24075, 24076, 24077, 24078, 24079, 24080, 24081, 24082, 24083, 24084, 24085, 24086, 24087, 24088, 24089, 24090, 24091, 24092, 24093, 24094, 24095, 24096, 24097, 24098, 24099, 24100, 24101, 24102, 24103, 24104, 24105, 24106, 24107, 24108, 24109, 24110, 24111, 24112, 24113, 24114, 24115, 24116, 24117, 24118, 24119, 24120, 24121, 24122, 24123, 24124, 24125, 24126, 24127, 24128, 24129, 24130, 24131, 24132, 24133, 24134, 24135, 24136, 24137, 24138, 24139, 24140, 24141, 24142, 24143, 24144, 24145, 24146, 24147, 24148, 24149, 24150, 24151, 24152, 24153, 24154, 24155, 24156, 24157, 24158, 24159, 24160, 24161, 24162, 24163, 24164, 24165, 24166, 24167, 24168, 24169, 24170, 24171, 24172, 24173, 24174, 24175, 24176, 24177, 24178, 24179, 24180, 24181, 24182, 24183, 24184, 24185, 24186, 24187, 24188, 24189, 24190, 24191, 24192, 24193, 24194, 24195, 24196, 24197, 24198, 24199, 24200, 24201, 24202, 24203, 24204, 24205, 24206, 24207, 24208, 24209, 24210, 24211, 24212, 24213, 24214, 24215, 24216, 24217, 24218, 24219, 24220, 24221, 24222, 24223, 24224, 24225, 24226, 24227, 24228, 24229, 24230, 24231, 24232, 24233, 24234, 24235, 24236, 24237, 24238, 24239, 24240, 24241, 24242, 24243, 24244, 24245, 24246, 24247, 24248, 24249, 24250, 24251, 24252, 24253, 24254, 24255, 24256, 24257, 24258, 24259, 24260, 24261, 24262, 24263, 24264, 24265, 24266, 24267, 24268, 24269, 24270, 24271, 24272, 24273, 24274, 24275, 24276, 24277, 24278, 24279, 24280, 24281, 24282, 24283, 24284, 24285, 24286, 24287, 24288, 24289, 24290, 24291, 24292, 24293, 24294, 24295, 24296, 24297, 24298, 24299, 24300, 24301, 24302, 24303, 24304, 24305, 24306, 24307, 24308, 24309, 24310, 24311, 24312, 24313, 24314, 24315, 24316, 24317, 24318, 24319, 24320, 24321, 24322, 24323, 24324, 24325, 24326, 24327, 24328, 24329, 24330, 24331, 24332, 24333, 24334, 24335, 24336, 24337, 24338, 24339, 24340, 24341, 24342, 24343, 24344, 24345, 24346, 24347, 24348, 24349, 24350, 24351, 24352, 24353, 24354, 24355, 24356, 24357, 24358, 24359, 24360, 24361, 24362, 24363, 24364, 24365, 24366, 24367, 24368, 24369, 24370, 24371, 24372, 24373, 24374, 24375, 24376, 24377, 24378, 24379, 24380, 24381, 24382, 24383, 24384, 24385, 24386, 24387, 24388, 24389, 24390, 24391, 24392, 24393, 24394, 24395, 24396, 24397, 24398, 24399, 24400, 24401, 24402, 24403, 24404, 24405, 24406, 24407, 24408, 24409, 24410, 24411, 24412, 24413, 24414, 24415, 24416, 24417, 24418, 24419, 24420, 24421, 24422, 24423, 24424, 24425, 24426, 24427, 24428, 24429, 24430, 24431, 24432, 24433, 24434, 24435, 24436, 24437, 24438, 24439, 24440, 24441, 24442, 24443, 24444, 24445, 24446, 24447, 24448, 24449, 24450, 24451, 24452, 24453, 24454, 24455, 24456, 24457, 24458, 24459, 24460, 24461, 24462, 24463, 24464, 24465, 24466, 24467, 24468, 24469, 24470, 24471, 24472, 24473, 24474, 24475, 24476, 24477, 24478, 24479, 24480, 24481, 24482, 24483, 24484, 24485, 24486, 24487, 24488, 24489, 24490, 24491, 24492, 24493, 24494, 24495, 24496, 24497, 24498, 24499, 24500, 24501, 24502, 24503, 24504, 24505, 24506, 24507, 24508, 24509, 24510, 24511, 24512, 24513, 24514, 24515, 24516, 24517, 24518, 24519, 24520, 24521, 24522, 24523, 24524, 24525, 24526, 24527, 24528, 24529, 24530, 24531, 24532, 24533, 24534, 24535, 24536, 24537, 24538, 24539, 24540, 24541, 24542, 24543, 24544, 24545, 24546, 24547, 24548, 24549, 24550, 24551, 24552, 24553, 24554, 24555, 24556, 24557, 24558, 24559, 24560, 24561, 24562, 24563, 24564, 24565, 24566, 24567, 24568, 24569, 24570, 24571, 24572, 24573, 24574, 24575, 24576, 24577, 24578, 24579, 24580, 24581, 24582, 24583, 24584, 24585, 24586, 24587, 24588, 24589, 24590, 24591, 24592, 24593, 24594, 24595, 24596, 24597, 24598, 24599, 24600, 24601, 24602, 24603, 24604, 24605, 24606, 24607, 24608, 24609, 24610, 24611, 24612, 24613, 24614, 24615, 24616, 24617, 24618, 24619, 24620, 24621, 24622, 24623, 24624, 24625, 24626, 24627, 24628, 24629, 24630, 24631, 24632, 24633, 24634, 24635, 24636, 24637, 24638, 24639, 24640, 24641, 24642, 24643, 24644, 24645, 24646, 24647, 24648, 24649, 24650, 24651, 24652, 24653, 24654, 24655, 24656, 24657, 24658, 24659, 24660, 24661, 24662, 24663, 24664, 24665, 24666, 24667, 24668, 24669, 24670, 24671, 24672, 24673, 24674, 24675, 24676, 24677, 24678, 24679, 24680, 24681, 24682, 24683, 24684, 24685, 24686, 24687, 24688, 24689, 24690, 24691, 24692, 24693, 24694, 24695, 24696, 24697, 24698, 24699, 24700, 24701, 24702, 24703, 24704, 24705, 24706, 24707, 24708, 24709, 24710, 24711, 24712, 24713, 24714, 24715, 24716, 24717, 24718, 24719, 24720, 24721, 24722, 24723, 24724, 24725, 24726, 24727, 24728, 24729, 24730, 24731, 24732, 24733, 24734, 24735, 24736, 24737, 24738, 24739, 24740, 24741, 24742, 24743, 24744, 24745, 24746, 24747, 24748, 24749, 24750, 24751, 24752, 24753, 24754, 24755, 24756, 24757, 24758, 24759, 24760, 24761, 24762, 24763, 24764, 24765, 24766, 24767, 24768, 24769, 24770, 24771, 24772, 24773, 24774, 24775, 24776, 24777, 24778, 24779, 24780, 24781, 24782, 24783, 24784, 24785, 24786, 24787, 24788, 24789, 24790, 24791, 24792, 24793, 24794, 24795, 24796, 24797, 24798, 24799, 24800, 24801, 24802, 24803, 24804, 24805, 24806, 24807, 24808, 24809, 24810, 24811, 24812, 24813, 24814, 24815, 24816, 24817, 24818, 24819, 24820, 24821, 24822, 24823, 24824, 24825, 24826, 24827, 24828, 24829, 24830, 24831, 24832, 24833, 24834, 24835, 24836, 24837, 24838, 24839, 24840, 24841, 24842, 24843, 24844, 24845, 24846, 24847, 24848, 24849, 24850, 24851, 24852, 24853, 24854, 24855, 24856, 24857, 24858, 24859, 24860, 24861, 24862, 24863, 24864, 24865, 24866, 24867, 24868, 24869, 24870, 24871, 24872, 24873, 24874, 24875, 24876, 24877, 24878, 24879, 24880, 24881, 24882, 24883, 24884, 24885, 24886, 24887, 24888, 24889, 24890, 24891, 24892, 24893, 24894, 24895, 24896, 24897, 24898, 24899, 24900, 24901, 24902, 24903, 24904, 24905, 24906, 24907, 24908, 24909, 24910, 24911, 24912, 24913, 24914, 24915, 24916, 24917, 24918, 24919, 24920, 24921, 24922, 24923, 24924, 24925, 24926, 24927, 24928, 24929, 24930, 24931, 24932, 24933, 24934, 24935, 24936, 24937, 24938, 24939, 24940, 24941, 24942, 24943, 24944, 24945, 24946, 24947, 24948, 24949, 24950, 24951, 24952, 24953, 24954, 24955, 24956, 24957, 24958, 24959, 24960, 24961, 24962, 24963, 24964, 24965, 24966, 24967, 24968, 24969, 24970, 24971, 24972, 24973, 24974, 24975, 24976, 24977, 24978, 24979, 24980, 24981, 24982, 24983, 24984, 24985, 24986, 24987, 24988, 24989, 24990, 24991, 24992, 24993, 24994, 24995, 24996, 24997, 24998, 24999, 25000, 25001, 25002, 25003, 25004, 25005, 25006, 25007, 25008, 25009, 25010, 25011, 25012, 25013, 25014, 25015, 25016, 25017, 25018, 25019, 25020, 25021, 25022, 25023, 25024, 25025, 25026, 25027, 25028, 25029, 25030, 25031, 25032, 25033, 25034, 25035, 25036, 25037, 25038, 25039, 25040, 25041, 25042, 25043, 25044, 25045, 25046, 25047, 25048, 25049, 25050, 25051, 25052, 25053, 25054, 25055, 25056, 25057, 25058, 25059, 25060, 25061, 25062, 25063, 25064, 25065, 25066, 25067, 25068, 25069, 25070, 25071, 25072, 25073, 25074, 25075, 25076, 25077, 25078, 25079, 25080, 25081, 25082, 25083, 25084, 25085, 25086, 25087, 25088, 25089, 25090, 25091, 25092, 25093, 25094, 25095, 25096, 25097, 25098, 25099, 25100, 25101, 25102, 25103, 25104, 25105, 25106, 25107, 25108, 25109, 25110, 25111, 25112, 25113, 25114, 25115, 25116, 25117, 25118, 25119, 25120, 25121, 25122, 25123, 25124, 25125, 25126, 25127, 25128, 25129, 25130, 25131, 25132, 25133, 25134, 25135, 25136, 25137, 25138, 25139, 25140, 25141, 25142, 25143, 25144, 25145, 25146, 25147, 25148, 25149, 25150, 25151, 25152, 25153, 25154, 25155, 25156, 25157, 25158, 25159, 25160, 25161, 25162, 25163, 25164, 25165, 25166, 25167, 25168, 25169, 25170, 25171, 25172, 25173, 25174, 25175, 25176, 25177, 25178, 25179, 25180, 25181, 25182, 25183, 25184, 25185, 25186, 25187, 25188, 25189, 25190, 25191, 25192, 25193, 25194, 25195, 25196, 25197, 25198, 25199, 25200, 25201, 25202, 25203, 25204, 25205, 25206, 25207, 25208, 25209, 25210, 25211, 25212, 25213, 25214, 25215, 25216, 25217, 25218, 25219, 25220, 25221, 25222, 25223, 25224, 25225, 25226, 25227, 25228, 25229, 25230, 25231, 25232, 25233, 25234, 25235, 25236, 25237, 25238, 25239, 25240, 25241, 25242, 25243, 25244, 25245, 25246, 25247, 25248, 25249, 25250, 25251, 25252, 25253, 25254, 25255, 25256, 25257, 25258, 25259, 25260, 25261, 25262, 25263, 25264, 25265, 25266, 25267, 25268, 25269, 25270, 25271, 25272, 25273, 25274, 25275, 25276, 25277, 25278, 25279, 25280, 25281, 25282, 25283, 25284, 25285, 25286, 25287, 25288, 25289, 25290, 25291, 25292, 25293, 25294, 25295, 25296, 25297, 25298, 25299, 25300, 25301, 25302, 25303, 25304, 25305, 25306, 25307, 25308, 25309, 25310, 25311, 25312, 25313, 25314, 25315, 25316, 25317, 25318, 25319, 25320, 25321, 25322, 25323, 25324, 25325, 25326, 25327, 25328, 25329, 25330, 25331, 25332, 25333, 25334, 25335, 25336, 25337, 25338, 25339, 25340, 25341, 25342, 25343, 25344, 25345, 25346, 25347, 25348, 25349, 25350, 25351, 25352, 25353, 25354, 25355, 25356, 25357, 25358, 25359, 25360, 25361, 25362, 25363, 25364, 25365, 25366, 25367, 25368, 25369, 25370, 25371, 25372, 25373, 25374, 25375, 25376, 25377, 25378, 25379, 25380, 25381, 25382, 25383, 25384, 25385, 25386, 25387, 25388, 25389, 25390, 25391, 25392, 25393, 25394, 25395, 25396, 25397, 25398, 25399, 25400, 25401, 25402, 25403, 25404, 25405, 25406, 25407, 25408, 25409, 25410, 25411, 25412, 25413, 25414, 25415, 25416, 25417, 25418, 25419, 25420, 25421, 25422, 25423, 25424, 25425, 25426, 25427, 25428, 25429, 25430, 25431, 25432, 25433, 25434, 25435, 25436, 25437, 25438, 25439, 25440, 25441, 25442, 25443, 25444, 25445, 25446, 25447, 25448, 25449, 25450, 25451, 25452, 25453, 25454, 25455, 25456, 25457, 25458, 25459, 25460, 25461, 25462, 25463, 25464, 25465, 25466, 25467, 25468, 25469, 25470, 25471, 25472, 25473, 25474, 25475, 25476, 25477, 25478, 25479, 25480, 25481, 25482, 25483, 25484, 25485, 25486, 25487, 25488, 25489, 25490, 25491, 25492, 25493, 25494, 25495, 25496, 25497, 25498, 25499, 25500, 25501, 25502, 25503, 25504, 25505, 25506, 25507, 25508, 25509, 25510, 25511, 25512, 25513, 25514, 25515, 25516, 25517, 25518, 25519, 25520, 25521, 25522, 25523, 25524, 25525, 25526, 25527, 25528, 25529, 25530, 25531, 25532, 25533, 25534, 25535, 25536, 25537, 25538, 25539, 25540, 25541, 25542, 25543, 25544, 25545, 25546, 25547, 25548, 25549, 25550, 25551, 25552, 25553, 25554, 25555, 25556, 25557, 25558, 25559, 25560, 25561, 25562, 25563, 25564, 25565, 25566, 25567, 25568, 25569, 25570, 25571, 25572, 25573, 25574, 25575, 25576, 25577, 25578, 25579, 25580, 25581, 25582, 25583, 25584, 25585, 25586, 25587, 25588, 25589, 25590, 25591, 25592, 25593, 25594, 25595, 25596, 25597, 25598, 25599, 25600, 25601, 25602, 25603, 25604, 25605, 25606, 25607, 25608, 25609, 25610, 25611, 25612, 25613, 25614, 25615, 25616, 25617, 25618, 25619, 25620, 25621, 25622, 25623, 25624, 25625, 25626, 25627, 25628, 25629, 25630, 25631, 25632, 25633, 25634, 25635, 25636, 25637, 25638, 25639, 25640, 25641, 25642, 25643, 25644, 25645, 25646, 25647, 25648, 25649, 25650, 25651, 25652, 25653, 25654, 25655, 25656, 25657, 25658, 25659, 25660, 25661, 25662, 25663, 25664, 25665, 25666, 25667, 25668, 25669, 25670, 25671, 25672, 25673, 25674, 25675, 25676, 25677, 25678, 25679, 25680, 25681, 25682, 25683, 25684, 25685, 25686, 25687, 25688, 25689, 25690, 25691, 25692, 25693, 25694, 25695, 25696, 25697, 25698, 25699, 25700, 25701, 25702, 25703, 25704, 25705, 25706, 25707, 25708, 25709, 25710, 25711, 25712, 25713, 25714, 25715, 25716, 25717, 25718, 25719, 25720, 25721, 25722, 25723, 25724, 25725, 25726, 25727, 25728, 25729, 25730, 25731, 25732, 25733, 25734, 25735, 25736, 25737, 25738, 25739, 25740, 25741, 25742, 25743, 25744, 25745, 25746, 25747, 25748, 25749, 25750, 25751, 25752, 25753, 25754, 25755, 25756, 25757, 25758, 25759, 25760, 25761, 25762, 25763, 25764, 25765, 25766, 25767, 25768, 25769, 25770, 25771, 25772, 25773, 25774, 25775, 25776, 25777, 25778, 25779, 25780, 25781, 25782, 25783, 25784, 25785, 25786, 25787, 25788, 25789, 25790, 25791, 25792, 25793, 25794, 25795, 25796, 25797, 25798, 25799, 25800, 25801, 25802, 25803, 25804, 25805, 25806, 25807, 25808, 25809, 25810, 25811, 25812, 25813, 25814, 25815, 25816, 25817, 25818, 25819, 25820, 25821, 25822, 25823, 25824, 25825, 25826, 25827, 25828, 25829, 25830, 25831, 25832, 25833, 25834, 25835, 25836, 25837, 25838, 25839, 25840, 25841, 25842, 25843, 25844, 25845, 25846, 25847, 25848, 25849, 25850, 25851, 25852, 25853, 25854, 25855, 25856, 25857, 25858, 25859, 25860, 25861, 25862, 25863, 25864, 25865, 25866, 25867, 25868, 25869, 25870, 25871, 25872, 25873, 25874, 25875, 25876, 25877, 25878, 25879, 25880, 25881, 25882, 25883, 25884, 25885, 25886, 25887, 25888, 25889, 25890, 25891, 25892, 25893, 25894, 25895, 25896, 25897, 25898, 25899, 25900, 25901, 25902, 25903, 25904, 25905, 25906, 25907, 25908, 25909, 25910, 25911, 25912, 25913, 25914, 25915, 25916, 25917, 25918, 25919, 25920, 25921, 25922, 25923, 25924, 25925, 25926, 25927, 25928, 25929, 25930, 25931, 25932, 25933, 25934, 25935, 25936, 25937, 25938, 25939, 25940, 25941, 25942, 25943, 25944, 25945, 25946, 25947, 25948, 25949, 25950, 25951, 25952, 25953, 25954, 25955, 25956, 25957, 25958, 25959, 25960, 25961, 25962, 25963, 25964, 25965, 25966, 25967, 25968, 25969, 25970, 25971, 25972, 25973, 25974, 25975, 25976, 25977, 25978, 25979, 25980, 25981, 25982, 25983, 25984, 25985, 25986, 25987, 25988, 25989, 25990, 25991, 25992, 25993, 25994, 25995, 25996, 25997, 25998, 25999, 26000, 26001, 26002, 26003, 26004, 26005, 26006, 26007, 26008, 26009, 26010, 26011, 26012, 26013, 26014, 26015, 26016, 26017, 26018, 26019, 26020, 26021, 26022, 26023, 26024, 26025, 26026, 26027, 26028, 26029, 26030, 26031, 26032, 26033, 26034, 26035, 26036, 26037, 26038, 26039, 26040, 26041, 26042, 26043, 26044, 26045, 26046, 26047, 26048, 26049, 26050, 26051, 26052, 26053, 26054, 26055, 26056, 26057, 26058, 26059, 26060, 26061, 26062, 26063, 26064, 26065, 26066, 26067, 26068, 26069, 26070, 26071, 26072, 26073, 26074, 26075, 26076, 26077, 26078, 26079, 26080, 26081, 26082, 26083, 26084, 26085, 26086, 26087, 26088, 26089, 26090, 26091, 26092, 26093, 26094, 26095, 26096, 26097, 26098, 26099, 26100, 26101, 26102, 26103, 26104, 26105, 26106, 26107, 26108, 26109, 26110, 26111, 26112, 26113, 26114, 26115, 26116, 26117, 26118, 26119, 26120, 26121, 26122, 26123, 26124, 26125, 26126, 26127, 26128, 26129, 26130, 26131, 26132, 26133, 26134, 26135, 26136, 26137, 26138, 26139, 26140, 26141, 26142, 26143, 26144, 26145, 26146, 26147, 26148, 26149, 26150, 26151, 26152, 26153, 26154, 26155, 26156, 26157, 26158, 26159, 26160, 26161, 26162, 26163, 26164, 26165, 26166, 26167, 26168, 26169, 26170, 26171, 26172, 26173, 26174, 26175, 26176, 26177, 26178, 26179, 26180, 26181, 26182, 26183, 26184, 26185, 26186, 26187, 26188, 26189, 26190, 26191, 26192, 26193, 26194, 26195, 26196, 26197, 26198, 26199, 26200, 26201, 26202, 26203, 26204, 26205, 26206, 26207, 26208, 26209, 26210, 26211, 26212, 26213, 26214, 26215, 26216, 26217, 26218, 26219, 26220, 26221, 26222, 26223, 26224, 26225, 26226, 26227, 26228, 26229, 26230, 26231, 26232, 26233, 26234, 26235, 26236, 26237, 26238, 26239, 26240, 26241, 26242, 26243, 26244, 26245, 26246, 26247, 26248, 26249, 26250, 26251, 26252, 26253, 26254, 26255, 26256, 26257, 26258, 26259, 26260, 26261, 26262, 26263, 26264, 26265, 26266, 26267, 26268, 26269, 26270, 26271, 26272, 26273, 26274, 26275, 26276, 26277, 26278, 26279, 26280, 26281, 26282, 26283, 26284, 26285, 26286, 26287, 26288, 26289, 26290, 26291, 26292, 26293, 26294, 26295, 26296, 26297, 26298, 26299, 26300, 26301, 26302, 26303, 26304, 26305, 26306, 26307, 26308, 26309, 26310, 26311, 26312, 26313, 26314, 26315, 26316, 26317, 26318, 26319, 26320, 26321, 26322, 26323, 26324, 26325, 26326, 26327, 26328, 26329, 26330, 26331, 26332, 26333, 26334, 26335, 26336, 26337, 26338, 26339, 26340, 26341, 26342, 26343, 26344, 26345, 26346, 26347, 26348, 26349, 26350, 26351, 26352, 26353, 26354, 26355, 26356, 26357, 26358, 26359, 26360, 26361, 26362, 26363, 26364, 26365, 26366, 26367, 26368, 26369, 26370, 26371, 26372, 26373, 26374, 26375, 26376, 26377, 26378, 26379, 26380, 26381, 26382, 26383, 26384, 26385, 26386, 26387, 26388, 26389, 26390, 26391, 26392, 26393, 26394, 26395, 26396, 26397, 26398, 26399, 26400, 26401, 26402, 26403, 26404, 26405, 26406, 26407, 26408, 26409, 26410, 26411, 26412, 26413, 26414, 26415, 26416, 26417, 26418, 26419, 26420, 26421, 26422, 26423, 26424, 26425, 26426, 26427, 26428, 26429, 26430, 26431, 26432, 26433, 26434, 26435, 26436, 26437, 26438, 26439, 26440, 26441, 26442, 26443, 26444, 26445, 26446, 26447, 26448, 26449, 26450, 26451, 26452, 26453, 26454, 26455, 26456, 26457, 26458, 26459, 26460, 26461, 26462, 26463, 26464, 26465, 26466, 26467, 26468, 26469, 26470, 26471, 26472, 26473, 26474, 26475, 26476, 26477, 26478, 26479, 26480, 26481, 26482, 26483, 26484, 26485, 26486, 26487, 26488, 26489, 26490, 26491, 26492, 26493, 26494, 26495, 26496, 26497, 26498, 26499, 26500, 26501, 26502, 26503, 26504, 26505, 26506, 26507, 26508, 26509, 26510, 26511, 26512, 26513, 26514, 26515, 26516, 26517, 26518, 26519, 26520, 26521, 26522, 26523, 26524, 26525, 26526, 26527, 26528, 26529, 26530, 26531, 26532, 26533, 26534, 26535, 26536, 26537, 26538, 26539, 26540, 26541, 26542, 26543, 26544, 26545, 26546, 26547, 26548, 26549, 26550, 26551, 26552, 26553, 26554, 26555, 26556, 26557, 26558, 26559, 26560, 26561, 26562, 26563, 26564, 26565, 26566, 26567, 26568, 26569, 26570, 26571, 26572, 26573, 26574, 26575, 26576, 26577, 26578, 26579, 26580, 26581, 26582, 26583, 26584, 26585, 26586, 26587, 26588, 26589, 26590, 26591, 26592, 26593, 26594, 26595, 26596, 26597, 26598, 26599, 26600, 26601, 26602, 26603, 26604, 26605, 26606, 26607, 26608, 26609, 26610, 26611, 26612, 26613, 26614, 26615, 26616, 26617, 26618, 26619, 26620, 26621, 26622, 26623, 26624, 26625, 26626, 26627, 26628, 26629, 26630, 26631, 26632, 26633, 26634, 26635, 26636, 26637, 26638, 26639, 26640, 26641, 26642, 26643, 26644, 26645, 26646, 26647, 26648, 26649, 26650, 26651, 26652, 26653, 26654, 26655, 26656, 26657, 26658, 26659, 26660, 26661, 26662, 26663, 26664, 26665, 26666, 26667, 26668, 26669, 26670, 26671, 26672, 26673, 26674, 26675, 26676, 26677, 26678, 26679, 26680, 26681, 26682, 26683, 26684, 26685, 26686, 26687, 26688, 26689, 26690, 26691, 26692, 26693, 26694, 26695, 26696, 26697, 26698, 26699, 26700, 26701, 26702, 26703, 26704, 26705, 26706, 26707, 26708, 26709, 26710, 26711, 26712, 26713, 26714, 26715, 26716, 26717, 26718, 26719, 26720, 26721, 26722, 26723, 26724, 26725, 26726, 26727, 26728, 26729, 26730, 26731, 26732, 26733, 26734, 26735, 26736, 26737, 26738, 26739, 26740, 26741, 26742, 26743, 26744, 26745, 26746, 26747, 26748, 26749, 26750, 26751, 26752, 26753, 26754, 26755, 26756, 26757, 26758, 26759, 26760, 26761, 26762, 26763, 26764, 26765, 26766, 26767, 26768, 26769, 26770, 26771, 26772, 26773, 26774, 26775, 26776, 26777, 26778, 26779, 26780, 26781, 26782, 26783, 26784, 26785, 26786, 26787, 26788, 26789, 26790, 26791, 26792, 26793, 26794, 26795, 26796, 26797, 26798, 26799, 26800, 26801, 26802, 26803, 26804, 26805, 26806, 26807, 26808, 26809, 26810, 26811, 26812, 26813, 26814, 26815, 26816, 26817, 26818, 26819, 26820, 26821, 26822, 26823, 26824, 26825, 26826, 26827, 26828, 26829, 26830, 26831, 26832, 26833, 26834, 26835, 26836, 26837, 26838, 26839, 26840, 26841, 26842, 26843, 26844, 26845, 26846, 26847, 26848, 26849, 26850, 26851, 26852, 26853, 26854, 26855, 26856, 26857, 26858, 26859, 26860, 26861, 26862, 26863, 26864, 26865, 26866, 26867, 26868, 26869, 26870, 26871, 26872, 26873, 26874, 26875, 26876, 26877, 26878, 26879, 26880, 26881, 26882, 26883, 26884, 26885, 26886, 26887, 26888, 26889, 26890, 26891, 26892, 26893, 26894, 26895, 26896, 26897, 26898, 26899, 26900, 26901, 26902, 26903, 26904, 26905, 26906, 26907, 26908, 26909, 26910, 26911, 26912, 26913, 26914, 26915, 26916, 26917, 26918, 26919, 26920, 26921, 26922, 26923, 26924, 26925, 26926, 26927, 26928, 26929, 26930, 26931, 26932, 26933, 26934, 26935, 26936, 26937, 26938, 26939, 26940, 26941, 26942, 26943, 26944, 26945, 26946, 26947, 26948, 26949, 26950, 26951, 26952, 26953, 26954, 26955, 26956, 26957, 26958, 26959, 26960, 26961, 26962, 26963, 26964, 26965, 26966, 26967, 26968, 26969, 26970, 26971, 26972, 26973, 26974, 26975, 26976, 26977, 26978, 26979, 26980, 26981, 26982, 26983, 26984, 26985, 26986, 26987, 26988, 26989, 26990, 26991, 26992, 26993, 26994, 26995, 26996, 26997, 26998, 26999, 27000, 27001, 27002, 27003, 27004, 27005, 27006, 27007, 27008, 27009, 27010, 27011, 27012, 27013, 27014, 27015, 27016, 27017, 27018, 27019, 27020, 27021, 27022, 27023, 27024, 27025, 27026, 27027, 27028, 27029, 27030, 27031, 27032, 27033, 27034, 27035, 27036, 27037, 27038, 27039, 27040, 27041, 27042, 27043, 27044, 27045, 27046, 27047, 27048, 27049, 27050, 27051, 27052, 27053, 27054, 27055, 27056, 27057, 27058, 27059, 27060, 27061, 27062, 27063, 27064, 27065, 27066, 27067, 27068, 27069, 27070, 27071, 27072, 27073, 27074, 27075, 27076, 27077, 27078, 27079, 27080, 27081, 27082, 27083, 27084, 27085, 27086, 27087, 27088, 27089, 27090, 27091, 27092, 27093, 27094, 27095, 27096, 27097, 27098, 27099, 27100, 27101, 27102, 27103, 27104, 27105, 27106, 27107, 27108, 27109, 27110, 27111, 27112, 27113, 27114, 27115, 27116, 27117, 27118, 27119, 27120, 27121, 27122, 27123, 27124, 27125, 27126, 27127, 27128, 27129, 27130, 27131, 27132, 27133, 27134, 27135, 27136, 27137, 27138, 27139, 27140, 27141, 27142, 27143, 27144, 27145, 27146, 27147, 27148, 27149, 27150, 27151, 27152, 27153, 27154, 27155, 27156, 27157, 27158, 27159, 27160, 27161, 27162, 27163, 27164, 27165, 27166, 27167, 27168, 27169, 27170, 27171, 27172, 27173, 27174, 27175, 27176, 27177, 27178, 27179, 27180, 27181, 27182, 27183, 27184, 27185, 27186, 27187, 27188, 27189, 27190, 27191, 27192, 27193, 27194, 27195, 27196, 27197, 27198, 27199, 27200, 27201, 27202, 27203, 27204, 27205, 27206, 27207, 27208, 27209, 27210, 27211, 27212, 27213, 27214, 27215, 27216, 27217, 27218, 27219, 27220, 27221, 27222, 27223, 27224, 27225, 27226, 27227, 27228, 27229, 27230, 27231, 27232, 27233, 27234, 27235, 27236, 27237, 27238, 27239, 27240, 27241, 27242, 27243, 27244, 27245, 27246, 27247, 27248, 27249, 27250, 27251, 27252, 27253, 27254, 27255, 27256, 27257, 27258, 27259, 27260, 27261, 27262, 27263, 27264, 27265, 27266, 27267, 27268, 27269, 27270, 27271, 27272, 27273, 27274, 27275, 27276, 27277, 27278, 27279, 27280, 27281, 27282, 27283, 27284, 27285, 27286, 27287, 27288, 27289, 27290, 27291, 27292, 27293, 27294, 27295, 27296, 27297, 27298, 27299, 27300, 27301, 27302, 27303, 27304, 27305, 27306, 27307, 27308, 27309, 27310, 27311, 27312, 27313, 27314, 27315, 27316, 27317, 27318, 27319, 27320, 27321, 27322, 27323, 27324, 27325, 27326, 27327, 27328, 27329, 27330, 27331, 27332, 27333, 27334, 27335, 27336, 27337, 27338, 27339, 27340, 27341, 27342, 27343, 27344, 27345, 27346, 27347, 27348, 27349, 27350, 27351, 27352, 27353, 27354, 27355, 27356, 27357, 27358, 27359, 27360, 27361, 27362, 27363, 27364, 27365, 27366, 27367, 27368, 27369, 27370, 27371, 27372, 27373, 27374, 27375, 27376, 27377, 27378, 27379, 27380, 27381, 27382, 27383, 27384, 27385, 27386, 27387, 27388, 27389, 27390, 27391, 27392, 27393, 27394, 27395, 27396, 27397, 27398, 27399, 27400, 27401, 27402, 27403, 27404, 27405, 27406, 27407, 27408, 27409, 27410, 27411, 27412, 27413, 27414, 27415, 27416, 27417, 27418, 27419, 27420, 27421, 27422, 27423, 27424, 27425, 27426, 27427, 27428, 27429, 27430, 27431, 27432, 27433, 27434, 27435, 27436, 27437, 27438, 27439, 27440, 27441, 27442, 27443, 27444, 27445, 27446, 27447, 27448, 27449, 27450, 27451, 27452, 27453, 27454, 27455, 27456, 27457, 27458, 27459, 27460, 27461, 27462, 27463, 27464, 27465, 27466, 27467, 27468, 27469, 27470, 27471, 27472, 27473, 27474, 27475, 27476, 27477, 27478, 27479, 27480, 27481, 27482, 27483, 27484, 27485, 27486, 27487, 27488, 27489, 27490, 27491, 27492, 27493, 27494, 27495, 27496, 27497, 27498, 27499, 27500, 27501, 27502, 27503, 27504, 27505, 27506, 27507, 27508, 27509, 27510, 27511, 27512, 27513, 27514, 27515, 27516, 27517, 27518, 27519, 27520, 27521, 27522, 27523, 27524, 27525, 27526, 27527, 27528, 27529, 27530, 27531, 27532, 27533, 27534, 27535, 27536, 27537, 27538, 27539, 27540, 27541, 27542, 27543, 27544, 27545, 27546, 27547, 27548, 27549, 27550, 27551, 27552, 27553, 27554, 27555, 27556, 27557, 27558, 27559, 27560, 27561, 27562, 27563, 27564, 27565, 27566, 27567, 27568, 27569, 27570, 27571, 27572, 27573, 27574, 27575, 27576, 27577, 27578, 27579, 27580, 27581, 27582, 27583, 27584, 27585, 27586, 27587, 27588, 27589, 27590, 27591, 27592, 27593, 27594, 27595, 27596, 27597, 27598, 27599, 27600, 27601, 27602, 27603, 27604, 27605, 27606, 27607, 27608, 27609, 27610, 27611, 27612, 27613, 27614, 27615, 27616, 27617, 27618, 27619, 27620, 27621, 27622, 27623, 27624, 27625, 27626, 27627, 27628, 27629, 27630, 27631, 27632, 27633, 27634, 27635, 27636, 27637, 27638, 27639, 27640, 27641, 27642, 27643, 27644, 27645, 27646, 27647, 27648, 27649, 27650, 27651, 27652, 27653, 27654, 27655, 27656, 27657, 27658, 27659, 27660, 27661, 27662, 27663, 27664, 27665, 27666, 27667, 27668, 27669, 27670, 27671, 27672, 27673, 27674, 27675, 27676, 27677, 27678, 27679, 27680, 27681, 27682, 27683, 27684, 27685, 27686, 27687, 27688, 27689, 27690, 27691, 27692, 27693, 27694, 27695, 27696, 27697, 27698, 27699, 27700, 27701, 27702, 27703, 27704, 27705, 27706, 27707, 27708, 27709, 27710, 27711, 27712, 27713, 27714, 27715, 27716, 27717, 27718, 27719, 27720, 27721, 27722, 27723, 27724, 27725, 27726, 27727, 27728, 27729, 27730, 27731, 27732, 27733, 27734, 27735, 27736, 27737, 27738, 27739, 27740, 27741, 27742, 27743, 27744, 27745, 27746, 27747, 27748, 27749, 27750, 27751, 27752, 27753, 27754, 27755, 27756, 27757, 27758, 27759, 27760, 27761, 27762, 27763, 27764, 27765, 27766, 27767, 27768, 27769, 27770, 27771, 27772, 27773, 27774, 27775, 27776, 27777, 27778, 27779, 27780, 27781, 27782, 27783, 27784, 27785, 27786, 27787, 27788, 27789, 27790, 27791, 27792, 27793, 27794, 27795, 27796, 27797, 27798, 27799, 27800, 27801, 27802, 27803, 27804, 27805, 27806, 27807, 27808, 27809, 27810, 27811, 27812, 27813, 27814, 27815, 27816, 27817, 27818, 27819, 27820, 27821, 27822, 27823, 27824, 27825, 27826, 27827, 27828, 27829, 27830, 27831, 27832, 27833, 27834, 27835, 27836, 27837, 27838, 27839, 27840, 27841, 27842, 27843, 27844, 27845, 27846, 27847, 27848, 27849, 27850, 27851, 27852, 27853, 27854, 27855, 27856, 27857, 27858, 27859, 27860, 27861, 27862, 27863, 27864, 27865, 27866, 27867, 27868, 27869, 27870, 27871, 27872, 27873, 27874, 27875, 27876, 27877, 27878, 27879, 27880, 27881, 27882, 27883, 27884, 27885, 27886, 27887, 27888, 27889, 27890, 27891, 27892, 27893, 27894, 27895, 27896, 27897, 27898, 27899, 27900, 27901, 27902, 27903, 27904, 27905, 27906, 27907, 27908, 27909, 27910, 27911, 27912, 27913, 27914, 27915, 27916, 27917, 27918, 27919, 27920, 27921, 27922, 27923, 27924, 27925, 27926, 27927, 27928, 27929, 27930, 27931, 27932, 27933, 27934, 27935, 27936, 27937, 27938, 27939, 27940, 27941, 27942, 27943, 27944, 27945, 27946, 27947, 27948, 27949, 27950, 27951, 27952, 27953, 27954, 27955, 27956, 27957, 27958, 27959, 27960, 27961, 27962, 27963, 27964, 27965, 27966, 27967, 27968, 27969, 27970, 27971, 27972, 27973, 27974, 27975, 27976, 27977, 27978, 27979, 27980, 27981, 27982, 27983, 27984, 27985, 27986, 27987, 27988, 27989, 27990, 27991, 27992, 27993, 27994, 27995, 27996, 27997, 27998, 27999, 28000, 28001, 28002, 28003, 28004, 28005, 28006, 28007, 28008, 28009, 28010, 28011, 28012, 28013, 28014, 28015, 28016, 28017, 28018, 28019, 28020, 28021, 28022, 28023, 28024, 28025, 28026, 28027, 28028, 28029, 28030, 28031, 28032, 28033, 28034, 28035, 28036, 28037, 28038, 28039, 28040, 28041, 28042, 28043, 28044, 28045, 28046, 28047, 28048, 28049, 28050, 28051, 28052, 28053, 28054, 28055, 28056, 28057, 28058, 28059, 28060, 28061, 28062, 28063, 28064, 28065, 28066, 28067, 28068, 28069, 28070, 28071, 28072, 28073, 28074, 28075, 28076, 28077, 28078, 28079, 28080, 28081, 28082, 28083, 28084, 28085, 28086, 28087, 28088, 28089, 28090, 28091, 28092, 28093, 28094, 28095, 28096, 28097, 28098, 28099, 28100, 28101, 28102, 28103, 28104, 28105, 28106, 28107, 28108, 28109, 28110, 28111, 28112, 28113, 28114, 28115, 28116, 28117, 28118, 28119, 28120, 28121, 28122, 28123, 28124, 28125, 28126, 28127, 28128, 28129, 28130, 28131, 28132, 28133, 28134, 28135, 28136, 28137, 28138, 28139, 28140, 28141, 28142, 28143, 28144, 28145, 28146, 28147, 28148, 28149, 28150, 28151, 28152, 28153, 28154, 28155, 28156, 28157, 28158, 28159, 28160, 28161, 28162, 28163, 28164, 28165, 28166, 28167, 28168, 28169, 28170, 28171, 28172, 28173, 28174, 28175, 28176, 28177, 28178, 28179, 28180, 28181, 28182, 28183, 28184, 28185, 28186, 28187, 28188, 28189, 28190, 28191, 28192, 28193, 28194, 28195, 28196, 28197, 28198, 28199, 28200, 28201, 28202, 28203, 28204, 28205, 28206, 28207, 28208, 28209, 28210, 28211, 28212, 28213, 28214, 28215, 28216, 28217, 28218, 28219, 28220, 28221, 28222, 28223, 28224, 28225, 28226, 28227, 28228, 28229, 28230, 28231, 28232, 28233, 28234, 28235, 28236, 28237, 28238, 28239, 28240, 28241, 28242, 28243, 28244, 28245, 28246, 28247, 28248, 28249, 28250, 28251, 28252, 28253, 28254, 28255, 28256, 28257, 28258, 28259, 28260, 28261, 28262, 28263, 28264, 28265, 28266, 28267, 28268, 28269, 28270, 28271, 28272, 28273, 28274, 28275, 28276, 28277, 28278, 28279, 28280, 28281, 28282, 28283, 28284, 28285, 28286, 28287, 28288, 28289, 28290, 28291, 28292, 28293, 28294, 28295, 28296, 28297, 28298, 28299, 28300, 28301, 28302, 28303, 28304, 28305, 28306, 28307, 28308, 28309, 28310, 28311, 28312, 28313, 28314, 28315, 28316, 28317, 28318, 28319, 28320, 28321, 28322, 28323, 28324, 28325, 28326, 28327, 28328, 28329, 28330, 28331, 28332, 28333, 28334, 28335, 28336, 28337, 28338, 28339, 28340, 28341, 28342, 28343, 28344, 28345, 28346, 28347, 28348, 28349, 28350, 28351, 28352, 28353, 28354, 28355, 28356, 28357, 28358, 28359, 28360, 28361, 28362, 28363, 28364, 28365, 28366, 28367, 28368, 28369, 28370, 28371, 28372, 28373, 28374, 28375, 28376, 28377, 28378, 28379, 28380, 28381, 28382, 28383, 28384, 28385, 28386, 28387, 28388, 28389, 28390, 28391, 28392, 28393, 28394, 28395, 28396, 28397, 28398, 28399, 28400, 28401, 28402, 28403, 28404, 28405, 28406, 28407, 28408, 28409, 28410, 28411, 28412, 28413, 28414, 28415, 28416, 28417, 28418, 28419, 28420, 28421, 28422, 28423, 28424, 28425, 28426, 28427, 28428, 28429, 28430, 28431, 28432, 28433, 28434, 28435, 28436, 28437, 28438, 28439, 28440, 28441, 28442, 28443, 28444, 28445, 28446, 28447, 28448, 28449, 28450, 28451, 28452, 28453, 28454, 28455, 28456, 28457, 28458, 28459, 28460, 28461, 28462, 28463, 28464, 28465, 28466, 28467, 28468, 28469, 28470, 28471, 28472, 28473, 28474, 28475, 28476, 28477, 28478, 28479, 28480, 28481, 28482, 28483, 28484, 28485, 28486, 28487, 28488, 28489, 28490, 28491, 28492, 28493, 28494, 28495, 28496, 28497, 28498, 28499, 28500, 28501, 28502, 28503, 28504, 28505, 28506, 28507, 28508, 28509, 28510, 28511, 28512, 28513, 28514, 28515, 28516, 28517, 28518, 28519, 28520, 28521, 28522, 28523, 28524, 28525, 28526, 28527, 28528, 28529, 28530, 28531, 28532, 28533, 28534, 28535, 28536, 28537, 28538, 28539, 28540, 28541, 28542, 28543, 28544, 28545, 28546, 28547, 28548, 28549, 28550, 28551, 28552, 28553, 28554, 28555, 28556, 28557, 28558, 28559, 28560, 28561, 28562, 28563, 28564, 28565, 28566, 28567, 28568, 28569, 28570, 28571, 28572, 28573, 28574, 28575, 28576, 28577, 28578, 28579, 28580, 28581, 28582, 28583, 28584, 28585, 28586, 28587, 28588, 28589, 28590, 28591, 28592, 28593, 28594, 28595, 28596, 28597, 28598, 28599, 28600, 28601, 28602, 28603, 28604, 28605, 28606, 28607, 28608, 28609, 28610, 28611, 28612, 28613, 28614, 28615, 28616, 28617, 28618, 28619, 28620, 28621, 28622, 28623, 28624, 28625, 28626, 28627, 28628, 28629, 28630, 28631, 28632, 28633, 28634, 28635, 28636, 28637, 28638, 28639, 28640, 28641, 28642, 28643, 28644, 28645, 28646, 28647, 28648, 28649, 28650, 28651, 28652, 28653, 28654, 28655, 28656, 28657, 28658, 28659, 28660, 28661, 28662, 28663, 28664, 28665, 28666, 28667, 28668, 28669, 28670, 28671, 28672, 28673, 28674, 28675, 28676, 28677, 28678, 28679, 28680, 28681, 28682, 28683, 28684, 28685, 28686, 28687, 28688, 28689, 28690, 28691, 28692, 28693, 28694, 28695, 28696, 28697, 28698, 28699, 28700, 28701, 28702, 28703, 28704, 28705, 28706, 28707, 28708, 28709, 28710, 28711, 28712, 28713, 28714, 28715, 28716, 28717, 28718, 28719, 28720, 28721, 28722, 28723, 28724, 28725, 28726, 28727, 28728, 28729, 28730, 28731, 28732, 28733, 28734, 28735, 28736, 28737, 28738, 28739, 28740, 28741, 28742, 28743, 28744, 28745, 28746, 28747, 28748, 28749, 28750, 28751, 28752, 28753, 28754, 28755, 28756, 28757, 28758, 28759, 28760, 28761, 28762, 28763, 28764, 28765, 28766, 28767, 28768, 28769, 28770, 28771, 28772, 28773, 28774, 28775, 28776, 28777, 28778, 28779, 28780, 28781, 28782, 28783, 28784, 28785, 28786, 28787, 28788, 28789, 28790, 28791, 28792, 28793, 28794, 28795, 28796, 28797, 28798, 28799, 28800, 28801, 28802, 28803, 28804, 28805, 28806, 28807, 28808, 28809, 28810, 28811, 28812, 28813, 28814, 28815, 28816, 28817, 28818, 28819, 28820, 28821, 28822, 28823, 28824, 28825, 28826, 28827, 28828, 28829, 28830, 28831, 28832, 28833, 28834, 28835, 28836, 28837, 28838, 28839, 28840, 28841, 28842, 28843, 28844, 28845, 28846, 28847, 28848, 28849, 28850, 28851, 28852, 28853, 28854, 28855, 28856, 28857, 28858, 28859, 28860, 28861, 28862, 28863, 28864, 28865, 28866, 28867, 28868, 28869, 28870, 28871, 28872, 28873, 28874, 28875, 28876, 28877, 28878, 28879, 28880, 28881, 28882, 28883, 28884, 28885, 28886, 28887, 28888, 28889, 28890, 28891, 28892, 28893, 28894, 28895, 28896, 28897, 28898, 28899, 28900, 28901, 28902, 28903, 28904, 28905, 28906, 28907, 28908, 28909, 28910, 28911, 28912, 28913, 28914, 28915, 28916, 28917, 28918, 28919, 28920, 28921, 28922, 28923, 28924, 28925, 28926, 28927, 28928, 28929, 28930, 28931, 28932, 28933, 28934, 28935, 28936, 28937, 28938, 28939, 28940, 28941, 28942, 28943, 28944, 28945, 28946, 28947, 28948, 28949, 28950, 28951, 28952, 28953, 28954, 28955, 28956, 28957, 28958, 28959, 28960, 28961, 28962, 28963, 28964, 28965, 28966, 28967, 28968, 28969, 28970, 28971, 28972, 28973, 28974, 28975, 28976, 28977, 28978, 28979, 28980, 28981, 28982, 28983, 28984, 28985, 28986, 28987, 28988, 28989, 28990, 28991, 28992, 28993, 28994, 28995, 28996, 28997, 28998, 28999, 29000, 29001, 29002, 29003, 29004, 29005, 29006, 29007, 29008, 29009, 29010, 29011, 29012, 29013, 29014, 29015, 29016, 29017, 29018, 29019, 29020, 29021, 29022, 29023, 29024, 29025, 29026, 29027, 29028, 29029, 29030, 29031, 29032, 29033, 29034, 29035, 29036, 29037, 29038, 29039, 29040, 29041, 29042, 29043, 29044, 29045, 29046, 29047, 29048, 29049, 29050, 29051, 29052, 29053, 29054, 29055, 29056, 29057, 29058, 29059, 29060, 29061, 29062, 29063, 29064, 29065, 29066, 29067, 29068, 29069, 29070, 29071, 29072, 29073, 29074, 29075, 29076, 29077, 29078, 29079, 29080, 29081, 29082, 29083, 29084, 29085, 29086, 29087, 29088, 29089, 29090, 29091, 29092, 29093, 29094, 29095, 29096, 29097, 29098, 29099, 29100, 29101, 29102, 29103, 29104, 29105, 29106, 29107, 29108, 29109, 29110, 29111, 29112, 29113, 29114, 29115, 29116, 29117, 29118, 29119, 29120, 29121, 29122, 29123, 29124, 29125, 29126, 29127, 29128, 29129, 29130, 29131, 29132, 29133, 29134, 29135, 29136, 29137, 29138, 29139, 29140, 29141, 29142, 29143, 29144, 29145, 29146, 29147, 29148, 29149, 29150, 29151, 29152, 29153, 29154, 29155, 29156, 29157, 29158, 29159, 29160, 29161, 29162, 29163, 29164, 29165, 29166, 29167, 29168, 29169, 29170, 29171, 29172, 29173, 29174, 29175, 29176, 29177, 29178, 29179, 29180, 29181, 29182, 29183, 29184, 29185, 29186, 29187, 29188, 29189, 29190, 29191, 29192, 29193, 29194, 29195, 29196, 29197, 29198, 29199, 29200, 29201, 29202, 29203, 29204, 29205, 29206, 29207, 29208, 29209, 29210, 29211, 29212, 29213, 29214, 29215, 29216, 29217, 29218, 29219, 29220, 29221, 29222, 29223, 29224, 29225, 29226, 29227, 29228, 29229, 29230, 29231, 29232, 29233, 29234, 29235, 29236, 29237, 29238, 29239, 29240, 29241, 29242, 29243, 29244, 29245, 29246, 29247, 29248, 29249, 29250, 29251, 29252, 29253, 29254, 29255, 29256, 29257, 29258, 29259, 29260, 29261, 29262, 29263, 29264, 29265, 29266, 29267, 29268, 29269, 29270, 29271, 29272, 29273, 29274, 29275, 29276, 29277, 29278, 29279, 29280, 29281, 29282, 29283, 29284, 29285, 29286, 29287, 29288, 29289, 29290, 29291, 29292, 29293, 29294, 29295, 29296, 29297, 29298, 29299, 29300, 29301, 29302, 29303, 29304, 29305, 29306, 29307, 29308, 29309, 29310, 29311, 29312, 29313, 29314, 29315, 29316, 29317, 29318, 29319, 29320, 29321, 29322, 29323, 29324, 29325, 29326, 29327, 29328, 29329, 29330, 29331, 29332, 29333, 29334, 29335, 29336, 29337, 29338, 29339, 29340, 29341, 29342, 29343, 29344, 29345, 29346, 29347, 29348, 29349, 29350, 29351, 29352, 29353, 29354, 29355, 29356, 29357, 29358, 29359, 29360, 29361, 29362, 29363, 29364, 29365, 29366, 29367, 29368, 29369, 29370, 29371, 29372, 29373, 29374, 29375, 29376, 29377, 29378, 29379, 29380, 29381, 29382, 29383, 29384, 29385, 29386, 29387, 29388, 29389, 29390, 29391, 29392, 29393, 29394, 29395, 29396, 29397, 29398, 29399, 29400, 29401, 29402, 29403, 29404, 29405, 29406, 29407, 29408, 29409, 29410, 29411, 29412, 29413, 29414, 29415, 29416, 29417, 29418, 29419, 29420, 29421, 29422, 29423, 29424, 29425, 29426, 29427, 29428, 29429, 29430, 29431, 29432, 29433, 29434, 29435, 29436, 29437, 29438, 29439, 29440, 29441, 29442, 29443, 29444, 29445, 29446, 29447, 29448, 29449, 29450, 29451, 29452, 29453, 29454, 29455, 29456, 29457, 29458, 29459, 29460, 29461, 29462, 29463, 29464, 29465, 29466, 29467, 29468, 29469, 29470, 29471, 29472, 29473, 29474, 29475, 29476, 29477, 29478, 29479, 29480, 29481, 29482, 29483, 29484, 29485, 29486, 29487, 29488, 29489, 29490, 29491, 29492, 29493, 29494, 29495, 29496, 29497, 29498, 29499, 29500, 29501, 29502, 29503, 29504, 29505, 29506, 29507, 29508, 29509, 29510, 29511, 29512, 29513, 29514, 29515, 29516, 29517, 29518, 29519, 29520, 29521, 29522, 29523, 29524, 29525, 29526, 29527, 29528, 29529, 29530, 29531, 29532, 29533, 29534, 29535, 29536, 29537, 29538, 29539, 29540, 29541, 29542, 29543, 29544, 29545, 29546, 29547, 29548, 29549, 29550, 29551, 29552, 29553, 29554, 29555, 29556, 29557, 29558, 29559, 29560, 29561, 29562, 29563, 29564, 29565, 29566, 29567, 29568, 29569, 29570, 29571, 29572, 29573, 29574, 29575, 29576, 29577, 29578, 29579, 29580, 29581, 29582, 29583, 29584, 29585, 29586, 29587, 29588, 29589, 29590, 29591, 29592, 29593, 29594, 29595, 29596, 29597, 29598, 29599, 29600, 29601, 29602, 29603, 29604, 29605, 29606, 29607, 29608, 29609, 29610, 29611, 29612, 29613, 29614, 29615, 29616, 29617, 29618, 29619, 29620, 29621, 29622, 29623, 29624, 29625, 29626, 29627, 29628, 29629, 29630, 29631, 29632, 29633, 29634, 29635, 29636, 29637, 29638, 29639, 29640, 29641, 29642, 29643, 29644, 29645, 29646, 29647, 29648, 29649, 29650, 29651, 29652, 29653, 29654, 29655, 29656, 29657, 29658, 29659, 29660, 29661, 29662, 29663, 29664, 29665, 29666, 29667, 29668, 29669, 29670, 29671, 29672, 29673, 29674, 29675, 29676, 29677, 29678, 29679, 29680, 29681, 29682, 29683, 29684, 29685, 29686, 29687, 29688, 29689, 29690, 29691, 29692, 29693, 29694, 29695, 29696, 29697, 29698, 29699, 29700, 29701, 29702, 29703, 29704, 29705, 29706, 29707, 29708, 29709, 29710, 29711, 29712, 29713, 29714, 29715, 29716, 29717, 29718, 29719, 29720, 29721, 29722, 29723, 29724, 29725, 29726, 29727, 29728, 29729, 29730, 29731, 29732, 29733, 29734, 29735, 29736, 29737, 29738, 29739, 29740, 29741, 29742, 29743, 29744, 29745, 29746, 29747, 29748, 29749, 29750, 29751, 29752, 29753, 29754, 29755, 29756, 29757, 29758, 29759, 29760, 29761, 29762, 29763, 29764, 29765, 29766, 29767, 29768, 29769, 29770, 29771, 29772, 29773, 29774, 29775, 29776, 29777, 29778, 29779, 29780, 29781, 29782, 29783, 29784, 29785, 29786, 29787, 29788, 29789, 29790, 29791, 29792, 29793, 29794, 29795, 29796, 29797, 29798, 29799, 29800, 29801, 29802, 29803, 29804, 29805, 29806, 29807, 29808, 29809, 29810, 29811, 29812, 29813, 29814, 29815, 29816, 29817, 29818, 29819, 29820, 29821, 29822, 29823, 29824, 29825, 29826, 29827, 29828, 29829, 29830, 29831, 29832, 29833, 29834, 29835, 29836, 29837, 29838, 29839, 29840, 29841, 29842, 29843, 29844, 29845, 29846, 29847, 29848, 29849, 29850, 29851, 29852, 29853, 29854, 29855, 29856, 29857, 29858, 29859, 29860, 29861, 29862, 29863, 29864, 29865, 29866, 29867, 29868, 29869, 29870, 29871, 29872, 29873, 29874, 29875, 29876, 29877, 29878, 29879, 29880, 29881, 29882, 29883, 29884, 29885, 29886, 29887, 29888, 29889, 29890, 29891, 29892, 29893, 29894, 29895, 29896, 29897, 29898, 29899, 29900, 29901, 29902, 29903, 29904, 29905, 29906, 29907, 29908, 29909, 29910, 29911, 29912, 29913, 29914, 29915, 29916, 29917, 29918, 29919, 29920, 29921, 29922, 29923, 29924, 29925, 29926, 29927, 29928, 29929, 29930, 29931, 29932, default */
/***/ (function(module) {

module.exports = ["aba","abad","abadi","abadiah","abah","abai","abaimana","abaka","abaktinal","abakus","abal-abal","aban","abang","abangan","abangga","abar","abatoar","abau","abdas","abdi","abdikasi","abdomen","abdominal","abdu","abduksi","abduktor","abece","aben","aberasi","abet","abian","abid","abidin","abilah","abing","abiogenesis","abiosfer","abiotik","abis","abisal","abiseka","abiturien","abjad","abjadiah","ablasi","ablaut","ablepsia","abnormal","abnormalitas","abnus","aboi","abolisi","abon","abonemen","abong-abong","aborsi","abortif","abortiva","abortus","abrak","abrakadabra","abrar","abras","abrasi","abreaksi","abrek","abreviasi","abrikos","abrit-abrit","abrosfer","absah","absen","absensi","absensia","absente","absenteisme","abses","absis","absolusi","absolut","absolutisme","absonan","absorb","absorben","absorbir","absorpsi","absorpsiometer","absorptif","abstain","abstinensi","abstrak","abstraksi","absurd","absurdisme","abtar","abu","abuan","abuh","abuk","abulhayat","abulia","abun-abun","abur","abus","abyad","acah","acak","acala","acan","acang","acap","acar","acara","acaram","acat","acau","acawi","acerang","aci","acik","aco","acu","acuh","acum","acung","ada","adab","adad","adagio","adagium","adakala","adakalanya","adakan","adaks","adaktil","adalah","adalat","adam","adan","adang","adap","adaptabel","adaptabilitas","adaptasi","adaptif","adaptometer","adaptor","adapun","adar","adas","adat","adati","adegan","adeh","adekuat","adem","adempauze","adendum","adenoid","adenoma","adenosis","adhesi","adhesif","adi","adiabatik","adiabatis","adiaktinik","adib","adibangkit","adibintang","adiboga","adibusana","adicita","adidaya","adigang","adiguna","adigung","adik","adika","adikara","adikarya","adikodrati","adikong","adiksi","adiktif","adikuasa","adil","adiluhung","adimarga","adinda","ading","adipati","adipenghantar","adiposa","adipositas","adipura","adiraja","adiratna","adisi","adisional","adisiswa","aditif","aditokoh","adiwangsa","adiwarna","adiwidia","adjektif","adjektiva","adjektival","adjuvan","administrasi","administratif","administrator","admiral","admisi","admitans","adnan","adolesens","adon","adopsi","adoptif","adpertensi","adrenal","adrenalin","adrenergik","adres","adsorben","adsorpi","adsorpsi","adstringen","adu","aduh","aduhai","aduk","aduksi","aduktor","adun","adveksi","adven","adventisia","adventisius","adverbia","adverbial","advertensi","advis","advokad","advokasi","advokat","aerasi","aerator","aerob","aerobatik","aerobik","aerobika","aerodinamik","aerodinamika","aerofisika","aerofisiologi","aerofon","aerogram","aerolit","aerologi","aerometer","aeromovel","aeronautika","aeroplangton","aeroplankton","aeroskop","aerosol","aerostat","aerostatika","aestetika","afair","afal","afasia","afdal","afdeling","afdruk","afek","afeksi","afektif","aferesis","afiat","afidavit","afiks","afiksasi","afiliasi","afinitas","afirmasi","afirmatif","afonia","aforisme","afotik","afrasia","afrikat","afrit","afrodisiak","afsun","afwah","aga","agah","agak","agak-agih","agal","agalaksia","agam","agama","agamais","agamawi","agamen","agamet","agami","agamogenesis","agan","agape","agar","agas","agen","agenda","agens","agentif","agih","agil","agio","agiria","agitasi","agitatif","agitator","aglikon","aglomerasi","aglomerat","aglutinasi","aglutinat","aglutinatif","aglutinin","agnosia","agnostik","agnostisisme","agogo","agometer","agon","agonia","agonis","agonistik","agorafobia","agradasi","agrafia","agraria","agraris","agregasi","agregat","agregatif","agresi","agresif","agresivitas","agresor","agriologi","agripnia","agrisilvikultur","agrobis","agrobisnis","agroekonomi","agroekosistem","agrogeologi","agroikos","agroindustri","agrokimia","agronom","agronomi","agrostologi","agrowisata","aguk","agul","agun","agung","agus","agustus","agut","ahad","ahadiat","ahimsa","ahistoris","ahkam","ahlan","ahli","ahlulbait","ahlulkitab","ahlulkubur","ahlunujum","ahlusuluk","ahlusunah","ahmak","ahmar","aho","ahsan","ahwal","aib","ain","ainulbanat","ainulyakin","ainunjariah","air","aja","ajab","ajaib","ajaibkhanah","ajak","ajal","ajang","ajar","ajek","ajektifa","ajektiva","ajengan","aji","ajigineng","ajimumpung","ajir","ajisaka","ajnabi","ajnas","ajojing","ajre","aju","ajudan","ajufan","ajujah","ajuk","ajun","ajung","ajur","ajuster","akad","akademi","akademik","akademikus","akademis","akademisi","akaid","akak","akal","akan","akang","akapela","akar","akas","akasia","akatalepsia","akbar","akene","akeo","akh","akhbar","akhir","akhirat","akhirulkalam","akhlak","akhlaki","akhwan","aki","akibat","akidah","akik","akikah","akil","aklamasi","aklasia","akli","akliah","aklimasi","aklimatisasi","akmal","akolade","akomodasi","akomodatif","akor","akordeon","akrab","akrawati","akreditasi","akriflavina","akrilat","akrilik","akrobat","akrobatik","akrofobia","akromegali","akrometer","akromion","akronim","aksa","aksara","akseleran","akselerasi","akselerator","akselerometer","aksen","aksentologi","aksentuasi","aksep","akseptabel","akseptabilitas","akseptasi","akseptor","akses","aksesibilitas","aksesori","aksi","aksidental","aksila","aksiologi","aksioma","aksiomatis","aksis","akson","aksostil","akta","aktentas","aktif","akting","aktinida","aktinik","aktinisme","aktinium","aktinokimia","aktinolit","aktinometer","aktiva","aktivis","aktivisme","aktivitas","aktor","aktris","aktual","aktualisasi","aktuaria","aktuaris","aku","akua","akuades","akuaduk","akuakultur","akualung","akuamarin","akuan","akuarel","akuaris","akuarium","akuarius","akuatik","akuifer","akuisisi","akuk","akulturasi","akumulasi","akumulatif","akumulator","akun","akuntabel","akuntabilitas","akuntan","akuntansi","akupungtur","akupungturis","akupunktur","akur","akurasi","akurat","akusatif","akustik","akustika","akut","akwal","ala","alabangka","alabio","alaf","alai","alai-belai","alaihisalam","alaika","alaikum","alak","alalia","alam","alamah","alamak","alamanda","alamas","alamat","alamatulhayat","alami","alamiah","alamin","alan-alan","alang","alangkah","alantois","alap","alarm","alas","alat","alau","alawar","alazon","albanat","albas","albatros","albedo","albedometer","albinisme","albino","albinoid","albit","albuginea","album","albumen","albumin","albuminoit","albuminometer","albuminuria","aldehida","alegori","alegoris","aleksandrit","aleksia","aleksin","alel","alem","alergen","alergi","alergis","alf","alfa","alfabet","alfabetis","alfaktorius","alfanumerik","alferes","alga","algilik","algoid","algojo","algologi","algometer","algoritme","algrafi","alhamdulillah","alhasil","ali","aliansi","alias","aliase","alibi","alienasi","alif","alifatik","alifbata","alih","alihragam","alik","alikuot","alim","alimbubu","alimentasi","alimenter","alimiah","alimiat","alimun","alin","alinea","aling","alip","alir","alis","alisiklik","alit","aliterasi","alizarin","aljabar","aljalil","alkabir","alkadim","alkadir","alkah","alkali","alkalinitas","alkalis","alkaloid","alkalometri","alkamar","alkana","alkari","alkasyaf","alkausar","alkena","alkil","alkimia","alkisah","alkitab","alkohol","alkoholis","alkoholisasi","alkoholisme","alkoholometer","alku","alkuna","alkus","allah","allahu","allahuma","almaktub","almalik","almalun","almamater","almanak","almandin","almandina","almandit","almarhum","almarhumah","almasih","almuazam","almukhlis","alobar","alofon","alograf","aloi","alokasi","alokron","aloleks","alomerisme","alomorf","alon","alonim","alopati","alopesia","alot","alotropi","alpa","alpaka","alperes","alpukah","alquran","altar","alter","alteratif","alternasi","alternatif","alternator","altimeter","alto","altokumulus","altostratus","altruis","altruisme","altruistis","alu","alufiru","alum","alumina","aluminium","alumni","alumnus","alun","alung","alup","alur","alusi","aluvial","aluvium","alveolar","alveolum","alveolus","alwah","alwasi","alwasia","ama","amabakdu","amah","amai-amai","amal","amalgam","amalgamasi","amalgamator","amaliah","aman","amanah","amanat","amandel","amandemen","amang","amanitin","amar","amarilis","amat","amatir","amatirisme","amatol","ambah","ambah-ambah","ambai","ambai-ambai","ambak","ambal","ambalang","ambalela","ambang","ambar","ambarau","ambasade","ambasador","ambau","ambeien","ambek","amben","amberal","ambergris","amberit","ambet","ambi","ambigu","ambiguitas","ambil","ambilingual","ambin","ambing","ambisi","ambisius","ambivalen","ambivalensi","amblas","amblek","ambles","ambliobia","amboi","ambreng-ambrengan","ambring","ambrol","ambruk","ambu-ambu","ambuh","ambul","ambulakral","ambulans","ambulatori","ambung","ambur","amburadul","ambyar","ameba","amebiasis","ameboid","amebosit","ameliorasi","amelioratif","amen","amendemen","amenorea","amensalisme","amenta","amerisium","amerospora","amerta","ametabola","ametis","ametobola","amfetamin","amfiartrosis","amfibi","amfibol","amfibolisme","amfiston","amfiteater","amfoterik","ami","amigdalin","amikal","amil","amilase","amilopektin","amin","amina","aminisasi","amino","amir","amirulbahar","amirulhaj","amirulmukminin","amis","amit","amitosir","amko","ammeter","amnesia","amnesti","amnion","amniotik","amoi","amonia","amonifikasi","amonit","amonium","amor","amoral","amorf","amortisasi","ampai","ampang","ampas","ampat","ampe","ampean","ampek","ampel","ampela","ampelam","ampelas","ampere","amperemeter","amperometri","ampisilin","amplas","amplifikasi","amplitudo","amplop","ampo","amprok","amprung","ampu","ampuh","ampuk","ampul","ampula","ampun","amput","amputasi","amra","amril","amsal","amtenar","amuba","amuh","amuk","amulet","amung","amunisi","ana","anabasis","anabiosis","anabolisme","anadrom","anaerob","anaerobik","anafilaksis","anafora","anaforis","anafrodisiak","anaglif","anai-anai","anak","anakoluton","anakronisme","anakronistis","anakrus","anal","analekta","analeptik","analgesik","analis","analisis","analitis","analog","analogi","analseks","analsit","anamel","anamnesis","anamorfosis","ananda","anang","anani","anapes","anaptiksis","anarki","anarkis","anarkisme","anarkistis","anasional","anasir","anastomosis","anatase","anatomi","anatomis","anbia","anca","ancai","ancak","ancala","ancam","ancang","ancar-ancar","ancoa","ancol","ancuk","anda","andai","andak","andaka","andal","andalas","andalusit","andam","andan","andang","andapita","andar","andarah","andeng-andeng","anderak","andesit","andewi","andika","andiko","andil","andilau","andok","andong","andragogi","andrawina","androgen","androgini","androgogi","androlog","andrologi","anduh","andur","aneh","aneka","anekdot","aneksasi","anemer","anemia","anemofili","anemograf","anemogram","anemometer","aneroid","anestesi","anestesia","anestesiolog","anestetis","aneuploid","aneurisme","anfas","angah","angan","angel","angga","anggai","anggak","anggal","anggan","anggap","anggar","anggara","anggau","anggerka","anggit","angglap","anggorokasih","anggota","anggrek","angguh","angguk","anggul","anggun","anggung","anggung-anggip","anggur","anggut","anghun","angin","angina","angiogenesis","angiologi","angiosperma","angit","angka","angkak","angkal-angkal","angkara","angkasa","angkat","angkel","angker","angket","angkin","angkit","angklung","angkong","angkring","angku","angkuh","angkuk","angkul-angkul","angkup","angkur","angkus","angkusa","angkut","angler","anglo","anglong","anglung","angon","angop","angot","angpau","angsa","angsana","angsoka","angsu","angsur","angus","angut","anhidrosis","ani","aniaya","anil","anilina","animasi","animis","animisme","animo","aning-aning","anion","aniridia","anis","anisogamet","anisogami","anisokoria","anisotropis","anja","anjak","anjal","anjang","anjangkarya","anjangsana","anjar","anjiman","anjing","anjir","anjlok","anju","anjung","anjur","ankilosis","anoa","anode","anodin","anofeles","anoksemia","anoksik","anom","anomali","anomi","anonim","anonimitas","anoreksia","anorganik","anorgastik","anortopia","anosmia","anotasi","ansa","ansambel","ansar","ansari","anta","antagonis","antagonisme","antagonistis","antah","antah-berantah","antakesuma","antalas","antalkali","antamir","antan","antap","antar","antara","antarbangsa","antarbenua","antardaerah","antari","antariksa","antarkelompok","antarlingkungan","antarmaster","antarmolekul","antarmuka","antarnegara","antarplanet","antarpribadi","antarpulau","antarras","antarruang","antarsel","antarsuku","antartika","antarwilayah","antasid","antasida","antawacana","ante","antedilivium","antediluvium","antefiks","antek","anteken","antelas","anteliks","antelmintik","antelop","antem","antemeridiem","antena","antenatal","anteng","antenul","antep","anter","antera","anteridium","anterior","antero","anteseden","anti","antianemia","antiartritik","antibarion","antibeku","antibiosis","antibiotik","antibodi","antidepresan","antidioksida","antidiuretik","antidot","antienzim","antiflogistik","antigen","antigravitasi","antih","antihistamin","antijasad","antik","antikarat","antikatalis","antiklimaks","antiklin","antiklinal","antiklor","antikonsepsi","antikristus","antikuari","antikuariat","antimateri","antimetari","antimonium","antimuntah","anting","antinomi","antinovel","antipartikel","antipati","antipenawar","antipiretik","antipode","antiproton","antipruritik","antisemitisme","antisepsis","antiseptik","antisiklogenesis","antisiklon","antisiklonal","antisiklonis","antisimpul","antisipasi","antisipatif","antitank","antitesis","antitoksin","antitragus","antiwirawan","antizarah","antoi","antologi","antonim","antonimi","antop","antosian","antraknosa","antraks","antrasena","antrasian","antrasit","antre","antri","antromometer","antromorfis","antropobiologi","antropoda","antropofagi","antropogeografi","antropoid","antropolog","antropologi","antropometer","antropomorfisme","antroponimi","antroposentris","antroposentrisme","antroposofi","antuk","antul","antun","antung-antung","antup","anturium","antusias","antusiasme","anu","anual","anugerah","anuitas","anulir","anulus","anumerta","anunasika","anuresis","anuria","anus","anuswara","anut","anyak","anyam","anyang","anyar","anyel","anyelir","anyep","anyes","anyik","anyir","aorta","apa","apabila","apak","apakah","apakala","apalagi","apam","apanase","apar","aparat","aparatur","aparatus","apartemen","apartemenisasi","apartheid","apartotel","apas","apatah","apati","apatis","apatride","ape","apek","apel","apelativa","apendektomi","apendiks","apendisitis","apepsi","apersepsi","apes","aphelion","apheliotropisme","api","apik","apikal","apikultur","apilan","aping","apion","apit","apium","apkir","aplasi","aplaus","aplikasi","aplikatif","aplus","apnea","apo","apodal","apoenzim","apogami","apoge","apograf","apok","apokalips","apokaliptik","apokope","apokrifa","apokrin","apokromatik","apolitis","apologetika","apologetis","apologi","apologia","apomiksis","apomorfin","apopleksi","aposematik","aposiopesis","aposisi","aposisional","apositif","apostasi","apostel","aposteriori","apostolik","apostrof","apotek","apoteker","apotik","apraksi","apraksia","apresiasi","apresiatif","apresorium","april","apriori","aprit","apron","apsara","apsari","aptasi","aptiklus","apu","apuh","apung","apuran","ara","arab","arababu","arabahu","arabes","arabesk","arabika","aragonit","arah","arai","arak","araknitis","araknoid","aral","aram","aramba","arang","aransemen","ararut","aras","arasy","arau","arbaa","arbab","arbei","arbiter","arbitrase","arbitrer","arboreal","arboretum","arborikultur","arca","arcas","ardi","are","area","areal","arek","arem-arem","aren","arena","areografi","areola","areometer","arerut","ares","arestasi","areta","argari","argentit","argentum","argirodit","argol","argometer","argon","argot","argumen","argumentasi","argumentatif","ari","aria","aries","arif","arifin","arih","arik","aril","aring","ariningsun","arip","aris","arisan","aristokrasi","aristokrat","aristokratis","aristotipe","arit","aritenoid","aritmetika","arja","arkade","arkais","arkaisme","arkan","arkati","arkegonium","arkeolog","arkeologi","arkeologis","arkeozoikum","arketipe","arkian","arkifonem","arkileksem","arkitraf","arktika","arku","arloji","armada","arnal","arogan","arogansi","aroma","aromatik","arombai","aron","arpus","arsenal","arsenik","arsenikum","arsip","arsipelago","arsir","arsis","arsitek","arsitektur","arta","artefak","arteri","arteriografi","arteriola","arteriosklerosis","artesis","artetis","arti","articok","artifak","artifisial","artik","artikel","artikulasi","artikulator","artileri","artiodaktil","artis","artisan","artistik","artisyok","artona","artotek","artrobrankium","artropoda","aru","aruan","aruda","aruk","arumba","arun","arung","arus","arwah","arwana","arya","aryaduta","arzak","asa","asabat","asabiah","asabiyah","asad","asah","asai","asak","asal","asali","asam","asan","asana","asap","asar","asas","asasi","asbak","asbes","asbut","aseksual","asemble","asembling","asepsis","aseptik","aseran","asese","aset","asetabulum","asetat","asetilena","asetimeter","aseton","asfal","asfar","asfiksia","asi","asibilan","asibilasi","asid","asidimeter","asidosis","asih","asiklik","asil","asilabis","asimetris","asimilasi","asimilatif","asimtot","asimus","asin","asindeton","asing","asinyor","asiri","asisten","asistensi","askar","askariasis","askarid","askese","asket","asketisisme","askon","askriptif","asli","asma","asmara","asmaradanta","asmaragama","asmaraloka","asmarandana","asnad","aso","asoi","asonansi","asong","asor","asortimen","asosial","asosiasi","asosiatif","aspal","asparaga","asparagus","aspartame","aspek","asperses","aspiran","aspirasi","aspirasional","aspirat","aspiratif","aspirator","aspirin","asprak","asrama","asrar","asri","assalamualaikum","asta","astadikpala","astaga","astagfirullah","astaka","astakona","astana","astasia","astatik","astatin","astenia","astenik","astenopia","asteositoma","aster","asteroid","astigmatis","astra","astral","astringen","astrofisika","astrolab","astrolog","astrologi","astronaut","astronautika","astronom","astronomi","astronomis","astrosit","asu","asuh","asumsi","asumtif","asung","asurador","asuransi","asusila","aswa","aswad","aswasada","asyera","asyik","asytoret","asyura","atak","ataksia","atap","atar","atas","atase","atau","atavisme","atebrin","ateis","ateisme","ateistis","atelir","atensi","atenuasi","ateret","atfal","ati","atlas","atlet","atletik","atma","atman","atmolisis","atmologi","atmometer","atmosfer","atmosferis","ato","atok","atol","atom","atomisasi","atomistis","atop","atos","atowa","atraksi","atraktan","atraktif","atresia","atret","atribut","atributif","atrisi","atrium","atrofi","atropin","atung","atur","atus","aubade","audiensi","audio","audiofil","audiofon","audiograf","audiogram","audiolingual","audiologi","audiometer","audiovisual","audit","auditor","auditorium","augmentatif","auk","auksanometer","auksi","auksin","aula","aulia","aum","aung","aur","aura","aural","aurat","aurikularia","aurora","aurum","aus","auskultasi","autad","autarki","autarkis","autentik","autentikasi","autentisitas","autisme","autistik","auto","autobiograf","autobiografi","autodidak","autodidaktik","autodin","autofon","autogami","autogen","autograf","autografi","autogram","autoklaf","autoklastik","autokrasi","autokrat","autokton","autoktonos","autolisis","autolitograf","autologi","automaton","automobil","automotif","autopsi","autoskop","autosom","autotoksin","autotrof","autotrofik","autotrop","autotropik","auzubillah","avalans","aven","aversi","avertebrata","avesta","avgas","aviari","aviasi","aviator","avifauna","avikultur","avirulen","avitaminosis","avokad","avontur","avonturir","avtur","avunkulokal","awa","awaair","awaarang","awabau","awabeku","awabulu","awabusa","awadara","awah","awahama","awai","awak","awal","awalengas","awam","awamineral","awan","awanama","awang","awar","awaracun","awas","awasenjata","awat","awawarna","awet","awewe","awi","awik-awik","awin","awur","awut","ayah","ayahan","ayahanda","ayak","ayal","ayam","ayan","ayanda","ayang-ayang","ayap","ayar","ayat","ayatullah","ayem","ayeng","ayid","ayit","ayo","ayom","ayu","ayuk","ayum","ayun","ayunda","ayut","azab","azal","azali","azam","azan","azeotrop","azimat","azimut","aziz","azmat","azoikum","azospermi","azurit","bab","baba","babad","babah","babak","babakan","babal","baban","babang","babar","babaring","babas","babat","babatan","babe","babesiasis","babet","babi","babil","babit","bablas","babon","babu","babun","babur","babut","baca","bacah","bacak","bacang","bacar","bacek","bacem","bacik","bacin","baco","bacok","bacot","bacul","bacut","bad","bada","badai","badak","badal","badam","badan","badang","badani","badar","badari","badasi","badau","bade","badi","badik","badminton","badong","badui","baduk","badung","badur","badut","baduyut","bafta","bagai","bagaimana","bagak","bagal","bagan","bagang","bagar","bagas","bagasi","bagat","bagau","bagea","bagi","baginda","bagong","bagor","baguk","bagul","bagur","bagus","bah","bahadur","bahaduri","bahagia","bahak","bahala","bahalan","baham","bahan","bahana","bahang","bahar","bahara","bahari","baharu","bahas","bahasa","bahaya","bahenol","baheula","bahimiah","bahkan","bahri","bahrulhayat","bahtera","bahu","bahuku","bahwa","bahwasanya","baiat","baid","baiduri","baik","bain","bainah","bais","bait","baitulharam","baitullah","baitulmakdis","baitulmakmur","baitulmal","baitulmukadas","baitulmukadis","baja","bajaj","bajak","bajan","bajang","bajar","bajau","bajetah","baji","bajigur","bajik","bajing","baju","bajul","bak","baka","bakak","bakal","bakalaureat","bakam","bakap","bakar","bakarat","bakas","bakat","bakau","bakda","bakdahu","bakdu","bakdul","bakelit","bakero","bakh","bakhil","baki","bakiak","bakik","bakir","bakmi","bako","bakpao","bakpia","baksi","baksis","bakso","baktau","bakteremia","bakteri","bakterin","bakteriofag","bakteriolisis","bakteriolog","bakteriologi","bakteriostatik","bakterisida","bakti","baku","bakul","bakung","bakup","bakut","bakwan","bal","bala","balabad","balad","balada","balah","balai","balairung","balak","balalaika","balam","balan","balang","balangkep","balans","balap","balar","balas","balau","balela","balen","balerina","balerong","balet","balgam","balian","balig","baliho","balik","baling","balistik","balistika","baliu","balkas","balkon","balneologi","balneoterapi","balok","balon","balong","balot","balsam","balseros","balu","baluarti","baluh","balui","baluk","balun","balung","balur","balut","bam","bambam","bambang","bambu","bambung","ban","bana","banal","banang","banar","banat","bancak","bancang","bancar","bancet","banci","bancik","bancuh","bancut","banda","bandan","bandang","bandar","bandara","bandarsah","bandasrayan","bandea","bandel","bandela","bandeng","bandering","banderol","banding","bandit","banditisme","bando","bandongan","bandos","bandot","bandrek","bandu","bandul","bandung","bandusa","bandut","bang","bangai","bangan","bangang","bangar","bangas","bangat","bangau","bangbung","banget","bangga","banggan","bangir","bangka","bangkah","bangkai","bangkal","bangkang","bangkar","bangkas","bangkasan","bangkeh","bangket","bangking","bangkir","bangkis","bangkit","bangkong","bangkot","bangkrut","bangku","bangkut","banglas","bangle","banglo","bango","bangor","bangpak","bangsa","bangsai","bangsal","bangsat","bangsi","bangun","bangus","bani","banian","baning","banir","banjang","banjar","banjaran","banji","banjir","banjur","bank","bankir","bantah","bantai","bantal","bantam","bantar","bantaran","bantat","bantau","banteng","banter","banting","bantu","bantun","bantut","banua","banyak","banyo","banyol","banyu","banyun","banzai","bao","bap","bapa","bapak","bapakisme","bapanda","bapang","bapet","baplang","baptis","bar","bara","baraat","baragajul","barah","barai","barak","barakat","barakatuh","baran","barang","barangan","barangkali","barap","baras","barat","barau-barau","barbar","barbarisme","barbel","barber","barbital","barbiton","barbiturat","barbur","bardi","bare-bare","barel","bareng","barep","baret","barga","bari","barid","barier","barik","barikade","baring","baringan","barion","baris","barisfer","barit","barita","bariton","barium","barjad","barkas","barkometer","barli","barograf","barogram","barok","barologi","barometer","barometri","baron","barong","barongan","barongsai","baroskop","barotermograf","barso","barter","baru","barua","baruh","baruje","baruna","barung-barung","barusan","barut","barzakh","barzanji","bas","basa","basa-basi","basah","basal","basalioma","basanit","basat","basau","basi","basil","basilari","basilika","basilus","basin","basir","basirah","basis","basit","baskara","baskat","basket","baskom","basmi","bastar","basuh","basung","basut","bata","batagor","batai","batak","batako","batal","batalion","batalyon","batang","batara","batari","batas","batekeng","batel","batela","baterai","bati","batih","batik","batil","batila","batimetri","batin","batiplankton","batir-batir","batis","batisfer","batok","batolit","baton","batu","batuk","batun","batung","bau","baud","bauk","bauksit","baun","baung","baur","baureksa","bausastra","bausuku","baut","bawa","bawab","bawah","bawak","bawal","bawang","bawasir","bawat","bawel","bawon","baya","bayak","bayam","bayan","bayang","bayangkara","bayangkari","bayar","bayas","bayat","bayata","bayati","bayem","bayi","bayonet","bayong","bayu","bayuh","bayun","bayung","bayur","bazar","bazoka","bea","beasiswa","beatifikasi","bebal","beban","bebandos","bebang","bebar","bebaru","bebas","bebat","bebe","bebek","bebekel","bebekisme","bebel","bebenah","beber","beberapa","beberas","bebesaran","bebi","bebodoran","bebotoh","bebrek","bebuyutan","becak","becek","beceng","becokok","becuk","becus","beda","bedah","bedak","bedal","bedama","bedan","bedar","bedaru","bedawi","bedaya","bedebah","bedegap","bedegong","bedel","bedeng","bedil","bedinde","bedo","bedol","bedudak","beduk","bedukang","bedung","beeng","bega","begadang","begah","begal","begana","begana-begini","begandering","begandring","begap","begar","begawan","begini","begitu","bego","begonia","begroting","begu","beguk","begundal","beha","behandel","behena","bejana","bejat","bek","beka","bekah","bekakak","bekakas","bekal","bekam","bekantan","bekap","bekas","bekat","bekatul","bekel","beken","beker","bekerma","bekicot","bekil","beking","bekisar","bekleding","bekles","beklit","beksan","beku","bekuk","bekuku","bekukung","bel","bela","belabas","belacak","belacan","belacu","belada","beladau","beladu","belah","belahak","belahong","belai","belak","belaka","belakang","belako","belalah","belalai","belalak","belalang","belam","belambang","belan","belanak","belanda","belandang","belandar","belandong","belandung","belang","belanga","belangah","belangir","belangkas","belangkin","belangkon","belanja","belantai","belantan","belantara","belantik","belantika","belantuk","belar","belarak","belas","belasah","belasting","belasungkawa","belasut","belat","belat-belit","belata","belater","belati","belatik","belatuk","belatung","belau","belawan","beldu","belebas","belebat","belecak","beleda","beledang","beledi","beledu","beleid","belek","belekek","belekok","belel","belelang","belembang","belencong","belendong","belendung","beleng","belenggu","belengket","belengkok","belengkong","belengset","belenting","belentung","belepas","belera","belerang","belerong","beleter","beli","belia","beliak","belian","beliau","belibas","belibat","belibis","belida","beligat","beligo","belik","belikan","belikat","beliku","belimbing","belincong","beling","belingkang","belingsat","belingut","belinjo","belintang","belis","belit","belitung","beliung","beliut","beloan","belobor","belodok","beloh","belok","belokok","belolang","belolok","belolong","belon","belonggok","belongkang","belongkeng","belongkot","belongkotan","belongsong","belontang","beloon","belot","belotong","belu","belu-belai","beluam","beluas","belubu","belubur","beludak","beludar","beludru","beluhan","beluk","belukap","belukar","beluku","belukut","belulang","beluluk","belulung","belum","belumpai","belungkang","belungkur","belungsing","belunjur","beluntas","beluru","belus","belusuk","belut","beluwek","bembam","bemban","bembar","bembarap","bembet","bemo","bemper","bena","benah","benak","benalu","benam","benang","benar","benara","benatu","bencah","bencana","bencat","benci","bencol","bencong","benda","bendahara","bendahari","bendala","bendalu","bendang","bendar","bendara","bendari","bendawat","bendawi","bende","bendel","bendela","bendera","benderang","benderung","bendesa","bendi","bendir","bendo","bendoro","bendu","benduan","bendul","bendung","benefaktif","bengah","bengal","bengang","bengang-bengut","bengap","bengawan","bengek","bengep","benggal","benggala","benggang","benggil","benggol","bengis","bengkah","bengkak","bengkal","bengkal-bengkil","bengkalai","bengkang-bengkok","bengkang-bengkong","bengkang-bengkung","bengkar","bengkarak","bengkarap","bengkaras","bengkarung","bengkatak","bengkawan","bengkawang","bengkayang","bengkel","bengkelai","bengkeng","bengker","bengkerap","bengkil","bengkok","bengkol","bengkong","bengkos","bengku","bengkuang","bengkudu","bengkunang","bengkung","bengoh","bengok","bengong","bengot","bengu","benguk","bengul","bengung","beni","benian","benih","bening","benitan","benjol","benjut","benkap","bensin","benta","bentak","bentala","bentan","bentang","bentangkan","bentangur","bentar","bentara","bentaus","benteh","benteng","bentes","bentet","bentik","bentoh","bentok","bentol","bentong","bentonit","bentos","bentrok","bentuk","bentul","bentulu","bentur","benturung","bentus","benua","benuang","benuaron","benulung","benum","benur","benyai","benyek","benyoh","benyot","benzedrin","benzena","benzil","benzoat","benzoil","benzoin","benzol","beo","beol","bera","berabe","beragan","berahi","berai","beraja","berak","berakah","beraksa","beram","berambang","beramin","beranang","beranda","berandal","berandang","berang","berangai","berangan","berangas","berangasan","berangga","berangkal","berangkat","berangsang","berangta","berangus","berani","beranta","berantak","berantas","berapa","beras","berat","bercak","berdikari","berdus","berebes","beredel","berek-berek","beremban","berembang","berendeng","bereng-bereng","berengau","berenggil","berengos","berengsek","berengut","berentang","bereo","bererot","beres","beresok","beret","berewok","bergajul","bergas","berguk","berhala","beri","beriang","beriani","berida","berik","beril","berilium","berinda","bering-bering","beringas","beringin","beringsang","berisik","berita","berkah","berkas","berkat","berkelium","berkik","berkil","berko","berkung","berlau","berlian","berma","bermat","bermi","bernas","bernga","beroci","beroga","berok","berokat","beron","beronang","berondok","berondong","berong","berongkos","berongsang","berongsong","beronjong","beronok","beronsang","berontak","berosot","beroti","beroya","bersat","bersih","bersil","bersin","bersit","bersut","bertam","bertih","beru","beruang","beruas","berubuh","berudu","berui","beruju","berujul","beruk","berumbun","berumbung","berunai","berunang","berungut","beruntus","beruri","berus","berwari","berzanji","besalen","besan","besar","besek","besel","besengek","beser","besero","beset","besi","besikal","besing","besit","beskal","beskap","beskat","beslah","beslit","besok","besot","bestari","bestek","bestel","bestialitas","bestik","bestir","bestral","besuk","besusu","besut","besuta","bet","beta","betah","betahak","betak-betak","betang","betapa","betara","betari","betas","betatas","betatron","betau","betet","beti","betik","betina","beting","betinga","betis","betok","beton","betonisasi","betot","betul","betung","betutu","bewok","bhayangkara","biadab","biadat","biadi","biah","biak","biang","bianglala","biaperi","biar","biara","biarpet","biarpun","bias","biasa","biat","biau","biawak","biawan","biawas","biaya","bibel","bibi","bibinda","bibir","bibit","biblio","bibliografi","bibliomania","bibliotek","bicana","bicara","bicokok","bicu","bida","bidadari","bidah","bidai","bidak","bidal","bidan","bidang","bidar","bidara","bidari","bidas","bidet","bidik","bido","biduan","biduanda","biduanita","biduk","bidur","biduri","bienial","biennale","bifasial","bifida","bigair","bigami","bigamis","bihi","bihun","bijak","bijaksana","bijan","bijana","biji","bijih","bik","bikameral","bikang","bikarbonat","bikin","bikini","bikir","bikonkaf","bikonveks","bikromat","biksah","biksu","biksuni","biku","bila","bilabial","bilah","bilai","bilakmata","bilal","bilamana","bilamasa","bilang","bilas","bilateral","bilateralisme","bilga","bilhak","biliar","bilik","bilineal","bilingual","bilingualisme","bilis","biliun","billahi","bilokal","bilur","bilyet","bimasakti","bimbang","bimbing","bimbit","bimetal","bin","bina","binal","binar","binara","binaraga","binasa","binatak","binatang","binatu","binawah","binayah","bincacak","bincang","bincang-bincut","bincu","bincul","bincut","bindam","bindeng","binder","bindu","bineka","binen","biner","bingas","bingit","bingka","bingkah","bingkai","bingkas","bingkatak","bingkis","bingung","bini","binjai","binjat","binokular","binomial","bintak","bintal","bintalak","bintan","bintang","bintara","binti","bintik","bintil","bintit","bintul","bintulbahar","bintur","binturung","biodata","biodin","biofera","biofilm","biofilter","biofisik","biofisika","biogas","biogenesis","biogenik","biogeografi","biografi","biokimia","bioklimatologi","biola","biolinguistik","biolit","biolog","biologi","biologis","bioluminesensi","biomassa","biomekani","biometeorologi","biometri","biometrika","bionomika","biopendar","bioplasma","biopsi","bioritme","bioritmik","biosekuen","biosfer","biosida","bioskop","biostatika","biota","biotek","bioteknologi","biotik","biotin","biotoksin","biotron","bipatride","bipolar","bipolaritas","bipolisentrisme","biprisma","bir","birah","birai","biram","birama","birang","biras","birat","biri-biri","biring","birit","biro","birofaks","birokrasi","birokrat","birokratis","birokratisasi","birokratisme","birsam","biru","bis","bisa","bisai","bisan","bisawab","bisbol","biseksual","bisektris","biseps","bisik","bising","bisinosis","biskuit","bismillah","bismut","bisnis","bison","bissu","bistik","bisu","bisul","bit","biti","biting","bitisik","bitumen","biuku","biumbai","bius","biut","bivak","biverbal","biyuh-biyuh","bizurai","blabar","blabitisme","blakblakan","blangko","blantik","blantika","blaster","blastostil","blazer","blek","blekek","blekok","blenda","blender","blepot","blewah","blirik","blog","bloger","blok","blokade","blokir","bloknot","blong","blower","bludrek","blues","blus","blustru","bobato","bobok","bobol","bobos","bobot","bobotok","bobrok","bocah","bocok","bocong","bocor","bodhi","bodhisatwa","bodi","bodoh","bodok","bodong","bodor","boga","bogam","bogel","bogem","bogi","bogol","bogor","bogot","bohemian","bohlam","bohong","bohorok","bohsia","boi","boikot","bois","bokar","bokca","bokek","boko","bokoh","bokong","bokop","bokor","boks","boksen","bokser","bokset","boksu","boku","bol","bola","bolak","bolak-balik","bolang-baling","boleh","bolero","bolide","boling","bolometer","bolong","bolos","bolot","bolotu","bolpoin","bolsak","bolu","bom","bombai","bombardemen","bombardir","bombas","bombastis","bomber","bomoh","bomseks","bon","bonafide","bonafiditas","bonang","bonanza","bonar","bonbon","boncel","bonceng","boncol","boncong","bondol","bondong","bondot","boneka","bonet","bong","bongak","bonggol","bongkah","bongkak","bongkar","bongkar-bangkir","bongkin","bongko","bongkol","bongkong","bongkor","bongkot","bongkrek","bonglai","bongmeh","bongo","bongok","bongsang","bongsor","bonjol","bonjor","bonsai","bontak","bonto","bontok","bontot","bonus","bonyok","bopeng","boplang","bopok","bopong","bor","bora","borak","boraks","borang","borat","borci","border","bordes","bordil","bordir","bordu","boreal","boreh","borek","borgol","borhan","borjuasi","borjuis","borkol","boro-boro","borok","boron","borong","boros","bortel","bos","bosan","boseta","bosman","boson","bosor","bosun","bot","bota","botak","botang","botani","botanikus","botanis","botelir","botlir","boto","botoh","botok","botol","botor","botridium","botulisme","bowo","boya","boyak","boyas","boyo-boyo","boyong","boyongan","bozah","bradikardi","brahma","brahmana","brahmani","brahmi","brahmin","braille","brakiasi","brakilogi","brakisefalik","brakistokron","brakiurus","braktea","bramacorah","brambang","brana","brander","brankar","brankas","branwir","braseri","brata","bratawali","bredel","breksi","breksia","brem","bren","brendi","brengsek","bretel","brevet","brifing","brigade","brigadir","brigidig","briket","brilian","briofita","briologi","briozoa","brisan","broiler","brokade","brokat","broker","brokoli","brom","bromat","bromida","bromin","bromisme","brompit","brongkos","bronkioli","bronkitis","bronkodilator","bronkotomi","bronkus","brontosaurus","bros","brosur","browser","bruder","bruk","brunai","brutal","brutalisme","bruto","bua","buah","buai","buak","bual","buana","buang","buani","buar","buari","buas","buat","buaya","bubar","bubo","bubu","bubuh","bubuhan","bubuk","bubul","bubun","bubung","bubur","bubus","bubut","bucu","budak","budanco","budaya","buddha","buddhis","buddhisme","bude","budek","budi","budian","budiman","budu","buduk","budur","bueng","bufer","bufet","bugar","bugenfil","bugenvil","bugi-bugi","bugil","buhuk","buhul","bui","buih","buil","bujal","bujam","bujang","bujangga","bujet","bujeter","bujuk","bujur","bujut","buk","buka","bukan","bukankah","bukantah","bukat","bukau","buket","bukit","buklet","bukti","buku","bukung","bukur","bukut","bulai","bulak","bulan","bulang","bulang-baling","bulangan","bular","bulat","bulbul","buldan","buldog","buldoser","bule","buleng","buletin","bulevar","bulgur","buli-buli","bulian","bulimia","bulir","bulsak","bulu","bulug","buluh","buluk","bulur","bulus","bum","bumantara","bumban","bumbu","bumbun","bumbung","bumel","bumerang","bumi","bumiah","bumiputra","bumper","bumpet","bumping","bun","buna","bunbunan","buncah","buncak","buncang","buncis","buncit","bunda","bundak","bundar","bundas","bundel","bunduk","bundung","bung","bunga","bungalo","bungar","bungkal","bungkam","bungkang","bungkas","bungker","bungkil","bungking","bungkuk","bungkul","bungkus","bunglai","bunglon","bungsil","bungsu","bungur","buni","bunian","bunjai","buntak","buntal","buntang","buntar","buntat","buntek","buntel","buntet","buntil","bunting","buntu","buntung","buntut","bunuh","bunut","bunyi","bupala","bupati","bupet","bur","bura","burai","burak","burakah","buraksa","buram","buras","burat","burayak","burdah","bureng","buret","burgundi","burhan","burik","burit","burjusumbulat","burkak","burnout","buron","bursa","buru","buruh","buruj","buruk","burun","burung","burut","bus","busa","busai","busana","busar","buset","bushido","busi","busik","bustan","buster","busuk","busung","busur","busut","buta","butadiena","butala","butana","butang","butarepan","butbut","butek","butik","butir","butirat","butongpai","butuh","butul","butun","butut","buwuh","buya","buyar","buyung","buyur","buyut","byarpet","caba","cabai","cabak","cabang","cabar","cabau","cabe","cabik","cabir","cabo","cabuh","cabuk","cabul","cabur","cabut","caca","cacah","cacak","cacap","cacar","cacat","cacau","caci","cacibar","cacil","cacing","cadai","cadang","cadar","cadas","cadel","cadik","cadok","caduk","cadung","caem","cagak","cagar","cagil","cagu","caguh","cagun","cagut","cah","cahang","cahar","cahari","cahaya","cahi","cailah","caima","caing","cair","cais","caisim","cak","cakah","cakak","cakalang","cakalele","cakap","cakar","cakawari","cakela","cakep","caki","cakiak","cakil","cakmar","cako","cakra","cakrabirawa","cakrabuana","cakram","cakrawala","cakruk","cakup","cakur","cakus","cal","calabikang","caladi","calak","calang","calar","calecer","calempong","caling","calir","calit","calo","calon","calui","caluk","calung","calus","cam","camar","camat","camau","cambahan","cambang","cambuk","cambul","cambung","camca","camil","campa","campah","campak","campang","campin","camping","camplungan","campuh","campung","campur","camuk","camur","canai","canak","canang","cancan","cancang","cancut","canda","candai","candak","candala","candang","candat","candi","candik","candit","candra","candradimuka","candramawa","candrasa","candrasengkala","candu","candung","cang","cangah","cangak","cangam","cangap","cangar","cangcang","cangga","canggaan","canggah","canggai","canggal","cangget","canggih","canggu","canggung","cangkang","cangkat","cangkel","cangkih","cangking","cangkir","cangklong","cangkok","cangkol","cangkrang","cangkrim","cangkriman","cangkring","cangkuk","cangkul","cangkulan","cangkum","cangkung","cangkup","canguk","cangut","cantas","cante","cantel","canteng","cantik","canting","cantol","cantrik","cantum","caos","cap","capa","capah","capai","capak","capal","capang","capar","capcai","cape","capek","capelin","capgome","capik","capil","caping","capit","capjiki","caplak","caplok","capuk","capung","cara","carah","carak","caraka","caram","caran","carang","caren","cari","carik","caring","carter","caruk","carut","cas","casciscus","cat","catat","catek","catu","catuk","catur","caturjalma","caturlarik","caturtunggal","caturwangsa","caturwarga","caturwarna","caturwulan","catut","caul","caung","cawai","cawak","cawan","cawangan","cawat","cawe-cawe","cawi","cawis","cebak","ceban","cebik","cebikas","cebil","cebir","cebis","cebok","cebol","cebong","cebur","cecah","cecak","cecap","cecar","cecawi","cece","ceceh","ceceng","cecengklok","cecer","cecere","cecok","cecongor","cecunguk","cedal","cedayam","cedera","ceding","cedok","cedong","ceduk","cegah","cegak","cegar","cegat","ceguk","cek","cekah","cekak","cekakak","cekakan","cekal","cekam","cekang","cekarau","cekat","cekau","cekcekcek","cekcok","cekdam","cekdel","cekek","cekel","ceker","cekeram","ceki","cekibar","cekih","cekik","cekikik","ceking","cekit","ceklek","cekluk","cekok","cekrem","cekres","ceku","cekuh","cekuk","cekung","cekup","cekur","cekut","cela","celaga","celah","celak","celaka","celampak","celana","celang","celangak","celangak-celinguk","celangap","celapak","celar","celari","celas","celas-celus","celat","celatuk","cele","celebuk","celedang-celedok","celek","celekeh","celemek","celemotan","celempong","celempung","celeng","celengan","celengkak-celengkok","celengkang","celentang","celep","celepik","celepuk","celetuk","celi","celih","celik","celinguk","celingus","celis","celok","celomes","celomok","celonok","celopar","celorot","celoteh","celsius","celuk","celum","celung","celup","celupak","celur","celuring","celurit","celurut","celus","celutak","celutuk","cema","cemani","cemar","cemara","cemas","cemat","cembeng","cemberut","cembul","cembung","cemburu","cemeeh","cemeh","cemek","cemekian","cemengkian","cemer","cemerlang","cemeti","cemetuk","cemomot","cemong","cemooh","cempa","cempaka","cempal","cempala","cempana","cempe","cempedak","cempek","cempelik","cempelung","cempeng","cempera","cemperai","cemperling","cempiang","cempil","cempin","cemping","cemplang","cemplung","cempor","cempreng","cempres","cempuling","cempung","cempurit","cemuas","cemuk","cena","cenak","cenal-cenil","cenangau","cenangga","cenangkas","cenayang","cencala","cencaluk","cencang","cencaru","cencawan","cencawi","cendala","cendana","cendang","cendawan","cendekia","cendera","cenderai","cenderasa","cenderawasih","cenderung","cendok","cendol","cenduai","cenela","ceng","cengal","cengam","cengang","cengap","cengar-cengir","cengbeng","cengeh","cengek","cengeng","cengengesan","cenggek","cengger","cenggeret","cengi","cengir-cengir","cengis","cengkal","cengkam","cengkar","cengkaruk","cengkau","cengkedi","cengkeh","cengkek","cengkelong","cengkeram","cengkerama","cengkerawak","cengkerik","cengkering","cengkerung","cengki","cengkiak","cengkih","cengking","cengkir","cengkiwing","cengkok","cengkol","cengkong","cengkung","cengkurai","cengli","cengung","cengut","centang","centangan","centeng","centet","centil","centong","centung","cenung","cepak","cepal","cepat","cepek","cepeng","cepengan","ceper","cepiau","ceplas-ceplos","ceples","ceplok","ceplos","cepo","cepol","cepu","cepuk","cerabah","cerabih","cerabut","ceracak","ceracam","ceracap","ceracau","cerah","cerai","cerai-berai","cerak","ceraka","cerakin","ceramah","cerana","cerancang","cerang","ceranggah","cerangka","cerap","cerat","ceratai","ceratuk","cerau","cerawat","cerbak","cerca","cercah","cercak","cercap","cerdas","cerdik","cere","cerecek","cerek","ceremai","cerempung","cerepu","ceret","cerewet","cergas","ceri","ceria","cericap","cericau","cericip","ceriga","cerih","cerita","ceriwis","cerkam","cerkau","cerlang","cerlih","cerling","cermai","cermat","cermin","cerna","ceroboh","cerobong","cerocok","cerocos","cerompong","ceronggah","ceropong","ceroteh","cerowok","cerpelai","cerpen","cerpenis","cerpu","cerucuh","cerucup","ceruh","ceruk","cerun","cerup","cerut","cerutu","cespleng","cetai","cetak","cetar","cetek","ceteng","ceter","cetera","ceteri","ceteria","ceti","cetok","cetus","ceuki","cewang","cewek","ciak","cialat","ciap","ciar","cibir","cibit","ciblon","cibuk","cicik","cicil","cicinda","cicip","cicit","cidomo","ciduk","cigak","cih","cihui","cik","cika","cikadas","cikal","cikar","cikok","cikrak","ciku","cikun","cikut","cilap","cilawagi","cili","cilik","ciling","cilok","ciluk","cilukba","cimplong","cina","cincang","cincau","cincin","cincong","cincu","cinda","cindai","cindaku","cinde","cindil","cindur","cing","cingak","cingam","cingangah","cingge","cingkat","cingkeh","cingkrang","cingur","cinta","cintamani","cinteng","cintrong","cip","cipai","cipan","ciplak","cipok","ciprat","cipta","cir","circir","ciri","cirit","ciriwangi","cis","cit","cita","citra","citraleka","ciu","cium","ciut","coak","coang","coba","coban","cobar-cabir","cobek","coblos","cocok","cocol","cocor","codak","codet","codot","cogah","cogan","cogok","cok","cokar","cokek","cokelat","coket","coklat","cokmar","coko","cokok","cokol","cokor","cokorda","cola-cala","colak","colak-caling","colang-caling","colek","coleng","colet","coli","colok","colong","colot","comat-comot","comberan","comblang","combong","comek","comel","comor","comot","compang-camping","compeng","compes","compoh","compreng","comro","concong","condong","conet","congak","congeh","congek","conggah-canggih","congget","conggok","congkah-cangkih","congkah-mangkih","congkak","congkel","congki","congklak","congklang","congkok","congkong","congo","congok","congol","congor","congsam","contek","conteng","contoh","contong","cop","copak-capik","copet","coplok","copot","cor","corak","corat-coret","corek","coreng","coret","coro","corob","corong","corot","cotet","cotok","cowok","cowokan","crat-crit","criping","cua","cuaca","cuai","cuak","cual","cuang","cuar","cuat","cubit","cublik","cubung","cuca","cucakrawa","cuci","cucu","cucuh","cucuk","cucun","cucunda","cucung","cucup","cucur","cucurut","cucut","cudang","cuek","cugat","cuh","cuik","cuil","cuit","cuk","cuka","cukai","cuki","cukil","cukimai","cukin","cukit","cukong","cuku","cukup","cukur","cula","culak","culan","culas","culi","culiah","culik","culika","culim","culun","cuma","cuman","cumbu","cumengkling","cumepak","cumi-cumi","cumil","cuming","cun","cunam","cundang","cundrik","cunduk","cung","cungap","cungkil","cungkup","cungo","cungul","cungur","cunia","cup","cupai","cupak","cupang","cupar","cupet","cuping","cuplik","cupu","cupul","cur","cura","curah","curai","curam","curang","curat","cureng","curi","curiah","curiga","curik","curna","curu","cus","cut","cutak","cutbrai","cutel","cuti","cuwil","daayah","dab","daba","dabak","dabal","dabat","dabih","dabik","dabing","dabir","dabit","dablek","dabol","dabung","dabus","dacin","dad","dada","dadah","dadaisme","dadak","dadal","dadali","dadap","dadar","dadek","dadi","dadih","dading","dadu","daduh","daduk","dadung","daeng","daerah","daerahisme","dafnah","daftar","daga","dagang","dage","dagel","dagi","daging","dagu","dah","dahaga","dahagi","dahak","daham","dahan","dahanam","dahar","dahi","dahiat","dahina","dahlia","dahriah","dahsyat","dahulu","dai","daidan","daidanco","daif","daim","daiman","daing","daitia","dajal","daka","dakah","dakaik","dakar","dakhil","daki","dakik","dakocan","dakon","dakron","daksa","daksina","daktil","daktilitis","daktilologi","daktiloskopi","daku","dakwa","dakwah","dal","dalal","dalalah","dalalat","dalam","dalang","daldaru","dalem","dalfin","dali-dali","dalih","dalil","daltonisme","dalu","daluang","dalung","dam","damah","damai","damak","damal","daman","damar","damaru","damas","damat","damba","dambin","dambir","dame","damen","dami","damik","damotin","dampak","dampal","dampan","dampar","dampeng","dampil","damping","dampit","damprat","dampung","dan","dana","danau","danawa","danda","dandan","dandang","dandanggula","dandapati","dandi","dang","dangai","dangar","dangau","dangdut","dange","danghyang","dangir","dangka","dangkal","dangkap","dangkar","dangkung","danguk","dansa","dansanak","danta","danuh","danur","danyang","dap","dapa","dapar","dapat","dapra","dapur","dar","dara","darab","darah","daras","darat","darau","dargah","dari","daripada","darji","darma","darmabakti","darmakelana","darmasiswa","darmatirta","darmawisata","daro","darpana","daru-daru","darulaitam","darulakhirat","darulbaka","darulfana","daruljalal","darun","darunu","darurat","darusalam","darwis","das","dasa","dasalomba","dasar","dasarian","dasasila","dasatitah","dasawarsa","dasbor","dasi","dasin","daster","dasun","data","datang","datar","datatamak","dati","datif","datu","datuk","datum","datung","dauk","daulat","daun","daur","dawai","dawan","dawat","dawet","daya","dayah","dayang","dayu","dayuh","dayuk","dayung","dayus","dealat","deaneksasi","debah","debak","debam","debap","debar","debarkasi","debas","debat","debet","debik","debil","debing","debirokratisasi","debit","debitase","debitor","debitur","debris","debu","debug","debuk","debum","debun","debung","debup","debur","debus","debut","decak","decap","deceh","decing","decit","decup","decur","decut","dedah","dedai","dedak","dedal","dedalu","dedap","dedar","dedara","dedare","dedas","dedau","dedek","dedel","dedemit","dedengkot","deder","dederuk","dedes","dedikasi","dedikatif","deduksi","deduktif","dedulang","deeskalasi","defaitisme","defekasi","defender","defensi","defensif","deferens","defile","definisi","definit","definitif","defisien","defisit","deflagrasi","deflagrator","deflasi","defleksi","deflorasi","defoliasi","defolisasi","defonologisasi","deforestasi","deformasi","deformatif","deg","degam","degan","degap","degar","degen","degenerasi","degeneratif","degil","deging","degradasi","degresi","deguk","degum","degung","degup","deh","deham","dehem","dehidrasi","dehidrat","dehidrogenasi","dehumanisasi","deideologisasi","deifikasi","deiksis","deiktis","deislamisasi","deisme","dek","dekade","dekaden","dekadensi","dekagram","dekah","dekak","dekaliter","dekam","dekameter","dekan","dekanal","dekantasi","dekap","dekapoda","dekar","dekare","dekat","dekik","dekil","deking","deklamasi","deklamator","deklarasi","deklaratif","deklasifikasi","deklerer","deklinasi","deklinometer","dekode","dekoder","dekolonisasi","dekomposer","dekomposisi","dekompresi","dekongestan","dekonsentrasi","dekontekstualisasi","dekor","dekorasi","dekoratif","dekorator","dekosistem","dekremeter","dekreolisasi","dekret","dekriminalisasi","deksa","dekstrin","dekstrosa","deksura","deku","dekunci","dekung","dekus","dekut","delabialisasi","delah","delamak","delan","delap","delapan","delas","delat","delegasi","delegat","delegitimasi","delepak","deler","delik","delikan","delikat","delikates","delima","delineasi","delinkuen","delinkuensi","delirium","delman","delong","delongop","delta","deltoid","delu","delusi","delusif","demabrasi","demagog","demagogi","demagogis","demah","demam","demang","demap","demarkasi","dembai","dembam","dembun","demek","demen","demes","demi","demik","demikian","demiliterisasi","demineralisasi","demisioner","demo","demobilisan","demobilisasi","demograf","demografi","demografis","demokrasi","demokrat","demokratis","demokratisasi","demon","demoniak","demonopolisasi","demonstran","demonstrasi","demonstratif","demonstrativa","demoralisasi","demosi","dempak","dempam","dempang","demper","dempet","dempir","demplon","dempok","dempuk","dempul","dempung","demung","den","dena","denah","denai","denak","denasalisasi","denasionalisasi","denawa","dencang","dencing","denda","dendam","dendang","dendeng","dendi","dendrokronologi","dendrologi","denervasi","dengak","dengan","dengap","dengar","dengih","denging","dengkang","dengkel","dengki","dengkik","dengking","dengkol","dengkul","dengkung","dengkur","dengkus","dengu","dengue","denguk","dengung","dengus","dengut","denim","denok","denominal","denominasi","denotasi","denotatif","densimeter","densitas","densitometer","densitometri","densometer","dental","dentam","dentang","dentat","dentin","denting","dentum","dentung","dentur","denudasi","denuklirisasi","denyar","denyit","denyut","deodoran","deoknumisasi","deontologi","depa","depak","depalatalisasi","depan","depang","depap","deparpolisasi","departemen","departemental","departementalisasi","dependen","dependensi","depersonalisasi","depersonifikasi","depigmentasi","depilasi","deplesi","depo","depolarisasi","depolitisasi","deponir","depopulasi","deportasi","deposan","deposit","deposito","depot","depresi","depresiasi","depresor","deprok","deprotonasi","depun","depus","deputasi","deputi","dera","deragem","derai","derajah","derajang","derajat","derak","deram","deran","derana","derang","derap","deras","derau","derawa","derebar","deregulasi","derek","derel","derep","deres","deresi","deret","dergama","derik","dering","deringo","deris","derit","derita","deritaan","derivasi","derivat","derivatif","derji","derma","dermaga","derman","dermatitis","dermatofitosis","dermatolog","dermatologi","dermatom","dermis","dermoid","dersana","dersik","deru","deruji","deruk","derum","derun","derung","derup","derus","derut","desa","desah","desain","desainer","desak","desakralisasi","desalinasi","desaneksasi","desar","desas-desus","desau","desegregasi","deselerasi","desember","desensitisasi","desentralisasi","deserebrasi","desersi","desertir","desibel","desidua","desigram","desih","desik","desikan","desikator","desil","desiliter","desiliun","desimal","desimeter","desinens","desinfeksi","desinfektan","desing","desintegrasi","desir","desis","desit","deskripsi","deskriptif","deskuamasi","desmonem","desmoplasia","desmosom","desorientasi","desorpsi","despot","despotik","despotisme","destabilisasi","destar","destinasi","destroyer","destruksi","destruktif","destruktor","desuk","desulfurisasi","desup","desur","desus","desut","detail","detak","detap","detar","detas","detasemen","detasering","detasir","deteksi","detektif","detektofon","detektor","detenidos","detensi","detente","detergen","deteriorasi","determinan","determinasi","determinatif","determinator","determinis","determinisme","detik","deting","detoksifikasi","detonasi","detonator","detritus","detrusor","detup","detus","deuterium","deuterokanonika","deuteron","deutranomalopia","deutranopia","devaluasi","developer","deverbal","deviasi","devisa","devosi","dewa","dewadaru","dewala","dewan","dewana","dewanagari","dewangga","dewasa","dewata","dewe","dewi","dia","diabetes","diad","diadem","diafon","diaforetik","diafragma","diagenesis","diagnosis","diagnostik","diagometer","diagonal","diagram","diaken","diakon","diakones","diakonia","diakritik","diakronis","dialek","dialektal","dialektik","dialektika","dialektis","dialektologi","dialinguistik","dialisis","dialog","dialogis","diam","diamagnetisme","diameter","diametral","diamorf","dian","diang","diaper","diapositif","diar","diare","dias","diasistem","diaspora","diastase","diastole","diat","diaterman","diatermi","diatermik","diatesis","diatipe","diatom","diatomit","diatonik","diatopik","diayah","dibasa","didaktik","didaktikus","didaktis","didih","didik","didis","didong","dielektrik","diensefalon","dies","diesel","diet","dietetika","difabel","diferensial","diferensiasi","difluens","difluensi","difraksi","difteri","diftong","difusi","digdaya","digenesis","digestif","digit","digital","digitalin","digitalis","digitalisasi","diglosia","digraf","digresi","digul","dihedral","dihidroksil","dik","dikara","dikau","dikit","diklorida","dikotil","dikotomi","dikroisme","dikromat","dikromatik","diksa","diksi","diktat","diktator","diktatorial","diktatoris","dikte","diktum","dil","dila","dilak","dilam","dilasi","dilatasi","dilatometer","dilema","dilematik","diler","diletan","diluvium","dim","dimensi","dimer","diminutif","dimorfik","dimorfisme","din","dina","dinamik","dinamika","dinamis","dinamisator","dinamisme","dinamit","dinamo","dinamometer","dinar","dinas","dinasti","dinding","dingin","dingkis","dingkit","dingklang","dingklik","dingo","dini","diniah","diniyah","dinosaurus","dinul-islam","diode","dioesis","dioksida","dioksin","diopsida","dioptase","dioptri","diorama","diorit","dioses","dipan","diplo","diploid","diploma","diplomasi","diplomat","diplomatik","diplomatis","dipsomania","diptera","diptotos","dirah","diraja","direk","direksi","direktorat","direktorium","direktris","direktur","dirgahayu","dirgantara","dirham","diri","dirigen","diris","dirus","disagio","disain","disainer","disakarida","disastria","disbursemen","disdrometer","disekuilibrium","disel","disensus","disentri","disertasi","disfonia","disfungsi","disharmoni","disiden","disilabik","disimilasi","disinfektan","disinformasi","disinsentif","disintegrasi","disiplin","disjoki","disjungsi","disjungtif","diska","disket","diskiasis","disklimaks","disko","diskoid","diskon","diskontinu","diskontinuitas","diskonto","diskordans","diskorobik","diskotek","diskredit","diskrepansi","diskresi","diskriminasi","diskriminatif","diskriminator","diskualifikasi","diskulpasi","diskursif","diskus","diskusi","dislalia","disleksia","dislokasi","dismembrasio","dismenorea","dismutasi","disolventia","disonansi","disoperasi","disorder","disorganisasi","disorientasi","disosiasi","dispareunia","disparitas","dispensasi","dispenser","dispepsia","dispersal","dispersi","disposisi","disposotio","disprosium","disrupsi","distabilitas","distal","distansi","distikiasis","distikon","distilasi","distilator","distingsi","distingtif","distoma","distorsi","distosia","distribusi","distributor","distrik","disuasi","disuria","dito","ditransitif","diuresis","diuretik","diurnal","divergen","divergensi","diversifikasi","diversitas","divestasi","dividen","divisi","diwala","doa","doang","dobel","dobi","doblangan","doble","dobol","dobolo","dobrak","dodekagon","dodekahedron","dodet","dodok","dodol","dodong","dodor","dodos","dodot","doeloe","dog","dogel","dogeng","doger","dogma","dogmatik","dogmatis","dogmatisme","dogol","dohok","dohyo","doi","dok","dokar","doko","dokoh","dokok-dokok","doksologi","dokter","doktor","doktoranda","doktorandus","doktrin","doku","dokumen","dokumentasi","dokumenter","dol","dolak-dalik","dolan","dolar","doldrum","dolfin","dolikosepalik","dolmen","dolok","dolomit","dom","domain","domba","domblong","domein","domestik","domestikasi","dominan","dominansi","dominasi","domine","dominggo","dominion","domino","domisili","domot","dompak","dompet","domplang","dompleng","dompol","don","donasi","donat","donatur","doncang","dondang","donder","dondon","dong","dongak","dongan","dongbret","dongeng","dongkak","dongkel","dongkok","dongkol","dongkrak","dongkrok","dongok","dongpan","dongsok","doni","donor","donto","dop","doping","dopis","dor","dorang","dorbi","dorbia","dorman","dormansi","dorna","dorong","dorsal","dorslah","dorsopalatal","dorsovelar","dorsum","dortrap","dos","dosa","dosen","dosin","dosir","dosis","dot","dowel","dower","doyak","doyan","doyang","doyo","doyong","draf","dragon","drai","drainase","drakula","dram","drama","dramatik","dramatikus","dramatis","dramatisasi","dramaturg","dramaturgi","draperi","drastis","drat","drel","dresoar","dresur","dribel","drif","dril","drip","drop","droping","dropsi","drum","drumben","drumer","druwe","dua","duafa","duai","duaja","dualis","dualisme","dualistis","duane","duang","duangsom","dub","dubalang","dubelir","dubes","dubila","dubing","dubius","duble","dublir","dubuk","dubur","duda","duduk","dudur","dudus","duel","duet","duga","dugal","dugang","dugas","dugdeng","dugder","duh","duha","duhai","duhe","duhu","duilah","duit","duk","duka","dukacarita","dukacita","dukan","dukana","dukat","dukaten","duktulus","duktus","duku","dukuh","dukun","dukung","dula","dulag","dulang","dulang-dulang","duli","dulur","dum","dumdum","dumi","dumping","dumung","dunah","dunak","dung","dungas","dungkelan","dungkul","dungu","dungun","dunia","duniawi","duodenum","duodesimal","duodrama","duopoli","dup","dupa","dupak","dupleks","duplik","duplikasi","duplikat","duplikator","duplisitas","duplo","dur","dura","duralumin","duramater","durasi","durat","duratif","duren","dureng","durhaka","duri","durian","durias","duriat","durja","durjana","durjasa","durkarsa","durma","durna","durno","durnois","durnoisme","durometer","dursila","duru","duruwiksa","dus","dusin","dusta","dustur","dusun","duta","duwegan","duwet","duyun","duyung","dwiarti","dwibahasa","dwidarma","dwidasawarsa","dwifungsi","dwiganda","dwiguna","dwilingga","dwimatra","dwiminggu","dwimuka","dwiperan","dwipurwa","dwisegi","dwitarung","dwitunggal","dwiwarna","dzal","ebam","eban","ebek","ebi","eboni","ebonit","ebro","eburina","ecek","eceng","ecer","eco","edafik","edafit","edafologi","edafon","edan","edar","edema","edentat","edisi","edit","editor","editorial","edukasi","edukatif","efedrina","efek","efektif","efektivitas","efektor","efelis","efendi","efisien","efisiensi","efloresensi","eforus","efusi","egah","egalisasi","egalitarian","egalitarianisme","egalitarisme","egaliter","egat","ego","egois","egoisme","egoistis","egol","egomania","egos","egosentris","egosentrisitas","egosentrisme","egrang","egresif","ehe","eidetik","eigendom","eikosan","einsteinium","eja","ejakulasi","ejan","ejawantah","ejek","ejektif","ejektor","ekabahasa","ekad","ekajati","ekakarsa","ekamatra","ekang","ekaristi","ekatantri","ekbalium","ekdemik","ekderon","ekdisis","ekeh","ekimosis","ekiofit","eklektik","eklektikus","eklektis","eklektisisme","eklektisme","eklips","ekliptika","ekliptis","eklosi","ekofisiologi","ekofraksia","ekofrasia","ekografi","ekogrup","ekoklimat","ekoklimatologi","ekokronologi","ekolabel","ekolalia","ekologi","ekologis","ekon","ekonom","ekonometri","ekonomi","ekonomis","ekopolitik","ekopraksia","ekor","ekornia","ekosfer","ekosistem","ekosistematika","ekospesies","ekostratigrafi","ekotipe","ekotipifikasi","ekoturisme","ekozona","ekrin","ekrinologi","eks","eksak","eksakta","eksaltasi","eksamen","eksaminasi","eksaminator","eksantem","eksantropus","eksarasi","eksegesis","ekseget","eksekusi","eksekutif","eksekutor","eksem","eksemplar","eksenterasi","eksentrik","eksepsi","ekseptor","ekses","eksesif","eksfoliasi","ekshalasi","ekshibisi","ekshibisionis","ekshibisionisme","ekshibitum","eksikator","eksin","eksipien","eksisi","eksistensi","eksistensialis","eksistensialisme","eksit","eksitasi","eksitus","ekskavasi","ekskavator","eksklave","eksklusif","eksklusivisme","ekskomunikasi","ekskresi","ekskreta","ekskursi","ekskursif","eksobiologi","eksobiotik","eksodermis","eksodos","eksodus","eksoenzim","eksoergik","eksofasia","eksofora","eksoftalmia","eksoftalmos","eksoftalmus","eksogam","eksogami","eksogen","eksogin","eksoisogami","eksordium","eksorsis","eksosfer","eksospora","eksostosis","eksoterik","eksotermik","eksotik","eksotis","eksotisme","ekspansi","ekspansif","ekspansionis","ekspansionisme","ekspansionistis","ekspatriasi","ekspatriat","ekspedisi","ekspeditor","ekspektoran","eksper","eksperimen","eksperimental","ekspirasi","eksplan","eksplikasi","eksplisit","eksploit","eksploitasi","eksploitir","eksplorasi","eksploratif","eksplorator","eksplosi","eksplosif","ekspo","eksponen","eksponensial","ekspor","eksportir","ekspos","ekspose","eksposisi","ekspres","ekspresi","ekspresif","ekspresionisme","ekspresionistik","ekspresivitas","ekstase","ekstasi","ekstensi","ekstensif","ekstensifikasi","ekstensor","eksterior","eksteriorisasi","eksteritorialitas","ekstern","eksternal","ekstin","ekstra","ekstradisi","ekstrak","ekstrakardial","ekstraksi","ekstraktif","ekstrakurikuler","ekstralinguistis","ekstramarital","ekstranei","ekstraparlementer","ekstrapolasi","ekstraseluler","ekstraterestrial","ekstrateritorialitas","ekstrauterin","ekstraversi","ekstrem","ekstremis","ekstremitas","ekstrinsik","ekstrospeksi","ekstrover","ekstrusi","eksudasi","eksudat","ektoblas","ektoderm","ektohormon","ektoparasit","ektoplasma","ektoterm","ektotermik","ekualitas","ekuatif","ekuator","ekuilibrium","ekuinoks","ekuitas","ekuiti","ekuivalen","ekuivalensi","ekuivokasi","ekumene","ekumenis","ekumenisme","ela","elaborasi","elak","elan","elang","elastik","elastin","elastis","elastisitas","elastomer","elatif","elefantiasis","elegan","elegansi","elegi","elektif","elektorat","elektret","elektrifikasi","elektrik","elektris","elektro","elektrode","elektrodinamika","elektroensefalogram","elektroforesis","elektrokardiogram","elektrokimia","elektrokoagulasi","elektrokusi","elektrolisi","elektrolisis","elektrolit","elektromagnet","elektromagnetik","elektromagnetisme","elektrometalurgi","elektromiografi","elektromotif","elektron","elektronegatif","elektronik","elektronika","elektronis","elektropatologi","elektropositif","elektroskop","elektrostatika","elektroteknik","elektroterapeutika","elektroterapi","elektrotipe","elektrum","elemen","elementer","elemi","eleng","elevasi","elevator","eliksir","eliminasi","eliminir","eling","elips","elipsis","elipsoid","elipsometer","elipsometri","eliptis","elite","elitis","elitron","elo","elok","elokuensi","elon","elongasi","elpiji","eltor","elu","eluat","eluen","elung","elus","elusi","elusian","elusif","elutriasi","eluvial","eluviasi","eluvium","email","emanasi","emang","emansipasi","emas","emaskulasi","emat","embacang","embah","embak","embal","embalase","embalau","emban","embar","embara","embarau","embargo","embarkasi","embaru","embat","embek","embel","ember","embih","embik","emblem","embok","embol","emboli","embolisme","embolus","embosur","embrat","embrio","embriogenesis","embriologi","embrionik","embuai","embuh","embun","embung","embus","embut","emendasi","emeraldin","emeritus","emetik","emetina","emfisema","emigran","emigrasi","eminen","eminensi","emir","emirat","emis","emisi","emisivitas","emitans","emiten","emoh","emol","emolumen","emong","emosi","emosional","emosionalisme","emotif","empal","empang","empap","empar","empas","empat","empati","empedal","empedu","empek","empela","empelas","empenak","empeng","emper","empet","empiema","empik","emping","empiri","empiris","empirisme","emplasemen","emplek","employe","empo","empoh","empok","emporium","empos","empot","emprak","empu","empuan","empuk","empul","empulur","empunya","emrat","emulasi","emulator","emulsi","emulsifikasi","emut","enak","enam","enamel","enap","enartrosis","enas","enau","encal","encang","enceh","encek","encel","encer","encik","encim","encit","encok","encot","endak","endal","endang","endap","endas","endasan","endemi","endemis","endilau","endoderm","endoderma","endodermis","endofit","endogami","endogen","endokardia","endokrin","endokrinologi","endolimfa","endometriosis","endometrium","endomiksis","endomiokarditis","endomisium","endon","endong","endoparasit","endoplasma","endorfin","endosemen","endosentris","endoskeleton","endoskop","endoskopi","endosmosis","endosperma","endotel","endoterm","endotermal","endotermis","endotoksin","endrin","enduk","endul","enduro","endus","endut","enek","eneng","energetik","energi","energik","enes","enfitotik","engah","engap-engap","engas","enggak","enggan","enggang","engget","enggil","enggok","engkah","engkak","engkang","engkau","engket-engket","engkoh","engkol","engkong","engku","engkuk","engsel","enigma","enjak","enjal","enjambemen","enjelai","enjin","enjut","enkapsulasi","enklave","enklitik","enkode","enkripsi","enkulturasi","enologi","enom","ensambel","ensefalitis","ensefalitogen","ensefalograf","ensefalografi","ensefalogram","ensefalomielitis","ensefalon","ensiform","ensiklik","ensiklopedia","ensiklopedis","ensopor","entah","entak","entalpi","entar","entas","ente","enten","enteng","entente","enteritis","enterograf","enterologi","enteron","enteropati","enterosel","enterostomi","enterotoksin","enterovirus","entit","entitas","entoderm","entogenus","entok","entomofili","entomolog","entomologi","entong","entot","entozoa","entozoik","entre","entrepot","entri","entropi","enukleasi","enumerasi","enuresis","envoi","enyah","enyak","enzim","enzimolisis","enzimologi","enzootik","eolit","eon","eosen","eosin","eozoikum","epak","epek","epentesis","epibentos","epidemi","epidemiologi","epidermis","epidiaskop","epifaring","epifil","epifiotik","epifisis","epifit","epifiton","epifora","epigastrium","epigenesis","epiglotis","epigon","epigraf","epigrafi","epigram","epik","epikotil","epikuris","epilepsi","epileptik","epilog","epimisium","epinasti","epinefrina","epinurim","episentrum","episiklik","episiotomi","episkopal","episkopat","episode","episodik","epispora","epistaksis","epistel","epistemologi","epistola","epitaf","epitaksi","epitel","epitelioma","epitermal","epitet","epizoik","epizootik","epok","epoksi","epolet","eponim","epos","epsilon","era","eradikasi","eradiksi","erak","eram","erang","erat","erata","erbis","erbium","ercis","ereh","erek-erek","ereksi","erektor","ereng","erepsin","eret","erg","ergasiofit","ergonomi","ergonomika","ergonomis","ergosterol","ergot","ergoterapi","erik","ering","erisipelas","eritema","eritroblas","eritrosit","erong","eror","erosentrisme","erosi","erot","erotik","erotika","erotis","erotisisme","erotisme","erpah","erpak","erti","eru","erupsi","es","esa","esai","esais","esak","esek","eselon","esembling","esens","esensi","esensial","esensialitas","eskader","eskadron","eskalasi","eskalator","eskapisme","eskas","eskatologi","eskatologis","esofagus","esok","esot","esoteris","estafet","ester","estesia","estetik","estetika","estetikus","estetis","estimasi","estriol","estrogen","estron","estrus","estuari","estuarin","eta","etalase","etana","etanol","etape","etatisme","etek","eter","eteris","eternit","etik","etika","etiket","etil","etilena","etimologi","etimologis","etimon","etiolin","etiologi","etis","etmoid","etnik","etnis","etnobotani","etnograf","etnografi","etnografis","etnolinguistik","etnolog","etnologi","etnologis","etnomusikolog","etnomusikologi","etnopolitik","etnosentrisme","etologi","etos","etsa","eudaemonisme","eufemisme","eufemistis","eufoni","eufonium","euforia","euforian","eugenetika","eugenika","eugenol","eukaliptol","eukaliptus","eukarion","eukariota","eulogi","euploid","eurasia","eurihalin","europium","eurosentris","euseksual","eusinantropus","eutanasia","eutektik","eutenika","eutrofikasi","evakuasi","evaluasi","evaluatif","evangeli","evangelis","evaporasi","evaporator","evaporimeter","evapotranspirasi","eversi","eviden","eviserasi","evokasi","evokatif","evolusi","evolusioner","evolusionisme","ewa","eyang","eyel","faal","faali","fabel","fabula","faden","fadihat","fadil","fadilat","faedah","fafa","fagosit","fagositosis","fagot","fahombe","fahrenheit","fahsya","fail","fajar","fakih","fakir","faks","faksi","faksimile","fakta","faktif","faktitius","faktor","faktual","faktur","fakultas","fakultatif","falah","falaj","falak","falakiah","falsafah","falsafi","fam","famili","familia","familier","familiisme","familisme","fana","fanatik","fanatisme","fanfare","fani","fantasi","fantastis","fantom","farad","faraid","faraj","farak","fardu","farik","faring","faringal","faringalisasi","faringitis","farisi","farji","farmakodinamika","farmakokinetika","farmakolog","farmakologi","farmakologis","farmakope","farmakoseutika","farmasi","farsakh","fasad","fasakh","fase","faset","fasia","fasid","fasih","fasihat","fasik","fasilitas","fasilitator","fasis","fasisme","fastabikhulkhairat","fatah","fatal","fatala","fatalis","fatalisme","fatalitas","fatamorgana","fatanah","fatihah","fatimah","fatir","fatom","fatometer","fatri","fatsun","fatur","fatwa","fauna","faunistik","favorit","favoritisme","febrin","februari","federal","federalis","federalisme","federalistis","federasi","feko","fekundasi","fekunditas","felon","felspar","feminin","feminisme","fenakit","fengsui","fenit","fenol","fenologi","fenomena","fenomenal","fenomenalisme","fenomenologi","fenosis","fenotipe","feodal","feodalisme","feodalistis","feral","feri","feritin","fermen","fermentasi","fermion","fermium","feromagnetik","feromagnetisme","feromon","feronikel","fertil","fertilasi","fertilisasi","fertilitas","fertilizin","ferum","feses","festival","fetis","fetor","fetus","fiasko","fiat","fiber","fibrasi","fibriblas","fibril","fibrilasi","fibrin","fibrinogen","fibrokistik","fidah","fider","fidiah","fidusia","fidyah","figur","figuran","figuratif","fiil","fikih","fikli","fikologi","fikrah","fiksasi","fiksi","fiktif","fikus","filamen","filantrop","filantropi","filantropis","filaria","filariasis","filateli","filatelik","filatelis","filharmoni","filial","filibuster","film","filmis","filo","filodendron","filogenesis","filogeni","filolog","filologi","filologis","filopur","filosof","filosofi","filosofis","filsafat","filsuf","filter","filtrasi","filtrat","filum","fimbria","final","finansial","finir","finis","fiolaks","firajullah","firasat","firauniah","firdaus","firdausi","firjatullah","firkah","firma","firman","firn","fisi","fisibel","fisibilitas","fisik","fisika","fisiognomi","fisiognomis","fisiologi","fisiologis","fisioterapi","fisis","fiskal","fit","fiting","fitnah","fitofag","fitofogus","fitogeni","fitogeografi","fitokimia","fitologi","fitometer","fiton","fitopatologi","fitosanitasi","fitososiologi","fitosterol","fitostrot","fitotoksin","fitotoksoid","fitotopografi","fitotron","fitrah","fitri","flakon","flamboyan","flamingo","flanel","flat","flegma","flegmatis","fleksi","fleksibel","fleksibilitas","fleksor","flensa","flip-plop","flis","floem","flop","flora","floret","flotasi","flotet","flu","fluensi","fluida","fluks","fluktuasi","fluktuatif","fluor","fluoresen","fluoresens","fluorin","fluorit","fobia","fokimeter","fokstrot","fokus","folder","foli","folikel","folio","folklor","folksong","fon","fonasi","fondamen","fondasi","fonds","fonem","fonemik","fonemis","fonetik","fonetis","fonik","fonis","fonograf","fonografi","fonologi","fonologis","fonon","fonotaktik","fonotipi","foramen","foraminifera","forensik","forklif","forma","formal","formalin","formalistis","formalitas","forman","formasi","format","formatif","formatir","formatur","formika","formula","formulasi","formulator","formulir","fornifikasi","fornikasi","forsep","forsir","forsit","forte","fortifikasi","fortin","forum","fosfat","fosfina","fosfit","fosfor","fosforesens","fosforilase","fosforus","fosgen","fosil","foto","fotodiode","fotoelektron","fotoemisi","fotogenik","fotograf","fotografer","fotografi","fotografis","fotograver","fotogravur","fotokimia","fotokonduksi","fotokonduktivitas","fotokonduktor","fotokopi","fotokromi","fotokromik","fotolisis","fotolitografi","fotometer","fotometri","fotomikrografi","fotomodel","foton","fotoperiodisme","fotosel","fotosfer","fotosintesis","fotostat","fototaksis","fototropis","fototustel","fovea","foya","fragmen","fragmentaris","fragmentasi","fraksi","fraksinasi","fraktur","fraktus","frambusia","fransium","frasa","frase","fraseologi","frater","fraternitas","freatofit","fregat","frekuen","frekuensi","frekuentatif","frenologi","freon","frib","frigid","frigorigraf","frigorimeter","frikatif","friksi","fron","front","frontal","fruktosa","frustrasi","fuad","fugasitas","fujur","fukaha","fukara","fuksina","fulgurit","fuli","fulminat","fulus","fumarol","fumigan","fumigasi","fumigator","fundamen","fundamental","fundamentalis","fundamentalisme","fundamentalistis","fungi","fungibel","fungisida","fungistatik","fungoid","fungsi","fungsional","fungsionalisasi","fungsionalisme","fungsionalitas","fungsionaris","fungus","furfural","furkan","furnitur","furqan","furuk","fusi","fusta","fusuk","futual","futur","futurisme","futuristik","futuristis","futurolog","futurologi","futurologis","fyord","gaba-gaba","gabah","gabai","gabak","gabardin","gabas","gabir","gableg","gablek","gabor","gabro","gabruk","gabuk","gabung","gabus","gaco","gacok","gacong","gada","gadai","gadamala","gadang","gading","gadis","gado","gadolinit","gadolinium","gadon","gaduh","gaduk","gadung","gadungan","gaek","gaet","gafar","gaflah","gaflat","gaftar","gafur","gaga","gagah","gagai","gagak","gagal","gagang","gagap","gagas","gagau","gagu","gaguk","gah","gaham","gahar","gahara","gahari","gaharu","gai","gaib","gail","gain","gaing","gairah","gait","gajah","gajak","gaji","gajih","gajul","gajus","gakang","gakari","gala","galaba","galaganjur","galagasi","galah","galai","galak","galaksi","galaktometer","galaktorea","galaktosa","galaktosemia","galaktosuria","galan","galang","galanggasi","galar","galas","galat","galau","galbani","galeng","galeri","galgal","gali","galias","galib","galibut","galih","galiot","galir","galium","galiung","galon","galu-galu","galuh","galung","galungan","galur","galvanis","galvanisasi","galvanometer","galvanometri","galvanoskop","galyas","gam","gama","gamak","gamal","gamalisasi","gamam","gaman","gamang","gamat","gambang","gambar","gambas","gambir","gamblang","gambling","gambuh","gambus","gambut","gambyong","gamelan","gamet","gametangium","gametofit","gametogenesis","gametosit","gamik","gamis","gamit","gamma","gamopetal","gamosepal","gampang","gampar","gamparan","gamping","gamuh","gana","gana-gini","ganal","ganang","ganar","ganas","gancang","gancar","ganco","gancu","ganda","gandal","gandapura","gandar","gandaria","gandarukem","gandarusa","gandarwa","gandasturi","gandasuli","gandek","gandem","ganden","gandeng","gandes","gandewa","gandi","gandik","gandin","ganding","gandok","gandola","gandos","gandringan","gandrung","gandu","ganduh","gandul","gandum","gandung","gang","ganggam","ganggang","ganggu","ganggut","ganglion","gangsa","gangsal","gangsar","gangsi","gangsir","gangster","gani","ganih","ganimah","ganja","ganjak","ganjal","ganjar","ganjat","ganjen","ganjil","ganjing","ganjling","ganjur","ganoid","gantal","gantang","gantar","gantel","ganteng","ganti","gantih","gantilan","ganting","gantol","gantole","gantung","ganyah","ganyang","ganyar","ganyong","ganyut","gaok","gap","gapah","gapah-gopoh","gapai","gapil","gapit","gaple","gaplek","gaplok","gapuk","gapura","gar","gara-gara","garah","garai","garam","garan","garang","garangan","garansi","garap","garasi","garau","garba","garbarata","garbis","garda","gardan","gardu","garebek","gari","garib","garindin","garing","garis","garit","garizah","garmen","garnet","garnis","garnisun","garong","garpu","garu","garuda","garuk","garung","garut","garwa","gas","gasab","gasak","gasal","gasang","gasatrin","gasifikasi","gasing","gasket","gasolin","gasometer","gaster","gastrektomi","gastrin","gastritis","gastroenteritis","gastroenterolog","gastroenterologi","gastrointestinal","gastronomi","gastrula","gastrulasi","gatal","gatot","gatra","gatrik","gatuk","gauk","gaukang","gaul","gaun","gaung","gaut","gawai","gawal","gawan","gawang","gawar","gawat","gawir","gaya","gayal","gayam","gayang","gayat","gayau","gayem","gayeng","gayuh","gayuk","gayun","gayung","gayut","gaz","gazal","gebah","gebang","gebar","gebeng","geber","geblak","geblek","geblok","gebogan","gebok","gebos","gebot","gebrak","gebu","gebuk","gebung","gebyah-uyah","gebyar","gebyur","gecar","gecek","gecer","gecul","gedabah","gedana-gedini","gedang","gede","gedebak-gedebuk","gedebar-gedebur","gedebeg","gedebok","gedebuk","gedebung","gedek","gedembai","gedembal","gedempol","gedeng","gedi","gedik","gedok","gedombak","gedombrongan","gedong","gedor","gedubang","gedung","geduyut","gegabah","gegadan","gegai","gegak","gegala","gegaman","gegana","gegaokan","gegap","gegar","gegares","gegas","gegat","gegau","gegep","geger","gegetar","gegetun","gegisik","gegua","geiger","geiser","gejah","gejala","gejolak","gejos","gejuju","gel","gela","gelabah","gelabir","gelabur","geladak","geladeri","geladi","geladir","geladrah","gelagah","gelagap","gelagar","gelagat","gelak","gelakak","gelalar","gelam","gelama","gelamai","gelambir","gelandang","gelandot","gelang","gelanggang","gelangsar","gelantang","gelanting","gelantung","gelap","gelapung","gelar","gelas","gelasak","gelasir","gelatak","gelatik","gelatin","gelatuk","gelayangan","gelayar","gelayut","gelebah","gelebap","gelebar","geleber","gelebuk","geleca","gelecik","geledah","geledang","geledek","geleding","geledur","gelegah","gelegak","gelegar","gelegata","gelek","gelekak","gelekek","gelema","gelemat","gelemberan","gelembong","gelembung","gelembur","gelempang","gelemprang","gelenang","gelendo","gelendong","gelendot","geleng","gelenggang","gelentang","gelenting","gelenyar","gelepai","gelepar","gelepek","gelepot","gelepung","gelepur","geler","gelesek","geleser","gelesot","geleta","geletak","geletar","geletek","geletik","geleting","geletis","geletuk","geli","geliang","geliat","gelibir","gelicik","geliga","geligi","geligin","geligis","geligit","gelignit","gelimang","gelimantang","gelimbir","gelimir","gelimpang","gelimun","gelincir","gelincuh","gelinding","gelinggam","gelinggaman","gelinggang","gelingsir","gelinjang","gelintang","gelintar","gelintin","gelinting","gelintir","gelipar","gelisah","gelita","gelitar","gelitik","gelo","gelobak","gelobok","gelocak","gelodar","gelodok","gelogok","gelohok","gelojoh","gelomang","gelombang","gelompar","gelondong","geloneng","gelonggong","gelongsor","gelontor","gelopak","gelora","gelosang","geloso","gelosok","gelotak","geluduk","geluga","gelugu","gelugur","gelugut","geluh","geluk","gelulur","gelumang","gelumat","geluncur","gelundung","gelung","gelup","gelupur","gelut","gema","gemah","gemak","gemal","geman","gemang","gemap","gemar","gemas","gemaung","gemawan","gembak","gembala","gembar-gembor","gembel","gembeng","gembil","gembili","gembira","gemblak","gembleng","gemblong","gemblung","gembok","gembol","gembolo","gembong","gembor","gembos","gembreng","gembrot","gembul","gembung","gembur","gembus","gembut","gemebyar","gemelentam","gemeletak","gemeletap","gemeletek","gemeletuk","gemelugut","gementam","gementar","gemercak","gemercik","gemerencang","gemerencik","gemerencing","gemerencung","gemeresak","gemeresik","gemeretak","gemeretuk","gemeretup","gemerlap","gemertak","gemertuk","gemerusuk","gemetar","gemi","gemik","gemilang","gemilap","geming","gemini","gemintang","geminte","gemirang","gempa","gempal","gempar","gempil","gempita","gempol","gempor","gempul-gempul","gempur","gemrobyos","gemuk","gemul","gemulai","gemulung","gemuntur","gemuruh","gen","gena","genah","genahar","genang","genap","gencar","gencat","gencel","gencer","gencet","gencir","gendak","gendala","gendam","gendang","gendar","gendarmeri","gendeng","gender","genderang","genderuwo","gendewa","gending","gendis","gendon","gendong","genduk","gendut","genealogi","genealogis","genegin","geneng","generalis","generalisasi","generalisimo","generasi","generatif","generator","generik","genesis","genetika","genetis","geng","genggam","genggang","genggong","gengsah","gengsi","gengsot","genial","genialitas","genikulum","genis","genit","genital","genitalia","genitif","genius","genjah","genjang","genjang-genjot","genjer","genjik","genjot","genjrang","genjring","genjur","genom","genosida","genotipe","genre","genta","gentala","gentar","gentas","gentat","gentayang","gentel","genteng","gentian","genting","gentong","gentrifikasi","gentur","gentus","genus","genyot","geobotani","geodesi","geofisika","geofisis","geofon","geognosi","geografi","geografis","geohidrologi","geokimia","geokronologi","geolog","geologi","geologis","geomansi","geometri","geometris","geomorfologi","geonomi","geopolitik","geosentris","geosinkronis","geostasioner","geostatika","geoteknik","geoteknologi","geotermal","geotermi","geotermometer","gepeng","gepit","geplak","gepok","geprak","gepuk","gera","gerabah","gerabak","gerabang","geradi","geragai","geragap","geragas","geragau","geragih","geragot","geraguk","gerah","geraham","gerai","gerak","geram","geraman","geramang","geramsut","geramus","gerang","gerangan","geranggang","geranium","gerantak","gerantang","geranyam","gerapai","gerapu","gerat","geratak","geratih","gerau","gerawan","gerawat","gerayah","gerayang","gerbak","gerbang","gerbas-gerbus","gerbera","gerbong","gerbus","gerda","gerdam","gerdan","gerdum","gerebek","gerecak","gerecok","gereget","gereh","gereja","gerejani","gerejawi","gerek","geremet","gerempang","gerencang","gerendel","gerendeng","gerenek","gereneng","gereng-gereng","gerengseng","gerenik","gerenjeng","gerenjet","gerentang","gerenyau","gerenyeng","gerenyet","gerenying","gerenyit","gerenyot","gerepe","gerepek","gerepes","geresek","geret","geretak","geretang","gergaji","gergajul","gergasi","gergeran","gerha","gerhana","geriak","geriak-geriuk","geriap","geriatrik","geribik","gericau","geridip","geridit","geriditpidit","gerigi","gerigik","gerigis","gerih","gerik","gerilya","gerim","gerimis","gerincing","gerinda","gerindin","gerinding","gering","geringging","geringgingan","geringsing","gerinjal","gerinjam","gerinting","gerinyau","gerip","geripir","geripis","gerisik","gerising","gerit","geriuk","gerlap","gerlip","germang","germanium","germinal","germisida","germo","germut","gero","geroak","gerobak","gerobok","gerobyak","gerocok","gerodak","gerogol","gerogot","gerohok","gerohong","gerojok","gerombol","gerombong","gerompok","gerong","geronggang","geronium","gerontokrasi","gerontol","gerontologi","geronyot","geropes","geropyok","geros","gerosak","gerot-gerot","gerowong","gerowot","gerpol","gersak","gersang","gersik","gertak","gertik","gertuk","geru","gerugut","geruh","geruit","gerumit","gerumpung","gerumuk","gerumut","gerun","gerundang","gerundel","gerung","gerunggung","gerunyam","gerup","gerupis","gerupuk","gerus","gerut","gerutu","gerutup","gerutus","gesa","gesek","gesel","geser","gesit","gesper","gestikulasi","geta","getah","getak-getuk","getang","getap","getar","getas","getek","getem-getem","geti-geti","getik","getil","getir","getis","getok","getol","getu","getuk","getun","geulis","gewang","gial","giam","giat","gibah","gibang","gibas","giblet","gibtah","gidik","gigahertz","gigantisme","gigi","gigih","gigil","gigir","gigis","gigit","gigolo","gila","gilang","gilap","gilas","gilbet","gili","gilik","giling","gilir","gim","gimbal","gimnasium","gimnastik","gimpal","gin","ginang","gincu","ginding","ginekolog","ginekologi","ginekomasti","ginesium","gingivitis","ginglimus","gingsir","gingsul","ginjal","ginjean","ginkang","ginogenesis","ginseng","gips","gipsi","gir","girah","giral","girang","girap-girap","giras","girasol","giri","girik","girikan","giring","giris","giro","giroskop","girostat","girostatika","gisar","gisik","gisil","gita","gitapati","gitar","gitaris","gites","gitik","gitok","giuk","giur","giwang","gizi","glabela","gladiator","gladiol","glamor","glandula","glans","glasial","glasir","glasnos","glaukoma","glegek","glenik","glenoid","gletser","glidik","glikogen","glikogenesis","glikogenolisis","glikol","glikolisis","glikosid","glikosida","glikosidasa","glikosidase","glikosuria","gliserida","gliserol","global","globalisasi","globalisme","globe","globulin","globus","glokidium","glomerulus","glomus","glosarium","glosem","glosematik","glositas","glositis","glotal","glotalisasi","glotis","glukagon","glukosa","glukosan","glukosida","gluten","gnomon","goak","gob","goba","gobak","gobang","gobar","gobek","gobet","goblok","gocap","gocek","gocoh","goda","godak","godam","godek","godok","godong","godot","goel","gogoh","gogok","gogos","gogrok","gohok","gohong","gojek","gojlok","gokar","gol","golak","golak-galik","golbi","golek","goleng","goler","golf","golok","golong","golput","gom","gombak","gombal","gombang","gombeng","gombrang","gombroh","gombyok","gompal","gompiok","gonad","gondang","gondas-gandes","gondok","gondol","gondola","gondong","gondorukem","gondrong","gong","gonggo","gonggok","gonggong","gongli","gongseng","gongyo","goni","gonidium","goniometri","gonjak","gonjang","gonjang-ganjing","gonjing","gonjlang","gonjlang-ganjling","gonjok","gonjong","gonokokus","gonore","gonrang","gontaganti","gontai","gontok","gonyak","gonyeh","gonyel","gonyoh","gopek","gopoh","gorap","gorden","gorek","goreng","gores","gori","gorila","gorilya","goroh","gorok","gorong-gorong","gosan","gosip","gosok","gosong","gospel","got","gotes","gotik","gotong","gotri","gotrok","gotun","gowok","goyah","goyak","goyang","grabadan","grad","gradasi","gradien","gradual","gradualisme","graf","grafem","grafemik","grafemis","grafetik","grafik","grafika","grafis","grafit","grafitasi","grafolog","grafologi","graha","grahita","gram","gramatika","gramatikal","grambyang","gramofon","granat","granit","granolitik","granula","granulasi","granulosit","grapyak","grasi","gratak","gratifikasi","gratis","gravel","graver","gravimeter","gravitas","gravitasi","grecok","gregarius","grehon","grempel","gres","gresek-gresek","gria","grip","griya","grogi","gronjong","gros","grosir","grup","gruwung","gua","gual","guam","guanidina","guanin","guanina","guano","guar","gubah","gubal","gubang","gubel","gubernemen","gubernur","gubit","gubris","gubuk","guci","gudam","gudang","gudangan","gude","gudeg","guderi","gudi","gudik","gudu-gudu","gue","gugah","gugat","gugu","guguh","guguk","gugup","gugur","gugus","guit","gujirak","gujirat","gukakas","gul","gula","gulah","gulai","gulali","gulam","gulambai","gulana","gulang-gulang","gulat","guli","guliga","guling","gulir","gulita","gulma","gulud","gulung","gulut","gum","guma","gumal","gumam","gumba","gumbaan","gumbang","gumbar","gumboro","gumbuk","gumebruk","gumelaran","gumpal","gumpil","gumuk","gumul","gumun","gun","guna","gunawan","guncang","gunci","gundah","gundal","gundala","gundang","gundar","gundi","gundik","gundu","gunduk","gundul","gung","gunggung","gunjai","gunjing","gunolugu","gunrit","gunseikan","guntai","guntak","guntang","guntil","gunting","guntung","guntur","gunung","gunyam","gup","gurab","gurah","guram","gurami","gurat","gurau","gurdan","gurdi","guri","gurih","gurik","gurindam","guring","gurit","gurita","gurnadur","guru","gurub","guruh","guruk","gurun","gurung","gurur","gus","gusah","gusar","gusel","gusi","gusrek","gusti","gusul","gusur","gutasi","gutik","gutuk","guyon","guyub","guyur","habenula","habib","habibi","habibulah","habibullah","habis","habitat","habituasi","habitus","habluk","hablun","hablur","habsyi","habuan","habuk","habung","had","hadanah","hadap","hadas","hadat","hadiah","hadir","hadirat","hadirin","hadis","hadron","hafal","hafiz","hafnium","hagiografi","hahnium","hai","haid","haik","haiking","haiku","hail","hailai","haj","hajah","hajar","hajat","haji","hajib","hajim","hajis","hak","hakaik","hakam","hakikat","hakiki","hakim","hakimah","hakul","hakulah","hakulyakin","hal","hala","halai-balai","halaik","halakah","halal","halalbihalal","halaman","halang","halau","halazon","halba","haleluya","halia","halilintar","halim","halimbubu","halimun","halimunan","halipan","halitosis","halkah","halma","halo","halobion","halofili","halofit","halofita","halofob","halogen","halogenasi","halotan","halsduk","halte","halter","haluan","halus","halusinasi","halusinogen","halwa","ham","hama","hamal","hamatum","hamba","hambali","hambar","hambat","hambur","hamburger","hamdalah","hamdu","hamik","hamil","haminte","hampa","hampang","hampar","hampir","hamud","hamulus","hamun","hamzah","hana","hanacaraka","hanafi","hancing","hancur","handai","handam","handaruan","handasah","handelar","handuk","hang","hangar","hangat","hanger","hanggar","hangit","hangus","hanif","hanjuang","hansop","hantai","hantam","hantap","hantar","hantir","hantu","hanya","hanyut","hap","hapetan","haplografi","haploid","haplologi","hapus","hara","harak","harakah","harakat","harakiri","haram","harap","harawan","harbi","hardik","harem","harendong","harfiah","harga","hari","haribaan","harimau","haring","harini","haris","harisah","harit","harkat","harmoni","harmonik","harmonika","harmonis","harmonisasi","harmonium","harnet","harpa","harpis","harpun","hart","harta","hartal","haru","haruan","harum","harungguan","harus","has","hasab","hasad","hasai","hasan","hasar","hasib","hasid","hasil","hasrat","hasta","hasta-wara","hasud","hasut","hasyiah","hasyis","hati","hatif","hatta","hatur","haud","haudah","haukalah","haul","haur","hauri","haus","haustorium","haver","hawa","hawar","hawari","hawiah","hayat","hayati","hayo","heban","hebat","heboh","hebras","hebring","hedonis","hedonisme","hegelianisme","hegemoni","hegemonik","hegemonisme","hegemonnisme","heiho","heksadesimal","heksagon","heksahedron","heksaklorida","heksameter","heksana","heksapoda","hektar","hektare","hektograf","hektogram","hektoliter","hektometer","hela","helah","helai","helat","helicak","helikopter","heling","heliofit","heliofobi","heliograf","heliogram","heliometer","heliosentrik","helioskop","heliotaksis","helioterapi","heliotrop","heliotropisme","helipad","helium","helm","helmintologi","hem","hemat","hematit","hematite","hematofobia","hematologi","hematom","hematometra","hematuri","hembak","hembalang","hembus","hemeralopi","hemikordat","hemiplegia","hemisfer","hemodialisis","hemofilia","hemoglobin","hemolisis","hemopoiesis","hemopteran","hemoragi","hemoroid","hemosit","hemositometer","hemostasis","hemostatik","hempap","hempas","hendak","hendam","hendel","heng","hengit","hengkang","hening","henoteisme","henry","hentar","henti","henyak","hepar","hepatitis","heptagon","heptahedron","heptameter","heptana","heraldik","heran","herba","herbarium","herbisida","herbivor","herbivora","herder","hereditas","herediter","heregistrasi","heresi","hering","hermafrodit","hermafroditisme","hermetis","hernia","hero","heroik","heroin","heroisme","herpes","herpetolog","herpetologi","hertz","hesperidin","heterodin","heterodoks","heterofemi","heterofil","heterofit","heterogamet","heterogami","heterogen","heterogenitas","heterograf","heterografi","heteroklitus","heteronim","heteronimi","heteronomi","heteroseksual","heteroseksualitas","heterosfer","heterosiklis","heterosis","heterospora","heterostili","heterotrof","heterozigot","heuristis","hewan","hewani","hia","hialin","hialit","hias","hiatus","hibah","hibal","hibat","hibernasi","hibiskus","hibob","hibrida","hibridis","hibridisasi","hibuk","hibur","hidang","hidatod","hidayah","hidayat","hidrasi","hidrat","hidraulik","hidraulika","hidraulis","hidrida","hidrodinamika","hidrofili","hidrofit","hidrofobia","hidrofoil","hidrofon","hidrogen","hidrogenasi","hidrogeologi","hidrograf","hidrografi","hidrogram","hidrokarbon","hidroklorida","hidrokori","hidroksida","hidroksil","hidrolika","hidrolisis","hidrologi","hidrometeorologi","hidrometer","hidrometri","hidromini","hidronan","hidropati","hidroperoksida","hidroponik","hidropsoma","hidrosfer","hidrosiklon","hidroskop","hidrostatika","hidrostatis","hidroterapi","hidrotermal","hidu","hidung","hidup","hiena","hierarki","hierarkis","hieroglif","hifa","higiene","higienis","higrograf","higrogram","higrometer","higrometri","higroskop","higroskopis","higrotermograf","higrotermogram","hijab","hijaiah","hijau","hijrah","hijriah","hikayat","hikmah","hikmat","hilal","hilang","hilap","hilau","hilir","hilofagus","himanga","himar","himen","himenium","himne","himpun","hina","hinap","hinayana","hindar","hindi","hindu","hinduisme","hingga","hinggap","hinggut","hio","hiosiamina","hiosin","hip","hipantium","hiperaktif","hiperamnesi","hiperbarik","hiperbol","hiperbolis","hiperemia","hiperestesia","hipergami","hiperkelas","hiperkinesis","hiperklas","hiperkorek","hiperkritis","hiperlipemia","hipermetropia","hiperon","hiperopia","hiperparasit","hiperplasia","hiperseks","hiperseksual","hipersensitif","hipersonik","hipersonika","hipertensi","hipertonik","hipertradisional","hipertrikosis","hipertrofi","hipervitaminosis","hipnosis","hipnoterapi","hipnotis","hipnotisme","hipoblas","hipodermis","hipodermoklisis","hipodrom","hipofisis","hipofremia","hipogen","hipoglikemia","hipokondria","hipokotil","hipokrisi","hipokrit","hipokritis","hipolimnion","hipomastia","hipomnesia","hiponim","hipopituitarisme","hipoplankton","hipoplasia","hipopotamus","hiposentrum","hipotaksis","hipotek","hipotensi","hipotenusa","hipotermia","hipotesis","hipotetis","hipotiroid","hipotiroidisme","hipotonik","hipovitaminosis","hipsometer","hipui","hirap","hirau","hirsutisme","hiru-biru","hiru-hara","hirudin","hiruk","hirup","his","hisab","histamina","histerektomi","histeria","histeris","histerisis","histidina","histogeni","histokimia","histologi","histon","histopatologi","histori","historikus","historiografi","historis","historisisme","historisitas","hit","hitam","hitung","hiu","hiyayat","hobat","hobi","hobo","hodadoda","hodah","hodometer","hoi","hokah","hoki","hol","holi","holisme","holistis","holmium","holobentos","holoenzim","holofit","holofitik","holofrasis","hologamet","hologami","holograf","holografis","hologram","holokrim","holokrin","holoplankton","holosen","holozoik","homeostasis","homili","hominid","hominoid","homo","homofon","homofoni","homogami","homogen","homogeni","homogenitas","homograf","homografi","homogram","homoiotermal","homolog","homologi","homonim","homonimi","homorgan","homoseks","homoseksual","homoseksualisme","homoseksualitas","homosfer","homospora","homoterm","homozigot","honae","honcoe","honji","honor","honorarium","honorer","honorifik","hop","hopagen","hopbiro","hopkantor","hopyes","horak","horas","hore","horizon","horizontal","hormat","hormon","hornblenda","horor","horoskop","hortikultura","hortikulturis","hoskut","hospital","hostel","hostes","hosti","hot","hotel","howitzer","huakiau","hubar","hubaya-hubaya","hububan","hubulwatan","hubung","huda","hudai","hudhud","hudud","hufaz","huh","hujah","hujaj","hujan","hujat","huji","hujin","hujung","hukah","hukama","hukum","hula-hula","hulam","huler","hulu","hulubalang","hulul","hulur","huma","human","humaniora","humanis","humanisasi","humanisme","humanistis","humanitas","humaniter","humas","humbalang","humektan","humerus","humidifikasi","humiditas","humifikasi","humin","humor","humoris","humoristis","humorolog","humus","hun","huncue","huni","hunjam","hunjuk","hunkue","hunus","hura-hura","hurah","huria","huriah","hurikan","huru-hara","huruf","hus","husnulkhatimah","hut","hutan","hutang","huyung","ialah","iambus","iatrogenik","iba","ibadah","ibadat","ibadurahman","iban","ibar-ibar","ibarat","ibayuh","ibid","ibidem","ibing","iblis","ibni","ibnu","ibra","ibrit","ibtida","ibtidaiah","ibu","ibul","ibun","ibunda","ibung","ibus","icak-icak","ida","idafi","idah","idam","idap","idarah","idas","ide","ideal","idealis","idealisasi","idealisme","idealistis","idem","identifikasi","identik","identitas","ideofon","ideograf","ideografi","ideografis","ideogram","ideologi","ideologis","ideosinkretik","idep","idiil","idiolek","idiom","idiomatis","idiomatologi","idiosi","idiosinkrasi","idiosinkretik","idiot","idola","idrak","idu","iduladha","idulfitri","ifah","ifrit","iftar","iftitah","iga","igal","igau","iglo","ihdad","ihram","ihsan","ihsanat","ihsas","ihtifal","ihtikar","ihtilam","ihtimal","ihwal","ijab","ijabat","ijajil","ijarah","ijas","ijazah","ijbar","ijeman","ijil","ijmak","ijmal","ijon","ijtihad","ijtimaiah","ijtimak","ijuk","ikab","ikal","ikamah","ikan","ikat","ikebana","ikhbar","ikhlas","ikhtiar","ikhtiari","ikhtilaf","ikhtiogeografi","ikhtiosarkotoksisme","ikhtiotoksisme","ikhtisar","ikhwan","iklan","iklim","ikon","ikonis","ikonograf","ikonografi","ikonoklasme","ikonometer","ikrab","ikram","ikrar","iktibar","iktidal","iktikad","iktikaf","iktiografi","iktiolit","iktiologi","iktiologis","iktirad","iktiraf","iktisab","ikuh","ikut","ilafi","ilah","ilahi","ilahiah","ilahiat","ilai","ilak","ilam-ilam","ilanun","ilar","ilas","ilat","ilegal","iler","iles","ileum","ilham","ili","ilian","iling","ilmiah","ilmu","ilu","iluminasi","ilusi","ilusif","ilusionis","ilustrasi","ilustratif","ilustrator","imago","imaji","imajinasi","imajinatif","imajiner","imak","imam","imamah","imamologi","iman","imanen","imanensi","imani","imbak","imbal","imbang","imbas","imbau","imbesil","imbesilitas","imbibisi","imbit","imbuh","imigran","imigrasi","iming-iming","imitasi","imitatif","imitator","imkan","imla","imlek","imobilisasi","impak","impas","impase","impedans","impedansi","impek","imperatif","imperfek","imperfeksi","imperial","imperialis","imperialisme","imperium","impersonal","impersonalia","impersonalitas","impi","impit","implan","implantasi","implemen","implementasi","implikasi","implisit","implosif","implosit","impor","importasi","importir","impoten","impotensi","impregnasi","impresariat","impresario","impresi","impresif","impresionis","impresionisme","impresionistik","imprimatur","improvisasi","impuls","impulsif","imsak","imsakiah","imtihan","imun","imunisasi","imunitas","imunokimia","imunokompromi","imunologi","imunologis","imunosupresi","imunoterapi","ina","inadaptabilitas","inai","inang","inangda","inap","inartikulat","inas","inaugurasi","inayat","inca","incang-incut","incar","inci","incit","incling","incrit","incu","incut","indah","indang","indap","indarus","indayang","indebitum","indehoi","indekos","indeks","inden","independen","inderawasih","indeterminisme","indigenos","indigo","indik","indikan","indikasi","indikatif","indikator","inding","indisipliner","indium","individu","individual","individualis","individualisasi","individualisme","individualistis","individualitas","individuasi","indoktrinasi","indolen","indolensi","indologi","indonesia","indonesianisasi","indra","indraloka","indranila","indria","indriawi","indu","induk","induksi","induktans","induktansi","induktif","induktor","indung","indusemen","industri","inefisiensi","inersia","infak","infanteri","infantil","infantilisasi","infantilisme","infarktus","infeksi","inferensi","inferensial","inferior","inferioritas","inferno","infertil","infertilitas","infiks","infiltrasi","infiltrometer","infinitif","infiradi","inflamasi","inflasi","inflatoar","infleksi","infleksibel","infleksif","infloresen","infloresens","influensa","influenza","info","informal","informan","informasi","informatif","informatika","inframerah","infrasonik","infrastruktur","infus","inga","ingar","ingat","ingau","inggang-inggung","inggris","inggu","inggung","ingin","ingkah","ingkar","ingkir","ingresif","ingsar","ingsun","ingsut","ingus","inheren","inhibisi","inhibitor","ini","inisial","inisiasi","inisiatif","inisiator","injak","injap","injeksi","injil","injin","inkarnasi","inkarserasi","inkarsunah","inkaso","inklaring","inklinasi","inklinometer","inklusif","inkognito","inkompabilitas","inkompatibilitas","inkompeten","inkomplet","inkonfeso","inkonsisten","inkonsistensi","inkonstitusional","inkonvensional","inkorporasi","inkremental","inkubasi","inkubator","inkulturasi","inlander","inohong","inokulasi","inovasi","inovatif","inovator","insaf","insan","insanan","insang","insani","insanulkamil","insar","insek","insekta","insektari","insektisida","insektivor","insektivora","insektologi","inseminasi","insentif","insersi","inses","inset","insiden","insidental","insinerator","insinuasi","insinuatif","insinye","insinyur","inskripsi","inslan","insolven","insomnia","inspeksi","inspektorat","inspektur","inspirasi","instabilitas","instalasi","instalatur","instan","instansi","insting","instingtif","institusi","institusional","institut","instruksi","instruksional","instruktif","instruktur","instrumen","instrumental","instrumentalia","instrumentalis","instrumentasi","insubordinasi","insulator","insuler","insulin","insulinde","insya","intai","intan","integral","integralistik","integrasi","integrasionis","integritas","integumen","intel","intelek","intelektual","intelektualisasi","intelektualisme","inteligen","inteligensi","inteligensia","intelijen","intendans","intens","intensi","intensif","intensifikasi","intensional","intensitas","interaksi","interaksionistik","interaktif","interdepartemental","interdependen","interdiksi","interdisipliner","interegnum","interelasi","interen","interes","interesan","interetnik","interferens","interferensi","interferometer","interferon","interglasial","interim","interinsuler","interior","interjeksi","interkom","interkoneksi","interkonsonantal","interkontinental","interlokal","interlokutor","interlud","intermeso","intermezo","intermolekuler","intern","internal","internalisasi","internasional","internasionalisasi","internat","internir","internis","internuntius","interogasi","interogatif","interogator","interpelan","interpelasi","interpelator","interpiu","interpolasi","interpretasi","interpretatif","interpretator","interpreter","intersepsi","intertestial","intertidal","interupsi","interval","intervensi","intervensionisme","interviu","interzona","inti","intifadah","intiha","intikad","intim","intima","intimasi","intimidasi","intip","intipati","intisari","intoksikasi","intoleran","intonasi","intradermal","intrakalimat","intrakurikuler","intralinguistis","intramembran","intramolekul","intramuskuler","intransitif","intraseluler","intrauniversiter","intravaskuler","intravena","intrik","intrinsik","intro","introduksi","introjeksi","introspeksi","introver","intrusi","intuisi","intuitif","intumesensi","invaginasi","invalid","invasi","invensi","inventaris","inventarisasi","inventif","inventor","inventori","inventoriminat","inversi","invertebrata","investasi","investigasi","investigatif","investor","invitasi","invois","involusi","inyik","inzar","inziaj","iodin","ion","ionisasi","ionosfer","iota","ipar","ipis","ipon","iprit","ipuh","ipuk","ipung","iqamat","iqra","ira","iradat","iradiasi","irafah","irah-irahan","iram","irama","iras","irasional","irasionalitas","iri","iridium","irigasi","irigator","irik","iring","iris","irit","iritabilitas","iritasi","iritatif","ironi","ironis","irsyad","irung","irus","isa","isak","isalohipse","isap","isbat","iseng","isentropik","isi","isim","isis","isit","iskemia","islah","islam","islami","islamiah","islamis","islamisasi","islamisme","islamologi","isoaglutinin","isobar","isobarik","isobat","isobron","isodin","isodinamik","isofase","isofen","isofet","isoflor","isofon","isogamet","isogami","isoglos","isogon","isogram","isohalin","isohel","isohiet","isohips","isokal","isokalori","isokemi","isokeraunik","isokor","isokorik","isokronisme","isolasi","isolasionisme","isolatif","isolator","isoleks","isolemen","isolir","isomer","isometrik","isomorf","isomorfis","isomorfisme","isonefel","isonomi","isopal","isopiestik","isoplet","isoriza","isosilabisme","isotah","isoterm","isotermal","isotop","isotrop","isotropik","isovolumik","isra","israf","istal","istan","istana","istanggi","istaz","istazah","istiadat","istianah","istiazah","istibdad","istibra","istidlal","istidraj","istifham","istigasah","istigfar","istihadah","istihsan","istikamah","istikharah","istikhlaf","istiklal","istikmal","istilah","istima","istimaiah","istimewa","istimna","istimtak","istinggar","istinja","istiqlal","istirahat","istislah","istislam","istisna","istitaah","istiwa","istri","isu","isya","isyarat","isytiak","isyu","italik","item","iterasi","iterbium","itibak","itibar","itidal","itifak","itihad","itik","itikad","itikaf","itil","itisal","itlak","itrium","itu","iudisasi","iur","iwad","iya","izah","izin","jaat","jab","jabal","jabang","jabar","jabariah","jabat","jabir","jables","jabrik","jabung","jadah","jadam","jadayat","jadi","jaduk","jadwal","jaga","jagabaya","jagabela","jagal","jagang","jagapati","jagaraga","jagat","jagawana","jago","jagra","jagrak","jaguar","jagung","jagur","jah","jaha","jahan","jahanam","jahar","jaharu","jahat","jahe","jahil","jahiliah","jahiriah","jahit","jahul","jail","jainisme","jaipong","jais","jaiz","jaja","jajah","jajak","jajal","jajan","jajar","jaka","jakal","jakas","jaket","jaksa","jaksi","jakun","jala","jalabria","jalad","jalak","jalal","jalan","jalang","jalangkote","jalangkung","jalar","jali","jalibut","jalil","jalin","jalma","jalu","jalur","jam","jamaah","jamadat","jamah","jamak","jamal","jaman","jamang","jambak","jambal","jamban","jambang","jambar","jambat","jambe","jambiah","jambian","jamblang","jambon","jambore","jambret","jambu","jambul","jambulan","jambur","jamhur","jamiah","jamiatul","jamik","jamil","jamin","jamis","jamiyah","jamiyatul","jampal","jampen","jampi","jampuk","jamrah","jamrud","jamu","jamung","jamur","janabah","janabijana","janah","janat","janda","jangak","jangan","jangar","jangat","janggal","janggelan","janggi","janggolan","janggung","janggut","jangka","jangkah","jangkang","jangkap","jangkar","jangkat","jangkau","jangki","jangkih","jangkih-mangkih","jangking","jangkir","jangkit","jangkrik","jangkung","jangla","jangol","jani","janik","janin","janjang","janji","jantan","jantang","jantina","jantuk","jantung","jantur","janturan","januari","janubi","janur","jap","japan","japin","japu","japuk","jara","jarab","jarah","jarak","jaram","jaran","jaranan","jarang","jaras","jarem","jargon","jari","jariah","jariji","jarimah","jaring","jarit","jarjau","jaro","jarotan","jarum","jarwa","jas","jasa","jasad","jasadi","jasmani","jasmaniah","jasus","jaswadi","jatah","jatayu","jati","jatilan","jatmika","jatuh","jatukrama","jauh","jauhar","jauhari","jauza","jawab","jawang","jawanisasi","jawara","jawat","jawawut","jawer","jawi","jawil","jaya","jayacihna","jayapatra","jayasong","jayastamba","jayeng","jaz","jazam","jazirah","jazirat","jebab","jebah","jebai","jebak","jebang","jebar","jebat","jeblok","jeblos","jebluk","jebol","jebor","jebrol","jebuh","jebung","jebur","jeda","jeding","jedot","jegal","jegang","jegil","jegogan","jegung","jejabah","jejak","jejaka","jejal","jejap","jejas","jejengkok","jejer","jejunum","jejuri","jeket","jeksi","jel","jela","jelabak","jelabir","jeladan","jeladren","jeladri","jelaga","jelagra","jelah","jelai","jelajah","jelak","jelalat","jelamprang","jelanak","jelang","jelangak","jelangkung","jelantah","jelapak","jelapang","jelar","jelarang","jelas","jelata","jelatang","jelau","jelawat","jelejeh","jelek","jelempah","jelengar","jelentik","jelepak","jelepok","jeli","jelih","jelijih","jelimet","jelimpat","jeling","jelir","jelit","jelita","jelma","jelu","jeluak","jeluang","jelujur","jeluk","jelum","jelungkap","jeluntung","jelunut","jelur-jelir","jelus","jelut","jelutung","jem","jemaah","jemaat","jemah","jemala","jemang","jemari","jemaring","jemawa","jemba","jembak","jembalang","jembar","jembatan","jembel","jember","jembiah","jembrana","jembut","jemeki","jemerlang","jempalik","jempalit","jempana","jemparing","jempol","jempul","jemput","jemu","jemuas","jemuju","jemur","jenahar","jenak","jenaka","jenama","jenang","jenangau","jenat","jenawi","jenayah","jenazah","jendal","jendala","jendel","jendela","jendera","jenderal","jendol","jendul","jenela","jeneng","jenewer","jeng","jengah","jengang","jengat","jengek","jenggala","jenggar","jengger","jengget","jengglong","jenggot","jengguk","jenggul","jenggut","jengit","jengkal","jengkang","jengkek","jengkel","jengkelit","jengkeng","jengker","jengket","jengki","jengking","jengkit","jengkol","jengkolet","jengkot","jenglong","jenguh","jenguk","jengul","jenis","jenius","jenjam","jenjang","jenjeng","jentaka","jentang","jentayu","jentelmen","jentera","jentik","jentur","jenu","jenuh","jepa","jepet","jepit","jeprat","jepret","jepun","jeput","jera","jerabai","jeradik","jeragih","jerah","jerahak","jerahap","jerait","jeram","jeramah","jerambah","jerambai","jerambang","jerambung","jerami","jeran","jerang","jerangan","jerangau","jerangkah","jerangkak","jerangkang","jerangkong","jerap","jerapah","jerat","jerau","jeraus","jerawat","jerba","jerbak","jereket","jeremak","jeremba","jerembap","jerembat","jerembet","jerembun","jerempak","jereng","jerepet","jeri","jeriau","jerigen","jerih","jeriji","jeriken","jering","jeringing","jerit","jerjak","jerkah","jerkat","jermal","jermang","jernang","jernih","jero","jeroan","jerohok","jerojol","jerongkang","jerongkes","jerongkok","jerongkong","jerubung","jeruji","jeruju","jeruk","jerukun","jerukup","jerum","jerumat","jerumbai","jerumun","jerumus","jerun","jerung","jerungkau","jerungkis","jerungkung","jerunuk","jerupih","jesben","jet","jetis","jetsam","jetset","jewer","jiawang","jib","jibaku","jibilah","jibrail","jibril","jibti","jibun","jicap","jicapgo","jicing","jidal","jidar","jidat","jidur","jigong","jigrah","jih","jihad","jihat","jijik","jijit","jijitsu","jika","jikalau","jil","jila","jilah","jilam","jilat","jilbab","jilid","jim","jimahir","jimak","jimakir","jimat","jimawal","jimbit","jimpit","jin","jinak","jinayah","jindra","jinem","jineman","jineng","jingap","jingau","jingga","jinggring","jingkat","jingkik","jingkrak","jingo","jingoisme","jingu","jinjang","jinjing","jinjit","jinsom","jintan","jip","jipang","jiplak","jipro","jir","jirak","jiran","jirat","jirian","jirus","jisim","jitah","jitak","jitok","jitu","jiwa","jiwat","jiwatman","jiwit","jizyah","jlegur","joang","jobak","jobong","jodang","jodoh","jodong","jogan","jogar","joget","joging","joglo","johan","johar","johari","jojing","jojol","jok","joki","jolak","jolek","joli","jolok","jolong","jolor","jombang","jomlo","jompak","jompo","jongang","jonget","jongga","jonggol","jonggolan","jongjorang","jongkang","jongkar-jangkir","jongkat-jangkit","jongki","jongko","jongkok","jongkong","jongos","jonjot","jontoh","jontor","jontrot","joran","joreng","jori","jorjoran","jorok","jorong","josna","jota","jotang","jotos","joule","jrambah","jreng","jua","juadah","juak","jual","juan","juandang","juang","juar","juara","jubah","jubel","jubin","jublag","jublek","judek","judes","judi","judo","judogi","judoka","judul","juek","juga","juhi","juhut","juih","juita","juja","jujah","jujai","jujitsu","juju","jujuh","jujur","jujuran","jujut","jukstaposisi","jukut","julab","julai","julang","julat","juli","juling","julir","julo","juluk","julung","julur","jumadilakhir","jumadilawal","jumantan","jumantara","jumat","jumbai","jumbil","jumbo","jumbuh","jumbul","jumeneng","jumhur","jumjumah","jumlah","jumpa","jumpalit","jumpang","jumpelang","jumpul","jumput","jumrah","jumud","jun","junam","jundai","jung","jungat","junggang","jungkal","jungkang","jungkar","jungkat","jungkir","jungkit","jungkol","jungur","jungut","juni","junior","junjung","junta","juntai","juntrung","junub","junun","jupang","jura","juragan","jurai","jurang","juri","jurik","juring","juris","jurit","jurnal","jurnalis","jurnalisme","jurnalistik","juru","juruh","jurung","jurus","jus","justifikasi","justru","juta","jute","juvenil","juz","kaabah","kaba","kabah","kabak","kabang-kabang","kabar","kabaret","kabat","kabau","kabel","kabihat","kabil","kabilah","kabin","kabinet","kabir","kabisat","kabit","kaboi","kabriolet","kabruk","kabu-kabu","kabuki","kabul","kabumbu","kabung","kabupaten","kabur","kabus","kabut","kaca","kacak","kacam","kacamata","kacang","kacapiring","kacapuri","kacar","kacau","kacau-balau","kacauan","kacek","kacer","kaci","kacici","kacip","kacir","kaco","kacrek","kacu","kacuk","kacukan","kacung","kad","kada","kadahajat","kadal","kadam","kadang","kadar","kadariah","kadas","kadaster","kadasteral","kadastral","kadaver","kade","kademat","kadensa","kader","kadera","kaderisasi","kades","kadet","kadi","kadim","kadipaten","kadir","kadiriah","kadmium","kado","kadofor","kadok","kadru","kadung","kadut","kaedah","kaf","kafaah","kafah","kafan","kafarat","kafe","kafeina","kafetaria","kafi","kafil","kafilah","kafir","kafiri","kaftan","kagak","kaget","kagok","kagum","kah","kahaf","kahak","kahan","kahang","kahar","kahat","kahin","kahrab","kahwa","kahwaji","kahyangan","kaidah","kaifiah","kaifiat","kail","kailalo","kaimat","kain","kaing","kainit","kainofobia","kais","kaisar","kait","kajai","kajang","kajangan","kajen","kaji","kak","kakaban","kakafoni","kakagau","kakah","kakak","kakaktua","kakanda","kakang","kakao","kakap","kakas","kakawin","kakbah","kakek","kakerlak","kaki","kakodil","kakofoni","kakografi","kakok","kakologi","kakostokrasi","kakrupukan","kaksa","kaktus","kaku","kakuminal","kakus","kala","kalah","kalai","kalajengking","kalaka","kalakanji","kalakati","kalakeran","kalakian","kalam","kalamba","kalamdan","kalamin","kalamisani","kalamkari","kalandar","kalander","kalang","kalap","kalar","kalas","kalat","kalau","kalaupun","kalawija","kalaza","kalbi","kalbu","kaldera","kaldron","kaldu","kalebas","kaleidoskop","kaleidoskopis","kalem","kalempagi","kalender","kaleng","kali","kalian","kaliber","kalibit","kalibrasi","kalibut","kalicau","kalifornium","kaligraf","kaligrafi","kaligrafis","kalih","kalikausar","kaliki","kalimah","kalimantang","kalimat","kalimatullah","kalimatusyahadat","kalimayah","kalimpanang","kalingan","kalio","kaliper","kalipso","kaliptra","kalis","kalistenik","kalium","kalk","kalkalah","kalkarium","kalkasar","kalkausar","kalkopirit","kalkosium","kalkulasi","kalkulator","kalkulus","kalkun","kalo","kalomel","kalong","kalongwese","kalongwewe","kalor","kalori","kalorimeter","kalorimetri","kalorisitas","kalowatan","kalpataru","kalsedon","kalsiferol","kalsifikasi","kalsinasi","kalsit","kalsium","kalui","kalumet","kalung","kalus","kalut","kam","kama","kamajaya","kamal","kamalir","kamantuhu","kamar","kamarban","kamariah","kamas","kamat","kamba","kamban","kambang","kambar","kambeh","kambeli","kamber","kambi","kambing","kambium","kambrik","kambrium","kambuh","kambus","kambut","kamelia","kamera","kamerad","kamfana","kamfer","kamfor","kamhar","kami","kamikaze","kamil","kamilmukamil","kamir","kamis","kamisa","kamisol","kamisosolen","kamit","kamitua","kamka","kamkama","kamomil","kamp","kampa","kampai","kampalogi","kampanologi","kampanye","kampas","kampemen","kamper","kampil","kamping","kampiun","kampos","kampret","kampuh","kampul","kampung","kampus","kamrad","kamsen","kamsia","kamu","kamuflase","kamus","kan","kana","kanaah","kanaat","kanabis","kanak-kanak","kanal","kanalisasi","kanan","kanang","kancah","kancap","kanceh","kancera","kancil","kancing","kancung","kancut","kanda","kandang","kandar","kandas","kandel","kandela","kandi","kandidat","kandidiasis","kandil","kandis","kandul","kandung","kandut","kane","kang","kangar","kangen","kangka","kangkang","kangkung","kangmas","kangsa","kangsar","kangtau","kanguru","kanibal","kanibalisasi","kanibalisme","kanigara","kanilem","kanina","kanisah","kanjal","kanjang","kanjar","kanjeng","kanji","kanker","kano","kanoman","kanon","kanonir","kanonis","kanopi","kans","kansel","kanselari","kanselir","kanser","kanstof","kanta","kantan","kantang","kantar","kantata","kanti","kantih","kantil","kantilever","kantin","kanto","kantong","kantor","kantuk","kantung","kanun","kanvas","kanya","kanyon","kaok","kaolin","kaon","kaos","kaotis","kap","kapa","kapabel","kapah","kapai","kapak","kapal","kapan","kapang","kapar","kaparinyo","kapas","kapasitans","kapasitas","kapasitor","kapat","kapel","kapela","kaper","kapi","kapilaritas","kapiler","kapiran","kapis","kapisa","kapit","kapita","kapital","kapitalis","kapitalisme","kapitalistis","kapitan","kapitol","kapitulasi","kapitulum","kaplares","kaplars","kapling","kaplok","kapok","kapon","kaporit","kappa","kaprah","kapri","kaprikornus","kapsalon","kapsel","kapstan","kapster","kapstok","kapsul","kapten","kapu","kapuk","kapung","kapur","kapurancang","kara","karabin","karaeng","karaf","karagen","karah","karahah","karakter","karakterisasi","karakteristik","karakterologi","karam","karamba","karambol","karamel","karang","karangkitri","karangwulu","karantina","karaoke","karap","karapaks","karapan","karar","karas","karat","karate","karategi","karateka","karau","karavan","karawitan","karbiah","karbid","karbida","karbohidrase","karbohidrat","karboksil","karbol","karbolat","karbolik","karbon","karbonado","karbonan","karbonat","karbonil","karbonisasi","karborundum","karburasi","karburator","karcis","kardamunggu","kardan","kardia","kardiak","kardigan","kardil","kardinal","kardiograf","kardiografi","kardiogram","kardiolog","kardiologi","kardiovaskular","karditis","kardus","karel","karembong","karena","karengga","kareseh-peseh","karet","kargo","kari","karib","karibu","karier","karies","karih","karikatur","karikatural","karikaturis","karil","karim","karimah","karina","karinasi","karisma","karismatik","karismatis","karitas","karitatif","karkas","karkata","karkum","karkun","karma","karmina","karminatif","karnaval","karnivor","karosel","karoseri","karotena","karotenoid","karotis","karpai","karpel","karper","karpet","karpopodil","karsa","karsinogen","karsinogenik","karsinologi","karsinoma","karst","karteker","kartel","karti","kartika","kartilago","kartografi","kartogram","karton","kartonase","kartotek","kartu","kartun","kartunis","karu","karuan","karuhun","karun","karung","karunia","karunkel","karusi","karut","karya","karyah","karyasiswa","karyat","karyawisata","kas","kasa","kasab","kasabandiah","kasad","kasah","kasai","kasak-kusuk","kasam","kasang","kasap","kasar","kasasi","kasatmata","kasau","kasdu","kasein","kasemat","kasemek","kasep","kaserin","kaserol","kaset","kasi","kasid","kasidah","kasih","kasihan","kasiku","kasim","kasima","kasino","kasintu","kasip","kasir","kasiterit","kaskade","kaskaya","kasmaran","kasmir","kasmutik","kaspe","kasrah","kasregister","kassia","kasta","kastal","kastanyet","kastel","kasti","kastrasi","kastroli","kasturi","kasual","kasualisme","kasualitas","kasuari","kasuarina","kasui","kasuis","kasuistik","kasur","kasus","kasut","kaswah","kata","katabalik","katabatik","katabolisme","katadrom","katafalk","katafora","katah","katai","katak","kataka","katakana","kataklisme","katakomba","katalase","katalepsi","katalina","katalis","katalisasi","katalisator","katalisis","katalisit","katalog","katalogisasi","katalogus","katamaran","katang-katang","katapel","katar","katarak","katarsis","katartik","katastrofe","katatoni","katatonia","katawi","kate","katebelece","katedral","kategori","kategorial","kategoris","kategorisasi","katek","katekese","katekis","katekisasi","katekismus","katekumen","katel","katelum","kater","katering","kates","kateter","katetometer","kati","katib","katibin","katifah","katifan","katik","katil","katimaha","katimumul","kation","katir","katirah","katiti","katode","katok","katolik","katrol","katuk","katul","katun","katung","katup","katut","katvanga","katwal","kau","kaukab","kaukasoid","kaukus","kaul","kaula","kauli","kaum","kaung","kaupui","kaus","kausa","kausal","kausalitas","kausatif","kaustik","kaustiksoda","kaut","kavaleri","kaveling","kaver","kaviar","kawa-kawa","kawah","kawak","kawal","kawan","kawang","kawanua","kawasan","kawat","kawi","kawih","kawijayan","kawin","kawista","kawruh","kawuk","kawula","kawung","kaya","kayai","kayak","kayambang","kayan","kayang","kayangan","kayau","kayu","kayuh","kayun","kebab","kebabal","kebah","kebaji","kebal","kebam","kebas","kebat","kebaya","kebayan","kebel","kebelet","kebembem","kebin","kebiri","keblangsak","keblinger","kebo","kebon","kebuk","kebul","kebuli","kebun","kebur","keburu","kebut","kebyar","kecai","kecak","kecalingan","kecam","kecambah","kecamuk","kecandan","kecantol","kecap","kecapi","kecar","kece","kecebong","kecek","kecele","keceng","kecepek","kecer","kecewa","keci","keciak","kecibak","kecibeling","kecik","kecil","kecimik","kecimpring","kecimpung","kecimus","kecipak","kecipir","kecipuk","kecit","keciut","kecoak","kecoh","kecombrang","kecong","kecrek","kecu","kecuali","kecubung","kecuh-kecah","kecumik","kecundang","kecup","kecut","kedabu","kedadak","kedah","kedai","kedak","kedal","kedaluwarsa","kedam","kedang","kedangkai","kedangkan","kedangsa","kedap","kedasih","kedau","kedaung","kedayan","kedebong","kedek","kedekai","kedeki","kedekik","kedekut","kedelai","kedele","kedemat","kedemplung","kedempung","kedengkang","kedengkik","keder","kedera","kederang","kedewaga","kedi","kedidi","kedik","kedikit","kedip","kedodoran","kedok","kedondong","kedongdong","kedongkok","kedot","keduduk","keduk","kedul","kedumung","kedung","kedut","keferdom","kehel","keibodan","kejai","kejam","kejamas","kejan","kejang","kejap","kejar","kejat","kejawen","kejen","kejer","keji","kejibeling","kejip","kejolak","kejora","keju","kejuju","kejur","kejut","kek","kekah","kekal","kekam","kekandi","kekang","kekapas","kekar","kekara","kekas","kekat","kekau","kekawin","kekeba","kekebik","kekeh","kekek","kekel","kekemben","kekep","keker","keki","kekitir","kekok","kekol","kekrupukan","kelab","kelabak","kelabang","kelabat","kelabau","kelabu","keladak","keladan","keladau","keladi","kelah","kelahi","kelai","kelak","kelak-kelik","kelak-keluk","kelakah","kelakanji","kelakar","kelalang","kelam","kelamai","kelamarin","kelambai","kelambir","kelambit","kelambu","kelambur","kelamin","kelamkari","kelana","kelandera","kelang","kelang-kelok","kelangkan","kelangkang","kelanjar","kelantang","kelap","kelapa","kelar","kelara","kelarah","kelarai","kelaras","kelari","kelas","kelasa","kelasah","kelasak","kelasi","kelat","kelati","kelawan","kelayan","kelayang","kelayu","kelder","kelebat","kelebek","kelebet","kelebu","kelebuk","kelebut","keledai","keledang","keledar","keledek","kelejat","kelek","kelekap","kelekatu","kelelap","kelelawar","kelelesa","kelelot","kelemak-kelemek","kelemantang","kelemayar","kelemayuh","kelembahang","kelembai","kelembak","kelemban","kelembuai","kelempai","kelemping","kelemton","kelemumur","kelemur","kelencer","kelendara","keleneng","kelengar","kelenggara","kelengkeng","kelengkiak","kelening","kelenjar","kelentang","kelenteng","kelentik","kelenting","kelentit","kelentong","kelentung","kelenung","kelenyit","kelep","kelepai","kelepak","kelepat","kelepek","kelepet","kelepik","kelepir","kelepit","kelepuk","kelepur","keler","kelereng","kelesa","kelesah","keleseh","kelesek","kelesot","keletah","keletak","keletang","keletar","keleti","keletik","keletuk","keletung","kelewang","keli","kelian","keliar","kelibang","kelibat","kelicap","kelici","kelicik","kelih","kelijak","kelik","kelika","kelikah","kelikat","keliki","kelikih","kelikik","kelikir","keliling","kelilip","kelim","kelimat","kelimpanan","kelimpungan","kelimun","kelimut","kelinci","kelincir","kelindan","keling","kelingking","kelingsir","kelining","kelinjat","kelintang","kelintar","kelinting","kelip","kelipat","kelir","keliru","kelis","kelisera","kelisere","kelit","keliti","kelitik","keliwon","kelobot","kelobotisme","kelocak","keloceh","kelodan","keloelektrovolt","keloid","kelojot","kelok","kelokak","kelola","kelolong","kelom","kelombeng","kelompang","kelompen","kelompok","kelon","keloneng","kelonet","kelong","kelongkong","kelongsong","kelontang","kelontang-kelantung","kelontong","kelonyo","kelop","kelopak","kelor","kelorak","kelos","kelosok","kelotok","keloyak","keloyang","keloyor","kelp","kelu","kelua","keluai","keluak","keluan","keluang","keluangsa","keluar","keluarga","kelubak","kelubi","keluburan","keluh","kelui","keluih","keluk","kelukup","kelukur","keluli","kelulu","kelulus","kelulut","kelumit","kelumpang","kelumun","kelun","keluna","kelunak","kelung","kelupas","kelupur","keluron","keluruk","kelurut","kelus","kelusuh-kelasah","kelut","kelutum","keluwung","keluyuk","keluyur","kemah","kemal","kemala","kemam","kemamang","keman","kemandang","kemandoran","kemang","kemangi","kemarau","kemari","kemarin","kemaruk","kemas","kemat","kematu","kematus","kemayu","kembal","kembali","kemban","kembang","kembar","kembara","kembatu","kembayat","kembeng","kembera","kembili","kemboja","kembol","kembu","kembuk","kembung","kembur","kembut","kemeja","kemejan","kemekmek","kemelut","kemenakan","kemendalam","kemendang","kemendur","kementam","kemenyan","kemerakan","kemesu","kemi","kemih","kemik","kemilap","kemiluminesens","kemiri","kemit","kemlaka","kemlandingan","kemloko","kemoceng","kemokinesis","kemon","kemopsikiatri","kemoterapi","kempa","kempal","kempang","kempas","kempek","kempes","kempetai","kempis","kempit","kemplang","kempot","kempu","kempuh","kempul","kempunan","kempung","kemput","kempyang","kemu","kemucing","kemudi","kemudian","kemudu","kemukus","kemul","kemumu","kemuncak","kemuncup","kemundir","kemung","kemungkus","kemuning","kemunting","kemurgi","kemut","kemutul","ken","kena","kenaf","kenal","kenan","kenang","kenanga","kenap","kenapa","kenapang","kenari","kenas","kencan","kencana","kencang","kencar","kenceng","kencing","kencit","kencong","kencrang-kencring","kencreng","kencung","kencur","kendaga","kendal","kendala","kendali","kendana","kendang","kendara","kendati","kendayakan","kendeka","kenderi","kendi","kendil","kendit","kendo","kendong","kenduduk","kendung","kendungan","kendur","kenduri","kenek","keneker","kenem","kenematik","kenes","keng","kengkang","kengkeng","kenidai","kenikir","kening","kenohong","kenong","kenop","kensel","kental","kentang","kentar","kentara","kenteng","kentrung","kentung","kentut","kenur","kenya","kenyal","kenyam","kenyang","kenyat","kenyat-kenyit","kenyet-kenyut","kenyi","kenyih","kenyir","kenyit","kenyut","keok","keong","kep","kepada","kepah","kepai","kepak","kepal","kepala","kepalang","kepam","kepang","kepar","keparat","kepayang","kepecong","kepek","kepel","kepencong","kepeng","keper","keperancak","kepet","kepetang","kepialu","kepiat","kepik","kepil","kepincut","kepinding","keping","kepingin","kepinis","kepinjal","kepiri","kepis","kepit","kepiting","keplak","kepleset","keplok","kepodang","kepoh","kepol","kepompong","keponakan","kepot","keprak","keprek","kepret","kepris","kepruk","kepuh","kepuk","kepul","kepulaga","kepundan","kepundung","kepung","kepurun","keputren","kepuyuk","kera","kerabang","kerabat","kerabik","kerabu","keracak","keracap","keraeng","kerah","kerahi","kerai","kerajang","kerajat","kerak","kerakah","kerakal","kerakap","kerakeling","keram","kerama","keraman","keramas","keramat","keramba","kerambil","kerambit","keramboja","keramik","keramikus","kerampagi","kerampang","keramunting","keran","kerancang","keranda","kerang","kerang-keroh","kerangas","kerangka","kerangkai","kerangkeng","kerani","keranjang","keranjat","keranji","keranjingan","keranta","kerantong","kerap","kerapu","keras","kerasan","kerat","keratabasa","keratin","keratitis","keratoelastin","keraton","kerau","kerawai","kerawak","kerawang","kerawat","kerawit","kerbang","kerbat","kerbau","kerbuk","kercap-kercip","kercap-kercup","kercing","kercit","kercup","kercut","kerdak","kerdam","kerdil","kerdom","kerdut","kere","kerebok","kereceng","kerecik","keredak","keredep","keredok","keredong","kerek","kereket","kerekot","kerekut","keremi","keremot","kerempagi","kerempeng","kerempung","keremus","keren","kerencang","kerencung","kerendang","kereneng","kereng","kerengga","kerenggamunggu","kerengkam","kerengkiang","kerentam","kerentang","kerenting","kerenyam","kerenyot","kerepas","kerepek","kerepes","kerepot","kerepyak","kerese","kerese-pese","keresek","kereseng","keresot","kereta","keretan","keretek","keretot","keretut","kereweng","keri","keriang-keriut","keriap","kerias","keriau","kerical","kericau","keridas","keridik","kerih","kerik","kerikal","kerikam","kerikil","kerikit","kerimut","kerinan","kerincing","kerinding","kering","keringat","keriningan","kerinjal","kerinjang","kerinjing","kerintil","kerinting","kerip","keripik","keriput","keris","kerisi","kerisik","kerising","kerisut","kerit","keritik","keriting","keriuk","keriut","kerja","kerjang","kerjantara","kerjap","kerkah","kerkak","kerkap","kerkau","kerkop","kerkup","kerlap","kerling","kerlip","kermak","kermanici","kermi","kernai","kerneli","kernet","kernu","kernyat-kernyut","kernyau","kernyih","kernying","kernyit","kernyut","kero","kerobak","kerobat","kerobek","keroco","kerocok","kerogen","keroh","kerok","kerokot","keromong","keron","keroncang","keroncong","keroncor","kerong","kerongkongan","kerongsang","kerontang","kerop","keropak","keropas-keropis","keropeng","keropok","keropong","keropos","kerosak","kerosek","kerosi","kerosin","kerosok","kerosong","kerot","kerotak","kerotot","keroyok","kerpai","kerpak","kerpas","kerpubesi","kerpuk","kerpus","kers","kersai","kersak","kersang","kersani","kersen","kersik","kersuk","kertaaji","kertah","kertak","kertang","kertap","kertas","kertau","kertuk","kertus","keruan","kerubim","kerubin","kerubung","kerubut","kerucil","kerucut","kerudung","keruh","keruing","keruit","keruk","kerukut","kerul","keruma","kerumit","kerumuk","kerumun","kerumus","kerun","kerung","kerunkel","keruntang-pungkang","kerunting","keruntung","kerunyut","kerup","kerupuk","kerut","kerutak","kerutup","keruyuk","kes","kesah","kesak","kesal","kesam","kesambet","kesambi","kesan","kesana","kesandung","kesang","kesangsang","kesap-kesip","kesasar","kesat","kesatria","kesek","kesel","keselak","keseleo","kesemek","kesengsem","keseran","keseser","keset","kesi","kesiap","kesik","kesima","kesimbukan","kesini","kesip","kesitu","kesiur","keskul","kesmaran","kesohor","kesomplok","kesongo","kesot","kesrakat","kesting","kesturi","kesu-kesi","kesuh-kesih","kesuk-kesik","kesuma","kesumat","kesumba","kesup","kesusu","kesut","keta","ketaban","ketai","ketak","ketakar","ketakong","ketal","ketam","ketambak","ketampi","ketan","ketang","ketap","ketapak","ketapang","ketapek","ketar","ketarap","ketat","ketaton","ketawa","ketaya","ketayap","ketegar","ketek","ketel","ketela","ketemu","keten","ketena","keteng","ketepel","ketepeng","keter","ketes","keteter","ketgat","keti","ketiak","ketial","ketiap","ketiau","ketiban","ketiding","ketik","ketika","ketil","ketilang","ketimbang","ketimbis","ketimbul","ketimbung","keting","ketinjau","ketinting","ketip","ketiplak","ketipung","ketirah","ketis","ketitir","ketlingsut","ketogenesis","ketok","ketola","ketombe","keton","ketonemia","ketonggeng","ketonuria","ketopong","ketoprak","ketosa","ketrek","ketu","ketua","ketuat","ketuban","ketuir","ketuk","ketul","ketumbar","ketumbi","ketumbit","ketumbu","ketumpang","ketun","ketungging","ketup","ketupa","ketupat","ketupuk","ketur","ketus","kev","kewalahan","keweni","kewer","kewes","kewuh","kha","khabis","khadam","khadim","khafi","khair","khairat","khalas","khalayak","khali","khalifah","khalifatulah","khalifatullah","khalik","khalikah","khalikul","khalil","khalilullah","khalis","khalwat","khamar","khamir","khamsin","khamzab","khanjar","kharab","khas","khasi","khasiat","khat","khatam","khatib","khatifah","khatimah","khatulistiwa","khauf","khaul","khawas","khawasulkhawas","khawatir","khayal","khayali","khazanah","khi","khianat","khiar","khidaah","khidmah","khidmat","khilaf","khilafiah","khinzir","khisit","khitah","khitan","khitbah","khizanatulkitab","khoja","khojah","khotbah","khuduk","khulafa","khuldi","khuluk","khunsa","khurafat","khusuf","khusus","khusyuk","kia","kiah","kiai","kiak","kial","kiam","kiamat","kiambang","kian","kiang-kiut","kiani","kiap","kiar","kiara","kias","kiasi","kiasmus","kiat","kiaupau","kibang","kibar","kibas","kibernetika","kibir","kiblat","kiblik","kibriah","kibul","kicang-kecoh","kicang-kicu","kicau","kici","kicik","kicu","kicuh","kicut","kida-kida","kidal","kidam","kidang","kidar","kidul","kidung","kifayah","kifoskaliose","kifoskaliosis","kihanat","kijai","kijang","kijil","kijing","kikih","kikik","kikil","kikir","kikis","kikitir","kikuk","kikus","kila","kilah","kilai","kilan","kilang","kilap","kilar","kilas","kilat","kilau","kili","kilik","kilir","kiln","kilo","kilogram","kilohertz","kilokalori","kiloliter","kilometer","kiloton","kilovolt","kilowatt","kilowattjam","kilus","kim","kima","kimah","kimantu","kimar","kimbah","kimbang","kimbul","kimia","kimiawi","kimkha","kimlo","kimo","kimograf","kimono","kimpal","kimpul","kimpus","kimput","kimus","kina","kinang","kinantan","kinanti","kinasa","kinasih","kinca","kincah","kincak","kincang","kincau","kincir","kincit","kincung","kincup","kindap","kinematika","kinematograf","kinesika","kinesimeter","kineskop","kinestesia","kinestesiometer","kinestesis","kinetik","kinetika","kinetokardiografi","kingking","kingkip","kingkit","kingkong","kini","kinine","kinja","kinjat","kinjeng","kinred","kintaka","kintal","kinte","kintil","kinyang","kio","kios","kipa","kipai","kipang","kipas","kiper","kiprah","kiprat","kipsiau","kipu","kir","kira","kiraah","kiraat","kirab","kirai","kiramat","kiran","kirana","kirap","kiras","kirau","kirbat","kiri","kirik","kirim","kirinyu","kirip","kiris","kirita","kirmizi","kiru","kiruh","kirung","kisa","kisah","kisai","kisar","kisas","kisat","kisi","kisik","kismat","kismis","kisruh","kista","kisut","kiswah","kit","kita","kitab","kitabulah","kitang","kitar","kitik","kitin","kiting","kitir","kitorang","kitri","kits","kiu","kiuk","kiwari","kiwi","kizib","klaim","klakklik","klakson","klamidospora","klan","klandestin","klangenan","klante","klarifikasi","klarinet","klasemen","klasifikasi","klasik","klasikal","klasis","klasisisme","klausa","klaustrofobia","klaustrum","klausul","klaver","klavikor","klavikula","klaviola","kleder","kleidotomi","kleistogami","klem","klemensi","klen","klenengan","klengkeng","klenik","klenteng","klep","klepon","klepsidra","kleptofobi","kleptoman","kleptomania","kleptomaniak","klerek","klerikal","klerikus","klerus","klien","klik","kliker","klimaks","klimakterium","klimaktorium","klimatografi","klimatolog","klimatologi","klimis","klimograf","klimosekuen","klimoskop","klin","klinik","klining","klinis","klinisi","klinometer","klip","kliping","klir","kliring","klise","klistron","klitelum","klitik","klitoris","kliwon","kliyengan","kloaka","klon","klona","kloning","klonograf","klonus","klop","klor","kloral","kloramina","klorat","klorida","kloridimeter","klorin","klorinasi","klorit","klorobenzena","klorofil","kloroform","kloroformat","klorokuin","klorolignin","kloroplas","kloroprena","klorosis","kloset","klub","kluntang-kluntung","klusium","knalpot","knop","knot","koa","koagel","koagregasi","koagulan","koagulasi","koak","koaksi","koaksial","koala","koalisi","koana","koar","kobah","kobak","kobalamin","kobalt","kobar","kober","koboi","koboisme","kobok","kobol","kobongan","kobra","kocah-kacih","kocak","kocar-kacir","kocek","koci","kocilembik","kocoh","kocok","kocolan","kocong","kocor","koda","kodak","kode","kodein","kodeks","kodi","kodifikasi","kodok","kodominan","kodrat","kodrati","koe","koedukasi","koefisien","koeksistensi","koenzim","koersi","koersif","kofaktor","kofein","kofermen","kognat","kognatif","kognisi","kognitif","koh","kohabitasi","koheren","koherensi","kohesi","kohesif","kohir","kohlea","kohol","kohong","kohor","koil","koin","koinseden","koinsiden","koinsidensi","koipuk","koit","koitus","koja","kojah","kojang","kojoh","kojol","kojor","kok","koka","kokah","kokaina","kokainisasi","kokainisme","kokang","kokarde","kokas","koki","kokila","koklea","kokoa","kokoh","kokok","kokokbeluk","kokol","kokon","kokosan","kokot","kokpit","koksa","koktail","kokurikuler","kokus","kol","kola","kolaborasi","kolaborator","kolagen","kolak","kolam","kolang-kaling","kolaps","kolaret","kolase","kolateral","kolator","kolega","kolegial","kolegialitas","koleh-koleh","kolek","koleksi","kolekte","kolektif","kolektivis","kolektivisasi","kolektivisme","kolektivitas","kolektor","kolembeng","kolemia","koleng","koleoptil","kolera","kolese","kolesom","kolesterin","kolesterol","koli","kolibri","koligasi","kolik","kolimasi","kolina","kolintang","koliseng","kolitis","kolkhoz","kolodion","kolofon","kologen","koloid","koloidal","kolok","kolokasi","kolokium","kolom","kolomben","kolon","kolone","kolonel","kolong","koloni","kolonial","kolonialis","kolonialisme","kolonis","kolonisasi","kolonoskop","kolonye","kolor","kolorimeter","kolorimetri","kolosal","kolosom","kolostomi","kolostrum","kolot","kolportir","kolt","kolum","kolumela","kolumnis","kolumnus","kolusi","koluvium","kom","koma","komaliwan","koman","komandan","komandemen","komanditer","komando","komaran","komat-kamit","kombat","kombinasi","kombo","kombor","kombusio","komedi","komedian","komendur","komeng","komensal","komensalisme","komentar","komentator","komersial","komersialisasi","komet","komfortabel","komidi","komik","komikal","komikus","kominusi","komis","komisar","komisariat","komisaris","komisi","komisioner","komisura","komit","komite","komitmen","komkoma","komoditas","komodo","komodor","kompak","kompanyon","komparasi","komparatif","komparator","kompartemen","kompas","kompatibel","kompatibilitas","kompatriot","kompendium","kompeni","kompensasi","kompes","kompeten","kompetensi","kompetisi","kompetitif","kompetitor","kompi","kompilasi","kompilator","komplain","kompleks","kompleksitas","komplemen","komplementer","komplet","komplikasi","komplikatif","komplimen","komplot","kompon","komponen","kompong","komponis","kompor","kompos","komposer","komposisi","komposit","kompositum","komprador","komprang","komprehensif","kompres","kompresi","kompresor","kompromi","kompromistis","kompulsi","kompulsif","komputer","komputerisasi","komtabilitas","komunal","komunalisme","komunalistik","komune","komuni","komunikabilitas","komunikan","komunikasi","komunikatif","komunikator","komunike","komunis","komunisme","komunistis","komunistofobi","komunistofobia","komunitas","komutator","komuter","konan","konco","koncoisme","kondang","kondangan","konde","kondektur","kondensasi","kondensat","kondensator","kondensor","kondilus","kondisi","kondom","kondominium","kondomisasi","kondor","kondrin","kondroblas","konduite","konduksi","konduktans","konduktimeter","konduktivitas","konduktor","kondusif","koneksi","koneksitas","konektor","konfederasi","konfeksi","konferensi","konfesi","konfigurasi","konfiks","konfirmasi","konflik","konform","konformitas","konfrontasi","konfrontatif","kongenital","kongesti","kongkalikong","kongko","kongkoan","kongkong","kongkret","konglomerasi","konglomerat","kongregasi","kongres","kongresis","kongsi","konifera","konis","konjugan","konjugasi","konjungsi","konjungter","konjungtif","konjungtiva","konjungtivitis","konjungtor","konjungtur","konkaf","konklaf","konklusi","konklusif","konkologi","konkomitan","konkordansi","konkordat","konkresi","konkret","konkretisasi","konkuisnador","konkuren","konkurensi","konkurs","konoid","konon","konosemen","konotasi","konotatif","konperensi","konsekrasi","konsekuen","konsekuensi","konsekutif","konseli","konseling","konselor","konsensus","konsentrasi","konsentrat","konsentrik","konsentris","konsep","konsepsi","konsepsional","konseptor","konseptual","konseptualisasi","konser","konsertina","konserto","konservasi","konservasionis","konservatif","konservatisme","konservator","konservatori","konservatorium","konsesi","konsesif","konsesional","konsiderans","konsiderasi","konsili","konsiliasi","konsinyasi","konsinyatir","konsisten","konsistensi","konsistori","konsol","konsolasi","konsolidasi","konsonan","konsonansi","konsonantal","konsorsium","konspirasi","konspiratif","konspirator","konstabel","konstan","konstanta","konstantagravitasi","konstatasi","konstatatif","konstatir","konstelasi","konstipasi","konstituante","konstituen","konstitusi","konstitusional","konstitusionalisme","konstriksi","konstriktor","konstruksi","konstruktif","konstruktivisme","konsul","konsulat","konsulen","konsuler","konsultan","konsultasi","konsumen","konsumer","konsumerisme","konsumsi","konsumtif","kontak","kontal-kantil","kontaminasi","kontan","kontang-kanting","konte","konteks","kontekstual","kontekstualisme","kontemplasi","kontemplatif","kontemporer","konten","konter","kontes","kontestan","kontet","kontiguitas","kontinen","kontinental","kontingen","kontinu","kontinuitas","kontinum","kontoid","kontol","kontra","kontrabande","kontrabas","kontradiksi","kontradiktif","kontraindikasi","kontrak","kontraksi","kontraktor","kontraktual","kontraproduktif","kontras","kontrasepsi","kontraseptif","kontravensi","kontribusi","kontributor","kontrol","kontrolir","kontroversi","kontroversial","kontur","konus","konveks","konveksi","konvektif","konvensi","konvensional","konvergen","konvergensi","konversasi","konversi","konveyor","konvoi","konvolusi","konvulsan","konvulsi","konyak","konyal","konyan","konyol","kooperasi","kooperatif","kooperativisme","kooperator","kooptasi","koordinasi","koordinat","koordinatif","koordinator","kop","kopah","kopaiba","kopak","kopal","kopat-kapit","kopbal","kopek","kopel","kopelrim","koper","koperasi","kopet","kopi","kopiah","kopilot","kopling","koplo","kopok","kopolimer","kopong","kopra","koprafagia","koprak","kopral","koprok","koprol","koprolit","kopula","kopulasi","kopulatif","kopyok","kopyor","kor","koral","koralit","koran","korano","korban","korden","kordial","kordit","kordon","korduroi","kored","koreferensialitas","korek","koreke","koreksi","korektif","korektor","korelasi","korelatif","korenah","koreng","koreograf","koreografer","koreografi","koreografis","kores","koresponden","korespondensi","koret","koridor","korion","kornea","kornel","korner","kornet","koroh","koroid","korok","korologi","korona","koronal","koroner","korong","korosi","korosif","korporasi","korporat","korporatif","korporatisme","korps","korpulensi","korpus","korsase","korsel","korselet","korset","korsleting","korteks","kortikulus","korting","kortison","korugator","korundum","korup","korupsi","koruptif","koruptor","korve","korvet","kosak-kasik","kosakata","kosar","kosbas","kosek","kosekan","kosel","kosen","koset","kosinus","kosmetik","kosmetilogi","kosmetolog","kosmetologi","kosmetologis","kosmis","kosmogoni","kosmografi","kosmologi","kosmologis","kosmonaut","kosmopolit","kosmopolitan","kosmopolitanisme","kosmos","kosmotron","kosokbali","kosong","kostum","kota","kotah","kotai","kotak","kotak-katik","kotaklema","kotek","koteka","koteks","koteng","koterek","kotes","kotiledon","kotipa","kotok","kotong","kotor","kotrek","kovalensi","kover","kowan","kowek","koyak","koyam","koyan","koyok","krai","krakal","kram","krama","kranapaksa","krangeyan","kraniologi","kraniometri","kraniotomi","kranium","krans","krasis","krayon","kreasi","kreatif","kreativitas","kreator","krebo","krecek","kredibilitas","kredit","kreditabel","kreditor","kredo","krem","kremasi","krematori","krematorium","kreol","kreolin","kreolisasi","kreosol","kresendo","kresol","kretin","kribo","kricak","krida","krifoli","krim","kriminal","kriminalis","kriminalisasi","kriminalitas","kriminolog","kriminologi","kriminologis","kring","krio","kriofil","kriofit","kriogen","kriogenika","krioterapi","kripta","kriptogam","kriptografi","kriptogram","kriptol","kripton","krisan","krisantemum","krisis","krisma","krisoberil","krisofil","krisolit","krisopras","krista","kristal","kristalisasi","kristalografi","kristaloid","kristalosa","kristen","kristiani","kristus","kriteria","kriterium","kritik","kritikus","kritis","kritisi","kriya","krobongan","kroco","kroket","krol","krom","kromat","kromatid","kromatika","kromatin","kromatis","kromatofor","kromatografi","kromit","kromium","kromo","kromofil","kromofob","kromogen","kromong","kromosfer","kromosom","kromotropi","krompyang","kronem","kroni","kronik","kroniometri","kronis","kronisme","kronobiologi","kronogram","kronologi","kronologis","kronometer","kronosekuen","kronoskop","krosboi","kroto","kru","kruistik","kruk","krukat","krusial","krustasea","ksatria","ksi","kuaci","kuadran","kuadrat","kuadratika","kuadratur","kuadratus","kuadrenium","kuadriliun","kuadripartit","kuadrisep","kuadrupel","kuadrupleks","kuadruplet","kuah","kuai","kuak","kuala","kualat","kuali","kualifikasi","kualitas","kualitatif","kualon","kuang","kuangkiut","kuangwung","kuantifikasi","kuantitas","kuantitatif","kuantum","kuap","kuar","kuari","kuarik","kuark","kuarsa","kuarsit","kuart","kuartal","kuarter","kuarterner","kuartet","kuartil","kuarto","kuas","kuasa","kuasar","kuasi","kuat","kuatren","kuau","kuaya","kuayah","kuayan","kubah","kubak","kubang","kubik","kubil","kubin","kubis","kubisme","kubistik","kubit","kuboid","kubra","kubti","kubu","kubul","kubung","kubur","kubus","kucai","kucak","kucam","kucandan","kucar-kacir","kucek","kucel","kucica","kucil","kucindan","kucing","kucir","kucup","kucur","kuda","kudai","kudang","kudap","kudeta","kudi","kudian","kudis","kudu","kuduk","kudung","kudup","kudus","kue","kueni","kuesioner","kuetiau","kufu","kufur","kui","kuih","kuil","kuilu","kuin","kuing","kuini","kuinina","kuintal","kuintesens","kuintet","kuintil","kuintiliun","kuintuplet","kuir","kuis","kuit","kuitansi","kujang","kujarat","kujung","kujur","kujut","kuk","kukabura","kukai","kukang","kukila","kuku","kukuh","kukuk","kukul","kukup","kukur","kukuruyuk","kukus","kulah","kulai","kulak","kulakasar","kulan","kulansing","kulasentana","kulat","kulawangsa","kuli","kuliah","kulik-kulik","kulikat","kulim","kulimat","kuliner","kulintang","kulir","kulit","kulkas","kulminasi","kulon","kulot","kult","kultivar","kultivasi","kultur","kultural","kulturisasi","kultus","kulub","kuluk","kulum","kulup","kulur","kulut","kulzum","kuma-kuma","kumai","kumal","kuman","kumandang","kumanga","kumat","kumba","kumbah","kumbang","kumbar","kumbik","kumbu","kumbuh","kumena","kumico","kuminter","kumis","kumkuma","kumpai","kumpal","kumpar","kumpi","kumpul","kumuh","kumulasi","kumulatif","kumulonimbus","kumulus","kumur","kumus","kumut","kunang-kunang","kunani","kunar-kunar","kunarpa","kunca","kuncah","kuncen","kunci","kuncir","kuncit","kuncung","kuncup","kundai","kundang","kundi","kundur","kunduran","kunfayakun","kung","kungfu","kungkang","kungki","kungkum","kungkung","kuning","kuningan","kunjung","kuno","kunta","kuntau","kuntilanak","kuntit","kuntuan","kuntul","kuntum","kuntung","kunut","kunyah","kunyam","kunyit","kunyuk","kuorum","kuosien","kuota","kup","kupa","kupahan","kupak","kupang","kupas","kupat","kupat-kapit","kupe","kupel","kupi","kupil","kuping","kupir","kuplet","kupluk","kupnat","kupon","kuproprotein","kuprum","kupu-kupu","kupui","kupur","kur","kura","kurai","kurambit","kurang","kurap","kuras","kurasani","kurasao","kuratif","kurator","kuratorium","kurau","kurawal","kurban","kurcaci","kuren","kuret","kuretase","kuria","kuricak","kurigram","kurik","kurikuler","kurikulum","kuring","kuriositas","kuripan","kurir","kuririk","kurium","kurkatovium","kurkuma","kurltase","kurma","kurs","kursemangat","kursi","kursif","kursor","kursus","kurtase","kurun","kurung","kurus","kuruyuk","kurva","kurvalinier","kurvatur","kus","kusa","kusal","kusam","kusanin","kusat-mesat","kusau","kusen","kusik","kusir","kuskus","kuspis","kusruk","kusta","kusu","kusuf","kusuk","kusuma","kusut","kuta","kutaha","kutak","kutang","kutat","kutat-kutet","kuteks","kuteri","kuti","kutik","kutikula","kutil","kutin","kuting","kutip","kutu","kutub","kutubaru","kutubusitah","kutuk","kutung","kutut","kuud","kuwu","kuwuk","kuwung-kuwung","kuwur","kuya","kuyang","kuyu","kuyuh","kuyup","kwartet","kwartir","kwasiorkor","kweni","kwetiau","kwosien","laal","lab","laba","labah-labah","labak","labang","labas","label","labelum","laberang","labi-labi","labial","labialisasi","labil","labiodental","labiovelar","labirin","labium","laboran","laboratoris","laboratorium","labrak","labrakan","labrang","labres","labrum","labu","labuda","labuh","labun","labur","labut","lacak","laci","lacur","lacut","lada","ladah","ladam","ladan","ladang","laden","ladi","lading","ladu","ladung","lafal","laga","lagak","lagam","lagan","lagang","lagau","lagi","lagiah","lago","lagonder","lagu","laguh-lagah","laguna","lagwu","lah","lahab","lahad","lahak","lahan","lahang","lahap","lahar","lahir","lahiriah","lai","laici","laif","laik","lailah","lailatulkadar","lain","lais","laja","lajak","lajang","lajat","lajnah","laju","lajur","lak","lakab","lakak","lakar","lakara","laken","lakeri","laki","laklak","laklakan","lakmus","laknat","laknatullah","lakon","lakonik","lakonisme","lakrimator","laksa","laksamana","laksana","laksatif","laksmi","laktase","laktasi","laktat","laktogen","laktoglobulin","laktometer","lakton","laktosa","laku","lakum","lakuna","lakur","lakustrin","lala","lalah","lalai","lalak","lalandak","lalang","lalap","lalat","lalau","laler","lali","lalim","lalu","lalu-lalang","lam","lama","lamalif","laman","lamang","lamar","lamat-lamat","lambai","lambak","lamban","lambang","lambar","lambat","lambda","lambe","lambert","lambit","lambo","lambu","lambuk","lambung","lambur","lamdukpai","lamela","lamender","lamin","lamina","laminah","laminasi","laminating","lampai","lampam","lampan","lampang","lampar","lampas","lampau","lampeni","lampes","lampias","lampik","lampin","lamping","lampion","lampir","lampit","lampok","lampor","lampu","lampung","lampus","lamtoro","lamtoronisasi","lamun","lamur","lamusir","lana","lanang","lanar","lanau","lanbau","lanca","lancang","lancap","lancar","lancia","lancing","lancip","lancit","lancong","lancung","lancur","lancut","landa","landahur","landai","landak","landang","landap","landas","landau","landors","landrad","landuk","landung","landur","lang","langah","langak-languk","langau","langen","langendrian","langenswara","langgah","langgai","langgam","langgan","langgang","langgar","langgas","langgayan","langgeng","langguk","langgung","langi","langir","langis","langit","langka","langkah","langkai","langkan","langkang","langkap","langkara","langkas","langkat","langkau","langking","langkisan","langkitang","langkong","langkup","langlai","langlang","langsai","langsam","langsang","langsar","langsat","langse","langseng","langsep","langsi","langsing","langsir","langsuir","langsung","langu","langut","lanhir","lanja","lanjai","lanjak","lanjam","lanjang","lanjar","lanjau","lanji","lanjuk","lanjung","lanjur","lanjut","lanolin","lanset","lansia","lansir","lanskap","lantah","lantai","lantak","lantam","lantan","lantang","lantanum","lantar","lantas","lantera","lantesari","lantik","lantin","lanting","lantip","lantun","lantung","lantur","lanugo","lanun","lanus","lanyah","lanyak","lanyau","laocu","laos","laoteng","lap","lapah","lapak","lapang","lapar","laparoskop","laparoskopi","lapat-lapat","lapektomi","lapel","lapih","lapik","lapili","lapir","lapis","lapislazuli","lapo","lapor","laptop","lapuk","lapun","lapur","lara","larah","larai","larak","laram","larang","larap","laras","larat","larau","largisimo","largo","lari","larih","larik","laring","laringal","laringitis","laringoskop","laris","larnaks","laron","lars","laru","larung","larut","larva","larvarium","las","lasa","lasah","lasak","lasana","lasat","laser","lasi","lasinia","laskar","laso","lasparaginase","lasuh","lat","lata","latah","latak","latam","latar","latas","lateks","laten","latensi","lateral","laterit","latif","latifundium","latih","lating","latis","latma","latosol","latuh","latuk","latung","latur","lauh","lauk","laun","laung","laur","laut","lauya","lava","lavase","lavendel","lavender","lawa","lawah","lawak","lawalata","lawamah","lawan","lawang","lawar","lawas","lawat","lawazim","lawe","lawean","lawi","lawina","lawon","lawrensium","layah","layak","layam","layan","layang","layap","layar","layas","layat","layer","layon","layu","layuh","layuk","layung","layur","layut","laza","lazim","lazuardi","leak","lebah","lebai","lebak","lebam","leban","lebang","lebap","lebar","lebaran","lebas","lebat","leber","lebih","lebuh","lebuk","lebum","lebun","lebung","lebur","lecah","lecak","lecap","lecat","leceh","lecek","lecer","lecet","leci","lecit","leco","lecok","lecuh","lecun","lecup","lecur","lecut","ledak","ledang","ledek","ledeng","ledes","leding","ledos","ledre","leduk","ledung","lefa","lega","legak-legok","legal","legalisasi","legalitas","legam","legap","legar","legasi","legasteni","legat","legataris","legato","legator","lege","legek","legen","legenda","legendaris","leger","leges","leghorn","legi","legih","legio","legislasi","legislatif","legislator","legisme","legit","legitimaris","legitimas","legitimasi","legitimitas","legiun","lego","legok","legong","legu","legum","legunder","legundi","legung","legup-legup","leha-leha","lehar","leher","lei","leja","lejang","lejar","lejas","lejit","lejok","leka","lekah","lekak-lekuk","lekam","lekang","lekap","lekap-lekup","lekar","lekas","lekat","lekemia","lekir","lekit","lekok","lekosit","leksem","leksikal","leksikograf","leksikografi","leksikografis","leksikolog","leksikologi","leksikon","leksikostatistik","leksis","lekton","lektor","lektur","leku","lekuh-lekih","lekuk","lekum","lekun","lekung","lekup-lekap","lela","lelabah","lelah","lelai","lelaki","lelancur","lelang","lelangon","lelangse","lelap","lelar","lelas","lelat","lelatu","lelawa","lele","leleh","lelembut","lelemuku","lelep","leler","leles","lelet","lelewa","leli","lelonobroto","leluasa","lelucon","leluhur","leluing","lelung","lelungit","leluri","lem","lema","lemah","lemak","lemang","lemari","lemas","lemata","lemau","lembaga","lembah","lembai","lembak","lembam","lemban","lembang","lembap","lembar","lembayung","lembega","lembek","lembeng","lembidang","lembing","lembok","lembora","lembu","lembung","lembur","lemburu","lembut","lemena","lemender","lemes","lemidi","lemo","lemon","lempah","lempai","lempang","lempap","lempar","lempari","lempaung","lempem","lempenai","lempeng","lemper","lemping","lempit","lempoh","lempuh","lempuk","lempung","lempuyang","lempuyangan","lemur","lemuru","lemusir","lena","lenan","lencana","lencang","lenceng","lencet","lenci","lencir","lencit","lencong","lencun","lenda","lendaian","lendeh","lender","lendir","lendot","lendung","lendut","leng","lenga","lengah","lengai","lengak","lengan","lengang","lengar","lengas","lengat","lenge","lenggak","lenggana","lengganan","lenggang","lenggara","lenggek","lengger","lenggok","lenggong","lenggor","lenggundi","lenggut","lengit","lengkai","lengkanas","lengkang","lengkap","lengkara","lengkeng","lengkesa","lengket","lengkiang","lengking","lengkitang","lengkok","lengkong","lengkuas","lengkung","lengkur","lengoh","lengong","lengos","lengseng","lengser","lengset","lenguh","lengung","lening","lenis","lenitrik","lenja","lenjan","lenjaran","lenjing","lenjuang","lenong","lenor","lens","lensa","lenser","lenset","lenso","lentam-lentum","lentang","lentang-lentok","lenteng","lentera","lentik","lenting","lentisel","lentoid","lentok","lentong","lentuk","lentum","lentung","lentur","lentus","lenung","lenyah","lenyai","lenyak","lenyap","lenyau","lenyeh","lenyet","lenyut","leo","leonid","leontin","leot","lepa","lepai","lepak","lepang","lepap","lepas","lepat","lepau","lepe","lepek","leper","leperi","lepes","lepet","lepih","lepik","lepit","leplap","lepoh","lepok","lepot","lepra","leproma","lepromin","leproseri","leptodos","leptoskop","leptosom","lepu","lepuh","lepuk","lepur","lerah","lerai","lerak","lerang","lerap","lereng","leret","lerok","lerot","lerum","les","lesa","lesak","lesan","lesang","lesap","lesat","lesbi","lesbian","lesbianisme","leseh","lesek","leset","lesi","lesing","lesir","lesit","lesitin","lesitina","lesnar","lesot","lesplang","lestari","lestek","lesterung","lesu","lesung","lesus","lesut","leta","letai","letak","letal","letalitas","letang","letargi","lete-lete","letek","leter","leterseter","letih","letik","leting","letis","letnan","letoi","letos","letraset","letuk","letum","letung","letup","letur","letus","leuca","leukemia","leukoderma","leukofit","leukoma","leukonisia","leukopenia","leukoplakia","leukore","leukorea","leukosit","leukositometer","leukositosis","level","lever","leveransir","levertran","levirat","levitin","levulosa","lewa","lewah","lewar","lewat","lewisid","lewu","leyeh","leyot","lezat","liabilitas","lian","liana","liang","liangliong","liar","lias","liat","liau","libas","libat","libei","liberal","liberalis","liberalisasi","liberalisme","liberalistis","liberasi","liberator","libero","libidis","libido","libitum","libra","librasi","libreto","libur","licak","licau","lici","licik","licin","licurai","lid","lidah","lidas","lidi","lidid","lifo","lift","lifter","liga","ligamen","ligan","ligar","ligas","ligasi","ligat","ligatur","ligih","lignin","lignit","lignoselulosa","lignosulfonat","lignotuber","lihai","lihat","lik","likantropi","likas","likat","likir","liku","likuid","likuida","likuidasi","likuiditas","likur","likut","lil","lila","lilah","lilan","lilau","lili","lilin","liliput","lilit","lillahi","lima","liman","limar","limas","limau","limbah","limbai","limbak","limban","limbang","limbat","limbing","limbubu","limbuk","limbung","limbur","limfa","limfadema","limfadenitis","limfadenoma","limfadenosis","limfaderitis","limfangioma","limfatik","limfoblartoma","limfoblas","limfoblastoma","limfografi","limfoma","limfonodus","limfopenia","limfosit","limfositopenia","limfositosis","limit","limitasi","limitatif","limnetik","limnologi","limnoplankton","limpa","limpah","limpap","limpapas","limpas","limpau","limpit","limpoh","limpung","limun","limusin","limut","lin","linang","linau","lincah","lincak","lincam","lincir","lincun","lindak","lindang","lindap","lindas","lindik","lindis","lindu","lindung","lindur","linear","linen","ling","lingar","lingat","lingga","linggam","linggata","linggayuran","linggi","linggis","lingkap","lingkar","lingkawa","lingkis","lingkung","lingkup","linglung","lingsa","lingsang","lingsir","lingsu","lingua","linguafon","linguis","linguistik","lini","linier","linimen","lining","linjak","linoleum","linsang","lintabung","lintadu","lintah","lintang","lintap","lintar","lintas","lintibang","linting","lintir","lintuh","lintup","linu","linuhung","linyak","linyar","lio","liofilisasi","liong","liontin","lipai","lipan","lipas","lipase","lipat","lipektomi","lipemia","lipid","lipiodol","lipit","liplap","lipoksidase","lipolisis","lipoprotein","lipstik","lipu","lipur","liput","lir","lira","lirida","lirih","lirik","liris","lis","lisah","lisan","lisani","lisensi","lisimeter","lisis","lisol","lisong","lisplang","lister","listeria","listrik","lisu","lisus","lisut","litah","litak","litani","liter","literator","literer","litium","litografi","litologi","litoral","litosfer","litotes","litotomi","litsus","liturgi","liturgis","liuk","liung-liung","liur","liut","liver","liwa","liwan","liwat","liwet","loak","lob","loba","lobak","loban","loberci","lobi","lobster","locok","locot","lodan","lodeh","lodoh","lodong","log","logam","logaritma","logat","logawiah","logika","logis","logistik","logo","logogram","logopedia","logotip","loh","loha","lohok","lohor","loji","lok","loka","lokacipta","lokakarya","lokal","lokalis","lokalisasi","lokan","lokananta","lokap","lokasi","lokastiti","lokatif","lokatikranta","lokatraya","lokawarta","lokawidura","lokawigna","lokawiruda","lokawisata","lokcuan","lokek","lokeswara","loket","loki","lokia","lokika","lokio","loklok","lokomobil","lokomotif","lokos","loksek","loksun","loktong","lokus","lokusi","lolak","loleng","loloh","lolohan","lolong","lolos","lomba","lombar","lombok","lombong","lomek","lomot","lompat","lompayang","lompok","lompong","lonan","loncat","loncek","lonceng","loncer","lonco","loncos","londang","londong","loneng","long","longak-longok","longdres","longgar","longgok","longgor","longitudinal","longo","longok","longong","longser","longsor","longtorso","lonjak","lonjong","lonjor","lonsong","lontai","lontang-lanting","lontang-lantung","lontar","lontara","lonte","lontok","lontong","lonyok","lop","lopak","lopek","loper","lopis","lopor","lor","lorah","loran","lorat","lorber","lorek","loreng","lori","lornyet","lorong","lorot","los","lose","losin","losion","losmen","loso","losong","lot","lota","lotak","lotek","loteng","lotis","lotong","lotre","lotus","lowong","loya","loyak","loyal","loyalis","loyalitas","loyang","loyar","loyo","loyong","lozenge","luah","luak","luang","luap","luar","luas","luat","luban","lubang","luber","lubuk","lucah","lucu","lucup","lucut","ludah","ludat","ludes","luding","ludruk","lues","lugas","lugu","lugut","luhak","luhmahful","luhung","luhur","luih","luik","luing","luk","luka","lukah","lukat","lukeh","lukis","luks","luku","lukut","lulai","luli","luluh","luluk","lulum","lulup","lulur","lulus","lulut","lum","lumai","lumang","lumar","lumas","lumat","lumayan","lumba-lumba","lumbal","lumbu","lumbung","lumen","lumer","lumi-lumi","luminositas","lumpang","lumpektomi","lumpia","lumping","lumpuh","lumpuk","lumpur","lumrah","lumsum","lumuh","lumur","lumus","lumut","lunak","lunas","lunau","luncai","luncas","luncung","luncur","lundang","lundi","lundu","luner","lung","lungguh","lungkah","lungkang","lungkum","lunglai","lunglung","lungsar","lungse","lungsin","lungsung","lungsur","lungun","lunjur","lunta","luntang","luntang-lantung","luntas","luntur","lunyah","lunyai","lup","lupa","lupat","lupi","lupuh","lupuk","lupung","lupus","luput","lurah","lurik","luru","lurub","luruh","lurus","lurut","lus","lusa","lusin","lustrum","lusuh","lut","lutetium","luti","lutu","lutung","lutut","luweng","luwes","luyak","luyu","luyut","maab","maaf","mabriuk","mabrur","mabuh","mabuk","mabul","macakal","macam","macan","macapat","mace","macet","macis","mad","mada","madah","madali","madam","madang","madani","madar","madat","madewi","madi","madia","madik","madinding","madmadah","mado","madona","madras","madrasah","madu","madukara","madumangsa","madya","maesan","maesenas","maestro","mafela","mafhum","mafia","mafioso","mafsadah","mafsadat","mag","magainin","magalah","magandi","magang","magasin","magel","magenta","magersari","magfirah","magfirat","magi","magis","magister","magistrat","maglub","magma","magnesium","magnesol","magnet","magnetik","magnetika","magnetis","magnetisme","magnetit","magnetometer","magnetor","magnetostatika","magnitudo","magrib","magribi","magrur","magun","mah","maha","mahabah","mahabintang","mahadewa","mahadewi","mahaduta","mahaguru","mahah","mahajana","mahakala","mahakarya","mahakuasa","mahal","mahamen","mahamenteri","mahamulia","mahang","mahaparana","mahapatih","mahar","maharaja","maharajalela","maharana","maharani","mahardika","maharesi","maharupa","mahasiswa","mahasiswi","mahasuci","mahatahu","mahatma","mahatur","mahayana","mahbub","mahbubah","mahbubat","mahdi","maherat","mahesa","maheswara","mahfuz","mahia","mahimahi","mahir","mahkamah","mahkota","mahligai","mahmud","mahoni","mahraj","mahram","mahsul","mahsyar","mahwu","mahyong","mahzurat","mai","maido","maimun","main","mair","mairat","maizena","maja","majaan","majakane","majakaya","majakeling","majal","majalah","majas","majasi","majati","majedub","majekeling","majelis","majemuk","majenun","majikan","majir","majizat","majong","maju","majuh","majuj","majun","majung","majusi","maka","makadam","makadasang","makadok","makalah","makalangkang","makam","makan","makantah","makantuh","makanya","makao","makaopo","makar","makara","makaroni","makas","makbud","makbul","makcik","makcomblang","makda","makdan","makelar","makerel","maket","makhdum","makhluk","makhraj","maki","makin","making","makiyah","makjuj","maklaf","maklum","maklumat","maklun","makmal","makmum","makmur","makna","maknawi","makramat","makrame","makrifat","makrifatullah","makro","makroekonomi","makrofita","makrofotografi","makroftalmus","makrogametosit","makrohistori","makrokosmos","makrokriminologi","makrolinguistik","makromelia","makrometeorologi","makromolekul","makrosefalik","makroskopis","makrosmatik","makrosmatis","makrososiologi","makruf","makruh","maksi","maksiat","maksila","maksim","maksimal","maksimum","maksud","maksum","maktab","maktub","makua","makul","makula","makulat","makurung","makuta","makyong","makzul","mal","mala","malabau","malabsorpsi","malafide","malafungsi","malagandang","malagizi","malah","malai","malaik","malaikat","malaikatulmaut","malaise","malak","malaka","malakama","malakat","malakit","malakofili","malakologi","malakut","malam","malan","malang","malangbang","malap","malapari","malapetaka","malapraktek","malapraktik","malar","malaria","malas","malasia","malasuai","malatindak","malau","maldistribusi","male","maleman","maleo","maleolus","mali-mali","maligai","malih","malik","maliki","malikuljabar","malikulmuluk","malim","maling","malis","malisol","malka","malnutrisi","maloklusi","malt","maltase","maltosa","malu","malun","malung","mam","mama","mamah","mamai","mamak","mamalia","maman","mamanah","mamanda","mamang","mamano","mamat","mambang","mambek","mambo","mambruk","mambu","mambung","mamduhah","mami","mamik","mamlakat","mamografi","mampai","mampat","mampir","mampu","mampung","mampus","mamut","man","mana","manah","manai","manajemen","manajer","manajerial","manakala","manakan","manakib","manalagi","manasik","manasongo","manasuka","manau","mancanegara","mancawarna","manci","mancis","mancung","mancur","manda","mandah","mandai","mandala","mandalika","mandam","mandar","mandarin","mandat","mandataris","mandau","mandeh","mandek","mandelevium","mandi","mandibula","mandil","mandir","mandiri","mandolin","mandor","mandraguna","mandril","mandrin","mandul","mandung","maneken","manerisme","manfaat","mang","mangan","mangap","mangas","mangau","mangayubagya","mangga","manggah","manggala","manggar","manggis","manggung","mangir","mangkak","mangkanya","mangkar","mangkas","mangkat","mangkel","mangkih","mangkir","mangkok","mangkubumi","mangkuk","mangkus","mangsa","mangsi","mangu","mangun","mangut","mani","mania","maniak","manifes","manifestasi","manifesto","manik","manik-depresif","manikam","manikdepresi","manikmaya","manikur","manila","manimba","manipol","manipulasi","manipulatif","manipulator","manira","manis","manise","manja","manjapada","manjau","manjeri","manjing","manjung","manjur","manol","manometer","manora","manostat","manset","mansiang","mansukh","manta","mantan","mantap","mantari","mantel","manten","manti","mantik","mantiki","mantisa","mantissa","mantra","mantram","mantri","mantu","mantuk","manual","manufaktur","manufakturing","manuk","manumisio","manumpak","manunggal","manusia","manusiawi","manuskrip","manut","manuver","manuwa","manyala","manyar","manzil","manzilah","maois","map","mapak","mapalus","mapan","mar","mara","marah","maraja","marak","marakas","marambung","maramus","maranta","marapulai","maras","maraton","marbling","marbut","marcapada","mardatilah","mardatillah","mardud","mare","marem","maret","marfuk","marga","margalit","margarin","margasatwa","margin","marginal","marginalisasi","marginalisme","margrit","marhaban","marhaen","marhaenis","marhaenisme","marhum","marhumah","mari","maria","marikan","marikh","marikultur","marimu","marina","marinade","marine","marinir","marinyo","marinyu","marital","maritim","mariyuana","marjik","marjinal","mark","marka","markado","markah","markas","markasit","marketri","markis","markisa","markoni","markonis","markusip","marlin","marmelade","marmer","marmot","maro","marpaud","mars","marsaoleh","marsekal","marsepen","marsose","martabak","martaban","martabat","martandang","martil","martini","martir","maru","marus","marut","marwas","marxisme","marzipan","mas","masa","masai","masak","masakan","masakat","masala","masalah","masam","masap","masase","masayu","masbuk","masdar","masehi","masektomi","maser","maserasi","mashaf","masif","masih","masin","masinal","masing-masing","masinis","masir","masjid","masjidilaksa","masjidilharam","maskanat","maskapai","maskara","maskat","maskawin","masker","maskodok","maskon","maskot","maskulin","maskulinitas","maskumambang","maslahat","masnawi","masohi","masoi","masokhis","masokhisme","masokisme","mason","masori","masrum","massa","massal","mastautin","mastektomi","master","masterplan","mastik","mastitis","mastodon","mastuli","masturbasi","masuk","masuliah","masya","masyakah","masyarakat","masygul","masyhadat","masyhur","masyrik","masyuk","mat","mata","matador","matahari","matakao","matalamat","matan","matang","mate","matematika","matematikus","matematis","materi","material","materialistis","materiil","mati","matine","matlak","matoa","maton","matra","matras","matres","matriarkal","matriarkat","matriks","matrikulasi","matrilineal","matrilokal","matris","matronim","matros","matu","matur","maturasi","maturitas","mau","mauizah","maujud","maujudat","maukhid","maukif","maukuf","maula","maulai","maulana","maulhayat","maulid","maulidurasul","maulud","maung","maupun","mausoleum","maut","mauz","mawadah","mawar","mawas","maweda","mawin","mawon","mawut","maya","mayam","mayang","mayangda","mayapada","mayas","mayat","mayeng","mayokratio","mayones","mayor","mayoret","mayoritas","mayung","mayur","mazarin","mazbah","mazhab","mazi","mazkur","mazmumah","mazmur","mbah","mbak","mbakyu","mbeling","mbok","mbokmas","meander","mebel","mecis","medali","medalion","medan","medang","mede","media","medial","median","mediasi","mediastinum","mediator","medik","medikamentosa","medikasi","mediko","medikolegal","medikus","medil","medio","medis","medisinal","medit","meditasi","mediterania","medium","medok","medu","medula","medusa","mega","megabyte","megafon","megah","megak","megakredit","megal-megol","megalit","megalitikum","megalomania","megalomaniak","megalopolis","megalosit","megamerger","megan","megaohm","megap-megap","megapolis","megaproyek","megar","megaspora","megasporangium","megasporofil","megat","megaton","megatren","megatruh","megawatt","meger","megrek-megrek","mei","meiosis","meja","mejam","mejan","mejana","mejeng","mek","mekanik","mekanika","mekanikgraha","mekanis","mekanisasi","mekanisme","mekanolinguistik","mekap","mekar","meko","mekonium","mel","melabuai","melambang","melamin","melanesia","melangkup","melanin","melanisme","melankolia","melankolis","melankonis","melanoderma","melar","melarat","melas","melase","melasma","melati","melawah","melayu","melek","melela","melempem","meleng","meler","melesek","meleset","melik","melilin","melinjo","melintir","melit","melitofili","meliwis","melodi","melodika","melodius","melodrama","melodramatik","melodramatis","melompong","melon","melor","melotot","melpari","melukut","melulu","melur","mem","memang","memar","membal","memble","membran","memedi","memek","memelas","memo","memoar","memorabilia","memorandum","memorat","memori","memorial","mempan","mempelai","mempelam","mempelas","mempelasari","mempening","memper","mempitis","memplak","mempurung","memutah","mena","menaga","menak","menampun","menang","menantu","menara","menat","mencak","mencelat","menceng","menceret","mencit","mencla-mencle","menclok","mencok","mencong","mencos","mencret","mendak","mendap","mendapa","mendeleka","mendelevium","mendeng","mendiang","mendikai","mending","mendira","mendoan","mendonan","mendong","mendreng","mendu","mendung","mendur","mendura","mendut","menep","menepaat","mengah","mengangah","mengap","mengapa","mengapmendam","mengeh","mengerawan","mengerna","menget","mengga","menggala","menggusta","mengi","mengiang","mengicip","mengirat","mengkal","mengkali","mengkara","mengkaras","mengkelan","mengkerang","mengkeret","mengking","mengkirai","mengkirik","mengkis","mengkona","mengkuang","mengkudu","mengok","mengor","mengot","mengsol","mengsong","mengung","menhir","meni","meningitis","menir","meniran","meniskus","menit","menjangan","menong","menopause","menor","menoragia","menostaksis","mens","menserendahi","mensiang","menstruasi","mensurasi","mentah","mentak","mental","mentalitas","mentang","mentari","mentaruh","mentas","mentaus","mentega","menteleng","menteng","mentereng","menteri","mentibu","mentifakta","mentigi","mentilau","mentimun","mentis","mentok","mentol","mentolo","mentor","mentora","mentua","mentul","menu","menuet","menung","menur","meong","mepet","meracang","meraga","meragi","merah","merajak","merak","merakan","meralgia","merambai","merambung","merana","merang","meranggi","merangsi","merangu","meranti","merapu","merat","merawal","merawan","merbah","merbau","merbaya","merbuk","merbulan","mercak-mercik","mercon","mercu","mercusuar","merdangga","merdeka","merdesa","merdinah","merdu","merduk","mere","merek","mereka","merem","merembung","mereng","meres","mergat","merger","mergul","meri","meriam","meriang","merica","meridian","merih","merik","merikan","merikarp","merinding","mering","meristem","merjan","merkah","merkantilisme","merkubang","merkuri","merkurium","merkurius","merkuro","merkurokrom","merlilin","merlimau","merogoni","merosot","merot","merpati","merpaud","merpitis","merpoyan","merserisasi","mersik","merta","mertamu","mertapal","mertayam","mertega","mertelu","mertua","meru","meruap","merubi","merunggai","merut","merwatin","mes","mesa","mesan","mesara","mesem","mesin","mesiu","mesjid","meskalin","meskalina","meski","mesmerisme","mesoderm","mesodermik","mesofili","mesofit","mesolitik","mesolitikum","mesometeorologi","mesomorf","meson","mesopause","mesosfer","mesotel","mesotoraks","mesozoa","mesozoikum","mesra","mester","mesti","mestika","mestizo","mesui","mesum","mesut","meta","metabahasa","metabolik","metabolis","metabolisme","metabolit","metafil","metafisik","metafisika","metafora","metaforis","metah","metai","metal","metalik","metalinguistik","metalografi","metaloid","metalurgi","metalurgis","metamorf","metamorfis","metamorfisme","metamorfosis","metana","metanefros","metanol","metari","metasenter","metastasis","metatarsus","metatesis","metazoa","mete","meteor","meteorit","meteorograf","meteorogram","meteoroid","meteorologi","meteorologis","meter","meterai","metil","metode","metodik","metodis","metodologi","metonimi","metonimia","metrik","metris","metro","metrologi","metromini","metronimik","metronom","metronomis","metropolis","metropolisasi","metropolitan","metroragia","metrum","meunasah","mewah","mewari","mewek","mezanin","mezbah","mezosopran","mi","miak","miana","miang","miap","miasma","midar","midi","midik","midodareni","mieloma","migrain","migran","migrasi","migren","mihrab","mihun","miiofili","mijil","miju","mik","mika","mikat","mikologi","mikoprotein","mikosis","mikotoksin","mikraj","mikro","mikroanalisis","mikroangiopati","mikrob","mikrobe","mikrobiologi","mikrobiologis","mikrobisida","mikrobus","mikroekonomi","mikroelektronika","mikroelemen","mikrofag","mikrofarad","mikrofilm","mikrofita","mikrofon","mikrofotografi","mikrogelombang","mikrograf","mikrografika","mikrogram","mikrohabitat","mikrohistori","mikrohm","mikroklimat","mikrokomputer","mikrokosmos","mikrolet","mikrolinguistik","mikrolit","mikrom","mikromanipulasi","mikrometer","mikrometri","mikron","mikroorganisme","mikroprosesor","mikrosefalia","mikrosekon","mikroskop","mikroskopis","mikrospora","mikrotom","mikrovilus","mikrowatt","mikser","miksoedema","mil","milad","milenium","miliampere","miliar","miliarder","miliaria","milibar","milieu","miligram","milik","mililiter","milimeter","milimikron","milimol","milioner","milir","milisi","militan","militansi","militer","militerisme","militeristis","miliun","miliuner","milivolt","milu","mim","mimbar","mimeograf","mimesis","mimi","mimik","mimikri","mimis","mimisan","mimosa","mimpi","min","mina","minangsraya","minat","minder","mindi","mindoan","mindring","mineral","mineralisasi","mineralogi","mineralogis","minggat","minggir","minggu","minhaj","mini","miniatur","minibasket","minibus","minikar","minikata","minikomputer","minim","minimal","minimarket","minimum","minium","minor","minoritas","minta","mintak","mintakat","mintakulburuj","mintal","minterat","mintuna","minum","minus","minyak","mioglobin","miokardia","mioma","miop","miopia","miosis","miotik","mipis","mirah","mirai","mirakel","mirat","miriapod","mirih","mirik","miring","mirip","miris","mirmekofag","mirmekofili","mirmekologi","misa","misai","misal","misan","misantrop","misbah","misdinar","misi","misil","misiologi","misionaris","misioner","miskal","miskin","miskram","misoa","misofobia","misogami","misoginis","mispersepsi","miss","mistar","mister","misteri","misterius","mistik","mistis","mistisisme","mistri","misuh","miswat","mitasi","mite","mitisida","mitogen","mitologi","mitologis","mitos","mitosis","mitra","mitraliur","mizab","mizan","mnemonik","moa","mob","mobil","mobilet","mobilisasi","mobilisator","mobilitas","moblong","mobokrasi","mochi","modal","modalitas","modar","mode","model","modeling","modem","moderamen","moderat","moderato","moderator","modern","modernisasi","modernisme","modernitas","modernomaniak","modifikasi","modifikatif","modin","modis","modiste","modol","modul","modular","modulasi","modulator","modus","mofet","moga","mogok","mohair","mohon","mohor","mojah","mojang","mok","moka","mokal","moke","moko","moksa","mol","mola","molar","mole","molek","molekul","molekuler","moler","moles","molibden","molibdenum","molor","molos","molotov","moluska","momen","momental","momentum","momok","momong","momot","monarki","moncong","moncor","mondar-mandir","mondeling","mondial","mondok","mondolan","mondong","monel","moneter","mong","monggo","monggol","mongkok","mongmong","mongolisme","mongoloid","monisme","monitor","mono","monoatom","monodi","monodrama","monofag","monofobia","monofonir","monogam","monogami","monogini","monografi","monogram","monokarpa","monokel","monokini","monoklin","monoklinal","monokotil","monokotiledon","monokrasi","monokrom","monokromatis","monokromator","monoksida","monokultur","monolingual","monolit","monolitik","monolog","monoloyalitas","monomania","monomer","monoploid","monopoli","monopolistik","monopsoni","monorel","monosakarida","monosem","monosemantik","monosemi","monosilabel","monosilabisme","monosit","monospermi","monoteis","monoteisme","monotipe","monoton","monsinyur","monster","monstera","monsun","montase","montering","montir","montit","montok","monumen","monumental","monyet","monyong","monyos","mop","mopela","mopit","morak","moral","moralis","moralisasi","moralisme","moralistis","moralitas","morat-marit","moratorium","morbiditas","morbili","mordan","moreng","mores","morf","morfem","morfemik","morfemis","morfin","morfinis","morfofonem","morfofonemik","morfofonemis","morfofonologi","morfogenesis","morfologi","mori","moril","mormon","moron","morong","morse","mortalitas","mortar","mortir","mosaik","mosi","mosok","moster","mota","motel","motif","motivasi","motivator","moto","motor","motorik","motoris","motorisasi","motorsaikel","moyang","mozah","mozaik","mu","mua","muadin","muai","muak","muakadah","mual","mualaf","mualamat","mualif","mualim","muamalah","muamalat","muanas","muara","muarikh","muas","muasasah","muasir","muat","muazam","muazin","mubah","mubalig","mubaligah","mubarak","mubarat","mubazir","mubtadi","mubut","mucikari","mud","muda","mudah","mudakar","mudarabah","mudarat","mudasir","mudat","mudigah","mudik","mudra","mudun","mufaham","mufakat","mufarik","mufasal","mufasir","muflis","mufrad","mufsidin","mufti","mugabat","muhabah","muhadarah","muhadat","muhajat","muhajir","muhajirin","muhal","muhalil","muhami","muhammad","muharam","muhasabah","muhib","muhibah","muhit","muhlikah","muhrim","muhsin","muhtasyam","muih","mujadalah","mujadid","mujahadat","mujahid","mujahidin","mujair","mujang","mujarab","mujarad","mujari","mujbir","mujtahid","mujtamak","mujur","muk","muka","mukabalah","mukadam","mukadas","mukadim","mukadimah","mukadin","mukadis","mukah","mukalaf","mukalid","mukaram","mukatabah","mukena","mukhabarah","mukhalaf","mukhalafah","mukhalif","mukhalis","mukhlis","mukhtasar","mukibat","mukim","mukimin","mukjizat","mukmin","mukminat","mukminin","mukoprotein","mukosa","mukositis","muktabar","muktamad","muktamar","muktamirin","muktazilah","mukun","mula","mulai","mulakat","mulamasah","mulas","mulat","mulato","mulazamah","mulhid","mulia","mullah","mulsa","multazam","multibahasa","multidimensi","multidisipliner","multietnik","multifaset","multifungsi","multigravida","multiguna","multikompleks","multikrisis","multikultur","multikulturalisme","multilateral","multilingual","multilingualisme","multimedia","multimeter","multimilioner","multinasional","multinegara","multiorgan","multipara","multipel","multipleks","multiplikasi","multiplikator","multipolar","multiprosesor","multirasial","multirasialisme","multiseluler","multivalen","multivalensi","multivitamin","muluk","mulur","mulus","mulut","mumayiz","mumbang","mumbul","mumbung","mumet","mumi","mumifikasi","mumpung","mumpuni","mumuk","mumur","mumut","munafik","munafikin","munajat","munajim","munasabah","muncang","munci","muncikari","muncrat","muncul","muncus","mundam","munding","mundu","mundur","mung","munggu","munggur","mungil","mungkar","mungkin","mungkir","mungkum","mungkur","mungmung","mungsi","mungut","munib","munjung","muno","munsyi","muntaber","muntah","muntaha","muntu","muntul","muntup","munyuk","muon","mupaham","muparik","mupus","mur","mura","murad","muradif","murah","murai","murakab","murakabi","mural","muram","murang","muras","murba","murbei","murca","muri","murid","muring","muris","murka","murni","mursal","mursyid","murtad","muruah","murung","murup","murus","mus","musaadah","musabab","musabaqah","musafir","musafirin","musakat","musala","musang","musara","museolog","museologi","museum","mushaf","musibah","musik","musikal","musikalisasi","musikalitas","musikolog","musikologi","musikologis","musikus","musim","musisi","muskil","muskovit","muslih","muslihat","muslim","muslimat","muslimin","muslin","musnah","muspra","mustahak","mustahik","mustahil","mustaid","mustajab","mustak","mustaka","mustakim","mustamik","mustang","musuh","musyarakah","musyarakat","musyarik","musyawarah","musyawarat","musyrik","musyrikin","musytak","musytari","mutabar","mutagen","mutah","mutakadim","mutakalim","mutakhir","mutaki","mutalaah","mutamad","mutan","mutasawif","mutasi","mutawif","mute","mutiara","mutih","mutilasi","mutisme","mutlak","mutmainah","mutu","mutualisme","mutung","muwafakat","muwahid","muwajahah","muwakal","muwakil","muwari","muzah","muzakar","muzakarah","muzaki","muzamil","muzawir","muzhab","naam","nabatah","nabati","nabi","nabtun","nabu","nada","nadi","nadim","nadir","naf","nafar","nafas","nafi","nafiri","nafkah","nafsi","nafsu","nafta","naftal","naftalena","naftena","naftol","naga","nagam","nagara","nagari","nagasari","nahak","nahas","nahdiyin","nahi","nahkoda","nahu","naib","naif","naik","naim","najam","najasah","najasat","najis","nak","naka","nakal","nakara","nakhoda","nal","nala","nalam","nalar","nali","nalih","naluri","naluriah","nama","namaskara","namatad","namatium","nambi","namnam","nampan","namun","nan","nanah","nanang","nanap","nanaplankton","nanar","nanas","nandu","nandung","nang","nangka","nangkoda","nangkring","nangui","naning","nanofarad","nanofosil","nanogram","nanometer","nanti","napal","napalm","napas","napuh","naqal","naqli","nara","narablog","narapati","narapidana","narapraja","narasi","narasumber","naratif","narator","narkolepsi","narkomaniak","narkose","narkosis","narkotik","narpati","narsis","narsisisme","narsisme","narwastu","nas","nasab","nasabah","nasakh","nasal","nasalisasi","nasar","nasehat","nasel","nasi","nasib","nasihat","nasion","nasional","nasionalis","nasionalisasi","nasionalisme","nasionalistis","nasionisme","naskah","nasofaring","nasrani","nasti","nasut","natal","natalis","natalitas","natang","natar","natijah","nativis","nativisme","nativistik","natolokal","natrium","natur","natura","natural","naturalis","naturalisasi","naturalisme","naturalistis","naturopatis","naung","nauplius","nausea","nautik","nautika","nautikal","nautilus","nauzubillah","navigasi","navigator","nawa","nawaitu","nawala","nawalapradata","nayaka","nayam","nayap","nazam","nazar","nazi","naziisme","nazim","nazir","ndoro","ndoroisme","neala","nealogi","nebeng","nebula","nebulium","neces","necis","nefoskop","nefrektomi","nefridium","nefrit","nefritis","nefroblastoma","nefrologi","nefron","nefrosis","negara","negasi","negatif","negativisme","negativistik","neger","negeri","negosi","negosiasi","negosiator","negrito","negro","negroid","negus","neka","nekad","nekara","nekat","nekel","neko","nekrofag","nekrofagus","nekrofili","nekrofilia","nekrogeografi","nekrolog","nekrologi","nekromansi","nekropolis","nekropsi","nekrosis","neksus","nektar","nelangsa","nelayan","nemagon","nematoda","nematologi","nematosida","nematosis","nenda","nendatan","nenek","nenekanda","nenen","nenenda","nener","nenes","neng","neodarwinisme","neodimium","neofeodalisme","neofeodalistis","neoiknologi","neoimpresionisme","neokarpi","neoklasik","neoklasisisme","neoklasisme","neokolonialisme","neoliberalisme","neolit","neolitik","neolitikum","neologi","neologisme","neolokal","neon","neonatal","neonatus","neontologi","neoplasma","neoplatonisme","neoprena","neositosis","neotipologi","neovirus","neozoikum","nepotis","nepotisme","neptunium","neptunus","neraca","nerak","neraka","neritik","neritopelagik","neritoplankton","neroglia","nervasi","nervur","nesa","nestapa","nestor","net","neting","neto","netra","netral","netralis","netralisasi","netralisme","netralitas","neural","neuralgia","neurastenia","neuritis","neuroblastoma","neuroglia","neurolinguistik","neurolog","neurologi","neurologis","neuron","neurosis","neurotik","neurotransmiter","neustonologi","neutrino","neutron","newton","ngabei","ngaben","ngablak","ngabur","ngakngikngok","ngalau","ngalor-ngidul","nganga","ngap-ngap","ngapain","ngarai","ngeang","ngebet","ngebut","ngeceng","ngeden","ngedumel","ngelindur","ngemil","ngenas","ngengat","ngenyek","ngeong","ngeres","ngeri","ngiang","ngilu","ngoko","ngos-ngosan","ngot-ngotan","ngowos","ngoyo","ngung","nia","niaga","nian","niasin","niat","nibung","nica","nidasi","nidera","nidikola","nidulus","nifak","nifas","nih","nihil","nihilis","nihilisme","nijas","nik","nikah","nikel","nikmat","nikotin","niktigami","nila","nilai","nilakandi","nilam","nilau","nilon","nimbostratus","nimbrung","nimfomania","ninabobo","ning","ningnong","ningrat","nini","ninik","ninitowok","niobium","nipah","nipis","nira","niraksara","nirgagasan","nirgesekan","nirguna","nirkabel","nirlaba","nirleka","nirmala","nirselera","nirwana","nirwarta","nisab","nisan","nisbah","nisbi","niscaya","niskala","nista","nistagmus","nistatin","nitrat","nitrifikasi","nitrobenzena","nitrofili","nitrofit","nitrogen","nitrogliserin","nitroselulosa","niyaga","noa","nobat","nobelium","noda","nodulus","nodus","noem","noja","noken","noktah","nokturia","nokturnal","nol","nomad","nomenklatur","nomina","nominal","nominalisasi","nominalisme","nominasi","nominatif","nominator","nomine","nomogram","nomokrasi","nomor","nomplok","non","nona","nonagresi","nonaktif","nonblok","nondepartemen","nondepartemental","none","nonekonomi","noneksakta","nonfiksi","nonformal","nong-nong","nongol","nongrata","nonhistoris","noni","nonilium","nonindustri","nonintervensi","nonius","nonkimia","nonkombatan","nonkonvensional","nonkooperasi","nonkooperatif","nonmedis","nonmigas","nonmiliter","nonok","nonol","nonong","nonpatogenik","nonpemerintah","nonpolitik","nonpredikatif","nonpribumi","nonproduktif","nonprofit","nonprotein","nonsens","nonsilabis","nonstandar","nonstop","nonteknis","nontradisional","nonverbal","nopek","norak","norit","norma","normal","normalisasi","normatif","nosologi","nostalgia","nostrum","not","nota","notabene","notariat","notaris","notasi","notes","notifikasi","notok","notula","notulis","nova","novel","novela","novelet","novelis","november","novena","novokaina","nrima","nuansa","nubuat","nudis","nudisme","nugat","nugraha","nujum","nukil","nukleat","nukleolus","nukleon","nukleoprotein","nukleus","nuklida","nuklir","nulipara","numeralia","numerik","numeris","numismatika","nun","nunatak","nung","nunsius","nunut","nur","nuraga","nurani","nurbisa","nuri","nuriah","nus","nusa","nusaindah","nusakambangan","nusantara","nusyu","nusyus","nutan","nutasi","nutfah","nutriea","nutrisi","nutrisionis","nutrisisme","nuzul","nuzulul","nyai","nyak","nyala","nyalang","nyalar","nyalawadi","nyale","nyali","nyaman","nyambing","nyamik","nyamleng","nyampang","nyamplung","nyamuk","nyamur","nyana","nyang","nyanya","nyanyah","nyanyang","nyanyar","nyanyi","nyanyu","nyanyuk","nyapang","nyapnyap","nyarang","nyarik","nyaring","nyaris","nyata","nyatuh","nyawa","nyawang","nyelekit","nyemplong","nyentrik","nyenyai","nyenyak","nyenyat","nyenyeh","nyenyep","nyenyet","nyepi","nyeri","nyerocos","nyi","nyilih","nyingnying","nyinyir","nyiri","nyiru","nyit","nyiur","nyolnyolan","nyolo","nyoman","nyong","nyonya","nyonyeh","nyonyong","nyonyor","nyungsung","nyunyut","nyureng","nyut","oase","oasis","obar","obat","obduksi","obelisk","obeng","obesitas","obi","obituarium","objek","objektif","objektivisme","objektivitas","oblak","oblasi","obligasi","oblong","obo","obor","obral","obras","obrol","obrus","observasi","observatorium","obsesi","obsesif","obsidian","obsolet","obstetri","obstruen","obstruksi","obversi","obviatif","obyek","obyektif","obyektivisme","obyektivitas","oceh","odalan","ode","odekolonye","odinometer","oditur","odoh","odol","odometer","odontoblas","odontoid","odontologi","odoran","oedipus-kompleks","oersted","ofensif","oferte","ofisial","ofset","oftalmia","oftalmoskop","oga","ogah","ogah-agih","ogak-agik","ogak-ogak","ogam","ogel","ogok","ogonium","ohm","ohmmeter","oikumene","oja","ojeg","ojek","ojok","okarina","oke","oker","oklokrasi","oklusi","oklusif","oknum","okok","oksalat","oksiasetilena","oksida","oksidan","oksidasi","oksidator","oksigen","oksigenase","oksimoron","oksitetrasiklin","oksiton","oktaf","oktagon","oktahedron","oktal","oktana","oktet","oktober","oktroi","okulasi","okuler","okulis","okultis","okultisme","okupasi","okupasional","olah","olahraga","olak","olak-alik","olanda","olang-aling","oleander","olefin","oleh","olek","oleng","oleografi","oleometer","oleovitamin","oles","olet","oleum","oli","olia","oligarki","oligofagus","oligofrenia","oligopoli","oligopolistis","oligopsoni","oligosen","oligositemia","oligotrofik","oliman","olimpiade","oliva","olivin","olok","olong-olong","om","oma","ombak","ombang-ambing","ombyok","omega","omel","omikron","omnibus","omnivor","omnivora","omong","ompol","ompong","ompreng","omprong","ompu","omset","omslah","omzet","onagata","onak","onani","onar","oncat","once","oncek","oncen","oncer","oncom","oncor","onde-onde","ondel-ondel","onder","onderdil","onderdistrik","onderneming","onderok","ondo","ondoafi","ondok","ondos","oneng-oneng","ong","ongahangih","ongeh","onggok","ongji","ongkang","ongkok","ongkos","ongok","ongol-ongol","oniks","onkogen","onkologi","onomasiologi","onomastika","onomatologi","onomatope","ons","onslah","ontogeni","ontologi","ontologis","ontran-ontran","onyah-anyih","onyak-anyik","onyang","onyok","onyot","oogenesis","oolit","opa","opak","opak-apik","opal","opalesen","opas","opasitas","opelet","open","opendim","openkap","oper","opera","operasi","operasional","operasionalisasi","operatif","operator","operet","operkulum","opini","opisometer","opium","oplah","oplet","oplos","opmak","opname","oponen","opor","oportunis","oportunisme","oportunistis","oportunitas","oposan","oposisi","oppo","opsen","opseter","opsi","opsin","opsinder","opsiner","opsional","opsir","opstal","optatif","optik","optika","optimal","optimalisasi","optimis","optimisme","optimistis","optimum","optis","optisien","optoelektronika","optometri","optometris","opus","orak","orak-arik","orakel","oral","oralit","orang","orang-aring","oranye","orasi","orat-oret","orator","oratoria","oratoris","oratorium","orbit","orbita","orbital","orde","order","ordi","ordinal","ordinasi","ordinat","ordiner","ordner","ordo","ordonans","ordonansi","oren","oreng","oreol","oret","organ","organdi","organel","organik","organis","organisasi","organisator","organisatoris","organisir","organisme","organismus","organogram","organon","orgasme","orgasmik","orgel","orien","oriental","orientalis","orientasi","origami","orion","orisinal","orisinalitas","orkes","orkestra","orkestrasi","ornamen","ornamental","ornamentasi","ornitologi","ornitologis","ornitosis","orografi","orografik","orografis","orok","orong-orong","ortodidaktik","ortodoks","ortodoksi","ortodrom","ortoepi","ortografi","ortografis","ortoklas","ortopedagogik","ortopedi","ortopedis","ose","osean","oseanarium","oseanografi","oseanologi","osifikasi","osikel","osilasi","osilator","osilograf","osilogram","osiloskop","oskilator","oskulum","osmium","osmometer","osmoregulasi","osmose","osmosis","osomosis","ostentasi","osteoblas","osteoklas","osteologi","osteopati","osteoporosis","ostium","otak","otak-atik","otak-otak","otar","otek","otentik","oto","otobus","otofon","otologi","otomat","otomatis","otomatisasi","otomobil","otomotif","otonom","otonomi","otopet","otorisasi","otoritas","otoriter","otoritet","otoskop","otot","ototipi","oval","ovarium","ovasi","oven","over","overaktif","overakting","overal","overdosis","overkompensasi","overpopulasi","overproduksi","oversimplifikasi","overste","oviduk","ovipar","oviparitas","ovipositor","ovitesis","ovovivipar","ovulasi","ovulum","ovum","oyak","oyek","oyok","oyong","oyot","ozokerit","ozon","ozonisasi","ozonisator","ozonometer","pabean","pabrik","pabrikan","pabrikasi","pacai","pacak","pacal","pacangan","pacar","pacat","pacau","pace","pacek","paceklik","pacet","pacih","pacik","pacok","pacu","pacuk","pacul","pada","padah","padahal","padak","padam","padan","padang","padas","padasan","padat","padepokan","padi","padma","padmasana","padmi","padri","padu","padudan","paduk","paduka","paduraksa","paedofil","paes","pagan","paganisme","pagar","pagas","pagebluk","pagelaran","pagi","pagina","pagoda","pagon","pagositosis","pagu","pagun","pagupon","pagut","paguyuban","pah","paha","pahala","paham","pahang","pahar","pahat","paheman","pahit","pahlawan","pahter","pai","paidon","pail","pailit","paing","paip","pair","pais","paitua","paja","pajak","pajan","pajang","pajuan","pajuh","pakai","pakal","pakan","pakanira","pakansi","pakar","pakaryan","pakat","pakau","pakcik","pakde","pakem","paket","pakihang","pakihi","paking","pakis","paklik","pakma","pakpui","pakpung","paksa","paksi","paksina","pakta","pakter","paku","pakuh","pakuk","pakuncen","pakus","pal","pala","paladium","palagan","palai","palak","palaka","palam","palamarta","palang","palapa","palar","palari","palas","palasik","palat","palatabilitas","palatal","palatalisasi","palatografi","palatogram","palatum","palau","palawa","palawija","paldu","pale","palem","palen","paleoantropologi","paleobotani","paleoekologi","paleogeografi","paleografi","paleografis","paleoklimatologi","paleolitik","paleolitikum","paleontologi","paleosen","paleozoikum","pales","palet","pali","paliatif","paliatip","palindrom","paling","palinologi","palis","palit","palka","pallawa","palmarosa","palmin","palmistri","palmit","palmitat","palolo","palpasi","palsu","paltu","palu","paluh","palun","palung","palut","pamah","paman","pameget","pamer","pamflet","pamit","pamong","pamor","pampa","pampan","pampang","pampas","pampat","pamper","pampiniform","pamrih","pamungkas","pan","pana","panah","panai","panakawan","panar","panas","panasea","panau","panca","pancabicara","pancabuta","pancacita","pancadarma","pancaindera","pancaindra","pancaka","pancakara","pancakembar","pancal","pancalima","pancalogam","pancalomba","pancalongok","pancamarga","pancamuka","pancang","pancaniti","pancapersada","pancar","pancaragam","pancarajadiraja","pancaroba","pancarona","pancasila","pancasilais","pancasona","pancasuara","pancasuda","pancausaha","pancawalikrama","pancawara","pancawarna","pancawarsa","panci","pancing","pancir","pancit","panco","pancong","pancung","pancur","pancut","pandai","pandak","pandam","pandan","pandang","pandau","pandawa","pandega","pandemi","pandemik","pandialektal","pandir","pandit","pandom","pandu","panekuk","panel","panelis","panembahan","panembrama","panen","panewu","pangabekti","pangah","pangan","pangeran","pangestu","panggak","panggal","panggang","panggar","panggau","panggih","panggil","panggon","panggu","panggul","panggung","pangkah","pangkai","pangkal","pangkas","pangkat","pangkek","pangkin","pangking","pangkon","pangku","pangkung","pangkur","panglima","pangling","panglong","pangolat","pangonan","pangpet","pangpung","pangreh","pangrehpraja","pangrukti","pangsa","pangsek","pangsi","pangsit","panguk","pangur","pangus","panik","paniki","panil","panili","paninggil","paningset","panir","paniradia","panitera","panitia","panja","panjak","panjang","panjar","panjarwala","panjat","panjer","panji","panjing","panjul","panjunan","panjut","pankreas","pankromatis","pankronis","panlektal","panleukapema","panleukopenia","panoptikum","panorama","panser","pantai","pantak","pantalon","pantang","pantar","pantas","pantat","pantau","panteis","panteisme","panteistis","pantek","pantekosta","panteon","panter","panti","pantik","panting","pantis","panto","pantofel","pantograf","pantomim","pantri","pantul","pantun","panus","panutan","panyembrama","pao-pao","papa","papacang","papah","papain","papak","papakerma","papan","papar","paparazi","papas","papat","papatong","papi","papil","papila","papirus","papras","paprika","papui","par","para","parab","parabasis","parabel","parabiosis","parabola","paradam","parade","paradigma","paradigmatis","paradiso","paradoks","paradoksal","parados","paraf","parafasia","parafemia","parafin","parafrasa","parafrase","parafrenia","paragaster","paragog","paragon","paragraf","parah","parak","paralaks","paraldehida","paralel","paralelisasi","paralelisme","paralelogram","paralgesia","paralinguistik","paralinguistis","paralipsis","paralisis","paralitis","param","paramaarta","paramarta","paramasastra","paramedis","paramen","parameter","paramiliter","parampara","paran","parang","paranoia","paranoid","paranormal","paranpara","parap","parapalatal","parapati","paraplasme","paraplegia","parapodium","parapsikolog","parapsikologi","paras","parasetamol","parasintesis","parasit","parasitisme","parasitoid","parasitologi","parasitoma","parasitopolis","parasut","parasutis","parataksis","parataktis","paratesis","paratifus","paratiroid","parau","pare","parenial","parenkim","parental","parentesis","parestesia","parewa","parfum","parga","parhelion","pari","paria","parididimis","parih","parik","parikan","paring","paripurna","paris","parit","paritas","pariwara","pariwisata","parji","parka","parket","parkinson","parkinsonisme","parkir","parkit","parlemen","parlementaria","parlementarisme","parlementer","parmitu","paro","parodi","paroki","parokial","parokialisme","parolfaktori","paron","paronim","paronisia","paronomasia","parotitis","pars","parser","parsi","parsial","partai","partenogenesis","partial","partikel","partikelir","partikularisme","partisan","partisi","partisipan","partisipasi","partitif","partitur","partner","partus","paru","paruh","parun","parut","parvenu","parwa","pas","pasah","pasai","pasak","pasal","pasang","pasanggiri","pasar","pasara","pasaraya","pasase","pasasir","pasat","pascabedah","pascadoktoral","pascajual","pascakawin","pascakrisis","pascalahir","pascalarva","pascalikuidasi","pascamodern","pascamodernisme","pascaoperasi","pascapanen","pascaperang","pascaproduksi","pascareformasi","pascasarjana","pascausaha","pascayuwana","paseban","paser","paset","pasfoto","pasi","pasien","pasif","pasifikasi","pasifisme","pasigrafi","pasik","pasilan","pasim","pasimologi","pasir","pasirah","pasit","pasiva","paskah","pasmat","pasmen","pasok","pasowan","paspor","pasrah","pasta","pastel","pasteur","pasteurisasi","pasti","pastiles","pastor","pastoral","pastoran","pastur","pastura","pasu","pasuel","pasuk","pasumandan","pasung","patah","pataka","patam","patang","patar","patek","patela","paten","pater","patera","pateram","paternalis","paternalisme","paternalistis","patet","patetis","patgulipat","pati","patih","patik","patikim","patil","patin","patina","pating","patio","patirasa","patiseri","patka","patogen","patogenesis","patogenik","patois","patok","patokimia","patol","patola","patolog","patologi","patologis","patolopolis","patos","patra","patrap","patri","patriark","patriarkat","patrilineal","patrimonium","patriot","patriotik","patriotisme","patroli","patron","patronasi","patrun","patuh","patuk","patung","patungan","patut","pauh","pauhi","pauk","paul","paun","paung","paus","pause","paut","paviliun","pawai","pawak","pawaka","pawana","pawang","pawiyatan","pawukon","paya","payah","payang","payar","payau","payet","payon","payu","payudara","payung","peang","pecah","pecai","pecak","pecal","pecara","pecat","pece","pecel","peci","pecicilan","pecinan","pecok","pecuk","pecun","pecut","peda","pedada","pedadah","pedagog","pedagogi","pedagogis","pedak","pedaka","pedal","pedanda","pedang","pedapa","pedar","pedas","pedati","pedel","pedena","pedendang","pedengan","pedepokan","pedestrian","pedet","pedewakan","pediatri","pedih","pedikur","pedis","pedisel","pedogenesis","pedok","pedologi","pedoman","pedometer","pedongkang","pedot","peduli","pedunkel","pedusi","pedut","pegagang","pegah","pegal","pegan","pegang","pegar","pegari","pegas","pegat","pegawai","pego","pegoh","pegon","peguam","pegun","pehong","pei","pejajaran","pejaka","pejal","pejam","pejatian","pejera","pek","peka","pekaja","pekak","pekakak","pekan","pekarang","pekasam","pekaseh","pekat","pekatu","pekatul","pekau","pekerti","pekik","peking","pekir","pekis","pekiwan","pekojan","peksi","pektik","pektil","pektin","peku","pekuk","pekulun","pekung","pekur","pel","pelabi","pelabur","pelaga","pelagas","pelagis","pelagra","pelah","pelak","pelalah","pelamin","pelampang","pelampung","pelan","pelana","pelancar","pelanduk","pelang","pelangai","pelanggi","pelangi","pelangkin","pelangpang","pelantar","pelanting","pelas","pelasah","pelasik","pelaspas","pelasuh","pelat","pelata","pelatuk","pelawa","pelayon","pelbagai","pelbak","pelbet","pelebat","pelebaya","pelebegu","pelebon","pelecet","pelecok","peleh","pelek","pelekat","pelekok","pelekuk","pelembaya","pelencit","pelengak","pelengan","pelengset","pelepah","peles","pelesat","peleset","pelesir","pelesit","pelet","peletek","peletik","peleting","peleton","pelias","pelihara","pelik","pelikan","pelikel","pelinggam","pelinteng","pelintir","pelipir","pelipis","pelir","pelisir","pelisit","pelit","pelita","pelitur","pelo","pelog","peloh","pelojok","pelonco","pelong","pelopor","pelor","pelorot","pelosok","pelosot","pelota","pelotaris","pelotot","pelples","pelpolisi","pels","peluang","peluh","peluit","peluk","peluluk","pelulut","pelumpung","pelungpung","pelupuh","pelupuk","peluru","peluruh","pelus","pelvis","pemair","pemali","pemarip","pematah","pematang","pemayang","pembarap","pembayan","pemendak","pemeo","pemetikan","pemidang","pemindang","peminggir","pempek","pemuda","pemudi","pemuras","pen","pena","penak","penaka","penalti","penampan","penampang","penanggah","penaram","penasaran","penat","penatu","penatua","penca","pencak","pencalang","pencar","pencet","pencil","pencok","pencong","pencu","pencut","penda","pendaga","pendahan","pendak","pendam","pendapa","pendar","pendaringan","pendek","pendekar","pendet","pendeta","pending","pendok","pendongkok","pendopo","pendua","penduk","pendulum","penembahan","penes","penetrasi","penetron","penewu","pengalasan","penganak","penganan","pengang","pengantin","pengap","pengapuh","pengar","pengaruh","pengat","pengatu","pengawinan","pengeng","pengerih","pengga","penggaga","penggah","penggal","penggar","penggawa","penghulu","pengin","pengkal","pengkar","pengki","pengkis","pengkol","pengkor","pengos","penguin","pengulun","peni","peniaram","pening","peningset","penis","penisilin","penisilinat","penitensi","peniti","penjajap","penjalin","penjara","penjaruman","penjor","penjuna","penjura","penjuru","penmes","penologi","penomah","pensi","pensil","pensiun","pentagin","pentagon","pentagor","pentagram","pentahedron","pental","pentameter","pentan","pentana","pentang","pentar","pentas","pentatonik","pentil","pentilasi","penting","pentode","pentol","pentosa","pentotal","pentung","penuh","penyap","penyek","penyet","penyok","penyu","peok","peot","pepagan","pepah","pepak","pepaku","peparu","pepas","pepat","pepatah","pepaya","pepe","pepek","pepeling","peper","pepermin","pepes","pepet","pepindan","peplum","pepsin","pepsina","pepsinogen","peptida","peptidase","peptik","pepton","pepuju","pepunden","pepung","peputut","per","pera","perabot","perabung","perada","peragat","perah","perahu","perai","peraji","perak","peraka","peram","perambut","peran","perancah","perang","perangah","perangai","peranggang","peranggu","peranggul","perangin","perangkap","perangkat","peranjat","peranti","peranye","perap","peras","peras-perus","perasat","perasukan","perat","perata","perawan","perawas","perawi","perawis","perbal","perban","perbani","perbatin","perbawa","perbegu","perbekel","perca","percaya","percik","percis","percit","percul","percuma","perdah","perdana","perdata","perdeo","perdikan","perdom","perdu","pere","peredus","pereh","perei","perek","perekik","perempuan","perencah","perenggan","perengkat","perengus","perengut","perenial","perenkum","perenyak","perenyuk","perepat","peres","peresau","peresih","perestroika","peretel","perewa","perfek","perfeksi","perfeksionis","perfeksionisme","perfektif","perforasi","perforator","performa","pergam","pergat","pergata","pergedel","pergi","pergok","pergol","pergola","perhati","peri","peria","perian","periang","periantium","peribahasa","periboga","peribudi","peridi","perifer","periferal","periferalis","periferi","perifiton","perifrasa","perifrase","perifrastis","perige","perigel","perigi","perih","perihal","perihelion","perikarditis","perikardium","perikemanusiaan","perikondrium","periksa","perilaku","perimbas","perimeter","perimisium","perimpin","perimping","perinci","perincit","perineorium","perineum","perineurium","pering","peringgan","peringgi","peringgitan","peringis","peringkat","perintah","periodat","periode","periodik","periodisasi","periodonsium","periodontium","periorbita","periosteum","perirana","perisa","perisai","periskop","perispora","peristalsis","peristaltik","peristerit","peristiwa","peristonium","perit","peritoneum","peritonitis","periuk","perivaskuler","perjaka","perji","perkakas","perkale","perkamen","perkara","perkasa","perkedel","perkelang","perkolar","perkolasi","perkolator","perkoler","perkosa","perkusi","perkutut","perlahan","perlak","perlambang","perleng","perlente","perlenteh","perli","perlina","perling","perlintih","perlip","perlit","perlop","perlu","perlup","perlus","permadani","permai","permaisuri","permak","permalin","permana","permanen","permanganat","permasan","permata","permeabel","permeabilitas","permen","permil","permisi","permisif","permutasi","pernah","pernak","pernekel","pernik","pernikel","pernis","perogol","perohong","peroi","peroksida","peroksidase","peroksisom","peroksisoma","peroman","perompak","peron","peroneal","peronyok","perop","perosok","perosot","perot","perpatih","perpetuasi","perponding","pers","persada","persangga","persegi","persekot","persekusi","persen","persentase","persentil","persepsi","perseptif","perseptivitas","persero","persetan","perseus","perseverasi","persih","persik","persil","persis","persisi","perslah","persneling","person","persona","personal","personalia","personalisme","personalitas","personel","personifikasi","perspektif","perspektivisme","persuasi","persuasif","pertal","pertama","pertepel","pertiwi","pertua","perturbasi","pertusis","peruak","peruan","peruang","perubalsem","perudang","peruk","perum","perumpung","perun","perunggu","perunjung","perupuk","perus","perusi","perut","perversi","perwara","perwira","pes","pesa","pesai","pesak","pesakin","pesam","pesan","pesanggrahan","pesantren","pesara","pesat","pesawat","pese","peseh","pesek","peser","pesero","peset","pesi","pesiar","pesimis","pesimisme","pesimistis","pesing","pesirah","pesisir","pesok","pesolot","pesona","pesong","pesta","pestaka","pestisida","pestol","pesuk","pesut","pet","peta","petah","petai","petak","petaka","petal","petala","petaling","petam","petamari","petan","petanen","petang","petaram","petarang","petarangan","petaruan","petas","petatang-peteteng","petatus","petegian","petek","petel","petenteng","petepete","peterana","peterseli","petes","peti","petia","petik","petikrah","petikut","petilan","peting","petinggi","petiolus","petir","petis","petisi","petitih","petitum","petogram","petola","petopan","petor","petrodolar","petrografi","petrogram","petrokimia","petrol","petrolatum","petroleum","petrologi","petromaks","petsai","petuah","petuding","petuduh","petuk","petunia","peturun","petus","petut","pewaka","pewat","peyek","peyorasi","peyot","phi","piadah","piagam","piah","piak","pial","piala","pialang","pialing","pialu","piama","piang","pianggang","pianggu","pianika","pianis","piano","pianola","piantan","piara","piarit","pias","piaster","piat","piatu","piawai","pica","picah","picik","picing","picis","picit","pico","picu","picung","pidana","pidato","pidi","piezoelektrik","piezoelektrisitas","piezometer","pigmen","pigmentasi","pigmi","pigura","pihak","pijah","pijak","pijar","pijat","pijin","pijinasi","pijit","pika","pikap","pikat","pikau","pike","piket","pikir","piknik","piknometer","pikofarad","pikogram","pikolo","piktografi","piktogram","pikul","pikun","pikup","pil","pilah","pilak","pilang","pilar","pilas","pilaster","pilau","pileh","pilek","pileren","pilih","pilin","pilis","pilon","pilong","pilorus","pilositas","pilot","pilsener","pilu","pilus","pimpel","pimpin","pimping","pin","pina-pina","pinak","pinang","pinar","pincang","pincuk","pincut","pinda","pindah","pindai","pindang","pines","pinga","pingai","pinggah","pinggan","pinggang","pinggir","pinggul","pingit","pingkal","pingkau","pingpong","pingsan","pingul","pinis","pinisepuh","pinisi","pinjal","pinjam","pinjung","pinset","pinta","pintal","pintan","pintang","pintar","pintas","pintil","pintu","pintur","pinus","piogenik","pion","pioner","piong","pionir","pipa","pipet","pipi","pipih","pipil","pipis","pipit","pir","pirai","piramid","piramida","piramidal","pirang","piranograf","piranogram","piranometer","pirasat","pirau","pireksia","pirektik","piretrum","pirian","piriform","pirik","piring","pirit","pirofilit","pirofobia","piroksen","pirolisis","piromania","pirometalurgi","pirometer","piroteknik","pirsa","piruet","pirus","pis","pisah","pisang","pisau","pises","pisiformis","pisik","pisin","pisit","pisitan","pisovonus","pispot","pistol","pistom","piston","pisuh","pit","pita","pitak","pitam","pitanggang","pitar","pitarah","pitawat","piting","pitiriasis","pitis","pitometer","piton","pitot","pitut","piuh","piung","piut","piutang","pivot","piwulang","piyik","piza","plafon","plagiarisme","plagiat","plagiator","plagioklas","plakat","plaket","plaksegel","plamir","plan","planaria","planel","planet","planetarium","planetoid","plang","plangkan","planimeter","planimetri","planing","planisfer","plankton","plano","planologi","planologis","planospora","plantase","planula","plasenta","plaser","plasma","plasmodium","plasmosis","plastid","plastik","plastin","plastis","plastisitas","plastogami","plastometer","plastron","platelet","platform","platina","platinoid","platinum","platisma","plato","platonik","platonisme","plaza","plebisit","pleidoi","pleiogami","pleistosen","pleksus","plengkung","pleno","pleonasme","pleopod","plerem","plester","pletora","pleura","plinplan","plintat-plintut","plinteng","plintit","pliosaurus","pliosen","ploi","ploidi","plombir","plonci","plonco","plong","plonga-plongo","plontos","plosif","plot","plug","plumbago","plumbum","plumbung","plural","pluralis","pluralisme","pluralistis","pluriform","plus","pluto","plutokrasi","plutonik","plutonium","pluvial","pluviograf","pluviometer","pneumatika","pneumatofos","pneumatokista","pneumonia","poal","poces","poci","pocok","pocong","podemporem","podikal","podium","poetika","pof","pogrom","pohon","poikilohalin","poikiloterm","poin","point","poise","poiseuille","pojok","pok","pokah","pokeng","poker","poket","poko","pokok","pokrol","poksai","pokta","pol","pola","polah","polan","polang","polarimeter","polarimetri","polaris","polarisasi","polaritas","poldan","polder","polemik","polemis","polen","poleng","polenter","poler","poles","polet","poliandri","poliantus","poliester","polifagia","polifase","polifoni","poligam","poligami","poligini","poliglot","poliglotisme","poligon","poligraf","polihalin","polikel","poliket","poliklinik","polikrom","polikultur","polimer","polimerisasi","polinia","polio","polip","polipeptida","polipetal","poliploid","polipropilena","polis","polisakarida","polisemi","polisentrisme","polisepal","polisi","polisiklis","polisilogisme","polisindeton","polisional","polispermi","polister","politbiro","politeis","politeisme","politeistis","politeknik","politena","politik","politika","politikus","politis","politisasi","poliuretan","polivini","polizoa","polka","polkadot","polmah","polo","polok","polones","polong","polonium","polonter","polos","polusi","polutan","polutif","poma","pomade","pomologi","pompa","pompang","pompon","pompong","pon","ponakan","ponco","pondamen","pondar","ponderabilitas","pondik","pondoh","pondok","pondong","pongah","ponggang","ponggok","pongkol","pongsu","poni","ponil","ponok","ponor","pons","pontang-panting","ponten","pontoh","ponton","poo","pop","popelin","popi","popok","popor","popularisasi","popularitas","populasi","populer","populis","populisme","pora","porah","porak-parik","porak-peranda","porak-poranda","porfiria","pori","porisitas","porno","pornografi","pornografis","porok","porong","poros","porositas","porot","porselen","porsi","porta","portabel","portal","portepel","portik","portir","porto","portofolio","pos","pose","poser","posesif","posisi","positif","positivisme","positivistik","positron","positronium","poskar","poso","posologi","postar","poster","posterior","postulat","postur","pot","potas","potasium","potator","potehi","potel","potensi","potensial","potensiometer","potia","potlot","potol","potong","potret","poundal","poyang","praanggapan","praba","prabu","pradana","pradesa","pradesain","pradini","praduga","pragmatik","pragmatika","pragmatis","pragmatisme","prah","prahara","prahoto","prairi","praja","prajaksa","prajurit","prakala","prakarsa","prakarya","prakata","prakilang","prakira","prakondisi","prakonsepsi","praksis","praktek","praktik","praktikan","praktikum","praktis","praktisi","pralahir","pramenstruasi","prameswari","pramodern","pramubakti","pramubarang","pramubayi","pramudi","pramugara","pramugari","pramujasa","pramuka","pramukamar","pramuniaga","pramupintu","pramuria","pramusaji","pramusiwi","pramutamu","pramuwisata","pramuwisma","pranala","pranata","pranatacara","pranatal","prangas","prangko","pranikah","prapalatal","prapatan","prapendapat","praperadilan","prapromosi","prapuber","prapubertas","prapuna","prapustaka","prarasa","prarekam","praremaja","prasaja","prasangka","prasaran","prasarana","prasasti","prasawya","prasejahtera","prasejarah","prasekolah","praseminar","praseodimium","prasetia","prasi","prasmanan","prastudi","prasyarat","pratersier","pratinjau","prawacana","prawira","prayang","prayitna","prayojana","prayuwana","preadvis","preambul","preantena","preasetabulum","predasi","predator","predestinasi","predikat","predikatif","prediksi","predisposisi","preferensi","prefiks","prehistori","prei","prekositas","prekursor","preliminer","prelude","preman","prematur","premi","premis","premium","premolar","prenatal","prenjak","preparat","preposisi","prepotensi","prerogatif","pres","presbiopia","presbiterium","preseden","presensi","presentabel","presentasi","presentil","preservasi","presesi","presiden","presidensial","presidentil","presidium","presiositas","presipitasi","presisi","preskripsi","preskriptif","prestasi","prestise","prestisius","presto","presumsi","pretel","pretensi","prevalensi","preventif","preview","prewangan","pria","priagung","priayi","pribadi","pribumi","prihatin","prima","primadona","primas","primata","primbon","primer","primitif","primogenetur","primordial","primordialisme","primpen","pringas-pringis","pringgitan","prinsip","prinsipiil","prioritas","pripih","pris","prisma","prit","privasi","privat","privatisasi","prive","privilese","pro","proaktif","probabilitas","problem","problematik","procot","prodemokrasi","prodeo","produk","produksi","produktif","produktivitas","produsen","produser","proenzim","prof","profan","profanitas","profase","profesi","profesional","profesionalisme","profesionalitas","profesor","profetik","profil","profilaksis","profit","profitabel","profitabilitas","proforma","progeni","progesteron","prognosis","program","programa","progres","progresif","progresivitas","prohibisi","proklamasi","proklamator","proklitik","proksimal","proksimat","prokurasi","prokurator","prolat","prolegomena","proleksem","proletar","proletariat","proletarisasi","proliferasi","prolog","promenade","prometium","prominen","prominensia","promiskuitas","promontorium","promosi","promotif","promotor","promovendus","pronomina","pronominal","pronominalisasi","prop","propaganda","propagandis","propana","propelan","propeler","properti","propfan","propilena","propinsi","proporsi","proporsional","proposal","proposisi","propulsi","prosa","prosais","prosede","prosedur","prosedural","prosenium","proses","prosesi","prosesor","proskonion","proskriptivisme","prosodi","prosodis","prospek","prospeksi","prospektif","prospektus","prostaglandin","prostat","prostitusi","protagonis","protaktinium","protandri","protandris","protasis","proteid","protein","proteinuria","proteksi","proteksionisme","protektif","protektorat","proteolisis","proteolitik","protes","protese","protesis","protestan","protestantisme","protista","proto","protofon","protogenesis","protokol","protokoler","protolisis","protolitik","proton","protoneolitik","protoplasma","protoraks","prototipe","protozoa","protrombin","protuberansia","provinsi","provinsialisme","provisi","provisional","provitamin","provokasi","provokatif","provokator","provokatur","provos","proyek","proyeksi","proyektil","proyektor","prudensial","prurigo","psalm","psamolitoral","pseudo","pseudokata","pseudomorf","pseudonim","psi","psike","psikiater","psikiatri","psikis","psikoanalisis","psikodrama","psikofarmakologi","psikofisiologis","psikokinesis","psikolepsi","psikolinguistik","psikolog","psikologi","psikologis","psikometri","psikometrika","psikomotor","psikomotorik","psikoneurosis","psikopat","psikopati","psikopatologi","psikosastra","psikoseksual","psikosis","psikosomatik","psikoteknik","psikoteknis","psikoterapi","psikotes","psikotropika","psikrofili","psikrometer","psikrometri","psitakosis","psoriasis","pterodaktil","pteropoda","ptialin","ptomaina","puadai","puah","puak","puaka","pual","pualam","puan","puas","puasa","puatang","pub","puber","pubertas","pubesens","publik","publikasi","publisis","publisistik","publisitas","pucang","pucat","pucik","pucuk","pucung","pudar","pudat","pudel","puder","pudi","puding","pudur","puerpera","puerperium","pugak","pugar","pugas","puguh","puih","puing","puisi","puitis","puitisasi","puja","pujangga","puji","pujuk","pujur","pujut","pukah","pukal","pukang","pukas","pukat","pukau","puki","pukul","pul","pula","pulai","pulan","pulang","pulas","pulasan","pulasari","pulau","pulen","pulih","pulik","pulover","pulp","pulpa","pulpen","pulper","pulsa","pulsar","pulsasi","puluh","pulun","pulung","pulut","puma","pumpun","pun","punah","punai","punakawan","punar","punat","punca","puncak","punci","pundak","punden","pundi","punding","punduh","punduk","pundung","pung","pungak-pinguk","punggah","punggai","punggal","punggawa","pungguk","punggung","punggur","pungkah","pungkang","pungkas","pungkur","pungli","pungsi","pungtuasi","punguk","pungut","punia","punjul","punjung","punjut","punk","puntal","punti","puntianak","puntir","puntuk","puntul","puntung","punuk","punya","pupa","pupil","pupu","pupuan","pupuh","pupuk","pupur","pupus","puput","pura","purba","purbakala","purbani","purbasangka","purbawisesa","purdah","pure","purgatif","puri","purifikasi","purik","puring","puris","purisme","puristis","puritan","puritanisme","purna","purnabakti","purnaintegrasi","purnajabatan","purnajual","purnakarya","purnama","purnapugar","purnasarjana","purnatugas","purnawaktu","purpura","purser","puruk","puruk-parak","purun","purus","purusa","purut","purwa","purwakanti","purwapada","purwarupa","pus","pusa","pusak","pusaka","pusang","pusar","pusara","pusat","puser","pusing","puskesmas","puso","puspa","puspadana","puspadanta","puspamala","pusparagam","puspas","puspawarna","puspita","pusta","pustaha","pustaka","pustakaloka","pusu","pusung","pusut","putar","putat","puter","puti","putih","putik","puting","putra","putranda","putrawali","putrefaksi","putresin","putri","putriditas","putu","putus","putut","puvi-puvi","puyan","puyeng","puyer","puyonghai","puyu","puyuh","qaf","qari","qariah","qasar","qiamulail","qiraah","qiraat","qudsi","quran","raba","raba-rubu","rabak","raban","rabana","rabani","rabas","rabat","rabet","rabi","rabies","rabik","rabit","rabiulakhir","rabiulawal","rabotase","rabu","rabuk","rabulizat","rabun","rabung","rabut","racak","racau","racik","racuh","racun","rad","rada","radaah","radah","radai","radak","radang","radar","radas","raden","rades","radi","radiah","radial","radian","radians","radiasi","radiator","radif","radikal","radikalisasi","radikalisme","radiks","radikula","radin","radio","radioaktif","radioaktivitas","radiogenetika","radiogoniometer","radiogoniometri","radiograf","radiografi","radiogram","radioisotop","radiokarbon","radiokimia","radiolisis","radiolog","radiologi","radiolokasi","radiometer","radiosonde","radiotelefoni","radiotelegrafi","radiotelegrafis","radioterapi","radis","radium","radius","radon","radu","radurisasi","rafak","rafaksi","rafe","rafi","rafia","rafidi","rafik","raflesia","raga","ragam","ragang","ragas","ragawi","ragi","ragib","ragil","ragu","raguk","ragum","ragung","ragut","rahak","rahang","rahap","raharja","rahasia","rahat","rahayu","rahib","rahim","rahimakallah","rahimakumullah","rahmah","rahman","rahmat","rahmatullah","rahu","rai","raib","raigedeg","raih","raimuna","rais","raja","rajab","rajabiah","rajah","rajalela","rajam","rajang","rajapati","rajawali","rajim","rajin","rajok","rajuk","rajul","rajungan","rajut","rak","raka","rakaat","rakah","rakanita","rakap","rakat","rakawira","rakbol","raket","rakila","rakis","rakit","rakitis","rakna","raksa","raksabumi","raksasa","raksi","rakuk","rakung","rakus","rakut","rakyat","rakyu","ralat","ralip","ram","rama","rama-rama","ramadan","ramah","ramai","ramal","ramanda","ramania","rambah","rambai","rambak","ramban","rambang","rambat","rambeh","rambih","rambu","rambun","rambung","rambut","rambutan","rambuti","rames","rami","ramin","ramirezi","rampa","rampai","rampak","rampang","rampas","rampat","ramping","rampok","rampuh","rampung","rampus","ramu","ramus","rana","ranah","ranai","ranap","ranca","rancah","rancak","rancam","rancang","rancap","rancau","rancu","rancung","randa","randa-rondo","randah","randai","randajawan","randak","randat","randau","randek","randi","randu","randuk","randung","rang","rangah","rangai","rangak","rangam","rangas","rangga","ranggah","ranggak","ranggas","ranggeh","ranggi","ranggit","ranggul","ranggung","rangin","rangina","rangka","rangkai","rangkak","rangkam","rangkang","rangkap","rangkaya","rangket","rangkiang","rangkik","rangking","rangkit","rangkok","rangkul","rangkum","rangkung","rangkup","rangkus","rangkut","rango-rango","rangrang","rangrangan","rangsang","rangu","rangum","rangup","rani","ranjah","ranjang","ranjau","ranji","ranjing","rankine","ransel","ransum","rantai","rantam","rantang","rantas","rantau","rante","ranti","ranting","rantuk","rantus","ranum","ranyah","ranyang","ranyau","ranyun","rap","rapah","rapai","rapak","rapal","rapang","rapat","rapel","rapi","rapiah","rapik","rapor","rapsodi","rapu","rapuh","rapun","rapung","rapus","raraha","rarai","rarak","rarangan","raras","ras","rasa","rasai","rasam","rasamala","rasan","rasau","rasberi","rase","rasem","rasi","rasia","rasial","rasialis","rasialisme","rasian","rasio","rasional","rasionalis","rasionalisasi","rasionalisme","rasionalitas","rasisme","raster","rasuk","rasul","rasuli","rasulullah","rasyid","rasywah","rat","rata","ratah","ratap","ratib","ratifikasi","ratna","ratu","ratus","rau","raudah","raudatul","raudatulatfal","raum","raun","raung","raup","raut","rawa","rawah","rawai","rawak","rawan","rawang","rawat","rawatib","rawi","rawin","rawit","rawon","rawuh","raya","rayah","rayan","rayang","rayap","rayau","rayon","rayonisasi","rayu","razia","reagen","reagensia","reak","reaksi","reaksioner","reaktan","reaktans","reaktansi","reaktif","reaktivitas","reakton","reaktor","reaktualisasi","real","realis","realisasi","realisme","realistis","realitas","realokasi","realpolitik","reasuransi","reaumur","reba","rebab","rebah","rebak","reban","rebana","rebas","rebat","rebeh","rebek","rebes","rebet","rebewes","reboisasi","rebon","rebu","rebuk","rebung","rebus","rebut","reca","recak","receh","recet","recik","recok","recup","reda","redah","redaksi","redaksional","redaktur","redam","redang","redap","redefinisi","redih","redik","redoks","reduksi","reduksionisme","redum","redup","reduplikasi","redusir","redut","reedukasi","reekspor","referat","referen","referendaris","referendum","referensi","referensial","reflasi","refleks","refleksi","reflektif","reflektor","reformasi","reformis","refraksi","refraktometer","refraktor","refrein","refrigerator","regah","regan","regang","regas","regat","regata","regel","regen","regenarasi","regenerasi","reges","regi","regio","region","regional","regionalisme","register","registrasi","regisur","reglemen","reglementer","regol","regresi","regresif","regu","reguk","regularisasi","regulasi","regulatif","regulator","reguler","regup","rehab","rehabilitasi","rehabilitatif","rehal","rehat","rehidrasi","reideologisasi","reindoktrinasi","reinkarnasi","reintegrasi","reinterpretasi","reinvestasi","reja","rejab","rejah","rejan","rejang","rejasa","rejeh","rejeng","rejuk","rek","reka","rekah","rekal","rekalkulasi","rekalsitran","rekam","rekan","rekanalisasi","rekanita","rekap","rekapangan","rekapitalisasi","rekapitulasi","rekat","rekata","rekayasa","reken","rekening","rekes","rekisitor","rekisitur","reklamasi","reklame","reklasering","reklasifikasi","rekognisi","rekoleksi","rekombinan","rekombinasi","rekomendasi","rekonsiliasi","rekonstruksi","rekonstruktif","rekonvensi","rekor","rekreasi","rekrut","rekrutmen","reksa","rekstok","rektifikasi","rekto","rektor","rekuiem","rekuisisi","rekuisitor","rekurs","rel","rela","relai","relaks","relaksasi","relang","relap","relas","relasi","relatif","relativisasi","relativisme","relativitas","relau","relban","relevan","relevansi","reli","reliabel","reliabilitas","relief","religi","religiositas","religius","relik","relikui","relikwi","relokasi","reluk","relung","rem","rema","remah","remai","remaja","remak","remanen","remang","remas","rematik","rematisme","rematoid","rembah","rembang","rembas","rembat","rembega","rembes","rembet","rembih","rembuk","rembulan","rembunai","remburs","rembut","remedi","remedial","remediasi","remeh","remenia","remet","remi","remiak","remiling","reminisensi","remis","remisi","remoh","rempa","rempah","rempak","rempela","rempelas","rempenai","rempeyek","rempong","rempuh","rempuk","rempus","remujung","remuk","remunerasi","remunggai","rena","renah","renai","renaisans","renal","renang","rencah","rencak","rencam","rencana","rencang","rencat","renceh","renceng","rencet","rencong","renda","rendabel","rendah","rendam","rendang","rendemen","rendeng","rendet","rendong","renegosiasi","renek","renes","reng","rengadean","rengap","rengas","rengat","rengeh","rengek","rengeng","rengga","renggam","renggang","renggat","renggek","rengges","rengginang","renggut","rengit","rengkah","rengkam","rengkeh","rengket","rengkit","rengkong","rengkudah","rengkuh","rengrengan","rengsa","rengus","rengut","renik","renin","renium","renjana","renjatan","renjeng","renjis","renjong","renjul","renkinang","renovasi","renta","rentabilitas","rentak","rentaka","rental","rentan","rentang","rentap","rentas","rente","renteng","rentenir","rentet","renti","rentik","renumerasi","renung","renvoi","renyah","renyai","renyam","renyang","renyap","renyau","renyeh","renyek","renyem","renyuk","renyut","reog","reol","reologi","reometri","reorganisasi","reorientasi","reostat","reot","rep-repan","repang","reparasi","repas","repatrian","repatriasi","repek","repertoar","repertorium","repes","repet","repeten","repetisi","repetitif","repetitor","repih","replik","replika","repolarisasi","repormir","reportase","reporter","reposisi","repot","representasi","representatif","represi","represif","reproduksi","reprografi","reptil","reptilia","republik","republiken","repuh","repui","reput","reputasi","rerak","rerangka","reranting","reras","rerata","reresanan","rerongkong","rerot","rerugi","reruntuk","resa","resah","resak","resam","resan","resap","resbang","resek","resensi","resensor","resep","resepsi","resepsionis","reseptif","reseptor","reserse","resersir","reservat","reserve","reservoir","reses","resesi","resi","residen","residivis","residivisme","residivistis","residu","resik","resiko","resimen","resin","resinol","resipien","resiprok","resiprokal","resistan","resistans","resistansi","resistor","resital","resitasi","resmi","resolusi","resonan","resonansi","resonator","resor","resorpsi","resorsinol","resosialisasi","respek","respirasi","respirator","responden","respons","responsi","responsif","restan","restiformis","restitusi","restoran","restorasi","restriksi","restriktif","restrukturisasi","restu","restung","resu","resultan","resume","resurjensi","ret","reta","retail","retak","retardasi","retas","retek","retenidos","retensi","retet","retih","retikuler","retina","retinakulum","retinitis","retok","retorik","retorika","retoris","retorsi","retradisionalisasi","retreatisme","retret","retribusi","retro","retroaktif","retrofleks","retrofleksi","retrogresi","retrogresif","retrolingual","retromamal","retromandibuler","retrospeksi","retur","retus","reumatismos","reuni","reunifikasi","revaksinasi","revaluasi","revans","reverberasi","revisi","revisibilitas","revisionis","revitalisasi","revolusi","revolusioner","revolver","rewak","rewan","rewanda","rewang","rewel","rewet","reyal","reyot","rezeki","rezim","rho","ria","riadat","riah","riak","rial","riam","rian","riang","riap","rias","riba","ribang","ribat","ribatat","riben","riboflavin","ribosom","ribu","ribut","rica","ricau","ricik","ricuh","rida","ridan","ridi","riding","ridip","ridu","rigai","rigi-rigi","rihat","rihlah","riil","rijal","rijalugaib","rijalulgaib","rijang","rikuh","rileks","rilis","rim","rima","rimas","rimata","rimba","rimbas","rimbat","rimbawan","rimbun","rime","rimis","rimpang","rimpel","rimpi","rimpuh","rimpung","rinai","rincih","rincis","rincu","rindang","rinding","rindu","ring","ringan","ringgit","ringih","ringik","ringin","ringis","ringkai","ringkas","ringkih","ringkik","ringking","ringkuk","ringkus","ringsek","ringsing","rini","rinitis","rinjing","rinoskop","rintang","rintas","rintih","rintik","rintis","rinyai","riol","ripit","ripta","ripuh","ripuk","ririt","risa","risak","risalah","risau","riset","risi","risik","risiko","risit","riskan","rit","ritel","ritma","ritme","ritmis","ritual","ritul","ritus","riuh","riuk","riung","rival","rivalitas","riwan","riwayat","robak-rabik","robat-rabit","robek","roboh","robok","robot","robotika","rocet","roda","rodan","rodat","rodensial","rodentisida","rodi","rodium","rodok","rodolit","rodong","roga","rogoh","rogok","rogol","roh","rohani","rohaniah","rohmat","rohulkudus","roi","rojeng","rojol","rok","rokade","roker","roket","roki","rokok","rol","rolet","rolpres","roma","roman","romanistik","romansa","romantik","romantika","romantikus","romantis","romantisisme","romawi","rombak","rombang-rambing","rombeng","rombik","rombohedron","romboid","rombok","rombong","rombus","romet","romok","romol-romol","romong","rompak","rompal","rompang","rompeng","rompes","rompi","rompoh","rompok","rompong","rompyok","romsus","romusa","rona","ronce","roncet","ronda","rondah-rondih","ronde","rondo","rondok","roneo","rong","rongak","rongga","ronggang","ronggeng","ronggok","ronggong","rongkoh","rongkok","rongkol","rongkong","rongos","rongrong","rongseng","rongsok","ronta","rontek","rontgen","rontok","ronyeh","ronyok","ropak-rapik","rorehe","rorod","ros","rosario","rosbang","rosela","roseng","roseola","roset","rosin","rosok","rosot","rotan","rotasi","rotator","roti","rotograf","rotok","rowa","rowot","royak","royal","royalti","royan","royemen","royer","royong","rua","ruadat","ruah","ruai","ruak","ruam","ruang","ruap","ruas","ruat","ruaya","ruba-ruba","rubah","rubai","rubaiat","ruban","rubanat","rubel","rubela","rubeola","rubiah","rubidium","rubik","rubin","rubing","rubrik","rubu","rubung","rucah","rudah","rudal","rudapaksa","rudi","rudimen","rudin","rudu","rudus","rugbi","rugi","ruh","ruhbahnat","ruhban","ruhbanat","ruhbaniat","ruilslag","ruing","ruit","rujah","rujak","ruji","rujuk","rukam","rukhsah","rukiah","ruko","ruku","rukuh","rukuk","rukun","rukyat","rukyatulhilal","rum","rumah","rumal","rumba","rumbah","rumbai","rumbia","rumbing","rumbu","rumen","rumenia","rumi","rumin","ruminansi","ruminansia","rumit","rumor","rumpakan","rumpang","rumpi","rumpil","rumpon","rumpun","rumput","rumrum","rumuk","rumung","rumus","runcing","runcit","runding","rundu-rundu","runduk","rundung","rungau","runggas","runggu","runggu-rangga","rungguh","runggut","rungkau","rungkuh","rungkun","rungkup","rungu","rungus","rungut","runjam","runjang","runjau","runjung","runtai","runtang-runtung","runtas","runti","runtih","runtuh","runtun","runtut","runut","runyam","runyut","ruok","rupa","rupee","rupiah","rurut","rusa","rusak","rusuh","rusuk","rutab","rute","rutenium","ruterfordium","rutin","rutuk","rutup","ruwah","ruwat","ruwet","ruyak","ruyap","ruyung","ruyup","saadah","saadin","saanen","saat","sab-sab","saba","sabah","sabak","saban","sabana","sabang","sabar","sabas","sabasani","sabat","sabatikal","sabda","sabel","saben","sabet","sabi","sabil","sabilillah","sabit","sabitah","sableng","sablon","sabo","sabot","sabotase","sabsab","sabtu","sabuk","sabun","sabung","sabur","sabut","sad","sadah","sadai","sadak","sadang","sadap","sadar","sadariah","sadarulkalam","sadarusalam","sadau","sadel","sadik","sadin","sading","sadir","sadis","sadisme","sadistis","sado","sadrah","sadran","sadu","sadur","saf","safa","safar","safari","safi","safih","safinah","safinatunajah","safir","safrah","safron","safsaf","safsah","saga","sagai","sagang","sagar","sagitarius","sagon","sagu","saguer","sagur","sah","sahabat","sahaja","saham","sahan","sahang","sahap","sahara","saharah","sahaya","sahayanda","sahda","sahdu","sahi","sahib","sahibulbait","sahibulhajat","sahibulhikayat","sahifah","sahih","sahir","sahkan","sahmura","sahur","sahut","sai","saif","sailan","sailo","saing","sains","saintis","sair","sais","saja","sajadah","sajak","sajang","sajen","saji","sak","saka","sakai","sakal","sakang","sakap","sakar","sakarida","sakarimeter","sakarin","sakarosa","sakat","sake","sakelar","sakelek","sakhawat","sakhi","sakhrat","sakhsi","saki","sakinah","saking","sakit","saklek","sakral","sakramen","sakramental","sakramentalia","sakratulmaut","sakrilegi","sakristi","sakrokoksigeal","sakrolumbal","sakrum","saksama","saksang","saksi","saksofon","sakti","saku","sakura","sal","sala","salaf","salah","salai","salak","salam","salang","salar","salaris","salasal","salat","salatin","saldo","sale","saleh","salem","salep","sali","salib","salihah","salim","salin","salina","salindia","salindra","saling","salinisasi","salinitas","salinometer","salip","salir","salira","salivasi","salju","salmon","salmonela","salon","salpeter","salping","saltasi","salto","saluir","saluk","salung","salur","salut","salvarsan","salvo","sama","samad","samak","saman","samanera","samaniah","samapta","samar","samara","samarium","samas","samawi","samba","sambal","sambalewa","sambang","sambangan","sambar","sambat","sambau","samben","sambet","sambi","sambil","sambiloto","sambit","sambuk","sambung","sambur","sambut","sami","samidra","samijaga","samin","samir","samo-samo","samovar","sampa","sampah","sampai","sampak","sampakan","sampan","sampang","sampanye","sampar","samparan","sampat","sampean","sampek","sampel","samper","sampeyan","sampil","sampilik","samping","sampir","sampling","samplok","sampo","sampu","sampuk","sampul","sampur","samsak","samsam","samseng","samsir","samsiti","samsu","samudra","samuh","samum","samun","samurai","sana","sanad","sanak","sanat","sanatogen","sanatorium","sanatulhijriah","sanatulmiladiah","sanawiah","sanca","sanda","sandal","sandang","sandar","sandel","sandera","sandi","sanding","sandiwara","sando","sandung","sandungan","sanering","sang","sanga","sangai","sangan","sangar","sangat","sangau","sangga","sanggah","sanggam","sanggama","sanggan","sanggang","sanggar","sanggarunggi","sanggat","sanggep","sanggerah","sangging","sanggit","sanggrah","sanggraloka","sanggul","sanggup","sanggurdi","sangha","sangih","sangir","sangit","sangka","sangkak","sangkakala","sangkal","sangkala","sangkan","sangkar","sangkil","sangku","sangkul","sangkur","sangkuriang","sangkut","sangkut-paut","sangli","sangling","sanglir","sangon","sangrai","sangsai","sangsam","sangsang","sangsi","sangu","sanguifikasi","sangulun","sangyang","sani","sanik","sanitas","sanitasi","saniter","sanjai","sanjak","sanjang","sanjung","sanksi","sano","sansai","sanseviera","sanskerta","santa","santai","santak","santam","santan","santap","santase","santau","santer","santet","santiaji","santing","santir","santo","santonin","santri","santun","santung","sanubari","sap","sapa","sapai","saparantu","sapat","sapau","sapersi","sapi","sapih","sapir","sapit","sapogenin","saponin","saprofit","sapta","saptadarma","saptamarga","saptapesona","sapu","saput","saputangan","sar","sara","saradasi","saraf","sarak","saran","sarana","sarang","sarangan","sarap","sarasehan","sarat","sarau","sarden","sardencis","sarean","sareh","sarekat","saren","sarengat","sarhad","sari","saridele","sarik","sarikan","saring","sarira","sarirah","sarit","sarjana","sarju","sarkasme","sarkastis","sarkode","sarkoderma","sarkofagus","sarkolema","sarkologi","sarkoma","sarkoplasma","saron","sarsaparila","sartan","saru","saruk","sarung","sarut","sarwa","sasa","sasak","sasakala","sasana","sasando","sasap","sasar","sasau","sasi","sasian","sasis","sasmita","sastra","sasus","sat","satai","satak","satang","satanologi","satar","sate","satelit","satih","satin","satinet","satir","satire","satiris","sato","satori","satpam","satria","satron","satu","saturnus","saturometer","satwa","satyagraha","satyalencana","satyawacana","sau","saudagar","saudara","saudari","sauh","saujana","sauk","saum","sauna","saung","saur","saus","saut","sauvinis","sauvinisme","sauvinistis","saw","sawa","sawab","sawah","sawai","sawala","sawan","sawang","sawangan","sawar","sawat","sawer","sawi","sawit","sawo","sawut","saya","sayak","sayang","sayap","sayat","sayembara","sayet","sayib","sayid","sayidani","sayidi","sayidina","sayu","sayung","sayup","sayur","seba","sebab","sebahat","sebai","sebak","sebal","sebam","sebar","sebarang","sebarau","sebasah","sebat","sebaur","sebekah","sebel","sebelas","sebeng","sebentar","seberang","seberhana","sebet","sebit","seblang","sebrot","sebu","sebuk","sebum","sebun","sebura","seburas","seburu","seburus","seburut","sebut","secang","seceng","secerek","secina","sedahan","sedak","sedam","sedan","sedang","sedap","sedat","sedatif","sedativa","sedawai","sedekah","sedekap","sedelinggam","sedeng","sederhana","sederum","sedia","sediakala","sedih","sedikit","sedimen","sedimentasi","sedimenter","sedingin","sedong","sedot","sedu","seduayah","seduh","sefalopoda","sefalotoraks","seg","sega","segah","segak","segala","segan","seganda","segani","segar","segara","segata","segeger","segeh","segel","segenap","segera","segi","segianya","segitiga","segmen","segmental","segmentasi","segregasi","seguna","seh","seharah","sehat","sehingga","seia","seilometer","sein","seismik","seismograf","seismogram","seismolog","seismologi","seismometer","sejahtera","sejajar","sejak","sejarah","sejarawan","sejari","sejat","sejati","sejingkat","sejuk","sek","seka","sekadar","sekah","sekak","sekakar","sekakmat","sekal","sekala","sekali","sekaligus","sekalipun","sekalor","sekam","sekan","sekang","sekap","sekapar","sekar","sekarang","sekarat","sekat","sekata","sekaten","sekati","sekaut","sekeber","sekebun","sekedeng","sekeduduk","sekedup","sekelat","sekelebatan","sekelian","sekema","sekendal","sekendi","sekengkeng","sekepat","sekeram","sekeri","sekerindangan","sekering","sekesel","seketeng","sekh","sekian","sekilwak","sekip","sekira","sekiram","sekitar","seko","sekoci","sekoi","sekolah","sekon","sekongkol","sekonyong-konyong","sekop","sekopong","sekoteng","sekrap","sekresi","sekret","sekreta","sekretariat","sekretaris","sekretin","sekring","sekrip","sekrup","seks","seksi","seksmaniak","seksolog","seksologi","seksologis","sekstan","sekstet","seksual","seksualitas","sektarian","sektarianisme","sekte","sektor","sektoral","sekuas","sekui","sekul","sekularis","sekularisasi","sekularisme","sekularitas","sekuler","sekulir","sekunar","sekunder","sekunyit","sekuritas","sekuriti","sekutu","sel","sela","selabar","selaber","selaberak","selada","seladang","seladon","selagi","selai","selain","selaju","selak","selaka","selakarang","selaku","selalu","selam","selamat","selamba","selampai","selampe","selampek","selampit","selan","selancak","selancang","selancar","selang","selangat","selangka","selangkang","selangkup","selanting","selap","selapan","selaput","selar","selara","selarak","selaras","selarung","selasa","selasar","selasih","selat","selatan","selawah","selawat","selawe","selaya","selayun","selayur","sele","selebaran","selebran","selebrasi","selebritas","selebriti","selebu","seleder","selederi","seledri","seleguri","selekeh","selekoh","selekor","seleksi","selekta","selektif","selektivitas","seleler","selembana","selembubu","selempada","selempang","selempukau","selempuri","selendang","selender","selendro","selenggara","selengkatan","selenium","selenografi","selenologi","selentang-selenting","selentik","selenting","seleo","selepa","selepang","selepat","selepe","seleper","selepetan","selepi","selera","selerak","selerang","seleret","selesa","selesai","selesma","seletuk","seleweng","selia","seliap","selibat","selibu","selibut","selidik","seligi","seligit","selimang","selimpang","selimpat","selimut","selinap","selindung","seling","selingar","selingkit","selingkuh","selingkup","selip","selipar","selir","selira","selirak","selirat","seliri","selisih","selisik","selisip","selisir","selit","seliwer","selo","selofan","selok","seloka","selokan","seloki","selom","selomot","selompret","selon","selonding","selong","selongkar","selongsong","selonjor","selonong","selop","seloroh","selot","seloyak","seloyong","selter","seluang","seluar","selubung","seludang","seludu","seluduk","seludup","selui","seluk","seluk-beluk","selukat","selukung","seluler","seluloid","selulosa","selulup","selulur","selumar","selumbar","selumbari","selumbat","selumu","selumur","seluncur","selundat","selundup","selungkang","selungkup","selup","selupan","selupat","selurah","seluru","seluruh","selusuh","selusup","selusur","selut","sema","semadi","semafor","semah","semai","semaja","semak","semalu","semambu","semampai","semampang","semampat","seman","semanak","semandan","semandarasa","semandarasah","semandera","semang","semangat","semanggi","semangka","semangkok","semangkuk","semantan","semantik","semantis","semantung","semaput","semara","semarai","semarak","semaram","semarmendem","semat","semata","semawang","semawar","semaya","semayam","semayi","sembab","sembabat","sembada","sembagi","sembah","sembahyang","sembai","sembak","sembam","sembap","sembar","sembarang","sembari","sembat","sembawang","sembayan","sembelih","sembelit","sember","semberap","semberip","sembesi","sembeta","sembiang","sembilan","sembilang","sembilik","sembilu","sembir","sembirat","semboyan","sembrani","sembrono","sembuang","sembuh","sembul","sembung","sembunyi","sembur","semburat","semburit","semecah","semedera","semejana","semeleh","sememeh","semen","semena","semenanjung","semenda","semendarasa","semenggah","semenjak","semenjana","sementang","sementara","sementasi","sementelah","sementung","semerawang","semerbak","semerdanta","semesta","semester","semi","semiang","semidiurnal","semifinal","semifinalis","semiidiom","semikonduktor","semilat","seminai","seminar","seminari","seminaris","seminau","semiologi","semiotik","semiotika","semipermanen","semir","semitisme","semivokal","semok","sempada","sempadan","sempak","sempal","sempalai","sempana","sempang","sempat","sempelah","sempena","sempil","sempit","semplak","sempoyong","sempoyongan","semprit","semprong","semprot","sempul","sempur","sempuras","sempurna","semrawut","semringah","semsem","semu","semua","semunding","semunian","semur","semut","sen","sena","senak","senam","senamaki","senandika","senandung","senang","senangin","senantan","senantiasa","senapan","senapati","senar","senarai","senario","senat","senator","senawan","senawar","senawat","senawi","senda","sendal","sendalu","sendam","sendang","sendar","sendarat","sendaren","sendat","sendawa","sendayan","sendayang","sendel","sendeng","sender","senderik","senderung","senderut","sendi","sending","sendiri","sendocong","sendok","sendon","sendorong","sendratari","sendu","senduduk","senduk","senen","senewen","seng","sengaja","sengal","sengam","sengangar","sengangkar","sengap","sengar","sengar-sengir","sengarat","sengaring","sengat","sengau","sengelat","senget","senggak","senggang","senggara","senggat","senggau","senggayut","senggerahan","senggeruk","sengget","senggiling","senggol","senggora","senggugu","senggugut","sengguk","senggulung","senggut","sengih","sengingih","sengir","sengit","sengkak","sengkal","sengkalan","sengkang","sengkar","sengkarut","sengkawang","sengkayan","sengked","sengkedan","sengkek","sengkela","sengkelang","sengkelat","sengkeling","sengkelit","sengkenit","sengker","sengketa","sengkil","sengkilit","sengkuang","sengkuap","sengon","sengsai","sengsam","sengsara","sengsem","sengsurit","senguk","sengungut","sengut","seni","senigai","senil","senilitas","seniman","senin","senior","senioritas","senja","senjak","senjang","senjata","senjolong","senjong","senohong","senonoh","senoyong","sensasi","sensasional","sensibel","sensibilitas","sensitif","sensitivitas","sensor","sensoris","sensual","sensualisme","sensualitas","sensur","sensus","senta","sentada","sentadu","sentagi","sentak","sentaka","sental","sentali","sentana","sentap","sentara","senteng","senter","senterpor","senti","sentiare","sentiasa","sentigram","sentil","sentiliter","sentimen","sentimental","sentimentalitas","sentimentil","sentimeter","senting","sentiong","sentiung","sentol","sentong","sentosa","sentra","sentral","sentralisasi","sentralistis","sentrifugal","sentripetal","sentrum","sentuh","sentuk","sentul","sentung","senu","senuh","senuk","senunggang","senur","senyampang","senyap","senyar","senyawa","senyum","senyur","seok","seolah-olah","sep","sepada","sepah","sepai","sepak","sepakat","sepal","sepala-pala","sepam","sepan","sepanar","sepandri","sepang","sepangkalan","separasi","separatis","separatisme","separbang","sepasin","sepat","sepatbor","sepatu","sepeda","sepedas","sepegoh","sepekuk","sepel","sepele","sepeling","sepen","sepenuh","seperah","seperantu","sepersi","seperti","sepesan","sepet","sepetir","sepi","sepih","sepiker","sepir","sepit","seples","sepoi","seprai","seprei","sepsis","september","septima","septum","sepuh","sepuit","sepuk","sepukal","sepul","sepulih","sepuluh","sepupu","sepur","seput","sera","serabi","serabut","serabutan","seraga","seragam","serah","serahi","serai","serak","serakah","seram","serama","serambi","serampang","serampin","serampu","serampuk","seran","serana","seranah","serandang","serandau","serandib","serandung","serang","serangga","serangguh","seranggung","serangkak","serangsang","serani","seranograf","seranometer","seranta","serap","serapah","serapat","serasa","serasah","serasi","serat","seratah","serati","seratung","serau","seraumeter","seraut","serawak","serawal","seraya","serba","serbaada","serbaakal","serbabaru","serbabisa","serbadua","serbaemas","serbaguna","serbah-serbih","serbaindah","serbak","serbakeemasan","serbakurang","serbamacam","serban","serbaneka","serbaputih","serbarumah","serbasalah","serbasama","serbasusah","serbat","serbausaha","serbet","serbi","serbu","serbuk","serdadu","serdak","serdam","serdang","serdawa","serdi","serdih","serealia","serealin","sereat","serebral","serebrospinal","serebrum","seregang","sereh","serembah-serembih","seremban","seremoni","seremonial","serempak","serempet","serempu","serendah","serendeng","sereng","serengam","serengeh","serengit","serenjak","serenjang","serenta","serentak","serep","seresin","seret","sergah","sergam","sergap","sergut","seri","serial","seriap","seriat","seriawan","seribulan","seriding","serigading","serigala","serigunting","serik","serikat","serikaya","serimala","serimpet","serimpi","serimpung","serindai","serindit","sering","seringai","seringing","seriosa","serit","serium","serius","serkah","serkai","serkap","serkup","serlah","serling","sermangin","sermet","sernak","sero","serobeh","serobok","serobot","serografi","seroja","serok","serologi","serombong","serompok","serondeng","serondok","serondol","serondong","serong","seronok","seroplastik","seropot","serositas","serosoh","serot","seroyong","serpentina","serpih","sersan","serse","sersi","serta","sertifikasi","sertifikat","sertu","seru","seruak","seruas","seruda","serudi","seruduk","serugah","serugat","seruh","serui","seruit","seruk","serul","seruling","serum","serumat","serumen","serumpu","serun","serunai","serunda","serundang","serundeng","seruni","serunjang","seruntun","serupih","seruput","seruru","serut","serutu","seruyuk","servis","sesah","sesai","sesaing","sesajen","sesak","sesal","sesam","sesamoid","sesanti","sesap","sesar","sesat","sesawi","sesenap","seser","sesi","sesil","sesira","sesium","sesoca","sespan","sestina","sesuai","sesuatu","sesumbar","set","seta","setabelan","setagen","setai","setaka","setakona","setal","setambun","setan","setana","setang","setangan","setanggi","setapak","setaria","setat","setawar","setebal","seteger","seteheng","setek","seteker","setel","setela","seteleng","setem","setempel","seten","setenggar","seter","seteranah","seteru","setewel","seti","setia","setiabu","setiar","setiga","setik","setin","setinggi","setip","setir","setirman","setiwel","setoka","setokin","setolop","setom","seton","setop","setoples","setor","setori","setoter","setra","setrap","setrat","setren","setreng","setrik","setrika","setrimin","setrip","setruk","setrum","setrup","setti","setu","setuil","setum","setung","setup","seturi","seturu","seudati","sewa","sewah","sewaka","sewal","sewar","sewat","sewot","sewu","sfenoidal","sferoid","sferometer","sfigmograf","sfigmomanometer","sfikmograf","sfingofili","sfingter","sfinks","sia","siaga","siah","siak","siakap","siakon","sial","sialang","sialit","siam","siamang","sian","sianamida","sianang","siang","sianggit","sianida","sianometer","sianometri","sianosis","siantan","siap","siap-sedia","siap-siaga","siapa","siapuh","siar","siarah","siarat","siasat","siat","siau","sibak","sibar","sibernetika","sibilan","sibir","sibuk","sibur","sibusuk","sice","sicerek","sida","sidai","sidamukti","sidang","sidat","siderit","sidi","sidik","siding","sidomukti","sidratulmuntaha","siduga","siduk","sif","sifat","sifatullah","sifer","sifilis","sifilobia","sifiloid","sifir","sifon","sigai","sigak","sigando","sigap","sigar","sigaret","sigasir","sigenting","siger","sigi","sigilografi","sigma","signifikan","signifikansi","signifikasi","sigot","sigung","sih","sihir","sijik","sijil","sika","sikah","sikai","sikak","sikap","sikari","sikas","sikat","sikedempung","sikeras","sikik","sikikih","sikin","sikit","siklik","siklis","sikloid","siklon","sikloparafin","siklotron","siklus","siksa","siku","sikudidi","sikudomba","sikut","sil","sila","silabel","silabis","silabus","silah","silalatu","silam","silampukau","silang","silap","silara","silase","silat","silaturahmi","silau","silengah","silet","silih","silik","silika","silikat","silikon","silikona","silikosis","silinder","silindris","silindroid","silir","silium","silo","silogisme","silok","silologi","silometer","siloptik","silsilah","silt","silu","siluet","siluk","siluman","silungkang","silvika","silvikultur","silvisida","simak","simalakama","simalu","simaung","simbah","simbai","simbang","simbar","simbat","simbion","simbiosis","simbiotis","simbiou","simbok","simbol","simbolis","simbolisme","simbukan","simbur","simetri","simetris","simfisis","simfoni","simifisis","simile","simpai","simpak","simpan","simpang","simpang-siur","simpanse","simpat","simpati","simpatik","simpatisan","simpel","simpetal","simping","simpir","simpleks","simplifikasi","simplistis","simposium","simpuh","simpuk","simpul","simpur","simtom","simtomatis","simtomatologi","simulasi","simulator","simulfiks","simultan","simuntu","sin","sinaga","sinagoga","sinagoge","sinambung","sinanaga","sinansari","sinar","sinatan","sinau","sinawar","sindap","sinden","sinder","sindeton","sindikalisme","sindikasi","sindikat","sindir","sindrom","sindur","sineas","sinekdoke","sinektika","sinema","sinemapleks","sinemaskop","sinematik","sinematograf","sinematografi","sinematografis","sinemikrografik","sineol","sinepleks","sinergi","sinergis","sinergisme","sineskop","sinestesia","sinetron","sing","singa","singahak","singelar","singga","singgah","singgan","singgang","singgasana","singgel","singgir","singgit","singgul","singgung","singit","singkak","singkang","singkap","singkat","singkeh","singkek","singkil","singkir","singkong","singkup","singkur","singlet","singsat","singse","singset","singsing","singularis","singulum","singulun","singunen","sini","sinis","sinisme","sinjang","sinklin","sinkonina","sinkope","sinkretis","sinkretisasi","sinkretisme","sinkron","sinkronis","sinkronisasi","sinkronisme","sinode","sinolog","sinologi","sinom","sinoman","sinonim","sinonimi","sinopsis","sinoptis","sinovia","sinovial","sinovitas","sinovitis","sinrili","sinse","sintagma","sintagmatis","sintaksis","sintaktis","sintal","sintar","sintas","sinter","sinterklas","sintese","sintesis","sintetik","sintetis","sinting","sintir","sintonik","sintren","sintua","sintuk","sintulang","sintung","sinu","sinuhun","sinus","sinusal","sinusitis","sinusoid","sinyal","sinyalemen","sinyalir","sinyo","sinyokolas","sio","sioca","siong","siongka","sip","sipahi","sipai","sipangkalan","sipat","sipatung","sipedas","sipesan","sipi","sipil","sipir","sipit","sipolan","sipongang","sipu","sipulut","siput","sir","sira","sirah","siram","sirangkak","sirap","sirat","siratalmustakim","siraut","sirene","sirep","siri","siriasis","sirib","sirih","sirik","siring","siringitis","sirip","sirkam","sirke","sirkol","sirkuit","sirkulasi","sirkuler","sirkumfiks","sirkumfleks","sirkus","sirlak","sirna","sirokumulus","sirop","sirostratus","sirsak","siru","sirup","sirus","sis","sisa","sisal","sisalak","sisi","sisih","sisik","sisip","sisir","sista","sistaltik","sistem","sistematik","sistematika","sistematis","sistematisasi","sistematisir","sistemis","sistemisasi","sisterna","sistitis","sistole","sistolik","sisurut","siswa","siswi","sit","sita","sitak","sitat","siter","siti","sitinggil","sitir","sitokrom","sitolilis","sitolisis","sitologi","sitoplasma","sitrat","sitrin","sitrun","situ","situasi","situasional","situn","situs","siuh","siuk","siul","siuman","siung","siur","siut","sivilisasi","siwalan","siwaratri","siwer","sizigi","skafa","skala","skalanisasi","skalar","skalop","skandal","skandium","skarifikasi","skatola","skatologi","skedul","skelet","skema","skematis","skenario","skene","skeptis","skeptisisme","sketsa","ski","skiameter","skiatika","skilot","skip","skiping","skisma","skizofrenia","skizoid","sklerenkima","sklerosis","skleroterapi","skolastik","skolastikus","skolastisi","skolastisisme","skombroid","skop","skopometer","skor","skorbut","skorpio","skors","skorsing","skrin","skrining","skrip","skripsi","skrobikulus","skrotum","skuadron","skuas","skuat","skuos","skuter","slagorde","slah","slang","slebor","slendro","sling","slintat-slintut","slip","slof","slogan","smes","smokel","snob","snobisme","soak","soal","soang","soarma","soba","soban","sobat","sobek","sobok","soda","sodet","sodium","sodok","sodomasosisme","sodomi","sodomia","sodor","soe","sofa","sofis","sofisme","sofistri","sofitel","soga","sogan","sogang","sogo","sogok","sohar","sohib","sohor","sohun","soja","sok","soka","sokah","soker","soket","sokom","sokong","sol","solah","solak","solang","solanina","solar","solarimeter","solder","solek","solempis","solenoide","solfatar","solfatara","solid","solidaritas","solider","soliditas","solilokui","solinometer","solipsisme","solis","soliter","solo","solois","solok","solokan","solot","solum","solusi","solvabilitas","solven","som","soma","somah","somasi","somatis","somatomegali","sombok","sombol","sombong","sombrero","someng","somnambulis","somnambulisme","sompek","sompeng","somplak","somplok","sompoh","sompok","sompong","sompret","sonar","sonata","sonatina","sondai","sondanco","sondang","sondase","sondek","sonder","sondok","sondong","soneta","songar","songel","songgeng","songket","songkok","songkro","songong","songsong","sonik","sono","sonogram","sonokeling","sonor","sonoran","sontak","sontek","sontok","sontoloyo","sop","sopak","sopan","sopek","sopi","sopir","soporifik","sopran","sorak","sorang","sorban","sorbet","sore","sorek","soren","sorgum","sori","sorog","sorok","sorong","sorot","sortir","sosi","sosial","sosialis","sosialisasi","sosialisme","sosialistis","sosio","sosio-kultural","sosiobiolog","sosiodemokrasi","sosiodrama","sosiokultural","sosiolek","sosiolinguistik","sosiolog","sosiologi","sosiologis","sosiometri","sosionasional","sosiopat","sosis","sositet","sosoh","sosok","sosor","soto","sotoh","sotong","sotor","soun","sowan","sowang","soyak","spageti","spalasi","span","spanduk","spaning","sparing","spasi","spasial","spasmodis","spasmus","spastik","spatbor","spatula","spedometer","spektakel","spektakuler","spektator","spektograf","spektogram","spektrograf","spektrogram","spektrokimia","spektrometer","spektroskop","spektrum","spekuk","spekulan","spekulasi","spekulatif","spekulator","speleologi","spelter","sperma","spermaseti","spermatid","spermatofora","spermatogenesis","spermatosit","spermatozoa","spermatozoid","spesial","spesialis","spesialisasi","spesialistis","spesies","spesifik","spesifikasi","spesimen","spidol","spidometer","spikul","spil","spina","spion","spionase","spiral","spiralisasi","spirilum","spirit","spiritis","spiritisme","spiritual","spiritualisasi","spiritualisme","spiritus","spirometer","spons","sponsor","spontan","spontanitas","spora","sporadis","sporangium","sporofil","sport","sportif","sportivitas","spring","sprint","sprinter","sputnik","sputum","sreg","sregep","srempet","sri","srigading","srigunggu","srigunting","srikandi","srikaya","srimanganti","sripah","sripanggung","sriti","stabil","stabilisasi","stabilisator","stabilitas","stabilizer","stadion","stadium","staf","stafilitis","stagnan","stagnasi","staking","stalagmit","stalagmometri","stalaktit","stalinisme","stalon","stamba","stambon","stambuk","stambul","stamen","stamina","stan","standar","standardisasi","stanplat","stanum","stanza","stapler","staples","start","starter","stasi","stasioner","stasis","stasiun","statis","statistik","statistika","statistis","stator","status","statuta","statuter","stearat","stearin","steatit","steatosis","stegodon","steik","stek","steker","stela","steling","stema","stemma","stempel","sten","stengun","steno","stenografer","stenografi","stenogram","stensil","step","stepa","stepler","steradian","stereo","stereofoni","stereofonik","stereognosis","stereograf","stereografi","stereoisomerisme","stereokimia","stereometri","stereoskop","stereotip","stereotipikal","steril","sterilisasi","sterilitas","steroid","steroidal","sterol","stetoskop","stevador","stibium","stigma","stigmata","stik","stiker","stilbestrol","stilir","stilistika","stilograf","stimulan","stimulans","stimulasi","stimulatif","stimulator","stimulus","stipendium","stipulasi","stirena","stoikiometri","stok","stokastik","stoker","stol","stoliditas","stolon","stomata","stomatitis","stomatogastrik","stomatoskop","stop","stoper","stopkeran","stopkontak","stoples","stori","stormking","strabotomi","strata","strategem","strategi","strategis","stratifikasi","stratigrafi","strato","stratokumulus","stratopause","stratopouse","stratosfer","stratum","stratus","streng","streptokokus","streptomisin","stres","striker","strimin","strip","striptis","stroberi","strobila","stroboskop","stroke","stromking","strontium","struktur","struktural","strukturalisasi","strukturalisme","struma","studen","studi","studio","stuko","stupa","sua","suah","suai","suak","suaka","suam","suami","suaminda","suang","suangi","suap","suar","suara","suarang","suargaloka","suari","suasa","suasana","suat","suatu","sub","subak","subal","subam","suban","subang","subbab","subbagian","subdirektorat","subentri","suberat","suberin","subetnik","subfilum","subgeneralisasi","subgenus","subhana","subhanallah","subhat","subirigasi","subjek","subjektif","subjektivisme","subkategorisasi","subkelas","subklas","subkontraktor","subkultur","sublema","subletal","sublim","sublimasi","sublimat","submarine","submukosa","subordinasi","subordinat","suborganisasi","subsider","subsidi","subskrip","subsonik","substandar","substansi","substansial","substantif","substitusi","substitutif","substrat","subtil","subtonik","subtropik","subuco","subuh","subunit","subur","subversi","subversif","subyek","subyektif","subyektivisme","suceng","suci","suda","sudah","sudet","sudi","sudip","sudoriferus","sudra","sudu","suduayah","suduk","sudung","sudut","suf","sufah","sufal","sufi","sufiks","sufisme","sufrah","sugar","sugesti","sugi","sugih","suguh","sugul","sugun","suh","suhad","suhian","suhu","suhuf","suhun","suiseki","suit","sujana","sujen","suji","sujud","suka","sukacita","sukade","sukamandi","sukan","sukar","sukarela","sukaria","sukat","sukduf","suke","suket","suki","suklapaksa","sukma","sukrosa","sukses","suksesi","suksesif","suku","sukuisme","sukun","sula","sulah","sulalah","sulalat","sulam","sulang","sulap","sulat-sulit","sulbi","sulfanasi","sulfanilamida","sulfat","sulfhidril","sulfolipid","sulfonamida","sulfur","sulfurasi","suli","sulih","suling","sulit","sultan","sultanat","sultani","suluh","suluk","sulung","sulur","sulut","sum","sumah","sumarah","sumare","sumasi","sumba","sumbang","sumbangsih","sumbar","sumbat","sumbel","sumber","sumbi","sumbing","sumbu","sumbuk","sumbul","sumbung","sumbur","sumbut","sumeh","sumengit","sumilir","sumir","sumirat","sumo","sumpah","sumpal","sumpek","sumpel","sumping","sumpit","sumsum","sumur","sumurung","sun","sunah","sunam","sunan","sunat","sunatullah","sunbulat","sundai","sundak","sundal","sundang","sundari","sundep","sunduk","sundul","sundus","sundusin","sundut","sungai","sungga","sunggi","sungging","sunggit","sungguh","sungguhpun","sungil","sungkah","sungkai","sungkal","sungkan","sungkap","sungkawa","sungkem","sungkit","sungkuk","sungkum","sungkup","sungkur","sungkuran","sungsang","sungu","sungut","suni","sunjam","sunti","suntiabu","suntih","suntik","sunting","suntuk","sunu","sunukung","sunyata","sunyi","sup","supa","supai","supaya","supel","super","superblok","supercepat","superfisial","superfosfat","superheterodin","superinfeksi","superintenden","superior","superioritas","superjet","superkomputer","superkonduktivitas","superkonduktor","superlatif","superlativisme","superlunar","supermarket","supermen","supernatural","supernova","superskrip","superskripsi","supersonik","superstar","superstruktur","supervisi","supervisor","suplai","suplemen","suplementasi","suplesi","supletoar","suporter","suportif","supra","supraalami","suprafiks","supramolekuler","supranasional","suprarene","suprarenoma","suprasasti","suprasegmental","supremasi","supresif","supresor","surah","surahi","surai","suralaya","suraloka","suram","surat","surati","surau","suraya","surealis","surealisme","suren","surfaktan","surga","surgaloka","surgawi","suri","surian","surih","surili","surjan","surogat","surplus","suruh","suruk","surup","surut","survei","surya","suryakanta","suryani","sus","susah","susastra","suseptibilitas","susila","susilat","suspender","suspensi","suster","susu","susuh","susuk","susul","susun","susung","susup","susur","susut","sut","sutan","suten","sutil","sutra","sutradara","sutura","suul","suun","suuzan","suvenir","suwarnabumi","suwarnadwipa","suwir","suwita","svedberg","swa","swabakar","swabela","swadana","swadarma","swadaya","swadesi","swadidik","swadisiplin","swagriya","swahara","swaharga","swaimbas","swak","swakaji","swakarsa","swakarya","swakelola","swakendali","swakontradiksi","swalayan","swanama","swanggi","swapraja","swarabakti","swasembada","swasensor","swasraya","swasta","swastanisasi","swastiastu","swastika","swatabur","swatantra","swausaha","sweter","swike","swimpak","swipoa","syabah","syabas","syafaat","syafakat","syafii","syah","syahadat","syahadatain","syahbandar","syahda","syahdan","syahdu","syahid","syahriah","syahsiah","syahwat","syair","syairi","syajar","syajarah","syak","syaka","syakban","syakduf","syakhsi","syakir","syal","syala","syam","syamali","syaman","syamanisme","syamsi","syamsiah","syamsir","syamsu","syantung","syar","syarab","syarah","syarak","syarat","syarbat","syarekat","syariat","syarif","syarifah","syarik","syarikat","syatar","syaulam","syawal","syeir","syekh","syeti","syiar","syikak","syin","syirik","syiwa","syiwaratri","syogun","syok","syubhat","syuhada","syukur","syumuliah","syur","syura","syurah","syuriah","syuruk","syuting","taajul","taala","taaruf","taasub","taat","taawud","taazur","tabah","tabak","tabal","taban","tabar-tabar","tabarak","tabaruk","tabayun","tabe","tabel","tabela","tabelaris","tabernakel","tabia","tabiat","tabib","tabii","tabiin","tabik","tabir","tablet","tablig","tablo","tabloid","tabo","tabok","tabrak","tabu","tabuh","tabuhan","tabula","tabulasi","tabulator","tabulatur","tabun","tabung","tabur","tabut","tabzir","taci","tadabur","tadah","tadaruk","tadarus","tadbir","tadi","tadir","tadung","tadwin","taekwondo","taeniasis","taf","tafadal","tafahus","tafakur","tafeta","tafsir","tagak","tagal","tagan","tagar","tageh","tagih","tago","tagut","tahajud","tahak","tahal","tahalul","tahan","tahana","tahang","tahap","tahar","taharah","tahbis","tahi","tahiat","tahil","tahir","tahkik","tahkim","tahlil","tahmid","tahniah","tahnik","tahsil","tahu","tahun","taib","taifun","taiga","taiko","taipan","tais","taiso","taja","tajak","tajali","tajam","tajarud","tajau","tajdid","tajen","taji","tajin","tajnis","tajribah","taju","tajuk","tajung","tajur","tajusalatin","tajwid","tak","takabur","takaful","takah","takak","takal","takang-takik","takar","takarir","takarub","takat","takbir","takbiratulihram","takdim","takdir","takdis","takeh","takel","takeyari","takhayul","takhlik","takhsis","takhta","taki","takigrafi","takik","takimeter","takir","takisme","takjil","takjub","taklid","taklif","taklik","taklikat","taklim","taklimat","takluk","takma","takmurni","takoah","takol","takometer","takraw","takrif","takrim","takrir","taksa","taksasi","taksem","taksi","taksidermi","taksimeter","taksin","taksir","taksologi","takson","taksonomi","taktik","taktil","taktis","takuh","takuk","takung","takur","takut","takwa","takwil","takwim","takwin","takyin","takziah","takzim","takzir","tal","tala","talabiah","talah","talak","talam","talang","talar","talas","talasemia","talasofit","talbiah","talek","talempong","talen","talenan","talenta","tali","talib","talibun","talium","talk","talkin","talon","talu","talun","talupuh","talut","tam","tamadun","tamah","tamak","tamam","taman","tamar","tamarinda","tamasya","tamat","tamatulkalam","tambah","tambak","tambakan","tambal","tamban","tambang","tambar","tambat","tamber","tambera","tambi","tambo","tamborin","tambuh","tambul","tambun","tambung","tambur","tambus","tameng","tamimah","tampah","tampak","tampal","tampan","tampang","tampar","tampas","tampel","tampi","tampik","tampil","tampin","tamping","tampon","tamponade","tampuk","tampung","tampus","tamsil","tamtam","tamtama","tamu","tamuk","tamyiz","tan","tanah","tanai","tanak","tanam","tanang","tanau","tanazul","tanbiat","tanbihat","tancang","tancap","tanda","tandak","tandan","tandang","tandas","tandem","tandik","tandikat","tandil","tanding","tandon","tandu","tanduk","tandun","tandur","tandus","tanfiziah","tang","tangan","tangap","tangar","tangas","tangeh","tangen","tangga","tanggah","tanggal","tanggam","tanggang","tanggap","tanggar","tanggetong","tangguh","tangguk","tanggul","tanggulang","tanggung","tangis","tangkah","tangkai","tangkaian","tangkal","tangkap","tangkar","tangkas","tangki","tangkil","tangkis","tangkue","tangkuk","tangkul","tangkup","tangkur","tangkut","tanglung","tango","tangsa","tangsel","tangsi","tani","tania","tanin","tanjak","tanji","tanjidor","tanju","tanjul","tanjung","tanjur","tank","tanker","tanpa","tansi","tantang","tante","tanti","tantiem","tantrisme","tanur","tanwin","tanwir","tanwujud","tanya","tanzih","tanzil","taocang","taoci","taoco","taoge","taoisme","taoke","taosi","tap","tapa","tapai","tapak","tapal","tapang","tapestri","tapi","tapih","tapin","tapioka","tapir","tapis","taplak","taprofit","taptibau","taptu","tapui","tapuk","tapung","tapus","tar","tara","taraf","tarah","tarak","taraksasin","taram","tarang","tarantisme","tarantula","tarap","taraqi","tarasul","tarawangsa","tarawih","tarbiah","tarbil","tarbus","tarcis","tarekat","target","tarhim","tari","tarif","tarik","tarikat","tarikh","taring","taris","tarjih","tarkas","tarling","tarmak","tarpaulin","tarsus","tartar","tartil","tartir","tartrat","taruh","taruk","taruko","tarum","tarung","tarup","tarzan","tas","tasa","tasai","tasak","tasalsul","tasamuh","tasaruf","tasawuf","tasbeh","tasbih","tasdik","tasel","tashih","tasik","taslim","tasmik","tasrif","tasrih","taswir","tasyahud","tasyakur","tasyaum","tasyayuh","tasybih","tasydid","tasyhid","tasyrih","tasyrik","tata","tataganing","tatah","tatai","tatak","tatal","tatami","tatanan","tatang","tatap","tatar","tatih","tating","tatkala","tato","tau","taubat","taucang","taufah","taufik","tauhid","tauhidiah","tauke","taul","tauliah","taun","taung","taur","taurat","tauret","taurus","taut","tautofoni","tautologi","tautomerisme","tautonimi","tautonomi","tawa","tawadu","tawaduk","tawaf","tawajuh","tawak","tawakal","tawan","tawang","tawar","tawarik","tawaruk","tawas","tawasul","tawes","tawon","tawur","tayamum","tayang","tayib","tayibah","tayub","tayum","tazkirah","tean","teater","teatris","tebah","tebak","tebal","teban","tebang","tebar","tebas","tebat","tebeng","teberau","tebing","tebok","tebon","tebu","tebuhar","tebuk","tebung","tebus","tedak","tedarus","tedas","tedeng","tedong","teduh","tedung","tefrit","tega","tegah","tegak","tegal","tegang","tegap","tegar","tegari","tegarun","tegas","tegel","tegil","tegmen","teguh","teguk","tegun","tegur","teh","teisme","teja","teji","teka","tekaan","tekad","tekah","tekak","tekalak","tekam","tekan","tekang","tekap","tekar","tekat","tekek","tekel","teken","teker","teki","tekidanto","tekik","tekis","teklek","teklok","teknifon","teknik","teknikus","teknis","teknisi","teknokrasi","teknokrat","teknokratik","teknokratisme","teknologi","teknonim","teknonimi","teko","tekoan","tekoh","tekokak","tekong","tekor","tekoran","tekpi","teks","tekstil","tekstur","tekstural","tekte","tektek","tektit","tektogenesa","tektonik","tektonis","tektum","tekua","tekuk","tekukur","tekun","tekung","tekur","tel","tela","telaah","telabang","telabat","telacak","teladan","teladas","telaga","telah","telajak","telak","telakup","telampung","telan","telancang","telang","telangkai","telangkup","telanjang","telanjur","telantar","telap","telapak","telas","telat","telatah","telatap","telaten","telau","tele","telearsika","teledek","teledor","teledrama","telefon","telefoni","telefoto","telegenik","telegraf","telegrafi","telegrafis","telegram","telegrap","telekan","telekap","telekinesis","telekomedi","telekomunikasi","teleks","teleku","telekung","telelensa","telemeter","telemetri","telempap","telempong","teleng","telenovela","telentang","teleologi","teleost","telepati","telepok","telepon","teleprinter","telepromter","telepuk","teler","telerang","teles","teleskop","telestesia","televisi","telgram","telik","telikung","telimpuh","telinak","telinga","telingkah","telingkung","teliti","telmotofit","telop","telor","telotak","telpon","teluh","teluk","teluki","telungkup","telunjuk","telur","telurat","telurit","telus","telusuk","telusur","telut","telutuh","telutur","telutut","tem","tema","temaah","temabur","temaha","temahak","temak","temalang","temali","teman","temangau","temangga","temanten","temara","temaram","temas","tematik","tematis","tematisasi","temayun","tembadau","tembaga","tembak","tembakang","tembakau","tembakul","tembam","tembang","tembarau","tembatar","tembatu","tembek","tembekar","tembel","tembelang","tembelian","tembeliung","tembelok","tembem","tembera","temberam","temberang","temberas","temberek","tembereng","temberih","temberos","tembesu","tembiang","tembikai","tembikar","tembilang","tembilar","tembiring","tembis","tembok","tembolok","tembong","tembosa","tembra","tembu","tembuk","tembuku","tembung","tembuni","tembus","tembusu","temegun","temeh","temengalan","temenggung","temenung","temesar","temetu","temiang","temilang","temin","temokus","temoleh","tempa","tempah","tempala","tempan","tempang","tempap","tempat","tempaus","tempawak","tempawan","tempayak","tempayan","tempayung","tempe","tempek","tempel","tempelak","tempeleng","temperamen","temperamental","temperas","temperatur","temperau","tempiar","tempias","tempik","tempilai","tempinah","tempinis","templek","templok","tempo","tempoh","tempolong","temponek","tempong","temporal","temporer","tempoyak","tempoyan","tempua","tempuh","tempui","tempuling","tempunai","tempunik","tempur","tempurung","tempus","tempuyung","temu","temucut","temukut","temungkul","temuras","temurat","temut-temut","tenaga","tenahak","tenak","tenam","tenang","tenar","tenat","tenda","tendang","tendas","tendensi","tendensius","tender","tendinitis","tendo","tendon","tener","teng","tengadah","tengah","tengak","tengalan","tengar","tengara","tengas","tenggadai","tenggak","tenggala","tenggalung","tenggan","tenggang","tenggara","tenggarang","tenggat","tenggayun","tenggayung","tenggehem","tenggek","tenggelam","tengger","tenggiling","tenggiri","tenggiring","tenggok","tenggorok","tengguli","tengik","tengil","tengkalak","tengkalang","tengkaluk","tengkam","tengkang","tengkar","tengkarah","tengkarap","tengkaras","tengkawang","tengkek","tengkel","tengkelek","tengker","tengkerong","tengkes","tengking","tengkoh","tengkolok","tengkorak","tengku","tengkujuh","tengkuk","tengkulak","tengkuluk","tengkurap","tengkuyung","tengok","tengteng","tengu","tenis","tenjet","tenok","tenong","tenor","tensi","tentakel","tentamen","tentang","tentara","tentatif","tentawan","tenteng","tenteram","tentir","tentu","tenuk","tenun","tenung","teodolit","teokrasi","teokratis","teolog","teologi","teologis","teoretikus","teoretis","teori","teorisasi","teosofi","teosofis","tepa","tepak","tepam","tepas","tepat","tepeh","tepek","tepekong","teperam","tepes","tepet","tepi","tepik","tepis","teplok","tepo","tepok","tepos","teptibau","tepu","tepuk","tepung","tepurang","tepus","ter","tera","teracak","terada","terajam","teraju","terak","terakota","terakup","teral","terala","terali","teraling","teramisin","terampil","teran","teranas","terang","terap","terapang","terapeutik","terapi","terarium","teras","terasi","teraso","terasul","teratai","teratak","teratap","teratologi","teratu","terau","terawang","teraweh","terban","terbang","terbis","terbit","terbium","terbul","terbut","terein","terem","terenang","terendak","terenen","terentang","terenyuh","teres","teret","teretet","teri","teriak","teriba","terigu","terik","terika","terikit","teriko","terima","terin","terindil","tering","teripang","terista","teritih","teritik","teritip","teritis","teritorial","teritorium","teriujung","terjal","terjang","terjemah","terjun","terka","terkadang","terkam","terkap","terkul","terkup","terlak","terlalu","terlut","term","termaestesia","termal","termin","terminal","terminasi","terminografi","terminologi","termion","termionika","termistor","termodinamika","termodinamis","termoelektris","termoelektrisitas","termofili","termofilik","termofosforesens","termograf","termogram","termohigrograf","termokimia","termoklin","termolabil","termolisis","termolistrik","termoluminesens","termometer","termonuklir","termoplastik","termos","termosfer","termostat","terna","ternak","terobos","terok","teroka","terombol","teromol","terompah","terompet","terondol","terong","terongko","teropong","teror","teroris","terorisme","terowongan","terpa","terpal","terpana","terpedo","terpentin","tersier","tertawa","tertib","terubuk","terubus","terucuk","terucukan","teruk","terum","terumba","terumbu","terumbuk","teruna","terung","terungku","teruntum","terup","terus","terusi","terwelu","terzina","tes","tesaurus","tesis","tesmak","testa","testamen","tester","testes","testikel","testimonium","testing","testis","testosteron","teta","tetak","tetal","tetampan","tetamu","tetangga","tetanus","tetap","tetapi","tetar","tetas","teteguk","teteh","tetek","tetelan","tetelo","teter","teterapan","tetes","tetibar","tetibau","tetikus","tetirah","tetiron","tetoron","tetra","tetrahidrokanabinol","tetrahidron","tetraklorida","tetraploid","tetris","tetua","tetuang","tewas","teyan","tezi","theta","tiada","tiaga","tiam","tian","tiang","tiangui","tiap","tiara","tiarap","tib","tiba","tiban","tidak","tidur","tifa","tifus","tiga","tigari","tigas","tihul","tijaniah","tik","tika","tikai","tikam","tikar","tikas","tike","tiket","tikim","tikpi","tikung","tikus","tilam","tilan","tilang","tilap","tilas","tilawah","tilde","tilik","tim","timah","timang","timarah","timba","timbal","timbang","timbau","timbel","timbil","timbo","timbre","timbrung","timbuk","timbul","timbun","timburu","timbus","timi","timol","timpa","timpal","timpang","timpani","timpanitis","timpanum","timpas","timpuh","timpuk","timpus","timu-timu","timun","timur","timus","tin","tindak","tindan","tindas","tindawan","tindih","tindik","tindis","tiner","ting","tinggal","tinggam","tinggi","tinggung","tingi","tingkah","tingkal","tingkalak","tingkap","tingkar","tingkarang","tingkarung","tingkas","tingkat","tingkeb","tingkis","tingkrang","tingkuh","tingting","tingtong","tingtur","tinja","tinjak","tinjau","tinju","tinta","tinting","tintir","tinulat","tip","tipar","tipe","tipi","tipikal","tipis","tipograf","tipografi","tipologi","tipologis","tipu","tir","tirah","tirai","tirakat","tiram","tiran","tirani","tiras","tiraton","tirau","tiri","tiris","tirkah","tiroid","tiroiditis","tiroksin","tirta","tiru","tirus","tis","tisik","tisotropi","tisu","titah","titanium","titar","titel","titer","titi","titik","titilasi","titimangsa","titinada","titip","titir","titis","titisara","titit","titrasi","titrimetri","tituler","tiung","tiup","tiwah","tiwikrama","tiwul","tmesis","toapekong","toas","tobak","tobang","tobat","toblos","toboh","tobong","tobralko","todak","todong","toga","togan","toge","togel","togok","toh","tohok","tohor","toilet","tok","tokak","tokcer","toke","tokek","toko","tokoh","tokok","tokong","toksemia","toksikogenik","toksikolog","toksikologi","toksin","toktok","tol","tolak","tolan","tolap","toleh","toleran","toleransi","tolerir","tolok","tolol","tolong","toluena","tom","toman","tomang","tomat","tombak","tomboi","tombok","tombol","tombola","tombong","tombru","tomong","tompel","ton","tona","tonase","tonem","tonetika","tong","tonggak","tonggara","tonggek","tonggeret","tonggok","tonggong","tonggos","tongkah","tongkang","tongkat","tongkeng","tongkol","tongkor","tongkrong","tongol","tongong","tongpes","tongsan","tongseng","tongsit","tongtong","tonik","tonikum","tonil","tonis","tonisitas","tonit","tonjok","tonjol","tonometer","tonsil","tonton","tonus","top","topan","topang","topas","topdal","topek","topeng","topes","tophit","topi","topiari","topik","topikalisasi","topikalitas","topo","topografi","topografis","topong","toponimi","torak","toraks","torani","toreh","torek","tores","torida","torium","tornado","torne","toro","torpedo","torpedor","torsi","torso","tortor","torus","tos","tosan","toserba","total","totalisator","totalitas","totaliter","totaliterisme","totau","totem","totemisme","totemproparte","totok","totol","towel","toya","toyor","tra","trabekula","tradisi","tradisional","tradisionalisme","trafo","tragedi","tragikomedi","tragis","tragus","trailer","trakeid","trakom","traksi","traktasi","traktat","traktir","traktor","traktus","trama","trampolin","trans","transaksi","transduksi","transek","transeksual","transenden","transendental","transfer","transfigurasi","transformasi","transformasionalis","transformatif","transformator","transfusi","transgenik","transisi","transistor","transit","transitif","transkrip","transkripsi","translasi","transliterasi","translokasi","translusens","transmigran","transmigrasi","transmisi","transmiter","transmogrifikasi","transmutasi","transnasional","transonik","transparan","transparansi","transpirasi","transplantasi","transpor","transportasi","transposisi","transversal","transvetisme","trap","trapesium","trapezoid","tras","trauler","trauma","traumatis","travesti","trawler","trayek","trek","trekbal","trem","trema","trematoda","trembesi","tremer","tremor","tren","trendi","trengginas","trenyuh","tres","tresna","tri","trias","triatlon","tribokelistrikan","tribologi","tribrata","tribunal","tribune","tributa","trica","tridarma","tridentat","trienial","triennale","trifoliat","triftong","trigatra","trigemius","trigliserida","trigonometri","trigraf","trihidrik","trik","triko","trikotomi","trikuspid","tril","trilateral","trilingga","trilipat","triliun","trilogi","trilomba","trim","trimatra","trimurti","trinil","trinitas","trinitrotoluena","trio","triode","trip","tripartit","tripleks","triplet","triplik","tripod","triprasetia","trips","tripsin","tripsinogen","triptofan","triptotos","trisep","trisula","tritunggal","triturasi","triumvirat","trivalen","trivialitas","triwangsa","triwindu","triwulan","trofi","trofoblas","troi","troika","trokanter","trokea","troli","trombin","trombon","trombosis","trombosit","trombus","tromol","trompet","trompong","tropik","tropika","tropis","tropisme","tropopause","troposfer","tropus","tros","trotoar","trubadur","truf","truk","truntum","trusa","tsar","tsunami","tsuru","tua","tuah","tuai","tuak","tual","tuala","tualang","tuam","tuan","tuang","tuangku","tuanku","tuap","tuar","tuarang","tuas","tuba","tubagus","tuban","tube","tubektomi","tuberkulosis","tubi","tubin","tubir","tubruk","tubuh","tuding","tuduh","tudung","tufa","tufah","tugal","tugar","tugas","tugi","tugu","tugur","tuhan","tuhfah","tuhfahlulajnas","tuhfahtulajnas","tuhfat","tuhmah","tuhu","tuidi","tuil","tuit","tujah","tuji","tuju","tujuh","tujul","tuk","tukai","tukak","tukal","tukam","tukang","tukar","tukas","tukik","tukil","tukmis","tuksedo","tuku","tukuk","tukul","tukun","tukung","tukup","tula","tulah","tulak","tulang","tular","tulat","tule","tulen","tuli","tulis","tulium","tulu","tulup","tulus","tum","tuma","tuman","tumang","tumbakan","tumbal","tumbang","tumbas","tumben","tumbu","tumbuh","tumbuk","tumbung","tumenggung","tumika","tumis","tumit","tumor","tumpah","tumpak","tumpal","tumpang","tumpang-tindih","tumpas","tumpat","tumpeng","tumper","tumpil","tumplak","tumplek","tumpu","tumpuk","tumpul","tumpur","tumtam","tumu","tumungkul","tumus","tun","tuna","tunaaksara","tunabusana","tunadaksa","tunaganda","tunagizi","tunagrahita","tunai","tunak","tunakarya","tunalaras","tunam","tunan","tunanetra","tunang","tunapolitik","tunarungu","tunas","tunasosial","tunasusila","tunatenaga","tunawicara","tunawisma","tunda","tundan","tundang","tundra","tunduk","tundun","tundung","tung","tungau","tunggak","tunggal","tungganai","tunggang","tunggik","tungging","tunggu","tunggul","tungkahan","tungkai","tungkak","tungkap","tungku","tungkul","tungkup","tungkus","tungro","tungsten","tungu","tunik","tunjal","tunjam","tunjang","tunjuk","tunjung","tuntas","tuntun","tuntung","tuntut","tunu","tupai","tur","tura","turang","turangga","turap","turas","turba","turbiditas","turbin","turbogenerator","turbojet","turbulen","turbulensi","turfat","turgor","turi","turiang","turinisasi","turis","turisme","turistik","turkuois","turmalin","turnamen","turne","turnoi","tursi","turun","turus","turut","tus","tusam","tusir","tuslah","tustel","tusuk","tuter","tutor","tutorial","tuts","tutu","tutuh","tutuk","tutul","tutung","tutup","tutur","tutut","tuwuhan","tuwung","tuyuk","tuyul","uai","uak","uan","uanda","uang","uap","uar","uba","ubah","uban","ubang","ubar","ubat","ubek","ubel","uber","ubet","ubi","ubikuitas","ubin","ubit","ubrak-abrik","ubub","ubudiah","ubun-ubun","ubung","ubur-ubur","ubyang-ubyung","ucap","ucek","uci-uci","ucis","ucok","ucu","ucus","uda","udak","udam","udang","udani","udap","udar","udara","ude","udek","udel","udeng","udet","udi","udik","udim","udo","udu","uduh","uduk","udut","uek","ufti","ufuk","ugahari","ugal-ugalan","ugem","uger","uget-uget","ugut","uhu","uih","uik","uir-uir","uis","uit","ujana","ujang","ujar","uji","uju","ujub","ujud","ujuk","ujul","ujung","ukas","ukhrawi","ukhuwah","ukik","ukir","uktab","ukulele","ukup","ukur","ula-ula","ulah","ulak","ulam","ulama","ulan","ulang","ulang-alik","ulang-aling","ulap-ulap","ular","ulas","ulat","ulayah","ulayat","ulek","ulem","ulen","ules","ulet","uli","ulik","ulin","uling","ulir","ulit","ulna","ulos","ultima","ultimatum","ultimo","ultimogenitur","ultra","ultrafilter","ultramarin","ultramikroskopik","ultramikroskopiks","ultramodern","ultrasonik","ultrasonika","ultrasonografi","ultraungu","ultraviolet","ulu","uluk","ulun","ulung","ulup","ulur","uma","umak","uman","umang-umang","umara","umat","umbai","umbalan","umban","umbang","umbang-ambing","umbar","umbara","umbi","umbilikus","umbin","umbisi","umbo","umbra","umbu","umbuk","umbul","umbur-umbur","umbut","umi","umlaut","umpak","umpama","umpan","umpat","umpet","umpil","umpuk","umpun","umput","umrah","umu","umuk","umum","umun","umur","unam","uncang","uncang-uncit","uncit","uncu","uncue","uncui","unda","undagi","undak","undan","undang","undi","unduh","unduk-unduk","undung-undung","undur","unek-unek","ungah-angih","ungam","ungar","unggah","unggal","unggang-anggit","unggas","unggat-unggit","unggis","unggit","unggul","unggun","unggut","ungka","ungkah","ungkai","ungkak","ungkal","ungkap","ungkat","ungkau","ungkil","ungkir","ungkit","ungkul","ungkur","ungsi","ungti","ungu","unguis","uni","uniat","unifikasi","uniform","uniformitas","unik","unilateral","unilineal","unilinear","union","uniseks","uniseluler","unit","unitaris","unitarisme","univalen","universal","universalia","universalisme","universalitas","universiade","universitas","universiter","universitet","universum","unjuk","unjun","unjung","unjur","unjut","unsur","unsuri","unta","untai","untal","untang-anting","unti","until","unting","untir","untuk","untun","untung","untut","unun","unyai","upa","upaboga","upacara","upaduta","upah","upajiwa","upak","upakara","upakarti","upam","upan","upanishad","upar","upau","upawasa","upaya","upet","upeti","upih","upik","upil","upsilon","ura-ura","uraemia","urah","urai","urak","urakus","uran-uran","uranisme","uranium","uranologi","uranus","urap","uras","urat","urban","urbanisasi","urbanisme","urdu","urea","uremia","ureter","uretra","uretritis","urgen","urgensi","uri","urian","uribang","urik","urinalisis","urine","uring","urinoar","urinometer","urip","uris","urit","urita","uritan","urna","urolog","urologi","uroskopi","uruk","urun","urung","urup","urus","urut","usada","usah","usaha","usai","usak","usali","usam","usang","usap","usar","usat","user-user","usia","usik","usil","usir","uskup","usrek","ustad","ustaz","ustazah","usuk","usul","usuluddin","usung","usur","usus","usut","uswah","utak-atik","utama","utang","utar-utar","utara","utarid","utas","uterus","utih","utik","utilitas","utopia","utopis","utopisme","utrikel","utrolokal","utuh","utus","uvula","uvular","uwar","uwungan","uwur","uyuh","uzlah","uzur","vagina","vak","vakansi","vakasi","vakatur","vakbon","vaksin","vaksinasi","vakum","vakuol","vakuola","valas","valensi","valentin","valentine","valeria","valid","validitas","valis","valium","valorisasi","valuta","vampir","vanadium","vandal","vandalisme","vandalistis","vandel","vanili","varia","variabel","variabilitas","varian","variansi","variasi","variatif","varietas","variola","varises","vas","vasal","vasektomi","vaselin","vaskular","vaskularisasi","vaskuler","vaskulum","vasodilasi","vasodilator","vasomotor","vatikan","vaucer","vedda","veddoid","veem","vegetarian","vegetarir","vegetaris","vegetarisme","vegetasi","vektor","velamentum","velar","velarisasi","velodrom","velositas","velum","vena","venal","venalitas","vendeta","vendor","ventilasi","ventilator","ventrikel","ventrikulus","venus","verba","verbal","verbalisan","verbalisasi","verbalisme","verbalistis","verbatim","verbena","verdigris","verifikasi","verifikatur","veritisme","verkoper","vermilium","vermiliun","vermiseli","vermisida","vernis","veronal","verset","versi","verso","verstek","versus","vertebra","vertebrata","vertikal","verzet","vespa","veste","vestibul","vestibula","vestibulum","vet","veter","veteran","veterinarian","veteriner","vetiver","veto","vetsin","via","viabel","viabilitas","viaduk","vibran","vibrasi","vibrator","vibrio","vide","video","videofon","videoklip","videoteks","vigia","vigili","vignet","vikariat","vikaris","vila","vinil","vinyet","viol","viola","violces","violet","violin","violinis","violis","virga","virginia","virgo","virilis","virilisme","virilitas","virilokal","virologi","virtual","virtuoso","virulen","virulensi","virus","visa","visera","visi","visibel","visibilitas","visioner","visitasi","visitator","visiun","viskometer","viskose","viskositas","vista","visual","visualisasi","visum","visus","vitakultur","vital","vitalitas","vitamin","vitelin","vitiligo","vitreositas","vitrifikasi","vitriol","vivarium","vivifikasi","vivipar","vla","vlek","voal","vodka","vokabularium","vokabuler","vokal","vokalia","vokalis","vokasional","vokatif","vokoid","volatil","volatilitas","voli","volt","voltameter","voltase","volume","volumeter","volumetri","volunter","vonis","vopo","vorteks","voting","votum","vrah","vrahoto","vulgar","vulgata","vulger","vulkan","vulkanis","vulkanisasi","vulkanolog","vulkanologi","vulkavit","vulpen","vulva","vulvektomi","vuring","waad","waadat","wabah","wabakdu","wabarakatuh","wacana","wadah","wadak","wadal","wadam","wadat","wadi","wadon","waduh","waduk","wadung","wafa","wafak","wafat","wage","wagon","wagu","wah","wahah","wahai","waham","wahana","wahdah","wahdaniah","wahdiah","wahib","wahid","wahyu","wai","waid","waima","waisak","waisya","waitankung","wajah","wajan","wajar","wajib","wajik","wak","wakaf","wakil","waktu","wakun","wakwak","walabi","walad","walafiat","walah","walak","walakhir","walakin","walang","walangkopo","walango","walat","walau","walaupun","waledan","waleh","walet","walhal","walhasil","wali","walikukun","walimah","walimana","waliullah","wallahi","wallahualam","wals","waluh","waluku","wambrau","wan","wana","wanara","wanawisata","wanda","wandu","wang","wangi","wangkang","wangsa","wangsit","wani","wanita","wanodya","wantah","wantek","wanti-wanti","wantilan","wara","warak","warakawuri","waralaba","warangan","waranggana","warangka","waras","warasah","warawiri","wardi","warga","wari","waria","warid","waringin","waris","warita","warkat","warna","warna-warni","warok","warsa","warta","waru","waruga","waruna","warung","warwar","wasahlan","wasak","wasal","wasalam","wasangka","wasi","wasiat","wasilah","wasir","wasit","wasitah","waskita","waskom","waslah","waslap","waspada","wastafel","waswas","watak","watan","watang","watas","watase","watermantel","watermark","waterpas","waterpruf","watt","watu","wau","wawa","wawancara","wawanmuka","wawanrembuk","wawas","wawu","wayang","wayuh","wazari","wazir","weda","wedam","wedana","wedang","wedani","wedar","wede","wedel","weduk","wegah","weh","weharima","wejang","wekel","weker","welahar","welas","weling","welirang","welit","welter","welut","wenang","wenter","werak","werangka","werda","werdatama","were","werek","wereng","werit","werst","wese","wesel","weselbor","wesi","wesket","westernis","westernisasi","wet","wetan","weton","wewarah","wewaton","wewe","wibawa","wicaksana","wicara","widi","widiaiswara","widiwasa","widodari","widoro","widuri","widyaiswara","widyawisata","wig","wigata","wihara","wijaya","wijayakusuma","wijayamala","wijayamulia","wijdaniah","wijen","wiji","wijik","wikalat","wiku","wiladah","wilah","wilangon","wilayah","wilis","wilwatikta","wimana","winaya","windu","wing","wingit","winglet","winter","wira","wirabank","wiracarita","wiraga","wirakarya","wirang","wiraniaga","wirasuara","wiraswasta","wirid","wiru","wisa","wisal","wisata","wisaya","wisesa","wisik","wiski","wisma","wisnu","wisuda","witir","wiwaha","wiweka","wiyaga","wiyata","wizurai","wodka","wol","wolanda","wolfram","wombat","won","wong","wora-wari","wortel","wosi","wotogal-agil","wrang","wreda","wredatama","wregu","wrisaba","wudani","wudu","wuduk","wujud","wuker","wukerar","wuku","wukuf","wulan","wulang","wulu","wulung","wungon","wungu","wuwungan","xantat","xantena","xantofil","xenia","xenofili","xenofobia","xenoglosia","xenograf","xenokrasi","xenolit","xenomania","xenon","xerofil","xerofit","xeroftalmia","xerografi","xerosis","xifoid","xilem","xilena","xilofon","xilograf","xilografi","xiloid","xiloidina","xilol","xilologi","xilonit","xilosa","yad","yahud","yahudi","yahudiah","yahwe","yais","yaitu","yakin","yakis","yakitori","yakjuj","yakni","yaksa","yakun","yakut","yamtuan","yang","yantra","yard","yargon","yasan","yasmin","yasti","yatim","yaum","yaumudin","yaumulakhir","yaumulaza","yaumuljamak","yaumuljaza","yaumulkiamah","yaumulmahsyar","yayasan","yayi","yayu","yehova","yel","yen","yeyunum","yodium","yoga","yoghurt","yogi","yogia","yohimbina","yojana","yokal","yolk","yos","yosong","yoyo","yubileum","yuda","yudikatif","yudisial","yudisium","yudo","yudoka","yuk","yunani","yunda","yunior","yunta","yupa","yupiter","yura","yuran","yuridis","yuris","yurisdiksi","yurisprudensi","yustisi","yute","yuvenil","yuwana","yuwaraja","yuyitsu","yuyu","zabah","zabaniah","zabarjad","zabib","zabur","zadah","zahid","zai","zaim","zair","zaitun","zakar","zakat","zakelek","zakiah","zakum","zal","zalim","zalir","zaman","zamin","zamindar","zamrud","zamzam","zan","zanggi","zantara","zarafah","zarah","zaratit","zariah","zariat","zat","zatua","zawal","zawiat","zebra","zebu","zelot","zen","zend-avesta","zendeling","zending","zeni","zenit","zeolit","zeoponik","zero","zet","zeta","ziadah","ziarah","zib","zig-zag","zigomorf","zigot","zikir","zilullah","zimase","zimi","zimogen","zimolisis","zimosis","zimotik","zimurgi","zina","zindik","zink","zinkografi","zion","zionis","zionisme","zirafah","zirah","zirbad","zirkonia","zirkonium","zirnikh","ziter","zodiak","zoetrop","zohal","zohrah","zohrat","zona","zonasi","zonder","zone","zoning","zoofit","zoofobia","zoogani","zoogeografi","zoologi","zoonosis","zoosemiotika","zuama","zuhud","zuhur","zulfikar","zulhijah","zulkaidah","zulmat","zulu","zurafah","zuriah","zus",""];

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\prefix_rules.js":
/*!**********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/indonesian/prefix_rules.js ***!
  \**********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2017, Alif Bhaskoro, Andy Librian, R. Kukuh (Reimplemented from https://github.com/sastrawi/sastrawi)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.

var Removal = __webpack_require__(/*! ./removal */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\removal.js");

// Make global variable for dictionary
var dictionary = [];
function loadDictionary(){
    var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");
    //var dirname = __dirname + "/../../../../data/kata-dasar.txt";
    //var fin = fs.readFileSync(dirname).toString().split("\n");
    var fin = __webpack_require__(/*! ./data/kata-dasar.json */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\data\\kata-dasar.json");
    fin.forEach(function (word) {
      if (word) {
        dictionary.push(word.trim());
      }
    });
}
loadDictionary();

function PrefixRules() {
	var PrefixRules = this;

	this.removal = undefined;
	this.current_word = undefined;

	// Find certain word in dictionary
	function find(word) {
	    return (dictionary.indexOf(word) != -1);
	}

	// Run the array of disambiguate rules on input word
	function runDisambiguator(disambiguateRules, word){
		var result = undefined;
	
		for(var i in disambiguateRules){
	    	result = disambiguateRules[i](word);
	    	if(find(result)){
	    		break;
	    	}
	    }
	    
	    if(result==undefined){
	    	this.current_word = word;
	    	this.removal = undefined;
	    	return this;
	    }

	    return createResultObject(result, word, "DP");
	}

	function createResultObject(result, word, type){
		var removedPart = word.replace(result, '');
		var removal = new Removal(word, result, removedPart, type);

		this.removal = removal;
		this.current_word = result;
		
		return this;
	}

	PrefixRules.RemovePlainPrefix = function(word){
		var result = word.replace(/^(di|ke|se)/, '');
		if(result!=word){
			var removedPart = word.replace(result, '');

			var removal = new Removal(word, result, removedPart, 'DP');

			this.removal = removal;
		}
		else{
			this.removal = undefined;
		}
		this.current_word = result;
		return this;
	}

	// RULE 1
	function disambiguateRule1A(word){
		// Rule 1a : berV -> ber-V
		var matches = word.match(/^ber([aiueo].*)$/);
	    if(matches){
	        return matches[1];
	    }
	}

	function disambiguateRule1B(word){
		// Rule 1b : berV -> be-rV
	    var matches = word.match(/^ber([aiueo].*)$/);
	    if(matches){
	        return 'r' + matches[1];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule1 = function(word){
		// Push rules 1A & 1B
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule1A);
		disambiguateRules.push(disambiguateRule1B);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 2
	function disambiguateRule2(word){
		// Rule 2 : berCAP -> ber-CAP where C != 'r' AND P != 'er'
		var matches = word.match(/^ber([bcdfghjklmnpqrstvwxyz])([a-z])(.*)/);
	    if(matches){
	    	if(matches[3].match(/^er(.*)$/)){
	    		return
	    	}
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule2 = function(word){
		// Push rule 2
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule2);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 3
	function disambiguateRule3(word){
		// Rule 3 : berCAerV -> ber-CAerV where C != 'r'
		var matches = word.match(/ber([bcdfghjklmnpqrstvwxyz])([a-z])er([aiueo])(.*)/);
	    if(matches){
	    	if(matches[1] == "r"){
	    		return
	    	}
	        return matches[1] + matches[2] + "er" + matches[3] + matches[4];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule3 = function(word){
		// Push rule 3
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule3);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 4
	function disambiguateRule4(word){
		// Rule 4 : belajar -> ajar
		if(word == "belajar"){
			return "ajar";
		}
	}

	PrefixRules.DisambiguatorPrefixRule4 = function(word){
		// Push rule 4
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule4);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 5
	function disambiguateRule5(word){
		// Rule 5 : beC1erC2 -> be-C1erC2 where C1 != 'r'
		var matches = word.match(/be([bcdfghjklmnpqstvwxyz])(er[bcdfghjklmnpqrstvwxyz])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule5 = function(word){
		// Push rule 5
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule5);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 6
	function disambiguateRule6a(word){
		// Rule 6a : terV -> ter-V
		var matches = word.match(/^ter([aiueo].*)$/);
	    if(matches){
	        return matches[1];
	    }
	}

	function disambiguateRule6b(word){
		// Rule 6b : terV -> te-rV
		var matches = word.match(/^ter([aiueo].*)$/);
	    if(matches){
	        return "r" + matches[1];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule6 = function(word){
		// Push rule 6
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule6a);
		disambiguateRules.push(disambiguateRule6b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 7
	function disambiguateRule7(word){
		// Rule 7 : terCerv -> ter-CerV where C != 'r'
		var matches = word.match(/^ter([bcdfghjklmnpqrstvwxyz])er([aiueo].*)$/);
	    if(matches){
	    	if(matches[1]=="r"){
	    		return
	    	}
	        return matches[1] + "er" + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule7 = function(word){
		// Push rule 7
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule7);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 8
	function disambiguateRule8(word){
		// Rule 8 : terCP -> ter-CP where C != 'r' and P != 'er'
		var matches = word.match(/^ter([bcdfghjklmnpqrstvwxyz])(.*)$/);
	    if(matches){
	    	if(matches[1]=="r" || matches[2].match(/^er(.*)$/)){
	    		return
	    	}
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule8 = function(word){
		// Push rule 8
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule8);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 9
	function disambiguateRule9(word){
		// Rule 9 : te-C1erC2 -> te-C1erC2 where C1 != 'r'
		var matches = word.match(/^te([bcdfghjklmnpqrstvwxyz])er([bcdfghjklmnpqrstvwxyz])(.*)$/);
	    if(matches){
	    	if(matches[1]=="r"){
	    		return
	    	}
	        return matches[1] + "er" + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule9 = function(word){
		// Push rule 9
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule9);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 10
	function disambiguateRule10(word){
		// Rule 10 : me{l|r|w|y}V -> me-{l|r|w|y}V
		var matches = word.match(/^me([lrwy])([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule10 = function(word){
		// Push rule 10
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule10);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 11
	function disambiguateRule11(word){
		// Rule 11 : mem{b|f|v} -> mem-{b|f|v}
		var matches = word.match(/^mem([bfv])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule11 = function(word){
		// Push rule 11
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule11);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 12
	function disambiguateRule12(word){
		// Nazief and Adriani Rule 12 : beC1erC2 -> be-C1erC2 where C1 != 'r'
        // Modified by Jelita Asian's CS Rule 12 : mempe -> mem-pe to stem mempengaruhi
		var matches = word.match(/^mempe(.*)$/);
	    if(matches){
	        return "pe" + matches[1];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule12 = function(word){
		// Push rule 12
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule12);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 13
	function disambiguateRule13a(word){
		// Rule 13a : mem{rV|V} -> me-m{rV|V}
		var matches = word.match(/^mem([aiueo])(.*)$/);
	    if(matches){
	        return "m" + matches[1] + matches[2];
	    }
	}

	function disambiguateRule13b(word){
		// Rule 13b : mem{rV|V} -> me-p{rV|V}
		var matches = word.match(/^mem([aiueo])(.*)$/);
	    if(matches){
	        return "p" + matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule13 = function(word){
		// Push rule 13
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule13a);
		disambiguateRules.push(disambiguateRule13b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 14
	function disambiguateRule14(word){
		/*Rule 14 modified by Andy Librian : men{c|d|j|s|t|z} -> men-{c|d|j|s|t|z}
        in order to stem mentaati
  
        Rule 14 modified by ECS: men{c|d|j|s|z} -> men-{c|d|j|s|z}
        in order to stem mensyaratkan, mensyukuri
  
        Original CS Rule no 14 was : men{c|d|j|z} -> men-{c|d|j|z}*/
		var matches = word.match(/^men([cdjstz])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule14 = function(word){
		// Push rule 14
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule14);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 15
	function disambiguateRule15a(word){
		// Rule 15a : men{V} -> me-n{V}
		var matches = word.match(/^men([aiueo])(.*)$/);
	    if(matches){
	        return "n" + matches[1] + matches[2];
	    }
	}

	function disambiguateRule15b(word){
		// Rule 15b : men{V} -> me-t{V}
		var matches = word.match(/^men([aiueo])(.*)$/);
	    if(matches){
	        return "t" + matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule15 = function(word){
		// Push rule 15
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule15a);
		disambiguateRules.push(disambiguateRule15b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 16
	function disambiguateRule16(word){
		// Original Nazief and Adriani's Rule 16 : meng{g|h|q} -> meng-{g|h|q}
        // Modified Jelita Asian's CS Rule 16 : meng{g|h|q|k} -> meng-{g|h|q|k} to stem mengkritik
		var matches = word.match(/^meng([g|h|q|k])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule16 = function(word){
		// Push rule 16
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule16);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 17
	function disambiguateRule17a(word){
		// Rule 17a : mengV -> meng-V
		var matches = word.match(/^meng([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	function disambiguateRule17b(word){
		// Rule 17b : mengV -> meng-kV
		var matches = word.match(/^meng([aiueo])(.*)$/);
	    if(matches){
	        return "k" + matches[1] + matches[2];
	    }
	}

	function disambiguateRule17c(word){
		// Rule 17c : mengV -> meng-V- where V = 'e'
		var matches = word.match(/^menge(.*)$/);
	    if(matches){
	        return matches[1];
	    }
	}

	function disambiguateRule17d(word){
		// Rule 17d : mengV -> me-ngV
		var matches = word.match(/^meng([aiueo])(.*)$/);
	    if(matches){
	        return "ng" + matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule17 = function(word){
		// Push rule 17
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule17a);
		disambiguateRules.push(disambiguateRule17b);
		disambiguateRules.push(disambiguateRule17c);
		disambiguateRules.push(disambiguateRule17d);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 18
	function disambiguateRule18a(word){
		// Rule 18a : menyV -> me-nyV to stem menyala -> nyala
		var matches = word.match(/^meny([aiueo])(.*)$/);
	    if(matches){
	        return "ny" + matches[1] + matches[2];
	    }
	}

	function disambiguateRule18b(word){
		// Original Rule 18b : menyV -> meny-sV
        // Modified by CC (shifted into 18b, see also 18a)
		var matches = word.match(/^meny([aiueo])(.*)$/);
	    if(matches){
	        return "s" + matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule18 = function(word){
		// Push rule 18
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule18a);
		disambiguateRules.push(disambiguateRule18b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 19
	function disambiguateRule19(word){
		// Original Rule 19 : mempV -> mem-pV where V != 'e'
        // Modified Rule 19 by ECS : mempA -> mem-pA where A != 'e' in order to stem memproteksi
		var matches = word.match(/^memp([abcdfghijklmopqrstuvwxyz])(.*)$/);
	    if(matches){
	        return "p" + matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule19 = function(word){
		// Push rule 19
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule19);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 20
	function disambiguateRule20(word){
		// Rule 20 : pe{w|y}V -> pe-{w|y}V
		var matches = word.match(/^pe([wy])([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule20 = function(word){
		// Push rule 20
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule20);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 21
	function disambiguateRule21a(word){
		// Rule 21a : perV -> per-V
		var matches = word.match(/^per([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	function disambiguateRule21b(word){
		// Rule 21b : perV -> pe-rV
		var matches = word.match(/^pe(r[aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule21= function(word){
		// Push rule 21
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule21a);
		disambiguateRules.push(disambiguateRule21b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 23
	function disambiguateRule23(word){
		// Rule 23 : perCAP -> per-CAP where C != 'r' AND P != 'er'
		var matches = word.match(/^per([bcdfghjklmnpqrstvwxyz])([a-z])(.*)$/);
	    if(matches){
	    	if(matches[3].match(/^er(.*)$/)){
	    		return
	    	}
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule23 = function(word){
		// Push rule 23
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule23);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 24
	function disambiguateRule24(word){
		// Rule 24 : perCAerV -> per-CAerV where C != 'r'
		var matches = word.match(/^per([bcdfghjklmnpqrstvwxyz])([a-z])er([aiueo])(.*)$/);
	    if(matches){
	    	if(matches[1] == "r"){
	    		return
	    	}
	        return matches[1] + matches[2] + "er" + matches[3] + matches[4];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule24 = function(word){
		// Push rule 24
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule24);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 25
	function disambiguateRule25(word){
		// Rule 25 : pem{b|f|v} -> pem-{b|f|v}
		var matches = word.match(/^pem([bfv])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule25 = function(word){
		// Push rule 25
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule25);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 26
	function disambiguateRule26a(word){
		// Rule 26a : pem{rV|V} -> pe-m{rV|V}
		var matches = word.match(/^pem([aiueo])(.*)$/);
	    if(matches){
	        return "m" + matches[1] + matches[2];
	    }
	}

	function disambiguateRule26b(word){
		// Rule 26b : pem{rV|V} -> pe-p{rV|V}
		var matches = word.match(/^pem([aiueo])(.*)$/);
	    if(matches){
	        return "p" + matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule26 = function(word){
		// Push rule 26
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule26a);
		disambiguateRules.push(disambiguateRule26b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 27
	function disambiguateRule27(word){
		// Rule 27 : pen{c|d|j|s|t|z} -> pen-{c|d|j|s|t|z}
		var matches = word.match(/^pen([cdjstz])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule27 = function(word){
		// Push rule 27
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule27);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 28
	function disambiguateRule28a(word){
		// Rule 28a : pen{V} -> pe-n{V}
		var matches = word.match(/^pen([aiueo])(.*)$/);
	    if(matches){
	        return "n" + matches[1] + matches[2];
	    }
	}

	function disambiguateRule28b(word){
		// Rule 28b : pen{V} -> pe-t{V}
		var matches = word.match(/^pen([aiueo])(.*)$/);
	    if(matches){
	        return "t" + matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule28 = function(word){
		// Push rule 28
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule28a);
		disambiguateRules.push(disambiguateRule28b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 29
	function disambiguateRule29(word){
		// Rule 29 by ECS : pengC -> peng-C
		var matches = word.match(/^peng([bcdfghjklmnpqrstvwxyz])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule29 = function(word){
		// Push rule 29
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule29);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 30
	function disambiguateRule30a(word){
		// Rule 30a : pengV -> peng-V
		var matches = word.match(/^peng([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	function disambiguateRule30b(word){
		// Rule 30b : pengV -> peng-kV
		var matches = word.match(/^peng([aiueo])(.*)$/);
	    if(matches){
	        return "k" + matches[1] + matches[2];
	    }
	}

	function disambiguateRule30c(word){
		// Rule 30c : pengV -> pengV- where V = 'e'
		var matches = word.match(/^penge(.*)$/);
	    if(matches){
	        return matches[1];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule30 = function(word){
		// Push rule 30
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule30a);
		disambiguateRules.push(disambiguateRule30b);
		disambiguateRules.push(disambiguateRule30c);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 31
	function disambiguateRule31a(word){
		// Rule 31a : penyV -> pe-nyV
		var matches = word.match(/^peny([aiueo])(.*)$/);
	    if(matches){
	        return "ny" + matches[1] + matches[2];
	    }
	}

	function disambiguateRule31b(word){
		// Original Rule 31 : penyV -> peny-sV
		var matches = word.match(/^peny([aiueo])(.*)$/);
	    if(matches){
	        return "s" + matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule31 = function(word){
		// Push rule 31
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule31a);
		disambiguateRules.push(disambiguateRule31b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 32
	function disambiguateRule32(word){
		// Rule 32 : pelV -> pe-lV except pelajar -> ajar
		if(word=="pelajar"){
			return "ajar";
		}
		var matches = word.match(/^pe(l[aiueo])(.*)/);
	    if(matches){
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule32 = function(word){
		// Push rule 32
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule32);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 34
	function disambiguateRule34(word){
		// Rule 34 : peCP -> pe-CP where C != {r|w|y|l|m|n} and P != 'er'
		var matches = word.match(/^pe([bcdfghjklmnpqrstvwxyz])(.*)$/);
	    if(matches){
	    	if(matches[2].match(/^er(.*)$/)){
	    		return
	    	}
	        return matches[1] + matches[2];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule34 = function(word){
		// Push rule 34
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule34);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 35
	function disambiguateRule35(word){
		// Rule 35 : terC1erC2 -> ter-C1erC2 where C1 != {r}
		var matches = word.match(/^ter([bcdfghjkpqstvxz])(er[bcdfghjklmnpqrstvwxyz])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule35 = function(word){
		// Push rule 35
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule35);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 36
	function disambiguateRule36(word){
		// Rule 36 : peC1erC2 -> pe-C1erC2 where C1 != {r|w|y|l|m|n}
		var matches = word.match(/^pe([bcdfghjkpqstvxz])(er[bcdfghjklmnpqrstvwxyz])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule36 = function(word){
		// Push rule 36
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule36);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 37
	function disambiguateRule37a(word){
		// Rule 37a : CerV -> CerV
		var matches = word.match(/^([bcdfghjklmnpqrstvwxyz])(er[aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	function disambiguateRule37b(word){
		// Rule 37b : CerV -> CV
		var matches = word.match(/^([bcdfghjklmnpqrstvwxyz])er([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule37 = function(word){
		// Push rule 37
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule37a);
		disambiguateRules.push(disambiguateRule37b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 38
	function disambiguateRule38a(word){
		// Rule 38a : CelV -> CelV
		var matches = word.match(/^([bcdfghjklmnpqrstvwxyz])(el[aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	function disambiguateRule38b(word){
		// Rule 38b : CelV -> CV
		var matches = word.match(/^([bcdfghjklmnpqrstvwxyz])el([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule38 = function(word){
		// Push rule 38
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule38a);
		disambiguateRules.push(disambiguateRule38b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 39
	function disambiguateRule39a(word){
		// Rule 39a : CemV -> CemV
		var matches = word.match(/^([bcdfghjklmnpqrstvwxyz])(em[aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	function disambiguateRule39b(word){
		// Rule 39b : CemV -> CV
		var matches = word.match(/^([bcdfghjklmnpqrstvwxyz])em([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule39 = function(word){
		// Push rule 39
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule39a);
		disambiguateRules.push(disambiguateRule39b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 40
	function disambiguateRule40a(word){
		// Rule 40a : CinV -> CinV
		var matches = word.match(/^([bcdfghjklmnpqrstvwxyz])(in[aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	function disambiguateRule40b(word){
		// Rule 40b : CinV -> CV
		var matches = word.match(/^([bcdfghjklmnpqrstvwxyz])in([aiueo])(.*)$/);
	    if(matches){
	        return matches[1] + matches[2] + matches[3];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule40 = function(word){
		// Push rule 40
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule40a);
		disambiguateRules.push(disambiguateRule40b);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 41
	function disambiguateRule41(word){
		// Rule 41 : kuA -> ku-A
		var matches = word.match(/^ku(.*)$/);
	    if(matches){
	        return matches[1];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule41 = function(word){
		// Push rule 41
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule41);

	    return runDisambiguator(disambiguateRules, word);
	}

	// RULE 42
	function disambiguateRule42(word){
		// Rule 42 : kauA -> kau-A
		var matches = word.match(/^kau(.*)$/);
	    if(matches){
	        return matches[1];
	    }
	}

	PrefixRules.DisambiguatorPrefixRule42 = function(word){
		// Push rule 42
		var disambiguateRules = [];
		disambiguateRules.push(disambiguateRule42);

	    return runDisambiguator(disambiguateRules, word);
	}
}

module.exports 	= PrefixRules;

// Initalize prefix rules array
var rules 		= [];
var pr = new PrefixRules();

// Push all rules
rules.push(pr.RemovePlainPrefix);
rules.push(pr.DisambiguatorPrefixRule1);
rules.push(pr.DisambiguatorPrefixRule2);
rules.push(pr.DisambiguatorPrefixRule3);
rules.push(pr.DisambiguatorPrefixRule4);
rules.push(pr.DisambiguatorPrefixRule5);
rules.push(pr.DisambiguatorPrefixRule6);
rules.push(pr.DisambiguatorPrefixRule7);
rules.push(pr.DisambiguatorPrefixRule8);
rules.push(pr.DisambiguatorPrefixRule9);
rules.push(pr.DisambiguatorPrefixRule10);
rules.push(pr.DisambiguatorPrefixRule11);
rules.push(pr.DisambiguatorPrefixRule12);
rules.push(pr.DisambiguatorPrefixRule13);
rules.push(pr.DisambiguatorPrefixRule14);
rules.push(pr.DisambiguatorPrefixRule15);
rules.push(pr.DisambiguatorPrefixRule16);
rules.push(pr.DisambiguatorPrefixRule17);
rules.push(pr.DisambiguatorPrefixRule18);
rules.push(pr.DisambiguatorPrefixRule19);
rules.push(pr.DisambiguatorPrefixRule20);
rules.push(pr.DisambiguatorPrefixRule21);
rules.push(pr.DisambiguatorPrefixRule23);
rules.push(pr.DisambiguatorPrefixRule24);
rules.push(pr.DisambiguatorPrefixRule25);
rules.push(pr.DisambiguatorPrefixRule26);
rules.push(pr.DisambiguatorPrefixRule27);
rules.push(pr.DisambiguatorPrefixRule28);
rules.push(pr.DisambiguatorPrefixRule29);
rules.push(pr.DisambiguatorPrefixRule30);
rules.push(pr.DisambiguatorPrefixRule31);
rules.push(pr.DisambiguatorPrefixRule32);
rules.push(pr.DisambiguatorPrefixRule34);
rules.push(pr.DisambiguatorPrefixRule35);
rules.push(pr.DisambiguatorPrefixRule36);
rules.push(pr.DisambiguatorPrefixRule37);
rules.push(pr.DisambiguatorPrefixRule38);
rules.push(pr.DisambiguatorPrefixRule39);
rules.push(pr.DisambiguatorPrefixRule40);
rules.push(pr.DisambiguatorPrefixRule41);
rules.push(pr.DisambiguatorPrefixRule42);

PrefixRules.rules = rules;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\removal.js":
/*!*****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/indonesian/removal.js ***!
  \*****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2017, Alif Bhaskoro, Andy Librian, R. Kukuh (Reimplemented from https://github.com/sastrawi/sastrawi)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.

function Removal (original_word, result, removedPart, affixType) {
    this.original_word 	= original_word;
    this.result 		= result;
    this.removedPart 	= removedPart
    this.affixType 		= affixType;
}
 
Removal.prototype.getOriginalWord = function() {
    return this.original_word;
};

Removal.prototype.getResult = function() {
    return this.result;
};

Removal.prototype.getRemovedPart = function() {
    return this.removedPart;
};

Removal.prototype.getAffixType = function() {
    return this.affixType;
};

module.exports = Removal;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\stemmer_id.js":
/*!********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/indonesian/stemmer_id.js ***!
  \********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2017, Alif Bhaskoro, Andy Librian, R. Kukuh (Reimplemented from https://github.com/sastrawi/sastrawi)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var baseStemmer = __webpack_require__(/*! ./base_stemmer_id */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\base_stemmer_id.js");
var stemmer = new baseStemmer();

// Dictionary
var dictionary = [];
loadDictionary();

// Rules
var SuffixRules = __webpack_require__(/*! ./suffix_rules */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\suffix_rules.js");
var PrefixRules = __webpack_require__(/*! ./prefix_rules */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\prefix_rules.js");

var suffix_rules = SuffixRules.rules;
var prefix_rules = PrefixRules.rules;

// Removals
var removals;

// Words
var original_word;
var current_word;

module.exports = stemmer;

// perform full stemming algorithm on a single word
stemmer.stem = function(token) {
    // Cache stemmer not yet implemented
    // Set to lowercase
    token = token.toLowerCase();

    //Initiate everything
    removals = [];

    if(isPlural(token)){
        return stemPluralWord(token);
    }
    else{
        return stemSingularWord(token);
    }
};

// Stem for plural word
function stemPluralWord(plural_word){
    var matches = plural_word.match(/^(.*)-(.*)$/);
    if(!matches){
        return plural_word;
    }
    words = [matches[1], matches[2]];

    //malaikat-malaikat-nya -> malaikat malaikat-nya
    suffix = words[1];
    suffixes = ["ku", "mu", "nya", "lah", "kah", "tah", "pun"];
    matches = words[0].match(/^(.*)-(.*)$/);
    if(suffixes.indexOf(suffix) != -1 && matches){
        words[0] = matches[1];
        words[1] = matches[2] + '-' + suffix;
    }

    //berbalas-balasan -> balas
    rootWord1 = stemSingularWord(words[0]);
    rootWord2 = stemSingularWord(words[1]);

    //meniru-nirukan -> tiru
    if(!find(words[1]) && rootWord2==words[1]){
        rootWord2 = stemSingularWord("me" + words[1]);
    }
    if(rootWord1==rootWord2){
        return rootWord1;
    }
    else{
        return plural_word;
    }
}

// Stem for singular word
function stemSingularWord(word){
    original_word = word; // Save the original word for reverting later
    current_word = word;

    // Step 1
    if(current_word.length>3){
        // Step 2-5
        stemmingProcess();
    }

    // Step 6
    if(find(current_word)){
        return current_word;
    }
    else{
        return original_word;
    }
}

// Return true if word is in plural form ex: gelas-gelas, else false
function isPlural(token){
    var matches = token.match(/^(.*)-(ku|mu|nya|lah|kah|tah|pun)$/);
    if(matches){
        return matches[1].search('-') != -1;
    }
    return token.search('-') != -1;
}

// Find certain word in dictionary
function find(word) {
    return (dictionary.indexOf(word) != -1);
}

function loadDictionary(){
    var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");
    //var dirname = __dirname + "/../../../../data/kata-dasar.txt";
    //var fin = fs.readFileSync(dirname).toString().split("\n");
    var fin = __webpack_require__(/*! ./data/kata-dasar.json */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\data\\kata-dasar.json");
    fin.forEach(function (word) {
        if (word) {
          dictionary.push(word.trim());
        }
    });
}

// Stemming from step 2-5
function stemmingProcess(){
    if(find(current_word))
        return

    // Confix Stripping
    // Try to remove prefixes first before suffixes if the specification is met
    if(precedenceAdjustmentSpecification(original_word)){
        // Step 4, 5
        removePrefixes();
        if(find(current_word))
            return

        // Step 2, 3
        removeSuffixes();
        if(find(current_word)){
            return
        }
        else{
            // if the trial is failed, restore the original word
            // and continue to normal rule precedence (suffix first, prefix afterwards)
            current_word = original_word;
            removals = []
        }
    }

    // Step 2, 3
    removeSuffixes();
    if(find(current_word))
        return

    // Step 4, 5
    removePrefixes();
    if(find(current_word))
        return

    //ECS Loop Restore Prefixes
    loopRestorePrefixes();
}

// Remove Suffixes
function removeSuffixes(){
    for(var i in suffix_rules){
        resultObj = suffix_rules[i](current_word);

        // Add result to variable
        if(resultObj.removal!=undefined){
            removals.push(resultObj.removal);
        }
        current_word = resultObj.current_word;

        if(find(current_word))
            return current_word;
    }
}

// Remove Prefixes
function removePrefixes(){
    for(var i=0; i<3; i++){
        var removalCount = removals.length;
        checkPrefixRules();
        if(find(current_word))
            return current_word;
    }
}

function checkPrefixRules(){
    var removalCount = removals.length;
    var j = 0;
    for(j=0; j<prefix_rules.length; j++){
        resultObj = prefix_rules[j](current_word);

        // Add result to variable
        if(resultObj.removal!=undefined){
            removals.push(resultObj.removal);
        }
        current_word = resultObj.current_word;

        if(find(current_word))
            return current_word;
        if(removals.length>removalCount){
            return
        }
    }
}

// Loop Restore Prefixes
function loopRestorePrefixes(){
    restorePrefix();

    var reversed_removals = removals.reverse();
    var temp_current_word = current_word;

    for(var i in reversed_removals){
        current_removal = reversed_removals[i];

        if(!isSuffixRemovals(current_removal)){
            continue
        }

        if(current_removal.getRemovedPart() == "kan"){
            current_word = current_removal.getResult() + "k";

            // Step 4, 5
            removePrefixes();
            if(find(current_word))
                return
            current_word = current_removal.getResult() + "kan";
        }
        else{
            current_word = current_removal.getOriginalWord();
        }

        // Step 4, 5
        removePrefixes();
        if(find(current_word))
            return

        current_word = temp_current_word;
    }
}

function isSuffixRemovals(removal){
    var type = removal.getAffixType();
    if(type == "DS" || type == "PP" || type == "P"){
        return true;
    }
    return false;
}
function restorePrefix(){
    for(var i=0; i<removals.length; i++){
        current_word = removals[i].getOriginalWord();
        break;
    }

    for(var i=0; i<removals.length; i++){
        if(removals[i].getAffixType() == "DP"){
            removals.splice(i, 1);
            i--;
        }
    }
}

// Check if word require precedence adjustment or not
// Adjustment means remove prefix then suffix instead of remove suffix then prefix
function precedenceAdjustmentSpecification(word){
    var regex_rules = [
        /^be(.*)lah$/,
        /^be(.*)an$/,
        /^me(.*)i$/,
        /^di(.*)i$/,
        /^pe(.*)i$/,
        /^ter(.*)i$/,
    ];

    for(var i in regex_rules){
        if(word.match(regex_rules[i])){
            return true;
        }
    }
    return false;
}

//exports for tests
stemmer.isPlural = isPlural;
stemmer.dictionary = dictionary;
stemmer.a = suffix_rules[0];


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\suffix_rules.js":
/*!**********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/indonesian/suffix_rules.js ***!
  \**********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2017, Alif Bhaskoro, Andy Librian, R. Kukuh (Reimplemented from https://github.com/sastrawi/sastrawi)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.

var Removal = __webpack_require__(/*! ./removal */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\indonesian\\removal.js");

function SuffixRules() {
	var SuffixRules = this;

	this.removal = undefined;
	this.current_word = undefined;

	function createResultObject(result, word, type){
		if(result!=word){
			var removedPart = word.replace(result, '');

			var removal = new Removal(word, result, removedPart, type);

			this.removal = removal;
		}
		else{
			this.removal = undefined;
		}
		this.current_word = result;
		return this;
	}

	SuffixRules.RemoveInflectionalParticle = function(word){
		var result = word.replace(/-*(lah|kah|tah|pun)$/, '');
		return createResultObject(result, word, "P");
	}

	SuffixRules.RemoveInflectionalPossessivePronoun = function(word){
		var result = word.replace(/-*(ku|mu|nya)$/, '');
		return createResultObject(result, word, "PP");
	}

	SuffixRules.RemoveDerivationalSuffix = function(word){
		var result = word.replace(/(is|isme|isasi|i|kan|an)$/, '');
		return createResultObject(result, word, "DS");
	}
}

module.exports = SuffixRules;

// Initalize suffix rules array
var rules = [];
var sr = new SuffixRules();

rules.push(sr.RemoveInflectionalParticle);
rules.push(sr.RemoveInflectionalPossessivePronoun);
rules.push(sr.RemoveDerivationalSuffix);

SuffixRules.rules = rules;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\lancaster_rules.js":
/*!**************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/lancaster_rules.js ***!
  \**************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

exports.rules = {
    "a": [
        {
            "continuation": false, 
            "intact": true, 
            "pattern": "ia", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": true, 
            "pattern": "a", 
            "size": "1"
        }
    ], 
    "b": [
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "bb", 
            "size": "1"
        }
    ], 
    "c": [
        {
            "appendage": "s", 
            "continuation": false, 
            "intact": false, 
            "pattern": "ytic", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ic", 
            "size": "2"
       }, 
        {
            "appendage": "t", 
            "continuation": true, 
            "intact": false, 
            "pattern": "nc", 
            "size": "1"
        }
    ], 
    "d": [
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "dd", 
            "size": "1"
        }, 
        {
            "appendage": "y", 
            "continuation": true, 
            "intact": false, 
            "pattern": "ied", 
            "size": "3"
        }, 
        {
            "appendage": "ss", 
            "continuation": false, 
            "intact": false, 
            "pattern": "ceed", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "eed", 
            "size": "1"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ed", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "hood", 
            "size": "4"
        }
    ], 
    "e": [
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "e", 
            "size": "1"
        }
    ], 
    "f": [
        {
            "appendage": "v", 
            "continuation": false, 
            "intact": false, 
            "pattern": "lief", 
            "size": "1"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "if", 
            "size": "2"
        }
    ], 
    "g": [
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ing", 
            "size": "3"
        }, 
        {
            "appendage": "y", 
            "continuation": false, 
            "intact": false, 
            "pattern": "iag", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ag", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "gg", 
            "size": "1"
        }
    ], 
    "h": [
        {
            "continuation": false, 
            "intact": true, 
            "pattern": "th", 
            "size": "2"
        }, 
        {
            "appendage": "ct", 
            "continuation": false, 
            "intact": false, 
            "pattern": "guish", 
            "size": "5"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ish", 
            "size": "3"
        }
    ], 
    "i": [
        {
            "continuation": false, 
            "intact": true, 
            "pattern": "i", 
            "size": "1"
        }, 
        {
            "appendage": "y", 
            "continuation": true, 
            "intact": false, 
            "pattern": "i", 
            "size": "1"
        }
    ], 
    "j": [
        {
            "appendage": "d", 
            "continuation": false, 
            "intact": false, 
            "pattern": "ij", 
            "size": "1"
        }, 
        {
            "appendage": "s", 
            "continuation": false, 
            "intact": false, 
            "pattern": "fuj", 
            "size": "1"
        }, 
        {
            "appendage": "d", 
            "continuation": false, 
            "intact": false, 
            "pattern": "uj", 
            "size": "1"
        }, 
        {
            "appendage": "d", 
            "continuation": false, 
            "intact": false, 
            "pattern": "oj", 
            "size": "1"
        }, 
        {
            "appendage": "r", 
            "continuation": false, 
            "intact": false, 
            "pattern": "hej", 
            "size": "1"
        }, 
        {
            "appendage": "t", 
            "continuation": false, 
            "intact": false, 
            "pattern": "verj", 
            "size": "1"
        }, 
        {
            "appendage": "t", 
            "continuation": false, 
            "intact": false, 
            "pattern": "misj", 
            "size": "2"
        }, 
        {
            "appendage": "d", 
            "continuation": false, 
            "intact": false, 
            "pattern": "nj", 
            "size": "1"
        }, 
        {
            "appendage": "s", 
            "continuation": false, 
            "intact": false, 
            "pattern": "j", 
            "size": "1"
        }
    ], 
    "l": [
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ifiabl", 
            "size": "6"
        }, 
        {
            "appendage": "y", 
            "continuation": false, 
            "intact": false, 
            "pattern": "iabl", 
            "size": "4"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "abl", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ibl", 
            "size": "3"
        }, 
        {
            "appendage": "l", 
            "continuation": true, 
            "intact": false, 
            "pattern": "bil", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "cl", 
            "size": "1"
        }, 
        {
            "appendage": "y", 
            "continuation": false, 
            "intact": false, 
            "pattern": "iful", 
            "size": "4"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ful", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ul", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ial", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ual", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "al", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ll", 
            "size": "1"
        }
    ], 
    "m": [
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ium", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": true, 
            "pattern": "um", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ism", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "mm", 
            "size": "1"
        }
    ], 
    "n": [
        {
            "appendage": "j", 
            "continuation": true, 
            "intact": false, 
            "pattern": "sion", 
            "size": "4"
        }, 
        {
            "appendage": "ct", 
            "continuation": false, 
            "intact": false, 
            "pattern": "xion", 
            "size": "4"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ion", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ian", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "an", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "een", 
            "size": "0"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "en", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "nn", 
            "size": "1"
        }
    ], 
    "p": [
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ship", 
            "size": "4"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "pp", 
            "size": "1"
        }
    ], 
    "r": [
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "er", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ear", 
            "size": "0"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ar", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "or", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ur", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "rr", 
            "size": "1"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "tr", 
            "size": "1"
        }, 
        {
            "appendage": "y", 
            "continuation": true, 
            "intact": false, 
            "pattern": "ier", 
            "size": "3"
        }
    ], 
    "s": [
        {
            "appendage": "y", 
            "continuation": true, 
            "intact": false, 
            "pattern": "ies", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "sis", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "is", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ness", 
            "size": "4"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ss", 
            "size": "0"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ous", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": true, 
            "pattern": "us", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": true, 
            "pattern": "s", 
            "size": "1"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "s", 
            "size": "0"
        }
    ], 
    "t": [
        {
            "appendage": "y", 
            "continuation": false, 
            "intact": false, 
            "pattern": "plicat", 
            "size": "4"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "at", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ment", 
            "size": "4"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ent", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ant", 
            "size": "3"
        }, 
        {
            "appendage": "b", 
            "continuation": false, 
            "intact": false, 
            "pattern": "ript", 
            "size": "2"
        }, 
        {
            "appendage": "b", 
            "continuation": false, 
            "intact": false, 
            "pattern": "orpt", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "duct", 
            "size": "1"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "sumpt", 
            "size": "2"
        }, 
        {
            "appendage": "iv", 
            "continuation": false, 
            "intact": false, 
            "pattern": "cept", 
            "size": "2"
        }, 
        {
            "appendage": "v", 
            "continuation": false, 
            "intact": false, 
            "pattern": "olut", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "sist", 
            "size": "0"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ist", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "tt", 
            "size": "1"
        }
    ], 
    "u": [
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "iqu", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ogu", 
            "size": "1"
        }
    ], 
    "v": [
        {
            "appendage": "j", 
            "continuation": true, 
            "intact": false, 
            "pattern": "siv", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "eiv", 
            "size": "0"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "iv", 
            "size": "2"
        }
    ], 
    "y": [
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "bly", 
            "size": "1"
        }, 
        {
            "appendage": "y", 
            "continuation": true, 
            "intact": false, 
            "pattern": "ily", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ply", 
            "size": "0"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ly", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ogy", 
            "size": "1"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "phy", 
            "size": "1"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "omy", 
            "size": "1"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "opy", 
            "size": "1"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ity", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ety", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "lty", 
            "size": "2"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "istry", 
            "size": "5"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ary", 
            "size": "3"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "ory", 
            "size": "3"
        }, 
        {
            "continuation": false, 
            "intact": false, 
            "pattern": "ify", 
            "size": "3"
        }, 
        {
            "appendage": "t", 
            "continuation": true, 
            "intact": false, 
            "pattern": "ncy", 
            "size": "2"
        }, 
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "acy", 
            "size": "3"
        }
    ], 
    "z": [
        {
            "continuation": true, 
            "intact": false, 
            "pattern": "iz", 
            "size": "2"
        }, 
        {
            "appendage": "s", 
            "continuation": false, 
            "intact": false, 
            "pattern": "yz", 
            "size": "1"
        }
    ]
};



/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\lancaster_stemmer.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/lancaster_stemmer.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Stemmer = __webpack_require__(/*! ./stemmer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer.js");
var ruleTable = __webpack_require__(/*! ./lancaster_rules */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\lancaster_rules.js").rules;

function acceptable(candidate) {
    if (candidate.match(/^[aeiou]/))
        return (candidate.length > 1);
    else
        return (candidate.length > 2 && candidate.match(/[aeiouy]/));
}

// take a token, look up the applicatble rule section and attempt some stemming!
function applyRuleSection(token, intact) {
    var section = token.substr( - 1);
    var rules = ruleTable[section];

    if (rules) {
        for (var i = 0; i < rules.length; i++) {
            if ((intact || !rules[i].intact)
            // only apply intact rules to intact tokens
            && token.substr(0 - rules[i].pattern.length) == rules[i].pattern) {
                // hack off only as much as the rule indicates
                var result = token.substr(0, token.length - rules[i].size);

                // if the rules wants us to apply an appendage do so
                if (rules[i].appendage)
                    result += rules[i].appendage;

                if (acceptable(result)) {
                    token = result;

                    // see what the rules wants to do next
                    if (rules[i].continuation) {
                        // this rule thinks there still might be stem left. keep at it.
                        // since we've applied a change we'll pass false in for intact
                        return applyRuleSection(result, false);
                    } else {
                        // the rule thinks we're done stemming. drop out.
                        return result;
                    }
                }
            }
        }
    }

    return token;
}

var LancasterStemmer = new Stemmer();
module.exports = LancasterStemmer;

LancasterStemmer.stem = function(token) {
    return applyRuleSection(token.toLowerCase(), true);
}

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer.js":
/*!*************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer.js ***!
  \*************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Stemmer = __webpack_require__(/*! ./stemmer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer.js");

// denote groups of consecutive consonants with a C and consecutive vowels
// with a V.
function categorizeGroups(token) {
    return token.replace(/[^aeiouy]+y/g, 'CV').replace(/[aeiou]+/g, 'V').replace(/[^V]+/g, 'C');
}

// denote single consonants with a C and single vowels with a V
function categorizeChars(token) {
    return token.replace(/[^aeiouy]y/g, 'CV').replace(/[aeiou]/g, 'V').replace(/[^V]/g, 'C');
}

// calculate the "measure" M of a word. M is the count of VC sequences dropping
// an initial C if it exists and a trailing V if it exists.
function measure(token) {
    if(!token)
    	return -1;

    return categorizeGroups(token).replace(/^C/, '').replace(/V$/, '').length / 2;
}

// determine if a token end with a double consonant i.e. happ
function endsWithDoublCons(token) {
    return token.match(/([^aeiou])\1$/);
}

// replace a pattern in a word. if a replacement occurs an optional callback
// can be called to post-process the result. if no match is made NULL is
// returned.
function attemptReplace(token, pattern, replacement, callback) {
    var result = null;
    
    if((typeof pattern == 'string') && token.substr(0 - pattern.length) == pattern)
        result = token.replace(new RegExp(pattern + '$'), replacement);
    else if((pattern instanceof RegExp) && token.match(pattern))
        result = token.replace(pattern, replacement);
        
    if(result && callback)
        return callback(result);
    else
        return result;
}

// attempt to replace a list of patterns/replacements on a token for a minimum
// measure M.
function attemptReplacePatterns(token, replacements, measureThreshold) {
    var replacement = token;

    for(var i = 0; i < replacements.length; i++) {   
    	if(measureThreshold == null || measure(attemptReplace(token, replacements[i][0], replacements[i][1])) > measureThreshold) {
    	    replacement = attemptReplace(replacement, replacements[i][0], replacements[i][2]) || replacement;
        }
    }
    
    return replacement;
}

// replace a list of patterns/replacements on a word. if no match is made return
// the original token.
function replacePatterns(token, replacements, measureThreshold) {
    return attemptReplacePatterns(token, replacements, measureThreshold) || token;
}

// TODO: this should replace all of the messy replacement stuff above
function replaceRegex(token, regex, includeParts, minimumMeasure) {
    var parts;
    var result = '';

    if(regex.test(token)) {
        parts = regex.exec(token);

        includeParts.forEach(function(i) {
            result += parts[i];
        });
    }

    if(measure(result) > minimumMeasure) {
        return result;
    }

    return null;
}

// step 1a as defined for the porter stemmer algorithm. 
function step1a(token) {    
    if(token.match(/(ss|i)es$/)) {
        return token.replace(/(ss|i)es$/, '$1');
    }

    if(token.substr(-1) == 's' && token.substr(-2, 1) != 's' && token.length > 2) {
        return token.replace(/s?$/, '');
    }

    return token;
}

// step 1b as defined for the porter stemmer algorithm. 
function step1b(token) {   
    if(token.substr(-3) == 'eed') {
        if(measure(token.substr(0, token.length - 3)) > 0)
            return token.replace(/eed$/, 'ee');
    } else {
        var result = attemptReplace(token, /(ed|ing)$/, '', function(token) {
            if(categorizeGroups(token).indexOf('V') >= 0) {
                result = attemptReplacePatterns(token, [['at', '', 'ate'],  ['bl', '', 'ble'], ['iz', '', 'ize']]);

                if(result != token) {
        		    return result;
        		} else {
        		  if(endsWithDoublCons(token) && token.match(/[^lsz]$/)) {
        			 return token.replace(/([^aeiou])\1$/, '$1');
                    }

        		  if(measure(token) == 1 && categorizeChars(token).substr(-3) == 'CVC' && token.match(/[^wxy]$/)) {
        			 return token + 'e';
                    }
        		}                

        		return token;
    	    }
    	    
    	    return null;
    	});
    	
    	if(result) {
    	    return result;
        }
    }

    return token;   
}

// step 1c as defined for the porter stemmer algorithm. 
function step1c(token) {
    var categorizedGroups = categorizeGroups(token);

    if(token.substr(-1) == 'y' && categorizedGroups.substr(0, categorizedGroups.length - 1).indexOf('V') > -1) {
        return token.replace(/y$/, 'i');
    }

    return token;
}

// step 2 as defined for the porter stemmer algorithm. 
function step2(token) {
    token = replacePatterns(token, [['ational', '', 'ate'], ['tional', '', 'tion'], ['enci', '', 'ence'], ['anci', '', 'ance'],
        ['izer', '', 'ize'], ['abli', '', 'able'], ['bli', '', 'ble'], ['alli', '', 'al'], ['entli', '', 'ent'], ['eli', '', 'e'],
        ['ousli', '', 'ous'], ['ization', '', 'ize'], ['ation', '', 'ate'], ['ator', '', 'ate'],['alism', '', 'al'],
        ['iveness', '', 'ive'], ['fulness', '', 'ful'], ['ousness', '', 'ous'], ['aliti', '', 'al'],
        ['iviti', '', 'ive'], ['biliti', '', 'ble'], ['logi', '', 'log']], 0);

    return token;
}

// step 3 as defined for the porter stemmer algorithm. 
function step3(token) {
    return replacePatterns(token, [['icate', '', 'ic'], ['ative', '', ''], ['alize', '', 'al'],
				   ['iciti', '', 'ic'], ['ical', '', 'ic'], ['ful', '', ''], ['ness', '', '']], 0);
}

// step 4 as defined for the porter stemmer algorithm. 
function step4(token) {
    return replaceRegex(token, /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/, [1], 1) || 
        replaceRegex(token, /^(.+?)(s|t)(ion)$/, [1, 2], 1) ||
        token; 
}

// step 5a as defined for the porter stemmer algorithm. 
function step5a(token) {
    var m = measure(token.replace(/e$/, ''));



    if(m > 1 || (m == 1 && !(categorizeChars(token).substr(-4, 3) == 'CVC' && token.match(/[^wxy].$/)))) {
        token = token.replace(/e$/, '');
    }

    return token;
}

// step 5b as defined for the porter stemmer algorithm. 
function step5b(token) {
    if(measure(token) > 1) {
       return token.replace(/ll$/, 'l'); 
    }
    
    return token;
}

var PorterStemmer = new Stemmer();
module.exports = PorterStemmer;


// perform full stemming algorithm on a single word
PorterStemmer.stem = function(token) {
    if(token.length < 3) return token;
    return step5b(step5a(step4(step3(step2(step1c(step1b(step1a(token.toLowerCase())))))))).toString();
};

//exports for tests
PorterStemmer.categorizeGroups = categorizeGroups;
PorterStemmer.measure = measure;
PorterStemmer.step1a = step1a;
PorterStemmer.step1b = step1b;
PorterStemmer.step1c = step1c;
PorterStemmer.step2 = step2;
PorterStemmer.step3 = step3;
PorterStemmer.step4 = step4;
PorterStemmer.step5a = step5a;
PorterStemmer.step5b = step5b;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_es.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_es.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*
  Copyright (c) 2018, Domingo Martín Mancera

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to deal
  in the Software without restriction, including without limitation the rights
  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
  copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
  THE SOFTWARE.
*/



var Stemmer = __webpack_require__(/*! ./stemmer_es */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_es.js");

// Inherit from the utility class in stemmer_es
class PorterStemmer extends Stemmer
{
    constructor() {
      super();
    }

    isVowel(c)
    {
        var regex = /[aeiouáéíóú]/gi;

        return regex.test(c);
    }

    nextVowelPosition(word, start = 0)
    {
        var length = word.length;

        for(var position = start; position < length; position++){
            if(this.isVowel(word[position])){
                return position;
            }
        }

        return length;
    }

    nextConsonantPosition(word, start = 0)
    {
        var length = word.length;

        for(var position = start; position < length; position++){
            if(!this.isVowel(word[position])){
                return position;
            }
        }

        return length;
    }

    endsIn(word, suffix)
    {
        if(word.length < suffix.length){
            return false;
        }

        return (word.slice(-suffix.length) === suffix);
    }

    endsInArr(word, suffixes)
    {
        var matches = [];
        for(var i in suffixes) {
            if(this.endsIn(word, suffixes[i])){
                matches.push(suffixes[i]);
            }
        }
        var longest = matches.sort(function (a, b) {
            return b.length - a.length;
        })[0];

        if(longest){
            return longest
        } else {
            return '';
        }
    }

    removeAccent(word)
    {
        var accentedVowels = ['á', 'é', 'í', 'ó', 'ú'];
        var vowels = ['a', 'e', 'i', 'o', 'u'];

        for(var i in accentedVowels){
            word = word.replace(accentedVowels[i], vowels[i]);
        }

        return word;
    }

    stem(word)
    {
        var length = word.length;

        word.toLowerCase();

        if(length < 2){
            return this.removeAccent(word);
        }

        var r1, r2, rv;
        r1 = length;
        r2 = length;
        rv = length;

        // R1 is the region after the first non-vowel following a vowel, or is the null region
        // at the end of the word if there is no such non-vowel.
        for(var i = 0; i < (length - 1) && r1 == length; i++){
            if(this.isVowel(word[i]) && !this.isVowel(word[i + 1])){
                r1 = i + 2;
            }
        }

        // R2 is the region after the first non-vowel following a vowel in R1,
        // or is the null region at the end of the word if there is no such non-vowel.
        for(var i = r1; i < (length - 1) && r2 == length; i++){
            if(this.isVowel(word[i]) && !this.isVowel(word[i + 1])){
                r2 = i + 2;
            }
        }

        if(length > 3){
            if(!this.isVowel(word[1])){
                rv = this.nextVowelPosition(word, 2) + 1;
            } else if(this.isVowel(word[0]) && this.isVowel(word[1])){
                rv = this.nextConsonantPosition(word, 2) + 1;
            } else {
                rv = 3;
            }
        }

        var r1Text = word.slice(r1);
        var r2Text = word.slice(r2);
        var rvText = word.slice(rv);
        var originalWord = word;

        // Step 0: Attached pronoun
        var pronounSuffix = ['me', 'se', 'sela', 'selo', 'selas', 'selos', 'la', 'le', 'lo', 'las', 'les', 'los', 'nos'];
        var pronounSuffixPre1 = ['iéndo', 'ándo', 'ár', 'ér', 'ír'];
        var pronounSuffixPre2 = ['iendo', 'ando', 'ar', 'er', 'ir'];

        var suffix = this.endsInArr(word, pronounSuffix);

        if(suffix != ''){
            var preSuffix = this.endsInArr(rvText.slice(0, -suffix.length), pronounSuffixPre1);

            if(preSuffix != ''){
                word = this.removeAccent(word.slice(0, -suffix.length));
            } else {
                preSuffix = this.endsInArr(rvText.slice(0, -suffix.length), pronounSuffixPre2);

                if(preSuffix != '' || (this.endsIn(word.slice(0, -suffix.length), 'uyendo'))){

                    word = word.slice(0, -suffix.length);
                }
            }
        }

        if(word != originalWord){
            r1Text = word.slice(r1);
            r2Text = word.slice(r2);
            rvText = word.slice(rv);
        }

        var wordAfter0 = word;

        if(( suf = this.endsInArr(r2Text, ['anza', 'anzas', 'ico', 'ica', 'icos', 'icas', 'ismo', 'ismos',
                                            'able', 'ables', 'ible', 'ibles', 'ista', 'istas', 'oso', 'osa',
                                            'osos', 'osas', 'amiento', 'amientos', 'imiento', 'imientos'])) != '')
        {
            word = word.slice(0, -suf.length);
		}
        else if((suf = this.endsInArr(r2Text, ['icadora', 'icador', 'icación', 'icadoras', 'icadores', 'icaciones',
                                            'icante', 'icantes', 'icancia', 'icancias', 'adora', 'ador', 'ación',
                                            'adoras', 'adores', 'aciones', 'ante', 'antes', 'ancia', 'ancias'])) != '')
        {
            word = word.slice(0, -suf.length);
		}
        else if((suf = this.endsInArr(r2Text, ['logía', 'logías'])) != ''){
            word = word.slice(0, -suf.length) + 'log';
		}
        else if((suf = this.endsInArr(r2Text, ['ución', 'uciones'])) != ''){
            word = word.slice(0, -suf.length) + 'u';
		}
        else if((suf = this.endsInArr(r2Text, ['encia', 'encias'])) != ''){
            word = word.slice(0, -suf.length) + 'ente';
		}
        else if((suf = this.endsInArr(r2Text, ['ativamente', 'ivamente', 'osamente', 'icamente', 'adamente'])) != ''){
            word = word.slice(0, -suf.length);
		}
        else if((suf = this.endsInArr(r1Text, ['amente'])) != ''){
			word = word.slice(0, -suf.length);
		}
        else if((suf = this.endsInArr(r2Text, ['antemente', 'ablemente', 'iblemente', 'mente'])) != ''){
			word = word.slice(0, -suf.length);
		}
        else if((suf = this.endsInArr(r2Text, ['abilidad', 'abilidades', 'icidad', 'icidades', 'ividad', 'ividades', 'idad', 'idades'])) != ''){
			word = word.slice(0, -suf.length);
		}
        else if((suf = this.endsInArr(r2Text, ['ativa', 'ativo', 'ativas', 'ativos', 'iva', 'ivo', 'ivas', 'ivos'])) != ''){
            word = word.slice(0, -suf.length);
		}

        if(word != wordAfter0){
            r1Text = word.slice(r1);
            r2Text = word.slice(r2);
            rvText = word.slice(rv);
        }
        var wordAfter1 = word;

        if(wordAfter0 === wordAfter1){

            // Do step 2a if no ending was removed by step 1.
            var suf = this.endsInArr(rvText, ['ya', 'ye', 'yan', 'yen', 'yeron', 'yendo', 'yo', 'yó', 'yas', 'yes', 'yais', 'yamos']);

			if(suf != '' && (word.slice(-suf.length - 1, -suf.length) == 'u')){
                word = word.slice(0, -suf.length);
			}

            if(word != wordAfter1){
				r1Text = word.slice(r1);
                r2Text = word.slice(r2);
                rvText = word.slice(rv);
            }

			var wordAfter2a = word;
            // Do Step 2b if step 2a was done, but failed to remove a suffix.
            if (wordAfter2a == wordAfter1) {
                if((suf = this.endsInArr(rvText, ['arían', 'arías', 'arán', 'arás', 'aríais', 'aría', 'aréis',
                                                    'aríamos', 'aremos', 'ará', 'aré', 'erían', 'erías', 'erán',
                                                    'erás', 'eríais', 'ería', 'eréis', 'eríamos', 'eremos', 'erá',
                                                    'eré', 'irían', 'irías', 'irán', 'irás', 'iríais', 'iría', 'iréis',
                                                    'iríamos', 'iremos', 'irá', 'iré', 'aba', 'ada', 'ida', 'ía', 'ara',
                                                    'iera', 'ad', 'ed', 'id', 'ase', 'iese', 'aste', 'iste', 'an',
                                                    'aban', 'ían', 'aran', 'ieran', 'asen', 'iesen', 'aron', 'ieron',
                                                    'ado', 'ido', 'ando', 'iendo', 'ió', 'ar', 'er', 'ir', 'as', 'abas',
                                                    'adas', 'idas', 'ías', 'aras', 'ieras', 'ases', 'ieses', 'ís', 'áis',
                                                    'abais', 'íais', 'arais', 'ierais', '  aseis', 'ieseis', 'asteis',
                                                    'isteis', 'ados', 'idos', 'amos', 'ábamos', 'íamos', 'imos', 'áramos',
                                                    'iéramos', 'iésemos', 'ásemos'])) != '')
                {
                    word = word.slice(0, -suf.length);
                }else if((suf = this.endsInArr(rvText, ['en', 'es', 'éis', 'emos'])) != '') {
					word = word.slice(0, -suf.length);
                    if(this.endsIn(word, 'gu')){
                        word = word.slice(0, -1);
					}
				}
            }
        }

        r1Text = word.slice(r1);
        r2Text = word.slice(r2);
        rvText = word.slice(rv);

        if ((suf = this.endsInArr(rvText, ['os', 'a', 'o', 'á', 'í', 'ó'])) != '') {
			word = word.slice(0, -suf.length);
		} else if ((this.endsInArr(rvText , ['e','é'])) != '') {
			word = word.slice(0, -1);
			rvText = word.slice(rv);
			if (this.endsIn(rvText, 'u') && this.endsIn(word, 'gu')) {
				word = word.slice(0, -1);
			}
		}

		return this.removeAccent(word);
    }

}

module.exports = new PorterStemmer();


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_fa.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_fa.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel
Farsi Porter Stemmer by Fardin Koochaki <me@fardinak.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Stemmer = __webpack_require__(/*! ./stemmer_fa */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_fa.js");

var PorterStemmer = new Stemmer();
module.exports = PorterStemmer;

// disabled stemming for Farsi
// Farsi stemming will be supported soon
PorterStemmer.stem = function(token) {
    return token;
};

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_fr.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_fr.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


/*
Copyright (c) 2014, Ismaël Héry

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

/*
 * Spec for the French Porter Stemmer can be found at:
 * http://snowball.tartarus.org/algorithms/french/stemmer.html
 */

var Stemmer = __webpack_require__(/*! ./stemmer_fr */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_fr.js");

var PorterStemmer = new Stemmer();
module.exports = PorterStemmer;

// Export
PorterStemmer.stem = stem;

// Exports for test purpose
PorterStemmer.prelude = prelude;
PorterStemmer.regions = regions;
PorterStemmer.endsinArr = endsinArr;

/**
 * Stem a word thanks to Porter Stemmer rules
 * @param  {String} token Word to be stemmed
 * @return {String}       Stemmed word
 */
function stem(token) {
  token = prelude(token.toLowerCase());

  if (token.length == 1)
    return token;

  var regs = regions(token);

  var r1_txt, r2_txt, rv_txt;
  r1_txt = token.substring(regs.r1);
  r2_txt = token.substring(regs.r2);
  rv_txt = token.substring(regs.rv);

  // Step 1
  var beforeStep1 = token;
  var suf, pref2, pref3, letterBefore, letter2Before, i;
  var doStep2a = false;

  if ((suf = endsinArr(r2_txt, ['ance', 'iqUe', 'isme', 'able', 'iste', 'eux', 'ances', 'iqUes', 'ismes', 'ables', 'istes'])) != '') {
    token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(token, ['icatrice', 'icateur', 'ication', 'icatrices', 'icateurs', 'ications'])) != '') {
    if (endsinArr(r2_txt, ['icatrice', 'icateur', 'ication', 'icatrices', 'icateurs', 'ications']) != '') {
      token = token.slice(0, -suf.length); // delete
    } else {
      token = token.slice(0, -suf.length) + 'iqU'; // replace by iqU
    }
  } else if ((suf = endsinArr(r2_txt, ['atrice', 'ateur', 'ation', 'atrices', 'ateurs', 'ations'])) != '') {
    token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(r2_txt, ['logie', 'logies'])) != '') {
    token = token.slice(0, -suf.length) + 'log'; // replace with log
  } else if ((suf = endsinArr(r2_txt, ['usion', 'ution', 'usions', 'utions'])) != '') {
    token = token.slice(0, -suf.length) + 'u'; // replace with u
  } else if ((suf = endsinArr(r2_txt, ['ence', 'ences'])) != '') {
    token = token.slice(0, -suf.length) + 'ent'; // replace with ent
  }
  // ement(s)
  else if ((suf = endsinArr(r1_txt, ['issement', 'issements'])) != '') {
    if (!isVowel(token[token.length - suf.length - 1])) {
      token = token.slice(0, -suf.length); // delete
      r1_txt = token.substring(regs.r1);
      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    }
  } else if ((suf = endsinArr(r2_txt, ['ativement', 'ativements'])) != '') {
    token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(r2_txt, ['ivement', 'ivements'])) != '') {
    token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(token, ['eusement', 'eusements'])) != '') {
    if ((suf = endsinArr(r2_txt, ['eusement', 'eusements'])) != '')
      token = token.slice(0, -suf.length); // delete
    else if ((suf = endsinArr(r1_txt, ['eusement', 'eusements'])) != '')
      token = token.slice(0, -suf.length) + 'eux'; // replace by eux
    else if ((suf = endsinArr(rv_txt, ['ement', 'ements'])) != '')
      token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(r2_txt, ['ablement', 'ablements', 'iqUement', 'iqUements'])) != '') {
    token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(rv_txt, ['ièrement', 'ièrements', 'Ièrement', 'Ièrements'])) != '') {
    token = token.slice(0, -suf.length) + 'i'; // replace by i
  } else if ((suf = endsinArr(rv_txt, ['ement', 'ements'])) != '') {
    token = token.slice(0, -suf.length); // delete
  }
  // ité(s)
  else if ((suf = endsinArr(token, ['icité', 'icités'])) != '') {
    if (endsinArr(r2_txt, ['icité', 'icités']) != '')
      token = token.slice(0, -suf.length); // delete
    else
      token = token.slice(0, -suf.length) + 'iqU'; // replace by iqU
  } else if ((suf = endsinArr(token, ['abilité', 'abilités'])) != '') {
    if (endsinArr(r2_txt, ['abilité', 'abilités']) != '')
      token = token.slice(0, -suf.length); // delete
    else
      token = token.slice(0, -suf.length) + 'abl'; // replace by abl
  } else if ((suf = endsinArr(r2_txt, ['ité', 'ités'])) != '') {
    token = token.slice(0, -suf.length); // delete if in R2
  } else if ((suf = endsinArr(token, ['icatif', 'icative', 'icatifs', 'icatives'])) != '') {
    if ((suf = endsinArr(r2_txt, ['icatif', 'icative', 'icatifs', 'icatives'])) != '') {
      token = token.slice(0, -suf.length); // delete
      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    }
    if ((suf = endsinArr(r2_txt, ['atif', 'ative', 'atifs', 'atives'])) != '') {
      token = token.slice(0, -suf.length - 2) + 'iqU'; // replace with iqU
      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    }
  } else if ((suf = endsinArr(r2_txt, ['atif', 'ative', 'atifs', 'atives'])) != '') {
    token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(r2_txt, ['if', 'ive', 'ifs', 'ives'])) != '') {
    token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(token, ['eaux'])) != '') {
    token = token.slice(0, -suf.length) + 'eau'; // replace by eau
  } else if ((suf = endsinArr(r1_txt, ['aux'])) != '') {
    token = token.slice(0, -suf.length) + 'al'; // replace by al
  } else if ((suf = endsinArr(r2_txt, ['euse', 'euses'])) != '') {
    token = token.slice(0, -suf.length); // delete
  } else if ((suf = endsinArr(r1_txt, ['euse', 'euses'])) != '') {
    token = token.slice(0, -suf.length) + 'eux'; // replace by eux
  } else if ((suf = endsinArr(rv_txt, ['amment'])) != '') {
    token = token.slice(0, -suf.length) + 'ant'; // replace by ant
    doStep2a = true;
  } else if ((suf = endsinArr(rv_txt, ['emment'])) != '') {
    token = token.slice(0, -suf.length) + 'ent'; // replace by ent
    doStep2a = true;
  } else if ((suf = endsinArr(rv_txt, ['ment', 'ments'])) != '') {
    // letter before must be a vowel in RV
    letterBefore = token[token.length - suf.length - 1];
    if (isVowel(letterBefore) && endsin(rv_txt, letterBefore + suf)) {
      token = token.slice(0, -suf.length); // delete
      doStep2a = true;
    }
  }

  // re compute regions
  r1_txt = token.substring(regs.r1);
  r2_txt = token.substring(regs.r2);
  rv_txt = token.substring(regs.rv);

  // Step 2a
  var beforeStep2a = token;
  var step2aDone = false;
  if (beforeStep1 === token || doStep2a) {
    step2aDone = true;
    if ((suf = endsinArr(rv_txt, ['îmes', 'ît', 'îtes', 'i', 'ie', 'Ie', 'ies', 'ir', 'ira', 'irai', 'iraIent', 'irais', 'irait', 'iras', 'irent', 'irez', 'iriez', 'irions', 'irons', 'iront', 'is', 'issaIent', 'issais', 'issait', 'issant', 'issante', 'issantes', 'issants', 'isse', 'issent', 'isses', 'issez', 'issiez', 'issions', 'issons', 'it'])) != '') {
      letterBefore = token[token.length - suf.length - 1];
      if (!isVowel(letterBefore) && endsin(rv_txt, letterBefore + suf))
        token = token.slice(0, -suf.length); // delete
    }
  }

  // Step 2b
  if (step2aDone && token === beforeStep2a) {
    if ((suf = endsinArr(rv_txt, ['é', 'ée', 'ées', 'és', 'èrent', 'er', 'era', 'erai', 'eraIent', 'erais', 'erait', 'eras', 'erez', 'eriez', 'erions', 'erons', 'eront', 'ez', 'iez', 'Iez'])) != '') {
      token = token.slice(0, -suf.length); // delete
      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    } else if ((suf = endsinArr(rv_txt, ['ions'])) != '' && endsinArr(r2_txt, ['ions'])) {
      token = token.slice(0, -suf.length); // delete
      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    }
    // add 'Ie' suffix to pass test for 'évanouie'
    else if ((suf = endsinArr(rv_txt, ['âmes', 'ât', 'âtes', 'a', 'ai', 'aIent', 'ais', 'ait', 'ant', 'ante', 'antes', 'ants', 'as', 'asse', 'assent', 'asses', 'assiez', 'assions'])) != '') {
      token = token.slice(0, -suf.length); // delete

      letterBefore = token[token.length - 1];
      if (letterBefore === 'e' && endsin(rv_txt, 'e' + suf))
        token = token.slice(0, -1);

      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    }
  }

  // Step 3
  if (!(token === beforeStep1)) {
    if (token[token.length - 1] === 'Y')
      token = token.slice(0, -1) + 'i';
    if (token[token.length - 1] === 'ç')
      token = token.slice(0, -1) + 'c';
  } // Step 4
  else {
    letterBefore = token[token.length - 1];
    letter2Before = token[token.length - 2];

    if (letterBefore === 's' && ['a', 'i', 'o', 'u', 'è', 's'].indexOf(letter2Before) == -1) {
      token = token.slice(0, -1);
      r1_txt = token.substring(regs.r1);
      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    }

    if ((suf = endsinArr(r2_txt, ['ion'])) != '') {
      letterBefore = token[token.length - suf.length - 1];
      if (letterBefore === 's' || letterBefore === 't') {
        token = token.slice(0, -suf.length); // delete
        r1_txt = token.substring(regs.r1);
        r2_txt = token.substring(regs.r2);
        rv_txt = token.substring(regs.rv);
      }
    }

    if ((suf = endsinArr(rv_txt, ['ier', 'ière', 'Ier', 'Ière'])) != '') {
      token = token.slice(0, -suf.length) + 'i'; // replace by i
      r1_txt = token.substring(regs.r1);
      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    }
    if ((suf = endsinArr(rv_txt, 'e')) != '') {
      token = token.slice(0, -suf.length); // delete
      r1_txt = token.substring(regs.r1);
      r2_txt = token.substring(regs.r2);
      rv_txt = token.substring(regs.rv);
    }
    if ((suf = endsinArr(rv_txt, 'ë')) != '') {
      if (token.slice(token.length - 3, -1) === 'gu')
        token = token.slice(0, -suf.length); // delete
    }
  }

  // Step 5
  if ((suf = endsinArr(token, ['enn', 'onn', 'ett', 'ell', 'eill'])) != '') {
    token = token.slice(0, -1); // delete last letter
  }

  // Step 6
  i = token.length - 1;
  while (i > 0) {
    if (!isVowel(token[i])) {
      i--;
    } else if (i !== token.length - 1 && (token[i] === 'é' || token[i] === 'è')) {
      token = token.substring(0, i) + 'e' + token.substring(i + 1, token.length);
      break;
    } else {
      break;
    }
  }

  return token.toLowerCase();

};

/**
 * Compute r1, r2, rv regions as required by french porter stemmer algorithm
 * @param  {String} token Word to compute regions on
 * @return {Object}       Regions r1, r2, rv as offsets from the begining of the word
 */
function regions(token) {
  var r1, r2, rv, len;
  var i;

  r1 = r2 = rv = len = token.length;

  // R1 is the region after the first non-vowel following a vowel,
  for (var i = 0; i < len - 1 && r1 == len; i++) {
    if (isVowel(token[i]) && !isVowel(token[i + 1])) {
      r1 = i + 2;
    }
  }
  // Or is the null region at the end of the word if there is no such non-vowel.

  // R2 is the region after the first non-vowel following a vowel in R1
  for (i = r1; i < len - 1 && r2 == len; i++) {
    if (isVowel(token[i]) && !isVowel(token[i + 1])) {
      r2 = i + 2;
    }
  }
  // Or is the null region at the end of the word if there is no such non-vowel.

  // RV region
  var three = token.slice(0, 3);
  if (isVowel(token[0]) && isVowel(token[1])) {
    rv = 3;
  }
  if (three === 'par' || three == 'col' || three === 'tap')
    rv = 3;
  // the region after the first vowel not at the beginning of the word or null
  else {
    for (i = 1; i < len - 1 && rv == len; i++) {
      if (isVowel(token[i])) {
        rv = i + 1;
      }
    }
  }

  return {
    r1: r1,
    r2: r2,
    rv: rv
  };
};

/**
 * Pre-process/prepare words as required by french porter stemmer algorithm
 * @param  {String} token Word to be prepared
 * @return {String}       Prepared word
 */
function prelude(token) {
  token = token.toLowerCase();

  var result = '';
  var i = 0;

  // special case for i = 0 to avoid '-1' index
  if (token[i] === 'y' && isVowel(token[i + 1])) {
    result += token[i].toUpperCase();
  } else {
    result += token[i];
  }

  for (i = 1; i < token.length; i++) {
    if ((token[i] === 'u' || token[i] === 'i') && isVowel(token[i - 1]) && isVowel(token[i + 1])) {
      result += token[i].toUpperCase();
    } else if (token[i] === 'y' && (isVowel(token[i - 1]) || isVowel(token[i + 1]))) {
      result += token[i].toUpperCase();
    } else if (token[i] === 'u' && token[i - 1] === 'q') {
      result += token[i].toUpperCase();
    } else {
      result += token[i];
    }
  }

  return result;
};

/**
 * Return longest matching suffixes for a token or '' if no suffix match
 * @param  {String} token    Word to find matching suffix
 * @param  {Array} suffixes  Array of suffixes to test matching
 * @return {String}          Longest found matching suffix or ''
 */
function endsinArr(token, suffixes) {
  var i, longest = '';
  for (i = 0; i < suffixes.length; i++) {
    if (endsin(token, suffixes[i]) && suffixes[i].length > longest.length)
      longest = suffixes[i];
  }

  return longest;
};


function isVowel(letter) {
  return (letter == 'a' || letter == 'e' || letter == 'i' || letter == 'o' || letter == 'u' || letter == 'y' || letter == 'â' || letter == 'à' || letter == 'ë' ||
    letter == 'é' || letter == 'ê' || letter == 'è' || letter == 'ï' || letter == 'î' || letter == 'ô' || letter == 'û' || letter == 'ù');
};

function endsin(token, suffix) {
  if (token.length < suffix.length) return false;
  return (token.slice(-suffix.length) == suffix);
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_it.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_it.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2012, Leonardo Fenu, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Stemmer = __webpack_require__(/*! ./stemmer_it */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_it.js");

var PorterStemmer = new Stemmer();
module.exports = PorterStemmer;


function isVowel(letter){
	return (letter == 'a' || letter == 'e' || letter == 'i' || letter == 'o' || letter == 'u' || letter == 'à' ||
			letter == 'è' || letter == 'ì' || letter == 'ò' || letter == 'ù');
};

function getNextVowelPos(token,start){
	start = start + 1;
	var length = token.length;
	for (var i = start; i < length; i++) {
		if (isVowel(token[i])) {
			return i;
		}
	}
	return length;
};

function getNextConsonantPos(token,start){
	length=token.length
			for (var i = start; i < length; i++)
				if (!isVowel(token[i])) return i;
			return length;
};


function endsin(token, suffix) {
	if (token.length < suffix.length) return false;
	return (token.slice(-suffix.length) == suffix);
};

function endsinArr(token, suffixes) {
	for(var i=0;i<suffixes.length;i++){
		if (endsin(token, suffixes[i])) return suffixes[i];
	}
	return '';
};

function replaceAcute(token) {
	var str=token.replace(/á/gi,'à');
	str=str.replace(/é/gi,'è');
	str=str.replace(/í/gi,'ì');
	str=str.replace(/ó/gi,'ò');
	str=str.replace(/ú/gi,'ù');
	return str;
};

function vowelMarking(token) {
	function replacer(match, p1, p2, p3){
  		return p1+p2.toUpperCase()+p3;
	};	
	str=token.replace(/([aeiou])(i|u)([aeiou])/g, replacer);	
	return str;
}


// perform full stemming algorithm on a single word
PorterStemmer.stem = function(token) {
	
	token = token.toLowerCase();
	token = replaceAcute(token);
	token = token.replace(/qu/g,'qU');	
	token = vowelMarking(token);
	
	if (token.length<3){
		return token;
	}

	var r1 = r2 = rv = len = token.length;
	// R1 is the region after the first non-vowel following a vowel, 
	for(var i=0; i < token.length-1 && r1==len;i++){
 		if(isVowel(token[i]) && !isVowel(token[i+1]) ){
 			r1=i+2;
 		}
	}
	// Or is the null region at the end of the word if there is no such non-vowel.  

	// R2 is the region after the first non-vowel following a vowel in R1
	for(var i=r1; i< token.length-1 && r2==len;i++){
		if(isVowel(token[i]) && !isVowel(token[i+1])){
			r2=i+2;
		}
	}

	// Or is the null region at the end of the word if there is no such non-vowel. 

	// If the second letter is a consonant, RV is the region after the next following vowel, 
	
	// RV as follow

	if (len > 3) {
		if(!isVowel(token[1])) {
			// If the second letter is a consonant, RV is the region after the next following vowel
			rv = getNextVowelPos(token, 1) +1;
		} else if (isVowel(token[0]) && isVowel(token[1])) { 
			// or if the first two letters are vowels, RV is the region after the next consonant
			rv = getNextConsonantPos(token, 2) + 1;
		} else {
			//otherwise (consonant-vowel case) RV is the region after the third letter. But RV is the end of the word if these positions cannot be found.
			rv = 3;
		}
	}

	var r1_txt = token.substring(r1);
	var r2_txt = token.substring(r2);
	var rv_txt = token.substring(rv);

	var token_orig = token;

	// Step 0: Attached pronoun

	var pronoun_suf = new Array('glieli','glielo','gliene','gliela','gliele','sene','tene','cela','cele','celi','celo','cene','vela','vele','veli','velo','vene','mela','mele','meli','melo','mene','tela','tele','teli','telo','gli','ci', 'la','le','li','lo','mi','ne','si','ti','vi');	
	var pronoun_suf_pre1 = new Array('ando','endo');	
	var pronoun_suf_pre2 = new Array('ar', 'er', 'ir');
	var suf = endsinArr(token, pronoun_suf);

	if (suf!='') {
		var pre_suff1 = endsinArr(rv_txt.slice(0,-suf.length),pronoun_suf_pre1);
		var pre_suff2 = endsinArr(rv_txt.slice(0,-suf.length),pronoun_suf_pre2);	
		
		if (pre_suff1 != '') {
			token = token.slice(0,-suf.length);
		}
		if (pre_suff2 != '') {
			token = token.slice(0,  -suf.length)+ 'e';
		}
	}

	if (token != token_orig) {
		r1_txt = token.substring(r1);
		r2_txt = token.substring(r2);
		rv_txt = token.substring(rv);
	}

	var token_after0 = token;

	// Step 1:  Standard suffix removal
	
	if ((suf = endsinArr(r2_txt, new  Array('ativamente','abilamente','ivamente','osamente','icamente'))) != '') {
		token = token.slice(0, -suf.length);	// delete
	} else if ((suf = endsinArr(r2_txt, new  Array('icazione','icazioni','icatore','icatori','azione','azioni','atore','atori'))) != '') {
		token = token.slice(0,  -suf.length);	// delete
	} else if ((suf = endsinArr(r2_txt, new  Array('logia','logie'))) != '') {
		token = token.slice(0,  -suf.length)+ 'log'; // replace with log
	} else if ((suf =endsinArr(r2_txt, new  Array('uzione','uzioni','usione','usioni'))) != '') {
		token = token.slice(0,  -suf.length) + 'u'; // replace with u
	} else if ((suf = endsinArr(r2_txt, new  Array('enza','enze'))) != '') {
		token = token.slice(0,  -suf.length)+ 'ente'; // replace with ente
	} else if ((suf = endsinArr(rv_txt, new  Array('amento', 'amenti', 'imento', 'imenti'))) != '') {
		token = token.slice(0,  -suf.length);	// delete
	} else if ((suf = endsinArr(r1_txt, new  Array('amente'))) != '') {
		token = token.slice(0,  -suf.length); // delete
	} else if ((suf = endsinArr(r2_txt, new Array('atrice','atrici','abile','abili','ibile','ibili','mente','ante','anti','anza','anze','iche','ichi','ismo','ismi','ista','iste','isti','istà','istè','istì','ico','ici','ica','ice','oso','osi','osa','ose'))) != '') {
		token = token.slice(0,  -suf.length); // delete
	} else if ((suf = endsinArr(r2_txt, new  Array('abilità', 'icità', 'ività', 'ità'))) != '') {
		token = token.slice(0,  -suf.length); // delete
	} else if ((suf = endsinArr(r2_txt, new  Array('icativa','icativo','icativi','icative','ativa','ativo','ativi','ative','iva','ivo','ivi','ive'))) != '') {
		token = token.slice(0,  -suf.length);
	}
	
	
	if (token != token_after0) {
		r1_txt = token.substring(r1);
		r2_txt = token.substring(r2);
		rv_txt = token.substring(rv);
	}
	

	var token_after1 = token;
	
	// Step 2:  Verb suffixes

	if (token_after0 == token_after1) {
		if ((suf = endsinArr(rv_txt, new Array('erebbero','irebbero','assero','assimo','eranno','erebbe','eremmo','ereste','eresti','essero','iranno','irebbe','iremmo','ireste','iresti','iscano','iscono','issero','arono','avamo','avano','avate','eremo','erete','erono','evamo','evano','evate','iremo','irete','irono','ivamo','ivano','ivate','ammo','ando','asse','assi','emmo','enda','ende','endi','endo','erai','Yamo','iamo','immo','irai','irei','isca','isce','isci','isco','erei','uti','uto','ita','ite','iti','ito','iva','ivi','ivo','ono','uta','ute','ano','are','ata','ate','ati','ato','ava','avi','avo','erà','ere','erò','ete','eva','evi','evo','irà','ire','irò','ar','ir'))) != '') {
			token = token.slice(0, -suf.length);
		}
	}

	
	r1_txt = token.substring(r1);
	r2_txt = token.substring(r2);
	rv_txt = token.substring(rv);

	// Always do step 3. 

	if ((suf = endsinArr(rv_txt, new Array('ia', 'ie', 'ii', 'io', 'ià', 'iè','iì', 'iò','a','e','i','o','à','è','ì','ò'))) != '') {
		token = token.slice(0, -suf.length);
	} 

	r1_txt = token.substring(r1);
	r2_txt = token.substring(r2);
	rv_txt = token.substring(rv);
	
	if ((suf =endsinArr(rv_txt, new  Array('ch'))) != '') {
		token = token.slice(0,  -suf.length) + 'c'; // replace with c
	} else if ((suf =endsinArr(rv_txt, new  Array('gh'))) != '') {
		token = token.slice(0,  -suf.length) + 'g'; // replace with g
	}

	
	r1_txt = token.substring(r1);
	r2_txt = token.substring(r2);
	rv_txt = token.substring(rv);

	return token.toLowerCase();

};

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_nl.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_nl.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*
Copyright (c) 2018, Hugo W.L. ter Doest

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

/*
 * Spec for the Dutch Porter Stemmer can be found at:
 * http://snowball.tartarus.org/algorithms/dutch/stemmer.html
 */


var Stemmer = __webpack_require__(/*! ./stemmer_nl */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_nl.js");

const DEBUG = false;
const vowels = "aeiouèy";


function isVowel(x) {
    return vowels.indexOf(x) > -1;
}


// * Return longest matching suffixes for a token or '' if no suffix match
String.prototype.endsinArr = function(suffixes) {
  var i, longest = '';
  for (i = 0; i < suffixes.length; i++) {
    if (this.endsin(suffixes[i]) && suffixes[i].length > longest.length)
      longest = suffixes[i];
  }

  if (DEBUG && longest != "") {
    console.log("Matched suffix: " + longest);
  }
  return longest;
};
  

// Returns true if token has suffix
String.prototype.endsin = function(suffix) {
  if (this.length < suffix.length) return false;
  return (this.slice(-suffix.length) == suffix);
};


// Removes a suffix of len characters and returns the string
String.prototype.removeSuffix = function(len) {
  return this.substr(0, this.length - len);
};


// Define undoubling the ending as removing the last letter if the word ends kk, dd or tt.
String.prototype.undoubleEnding = function() {
  if (this.substr(-2) == "kk" || this.substr(-2) == "tt" || this.substr(-2) == "dd") {
      return this.substr(0, this.length - 1);
  }
  else {
    return this;
  }
}


class PorterStemmer extends Stemmer {
  constructor() {
    super();
  }


  replaceAccentedCharacters(word) {
    var accentedCharactersMapping = {
      "ä": "a",
      "ë": "e",
      "ï": "i",
      "ö": "o",
      "ü": "u",
      "á": "a",
      "é": "e",
      "í": "i",
      "ó": "o",
      "ú": "u"
    }
    var result = word;
    for (var x in accentedCharactersMapping) {
      result = result.replace(new RegExp(x, "g"), accentedCharactersMapping[x]);
    }
    if (DEBUG) {
      console.log("replaceAccentedCharacters: " + result);
    }
    return result;
  }


  //Put initial y, y after a vowel, and i between vowels into upper case.
  handleYI(word) {
    // Initial y
    var result = word.replace(/^y/, "Y");
    if (DEBUG) {
      console.log("handleYI: initial y: " + result);
    }
    // y after vowel
   result = result.replace(/([aeioué])y/g, "$1Y");
    if (DEBUG) {
      console.log("handleYI: y after vowel: " + result);
    }
    // i between vowels
    var result = result.replace(/([aeioué])i([aeioué])/g, "$1I$2");
    if (DEBUG) {
      console.log("handleYI: i between vowels:" + result);
    }
    return result;
  }


  // Determines R1 and R2; adapted from the French Porter Stemmer
  markRegions(token) {
    var r1, r2, len;

    r1 = r2 = len = token.length;

    // R1 is the region after the first non-vowel following a vowel,
    for (var i = 0; i < len - 1 && r1 == len; i++) {
      if (isVowel(token[i]) && !isVowel(token[i + 1])) {
        r1 = i + 2;
      }
    }
    // Or is the null region at the end of the word if there is no such non-vowel.

    // R1 is adjusted such that the region before it contains at least 3 characters
    if (r1 != len) {
      // R1 is not null
      if (r1 < 3) {
        // Region before does not contain at least 3 characters
        if (len > 3) {
          r1 = 3;
          // Now R1 contains at least 3 characters
        }
        else {
          // It is not possible to make the region before long enough
          r1 = len;
        }
      }
    }

    // R2 is the region after the first non-vowel following a vowel in R1
    for (i = r1; i < len - 1 && r2 == len; i++) {
      if (isVowel(token[i]) && !isVowel(token[i + 1])) {
        r2 = i + 2;
      }
    }
    // Or is the null region at the end of the word if there is no such non-vowel.

    if (DEBUG) {
      console.log("Regions r1 = " + r1 + " r2 = " + r2);
    }

    this.r1 = r1;
    this.r2 = r2;
  }


  prelude(word) {
    var result = this.replaceAccentedCharacters(word);
    result = this.handleYI(result);
    this.markRegions(result);
    if (DEBUG) {
      console.log("Prelude: " + result);
    }
    return result;
  }

  
  // (1b) en   ene => delete if in R1 and preceded by a valid en-ending, and then undouble the ending
  // Define a valid en-ending as a non-vowel, and not gem.
  // Define undoubling the ending as removing the last letter if the word ends kk, dd or tt.
  step1b(word, suffixes) {
    var result = word;
    
    var match = result.endsinArr(suffixes);
    if (match != "") {
      var pos = result.length - match.length;
      if (pos >= this.r1) {
        // check the character before the matched en/ene AND check for gem
        if (!isVowel(result[pos - 1]) && result.substr(pos - 3, 3) !== "gem") {
          // delete
          result = result.removeSuffix(match.length);
          // Undouble the ending
          result = result.undoubleEnding();
        }
      }
    }
    if (DEBUG) {
      console.log("step 1b: " + result);
    }
    return result;
  }

  
  step1(word) {
    var result = word;
    // (1a) heden => replace with heid if in R1
    if (result.endsin("heden") && result.length - 5 >= this.r1) {
      result = result.removeSuffix(5);
      result += "heid";
    }
    if (DEBUG) {
      console.log("step 1a: " + result);
    }

    result = this.step1b(result, ["en", "ene"]);

    // (1c) s   se => delete if in R1 and preceded by a valid s-ending
    // Define a valid s-ending as a non-vowel other than j.
    var match = result.endsinArr(["se", "s"]);
    if (match != "") {
      var pos = result.length - match.length;
      if (pos >= this.r1) {
        // check the character before the matched s/se
        // HtD: if there is a s before the s/se the suffix should stay
        //if (!isVowel(result[pos - 1]) && result[pos - 1] != "j") {
        if (!isVowel(result[pos - 1]) && !result.match(/[js]se?$/)) {
          result = result.removeSuffix(match.length);
        }
      }  
    }
    if (DEBUG) {
      console.log("step 1c: " + result);
    }
    return result;
  }


  // Delete suffix e if in R1 and preceded by a non-vowel, and then undouble the ending
  step2(word) {
    var result = word;
    if (result.endsin("e") && this.r1 < result.length) {
      if (result.length > 1 && !isVowel(result[result.length - 2])) {
        // Delete
        result = result.removeSuffix(1);
        this.suffixeRemoved = true;
        // Undouble the ending
        result = result.undoubleEnding();
      }
    }


    if (DEBUG) {
      console.log("step2: " + result);
    }
    return result;
  }


  // Step 3a: heid => delete heid if in R2 and not preceded by c, and treat a preceding en as in step 1(b)
  step3a(word) {
    var result = word;
    if (result.endsin("heid") && result.length - 4 >= this.r2 && result[result.length - 5] != "c") {
      // Delete
      result = result.removeSuffix(4);
      // Treat a preceding en as in step 1b
      result = this.step1b(result, ["en"]);
    }
    if (DEBUG) {
      console.log("step 3a: " + result);
    }
    return result;
  }

  
  // d suffixes: Search for the longest among the following suffixes, and perform the action indicated.
  step3b(word) {
    var result = word;

    // end   ing => delete if in R2; if preceded by ig, delete if in R2 and not preceded by e, otherwise undouble the ending
    var suf = "";
    if (suf = result.endsinArr(["end", "ing"])) {
      if ((result.length - 3) >= this.r2) {
        // Delete suffix
        result = result.removeSuffix(3);
        //this.regions(result);
        if (result.endsin("ig") && (result.length - 2 >= this.r2) && result[result.length - 3] != "e") {
          // Delete suffix
          result = result.removeSuffix(2);
        }
        else {
          result = result.undoubleEnding();
        }
      }
    }
      
    // ig => delete if in R2 and not preceded by e
    if (result.endsin("ig") && this.r2 <= result.length - 2 && result[result.length - 3] != "e") {
      result = result.removeSuffix(2);
    }
        
    // lijk => delete if in R2, and then repeat step 2
    if (result.endsin("lijk") && this.r2 <= result.length - 4) {
      result = result.removeSuffix(4);
      // repeat step 2
      result = this.step2(result);
    }

    // baar => delete if in R2
    if (result.endsin("baar") && this.r2 <= result.length - 4) {
      result = result.removeSuffix(4);
    }    

    // bar => delete if in R2 and if step 2 actually removed an e
    if (result.endsin("bar") && this.r2 <= result.length - 3 && this.suffixeRemoved) {
      result = result.removeSuffix(3);
    }    
    
    if (DEBUG) {
      console.log("step 3b: " + result);
    }
    return result;
  }

  
  // undouble vowel => If the words ends CVD, where C is a non-vowel,
  // D is a non-vowel other than I, and V is double a, e, o or u,
  // remove one of the vowels from V (for example, maan -> man, brood -> brod)
  step4(word) {
    var result = word;
    
    if (result.match(/[bcdfghjklmnpqrstvwxz](aa|ee|oo|uu)[bcdfghjklmnpqrstvwxz]$/)) {
      result = result.substr(0, result.length - 2) + result[result.length - 1];
    }
    
    if (DEBUG) {
      console.log("step4: " + result);
    }
    return result;
  }

  // Turn I and Y back into lower case.
  postlude(word) {
    return word.toLowerCase();
  }

  stem(word) {
    return this.postlude(this.step4(this.step3b(this.step3a(this.step2(this.step1(this.prelude(word)))))));
  }
}


module.exports = new PorterStemmer();


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_no.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_no.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2014, Kristoffer Brabrand

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Stemmer = __webpack_require__(/*! ./stemmer_no */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_no.js");

// Get the part of the token after the first non-vowel following a vowel
function getR1(token) {
    var match = token.match(/[aeiouyæåø]{1}[^aeiouyæåø]([A-Za-z0-9_æøåÆØÅäÄöÖüÜ]+)/);

    if (match) {
        var preR1Length = match.index + 2;

        if (preR1Length < 3 && preR1Length > 0) {
            return token.slice(3);
        } else if (preR1Length >= 3) {
            return match[1];
        } else {
            return token;
        }
    }

    return null;
}

function step1(token) {
    // Perform step 1a-c
    var step1aResult = step1a(token),
        step1bResult = step1b(token),
        step1cResult = step1c(token);

    // Returne the shortest result string (from 1a, 1b and 1c)
    if (step1aResult.length < step1bResult.length) {
        return (step1aResult.length < step1cResult.length) ? step1aResult : step1cResult;
    } else {
        return (step1bResult.length < step1cResult.length) ? step1bResult : step1cResult;
    }
}

// step 1a as defined for the porter stemmer algorithm.
function step1a(token) {
    var r1 = getR1(token);

    if (!r1) {
        return token;
    }

    var r1Match = r1.match(/(a|e|ede|ande|ende|ane|ene|hetene|en|heten|ar|er|heter|as|es|edes|endes|enes|hetenes|ens|hetens|ers|ets|et|het|ast)$/);

    if (r1Match) {
        return token.replace(new RegExp(r1Match[1] + '$'), '');
    }

    return token;
}

// step 1b as defined for the porter stemmer algorithm.
function step1b(token) {
    var r1 = getR1(token);

    if (!r1) {
        return token;
    }

    if (token.match(/(b|c|d|f|g|h|j|l|m|n|o|p|r|t|v|y|z)s$/)) {
        return token.slice(0, -1);
    }

    if (token.match(/([^aeiouyæåø]k)s$/)) {
        return token.slice(0, -1);
    }

    return token;
}

// step 1c as defined for the porter stemmer algorithm.
function step1c(token) {
    var r1 = getR1(token);

    if (!r1) {
        return token;
    }

    if (r1.match(/(erte|ert)$/)) {
        return token.replace(/(erte|ert)$/, 'er');
    }

    return token;
}

// step 2 as defined for the porter stemmer algorithm.
function step2(token) {
    var r1 = getR1(token);

    if (!r1) {
        return token;
    }

    if (r1.match(/(d|v)t$/)) {
        return token.slice(0, -1);
    }

    return token;
}

// step 3 as defined for the porter stemmer algorithm.
function step3(token) {
    var r1 = getR1(token);

    if (!r1)
        return token;

    var r1Match = r1.match(/(leg|eleg|ig|eig|lig|elig|els|lov|elov|slov|hetslov)$/);

    if (r1Match) {
        return token.replace(new RegExp(r1Match[1] + '$'), '');
    }

    return token;
}

var PorterStemmer = new Stemmer();
module.exports = PorterStemmer;

// perform full stemming algorithm on a single word
PorterStemmer.stem = function(token) {
    return step3(step2(step1(token.toLowerCase()))).toString();
};

//exports for tests
PorterStemmer.getR1  = getR1;
PorterStemmer.step1  = step1;
PorterStemmer.step1a = step1a;
PorterStemmer.step1b = step1b;
PorterStemmer.step1c = step1c;
PorterStemmer.step2  = step2;
PorterStemmer.step3  = step3;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_pt.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_pt.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2015, Luís Rodrigues

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

module.exports = (function () {
  'use strict';

  var Stemmer     = __webpack_require__(/*! ./stemmer_pt */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_pt.js"),
    Token         = __webpack_require__(/*! ./token */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\token.js"),
    PorterStemmer = new Stemmer();

  /**
   * Marks a region after the first non-vowel following a vowel, or the
   * null region at the end of the word if there is no such non-vowel.
   *
   * @param {Object} token Token to stem.
   * @param {Number} start Start index (defaults to 0).
   * @param {Number}       Region start index.
   */
   var markRegionN = function (start) {
    var index = start || 0,
      length = this.string.length,
      region = length;

    while (index < length - 1 && region === length) {
      if (this.hasVowelAtIndex(index) && !this.hasVowelAtIndex(index + 1)) {
        region = index + 2;
      }
      index++;
    }

    return region;
  };

  /**
   * Mark RV.
   *
   * @param  {Object} token Token to stem.
   * @return {Number}       Region start index.
   */
  var markRegionV = function () {
    var rv = this.string.length;

    if (rv > 3) {
      if (!this.hasVowelAtIndex(1)) {
        rv = this.nextVowelIndex(2) + 1;

      } else if (this.hasVowelAtIndex(0) && this.hasVowelAtIndex(1)) {
        rv = this.nextConsonantIndex(2) + 1;

      } else {
        rv = 3;
      }
    }

    return rv;
  };

  /**
   * Prelude.
   *
   * Nasalised vowel forms should be treated as a vowel followed by a consonant.
   *
   * @param  {String} token Word to stem.
   * @return {String}       Stemmed token.
   */
  function prelude (token) {
    return token
    .replaceAll('ã', 'a~')
    .replaceAll('õ', 'o~');
  }

  /**
   * Step 1: Standard suffix removal.
   *
   * This step should always be performed.
   *
   * @param  {Token} token Word to stem.
   * @return {Token}       Stemmed token.
   */
  function standardSuffix (token) {

    token.replaceSuffixInRegion([
      'amentos', 'imentos', 'aço~es', 'adoras', 'adores', 'amento', 'imento',

      'aça~o', 'adora', 'ância', 'antes', 'ismos', 'istas',

      'ador', 'ante', 'ável', 'ezas', 'icas', 'icos', 'ismo', 'ista', 'ível',
      'osas', 'osos',

      'eza', 'ica', 'ico', 'osa', 'oso'

      ], '', 'r2');

    token.replaceSuffixInRegion(['logias', 'logia'], 'log', 'r2');

    // token.replaceSuffixInRegion(['uço~es', 'uça~o'], 'u', 'r1');

    token.replaceSuffixInRegion(['ências', 'ência'], 'ente', 'r2');

    token.replaceSuffixInRegion([
      'ativamente', 'icamente', 'ivamente', 'osamente', 'adamente'
    ], '', 'r2');

    token.replaceSuffixInRegion('amente', '', 'r1');

    token.replaceSuffixInRegion([
      'antemente', 'avelmente', 'ivelmente', 'mente'
    ], '', 'r2');

    token.replaceSuffixInRegion([
      'abilidades', 'abilidade',
      'icidades', 'icidade',
      'ividades', 'ividade',
      'idades', 'idade'
    ], '', 'r2');

    token.replaceSuffixInRegion([
      'ativas', 'ativos', 'ativa', 'ativo',
      'ivas', 'ivos', 'iva', 'ivo'
    ], '', 'r2');

    if (token.hasSuffix('eiras') || token.hasSuffix('eira')) {
      token.replaceSuffixInRegion(['iras', 'ira'], 'ir', 'rv');
    }

    return token;
  }

  /**
   * Step 2: Verb suffix removal.
   *
   * Perform this step if no ending was removed in step 1.
   *
   * @param  {Token} token   Token to stem.
   * @return {Token}         Stemmed token.
   */
  function verbSuffix (token) {

    token.replaceSuffixInRegion([
      'aríamos', 'ássemos', 'eríamos', 'êssemos', 'iríamos', 'íssemos',

      'áramos', 'aremos', 'aríeis', 'ásseis', 'ávamos', 'éramos', 'eremos',
      'eríeis', 'ésseis', 'íramos', 'iremos', 'iríeis', 'ísseis',

      'ara~o', 'ardes', 'areis', 'áreis', 'ariam', 'arias', 'armos', 'assem',
      'asses', 'astes', 'áveis', 'era~o', 'erdes', 'ereis', 'éreis', 'eriam',
      'erias', 'ermos', 'essem', 'esses', 'estes', 'íamos', 'ira~o', 'irdes',
      'ireis', 'íreis', 'iriam', 'irias', 'irmos', 'issem', 'isses', 'istes',

      'adas', 'ados', 'amos', 'ámos', 'ando', 'aram', 'aras', 'arás', 'arei',
      'arem', 'ares', 'aria', 'asse', 'aste', 'avam', 'avas', 'emos', 'endo',
      'eram', 'eras', 'erás', 'erei', 'erem', 'eres', 'eria', 'esse', 'este',
      'idas', 'idos', 'íeis', 'imos', 'indo', 'iram', 'iras', 'irás', 'irei',
      'irem', 'ires', 'iria', 'isse', 'iste',

      'ada', 'ado', 'ais', 'ara', 'ará', 'ava', 'eis', 'era', 'erá', 'iam',
      'ias', 'ida', 'ido', 'ira', 'irá',

      'am', 'ar', 'as', 'ei', 'em', 'er', 'es', 'eu', 'ia', 'ir', 'is', 'iu', 'ou'

    ], '', 'rv');

    return token;
  }

  /**
   * Step 3: Delete suffix i.
   *
   * Perform this step if the word was changed, in RV and preceded by c.
   *
   * @param  {Token} token   Token to stem.
   * @return {Token}         Stemmed token.
   */
  function iPrecededByCSuffix (token) {

    if (token.hasSuffix('ci')) {
      token.replaceSuffixInRegion('i', '', 'rv');
    }

    return token;
  }

  /**
   * Step 4: Residual suffix.
   *
   * Perform this step if steps 1 and 2 did not alter the word.
   *
   * @param  {Token} token Token to stem.
   * @return {Token}       Stemmed token.
   */
  function residualSuffix (token) {

    token.replaceSuffixInRegion(['os', 'a', 'i', 'o', 'á', 'í', 'ó'], '', 'rv');

    return token;
  }

  /**
   * Step 5: Residual form.
   *
   * This step should always be performed.
   *
   * @param  {Token} token Token to stem.
   * @return {Token}       Stemmed token.
   */
  function residualForm (token) {

    var tokenString = token.string;

    if (token.hasSuffix('gue') || token.hasSuffix('gué') || token.hasSuffix('guê')) {
      token.replaceSuffixInRegion(['ue', 'ué', 'uê'], '', 'rv');
    }

    if (token.hasSuffix('cie') || token.hasSuffix('cié') || token.hasSuffix('ciê')) {
      token.replaceSuffixInRegion(['ie', 'ié', 'iê'], '', 'rv');
    }

    if (tokenString === token.string) {
      token.replaceSuffixInRegion(['e', 'é', 'ê'], '', 'rv');
    }

    token.replaceSuffixInRegion('ç', 'c', 'all');

    return token;
  }

  /**
   * Postlude.
   *
   * Turns a~, o~ back into ã, õ.
   *
   * @param  {String} token Word to stem.
   * @return {String}       Stemmed token.
   */
  function postlude (token) {
    return token
      .replaceAll('a~', 'ã')
      .replaceAll('o~', 'õ');
  }

  /**
   * Stems a word using a Porter stemmer algorithm.
   *
   * @param  {String} word Word to stem.
   * @return {String}      Stemmed token.
   */
  PorterStemmer.stem = function (word) {
    var token = new Token(word.toLowerCase()),
      original;

    token = prelude(token);

    token.usingVowels('aeiouáéíóúâêôàãõ')
      .markRegion('all', 0)
      .markRegion('r1', null, markRegionN)
      .markRegion('r2', token.regions.r1, markRegionN)
      .markRegion('rv', null, markRegionV);

    original = token.string;

    // Always do step 1.
    token = standardSuffix(token);

    // Do step 2 if no ending was removed by step 1.
    if (token.string === original) {
      token = verbSuffix(token);
    }

    // If the last step to be obeyed — either step 1 or 2 — altered the word,
    // do step 3. Alternatively, if neither steps 1 nor 2 altered the word, do
    // step 4.
    token = token.string !== original ? iPrecededByCSuffix(token) : residualSuffix(token);

    // Always do step 5.
    token = residualForm(token);

    token = postlude(token);

    return token.string;
  };

  return PorterStemmer;
})();


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_ru.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_ru.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2012, Polyakov Vladimir, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Stemmer = __webpack_require__(/*! ./stemmer_ru */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_ru.js");

var PorterStemmer = new Stemmer();
module.exports = PorterStemmer;

function attemptReplacePatterns(token, patterns) {
	var replacement = null;
	var i = 0, isReplaced = false;
	while ((i < patterns.length) && !isReplaced) {
		if (patterns[i][0].test(token)) {
			replacement = token.replace(patterns[i][0], patterns[i][1]);
			isReplaced = true;
		}
		i++;
	}
	return replacement;
};

function perfectiveGerund(token) {
	var result = attemptReplacePatterns(token, [
			[/[ая]в(ши|шись)$/g, ''],
			[/(ив|ивши|ившись|ывши|ывшись|ыв)$/g, '']
		]);
	return result;
};

function adjectival(token) {
	var result = adjective(token);
	if (result != null) {
		var pariticipleResult = participle(result);
		result = pariticipleResult ? pariticipleResult : result;
	}
	return result;
};

function adjective(token) {
	var result = attemptReplacePatterns(token, [
			[/(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$/g, '']
		]);
	return result;
};

function participle(token) {
	var result = attemptReplacePatterns(token, [
		[/([ая])(ем|нн|вш|ющ|щ)$/g, '$1'],
		[/(ивш|ывш|ующ)$/g, '']
	]);
	return result;
};

function reflexive(token) {
	var result = attemptReplacePatterns(token, [
		[/(ся|сь)$/g, '']
	]);
	return result;
};

function verb(token) {
	var result = attemptReplacePatterns(token, [
		[/([ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)$/g, '$1'],
		[/(ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|ит|ыт|ены|ить|ыть|ишь|ую|ю)$/g, '']
	]);
	return result;
};

function noun(token) {
	var result = attemptReplacePatterns(token, [
		[/(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$/g, '']
	]);
	return result;
};

function superlative (token) {
	var result = attemptReplacePatterns(token, [
		[/(ейш|ейше)$/g, '']
	]);
	return result;
};

function derivational (token) {
	var result = attemptReplacePatterns(token, [
		[/(ост|ость)$/g, '']
	]);
	return result;
};

// perform full stemming algorithm on a single word
PorterStemmer.stem = function(token) {
	token = token.toLowerCase().replace(/ё/g, 'е');
	var volwesRegexp = /^(.*?[аеиоюяуыиэ])(.*)$/g;
	var RV = volwesRegexp.exec(token);
	if (!RV || RV.length < 3) {
		return token;
	}
	var head = RV[1];
	RV = RV[2];
	volwesRegexp.lastIndex = 0;
	var R2 = volwesRegexp.exec(RV);
	var result = perfectiveGerund(RV);
	if (result === null) {
		var resultReflexive = reflexive(RV) || RV;
		result = adjectival(resultReflexive);
		if (result === null) {
			result = verb(resultReflexive);
			if (result === null) {
				result = noun(resultReflexive);
				if (result === null) {
					result = resultReflexive;
				}
			}
		}
	}
	result = result.replace(/и$/g, '');
	var derivationalResult = result
	if (R2 && R2[2]) {
		derivationalResult = derivational(R2[2]);
		if (derivationalResult != null) {
			derivationalResult = derivational(result);
		} else {
			derivationalResult = result;
		}
	}

	var superlativeResult = superlative(derivationalResult) || derivationalResult;

	superlativeResult = superlativeResult.replace(/(н)н/g, '$1');
	superlativeResult = superlativeResult.replace(/ь$/g, '');
	return head + superlativeResult;
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\porter_stemmer_sv.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/porter_stemmer_sv.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2017, Dogan Yazar

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Stemmer = __webpack_require__(/*! ./stemmer_sv */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_sv.js")

//Get R1 region
function getRegions(str) {
  const match = str.match(/[aeiouyäåö][^aeiouyäåö]([a-zåäö]+)/)
  let r1 = ''
  if (match && match[1]) {
    r1 = match[1]
    if (match.index + 2 < 3) { //Not clear why we need this! Algorithm does not describe this part!
      r1 = str.slice(3)
    }
  }
  return {
    r1,
    rest: str.slice(0, str.length - r1.length)
  }
}

function step1a(str, regions = getRegions(str)) {
  const r1 = regions.r1
  if (!r1) {
    return str
  }

  const regEx = /(heterna|hetens|anden|andes|andet|arens|arnas|ernas|heten|heter|ornas|ande|ades|aren|arna|arne|aste|erna|erns|orna|ade|are|ast|ens|ern|het|ad|ar|as|at|en|er|es|or|a|e)$/
  const match = r1.match(regEx)
  return match ? regions.rest + r1.slice(0, match.index) : str
}

function step1b(str, regions = getRegions(str)) {
  if (regions.r1 && str.match(/(b|c|d|f|g|h|j|k|l|m|n|o|p|r|t|v|y)s$/)) {
    return str.slice(0, -1)
  }

  return str
}

function step1(str) {
  const regions = getRegions(str)
  const resA = step1a(str, regions)
  const resB = step1b(str, regions)

  return resA.length < resB.length ? resA : resB
}

function step2(str, regions = getRegions(str)) {
  const r1 = regions.r1
  if (r1 && r1.match(/(dd|gd|nn|dt|gt|kt|tt)$/)) {
    return str.slice(0, -1)
  }
  return str
}

function step3(str, regions = getRegions(str)) {
  const r1 = regions.r1
  if (r1) {
    if (r1.match(/(lös|full)t$/)) {
      return str.slice(0, -1)
    }

    const match = r1.match(/(lig|ig|els)$/)
    return match ? regions.rest + r1.slice(0, match.index) : str
  }

  return str
}

function stem(_str) {
  const str = _str.toLowerCase()
  return step3(step2(step1(str)))
}

var PorterStemmer = new Stemmer()
module.exports = PorterStemmer

// perform full stemming algorithm on a single word
PorterStemmer.stem = stem


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer.js":
/*!******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer.js ***!
  \******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer.js");

module.exports = function() {
    var stemmer = this;

    stemmer.stem = function(token) {
        return token;
    };

    stemmer.addStopWord = function(stopWord) {
        stopwords.words.push(stopWord);
    };

    stemmer.addStopWords = function(moreStopWords) {
        stopwords.words = stopwords.words.concat(moreStopWords);
    };

    stemmer.removeStopWord = function(stopWord) {
        this.removeStopWords([stopWord])
    };

    stemmer.removeStopWords = function(moreStopWords) {
        moreStopWords.forEach(function(stopWord){
            var idx = stopwords.words.indexOf(stopWord);
            if (idx >= 0) {
                stopwords.words.splice(idx, 1);
            }
        });

    };


    stemmer.tokenizeAndStem = function(text, keepStops) {
        var stemmedTokens = [];
        var lowercaseText = text.toLowerCase();
        var tokens = new Tokenizer().tokenize(lowercaseText);

        if (keepStops) {
            tokens.forEach(function(token) {
                stemmedTokens.push(stemmer.stem(token));
            });
        }

        else {
            tokens.forEach(function(token) {
                if (stopwords.words.indexOf(token) == -1)
                    stemmedTokens.push(stemmer.stem(token));
            });
        }

        return stemmedTokens;
    };

    stemmer.attach = function() {
        String.prototype.stem = function() {
            return stemmer.stem(this);
        };

        String.prototype.tokenizeAndStem = function(keepStops) {
            return stemmer.tokenizeAndStem(this, keepStops);
        };
    };
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_es.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_es.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2012, 2018 David Przybilla, Chris Umbel, Hugo W.L. ter Doest 

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords_es */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_es.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer_es */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_es.js");

class Stemmer {
    constructor() {
      
    }

    stem(token) {
        return token;
    };

    tokenizeAndStem(text, keepStops) {
        var stemmedTokens = [];
        
        var that = this;
        new Tokenizer().tokenize(text).forEach(function(token) {
            if (keepStops || stopwords.words.indexOf(token) == -1) {
                var resultToken = token.toLowerCase();
                if (resultToken.match(new RegExp('[a-záéíóúüñ0-9]+', 'gi'))) {
                    resultToken = that.stem(resultToken);
                }
                stemmedTokens.push(resultToken);
            }
        });
        
        return stemmedTokens;
    };

    attach() {
      var that = this;
      String.prototype.stem = function() {
            return that.stem(this);
        };
        
      String.prototype.tokenizeAndStem = function(keepStops) {
          return that.tokenizeAndStem(this, keepStops);
      };
    };
}

module.exports = Stemmer;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_fa.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_fa.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel
Farsi Stemmer by Fardin Koochaki <me@fardinak.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords_fa */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_fa.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer_fa */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_fa.js");

module.exports = function() {
    var stemmer = this;

    stemmer.stem = function(token) {
        return token;
    };

    stemmer.tokenizeAndStem = function(text, keepStops) {
        var stemmedTokens = [];
        
        new Tokenizer().tokenize(text).forEach(function(token) {
            if(keepStops || stopwords.words.indexOf(token) == -1)
                stemmedTokens.push(stemmer.stem(token));
        });
        
        return stemmedTokens;
    };

    stemmer.attach = function() {
        String.prototype.stem = function() {
            return stemmer.stem(this);
        };
        
        String.prototype.tokenizeAndStem = function(keepStops) {
            return stemmer.tokenizeAndStem(this, keepStops);
        };
    };
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_fr.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_fr.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2014, Ismaël Héry

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords_fr */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_fr.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer_fr */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_fr.js");

module.exports = function() {
   var stemmer = this;

   stemmer.stem = function(token) {
      return token;
   };

   stemmer.tokenizeAndStem = function(text, keepStops) {
      var stemmedTokens = [];

      new Tokenizer().tokenize(text).forEach(function(token) {
         if (keepStops || stopwords.words.indexOf(token) == -1) {
            var resultToken = token.toLowerCase();
            if (resultToken.match(/[a-zâàëéêèïîôûùç0-9]/gi)) {
               resultToken = stemmer.stem(resultToken);
            }
            stemmedTokens.push(resultToken);
         }
      });

      return stemmedTokens;
   };

   stemmer.attach = function() {
      String.prototype.stem = function() {
         return stemmer.stem(this);
      };

      String.prototype.tokenizeAndStem = function(keepStops) {
         return stemmer.tokenizeAndStem(this, keepStops);
      };
   };
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_it.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_it.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var stopwords = __webpack_require__(/*! ../util/stopwords_it */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_it.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer_it */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_it.js");

module.exports = function() {
    var stemmer = this;

    stemmer.stem = function(token) {
        return token;
    };

    stemmer.tokenizeAndStem = function(text, keepStops) {
        var stemmedTokens = [];
        
        new Tokenizer().tokenize(text).forEach(function(token) {
            if (keepStops || stopwords.words.indexOf(token) == -1) {
                var resultToken = token.toLowerCase();
                if (resultToken.match(/[a-zàèìòù0-9]/gi)) {
                    resultToken = stemmer.stem(resultToken);
                }
                stemmedTokens.push(resultToken);
            }
        });
        
        return stemmedTokens;
    };

    stemmer.attach = function() {
        String.prototype.stem = function() {
            return stemmer.stem(this);
        };
        
        String.prototype.tokenizeAndStem = function(keepStops) {
            return stemmer.tokenizeAndStem(this, keepStops);
        };
    };
}

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_ja.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_ja.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
 Copyright (c) 2012, Guillaume Marty

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * A very basic stemmer that performs the following steps:
 * * Stem katakana.
 * Inspired by:
 * http://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilter.java
 *
 * This script assumes input is normalized using normalizer_ja().
 *
 * \@todo Use .bind() in StemmerJa.prototype.attach().
 */

var Tokenizer = __webpack_require__(/*! ../tokenizers/tokenizer_ja */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer_ja.js");
var stopwords = __webpack_require__(/*! ../util/stopwords_ja */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_ja.js");



/**
 * @constructor
 */
var StemmerJa = function() {
};


/**
 * Tokenize and stem a text.
 * Stop words are excluded except if the second argument is true.
 *
 * @param {string} text
 * @param {boolean} keepStops Whether to keep stop words from the output or not.
 * @return {Array.<string>}
 */
StemmerJa.prototype.tokenizeAndStem = function(text, keepStops) {
  var self = this;
  var stemmedTokens = [];
  var tokens = new Tokenizer().tokenize(text);

  // This is probably faster than an if at each iteration.
  if (keepStops) {
    tokens.forEach(function(token) {
      var resultToken = token.toLowerCase();
      resultToken = self.stem(resultToken);
      stemmedTokens.push(resultToken);
    });
  } else {
    tokens.forEach(function(token) {
      if (stopwords.indexOf(token) == -1) {
        var resultToken = token.toLowerCase();
        resultToken = self.stem(resultToken);
        stemmedTokens.push(resultToken);
      }
    });
  }

  return stemmedTokens;
};


/**
 * Stem a term.
 *
 * @param {string} token
 * @return {string}
 */
StemmerJa.prototype.stem = function(token) {
  token = this.stemKatakana(token);

  return token;
};


/**
 * Remove the final prolonged sound mark on katakana if length is superior to
 * a threshold.
 *
 * @param {string} token A katakana string to stem.
 * @return {string} A katakana string stemmed.
 */
StemmerJa.prototype.stemKatakana = function(token) {
  var HIRAGANA_KATAKANA_PROLONGED_SOUND_MARK = 'ー';
  var DEFAULT_MINIMUM_LENGTH = 4;

  if (token.length >= DEFAULT_MINIMUM_LENGTH
      && token.slice(-1) === HIRAGANA_KATAKANA_PROLONGED_SOUND_MARK
      && this.isKatakana(token)) {
    token = token.slice(0, token.length - 1);
  }
  return token;
};


/**
 * Is a string made of fullwidth katakana only?
 * This implementation is the fastest I know:
 * http://jsperf.com/string-contain-katakana-only/2
 *
 * @param {string} str A string.
 * @return {boolean} True if the string has katakana only.
 */
StemmerJa.prototype.isKatakana = function(str) {
  return !!str.match(/^[゠-ヿ]+$/);
};

// Expose an attach function that will patch String with new methods.
StemmerJa.prototype.attach = function() {
  var self = this;

  String.prototype.stem = function() {
    return self.stem(this);
  };

  String.prototype.tokenizeAndStem = function(keepStops) {
    return self.tokenizeAndStem(this, keepStops);
  };
};

module.exports = StemmerJa;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_nl.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_nl.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2018 Hugo W.L. ter Doest 

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords_nl */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_nl.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer.js");

class Stemmer {
    constructor() {
      
    }

    stem(token) {
        return token;
    };

    tokenizeAndStem(text, keepStops) {
        var stemmedTokens = [];
        
        var that = this;
        new Tokenizer().tokenize(text).forEach(function(token) {
            if (keepStops || stopwords.words.indexOf(token) == -1) {
                var resultToken = token.toLowerCase();
                if (resultToken.match(new RegExp('[a-zäëïöüáéíóúè0-9]+', 'gi'))) {
                    resultToken = that.stem(resultToken);
                }
                stemmedTokens.push(resultToken);
            }
        });
        
        return stemmedTokens;
    };

    attach() {
      var that = this;
      String.prototype.stem = function() {
            return that.stem(this);
        };
        
      String.prototype.tokenizeAndStem = function(keepStops) {
          return that.tokenizeAndStem(this, keepStops);
      };
    };
}

module.exports = Stemmer;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_no.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_no.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2014, Kristoffer Brabrand

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords_no */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_no.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer_no */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_no.js");

module.exports = function() {
    var stemmer = this;

    stemmer.stem = function(token) {
        return token;
    };

    stemmer.addStopWord = function(stopWord) {
        stopwords.words.push(stopWord);
    };

    stemmer.addStopWords = function(moreStopWords) {
        stopwords.words = stopwords.words.concat(moreStopWords);
    };

    stemmer.tokenizeAndStem = function(text, keepStops) {
        var stemmedTokens = [];

        new Tokenizer().tokenize(text).forEach(function(token) {
            if(keepStops || stopwords.words.indexOf(token.toLowerCase()) == -1)
                stemmedTokens.push(stemmer.stem(token));
        });

        return stemmedTokens;
    };

    stemmer.attach = function() {
        String.prototype.stem = function() {
            return stemmer.stem(this);
        };

        String.prototype.tokenizeAndStem = function(keepStops) {
            return stemmer.tokenizeAndStem(this, keepStops);
        };
    };
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_pt.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_pt.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2014, Ismaël Héry

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

module.exports = function () {
  'use strict';

  var Stemmer = this,
    stopwords = __webpack_require__(/*! ../util/stopwords_pt */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_pt.js"),
    Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer_pt */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_pt.js");

  Stemmer.stem = function (token) {
    return token;
  };

  Stemmer.addStopWords = function (word) {
    stopwords.words.push(word);
  };

  Stemmer.addStopWords = function (words) {
    stopwords.words = stopwords.words.concat(words);
  };

  Stemmer.tokenizeAndStem = function(text, keepStops) {
    var stemmedTokens = [];

    var tokenStemmer = function (token) {
      if (keepStops || stopwords.words.indexOf(token.toLowerCase()) === -1) {
        stemmedTokens.push(Stemmer.stem(token));
      }
    };

    new Tokenizer().tokenize(text).forEach(tokenStemmer);

    return stemmedTokens;
  };

  Stemmer.attach = function () {
    String.prototype.stem = function () {
      return Stemmer.stem(this);
    };

    String.prototype.tokenizeAndStem = function (keepStops) {
      return Stemmer.tokenizeAndStem(this, keepStops);
    };
  };
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_ru.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_ru.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2012, Polyakov Vladimir, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords_ru */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_ru.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer_ru */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_ru.js");

module.exports = function() {
    var stemmer = this;

    stemmer.stem = function(token) {
        return token;
    };

    stemmer.tokenizeAndStem = function(text, keepStops) {
        var stemmedTokens = [];
        
        new Tokenizer().tokenize(text).forEach(function(token) {
            if (keepStops || stopwords.words.indexOf(token) == -1) {
                var resultToken = token.toLowerCase();
                if (resultToken.match(new RegExp('[а-яё0-9]+', 'gi'))) {
                    resultToken = stemmer.stem(resultToken);
                }
                stemmedTokens.push(resultToken);
            }
        });
        
        return stemmedTokens;
    };

    stemmer.attach = function() {
        String.prototype.stem = function() {
            return stemmer.stem(this);
        };
        
        String.prototype.tokenizeAndStem = function(keepStops) {
            return stemmer.tokenizeAndStem(this, keepStops);
        };
    };
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\stemmer_sv.js":
/*!*********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/stemmer_sv.js ***!
  \*********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2017, Dogan Yazar

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var stopwords = __webpack_require__(/*! ../util/stopwords_sv */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_sv.js");
var Tokenizer = __webpack_require__(/*! ../tokenizers/aggressive_tokenizer_sv */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_sv.js");

module.exports = function() {
    var stemmer = this;

    stemmer.stem = function(token) {
        return token;
    };

    stemmer.addStopWord = function(stopWord) {
        stopwords.words.push(stopWord);
    };

    stemmer.addStopWords = function(moreStopWords) {
        stopwords.words = stopwords.words.concat(moreStopWords);
    };

    stemmer.tokenizeAndStem = function(text, keepStops) {
        var stemmedTokens = [];

        new Tokenizer().tokenize(text).forEach(function(token) {
            if(keepStops || stopwords.words.indexOf(token.toLowerCase()) == -1)
                stemmedTokens.push(stemmer.stem(token));
        });

        return stemmedTokens;
    };

    stemmer.attach = function() {
        String.prototype.stem = function() {
            return stemmer.stem(this);
        };

        String.prototype.tokenizeAndStem = function(keepStops) {
            return stemmer.tokenizeAndStem(this, keepStops);
        };
    };
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\stemmers\\token.js":
/*!****************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/stemmers/token.js ***!
  \****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2015, Luís Rodrigues

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

module.exports = (function () {
  'use strict';

  /**
   * Stemmer token constructor.
   *
   * @param {String} string Token string.
   */
  var Token = function (string) {
    this.vowels   = '';
    this.regions  = {};
    this.string   = string;
    this.original = string;
  }

  /**
   * Set vowels.
   *
   * @param  {String|Array} vowels List of vowels.
   * @return {Token}               Token instance.
   */
  Token.prototype.usingVowels = function (vowels) {
    this.vowels = vowels;
    return this;
  };

  /**
   * Marks a region by defining its starting index or providing a callback
   * function that does.
   *
   * @param  {String}       region   Region name.
   * @param  {Array|Number} args     Callback arguments or region start index.
   * @param  {Function}     callback Function that determines the start index (optional).
   * @param  {Object}       context  Callback context (optional, defaults to this).
   * @return {Token}                 Token instance.
   */
  Token.prototype.markRegion = function (region, args, callback, context) {
    if (typeof callback === 'function') {
      this.regions[region] = callback.apply(context || this, [].concat(args));

    } else if (!isNaN(args)) {
      this.regions[region] = args;
    }

    return this;
  };

  /**
   * Replaces all instances of a string with another.
   *
   * @param  {String} find    String to be replaced.
   * @param  {String} replace Replacement string.
   * @return {Token}          Token instance.
   */
  Token.prototype.replaceAll = function (find, replace) {
    this.string = this.string.split(find).join(replace);
    return this;
  };

  /**
   * Replaces the token suffix if in a region.
   *
   * @param  {String} suffix  Suffix to replace.
   * @param  {String} replace Replacement string.
   * @param  {String} region  Region name.
   * @return {Token}          Token instance.
   */
  Token.prototype.replaceSuffixInRegion = function (suffix, replace, region) {
    var suffixes = [].concat(suffix);
    for (var i = 0; i < suffixes.length; i++) {
      if (this.hasSuffixInRegion(suffixes[i], region)) {
        this.string = this.string.slice(0, -suffixes[i].length) + replace;
        return this;
      }
    }
    return this;
  };

  /**
   * Determines whether the token has a vowel at the provided index.
   *
   * @param  {Integer} index Character index.
   * @return {Boolean}       Whether the token has a vowel at the provided index.
   */
  Token.prototype.hasVowelAtIndex = function (index) {
    return this.vowels.indexOf(this.string[index]) !== -1;
  };

  /**
   * Finds the next vowel in the token.
   *
   * @param  {Integer} start Starting index offset.
   * @return {Integer}       Vowel index, or the end of the string.
   */
  Token.prototype.nextVowelIndex = function (start) {
    var index = (start >= 0 && start < this.string.length) ? start : this.string.length;
    while (index < this.string.length && !this.hasVowelAtIndex(index)) {
      index++;
    }
    return index;
  };

  /**
   * Finds the next consonant in the token.
   *
   * @param  {Integer} start Starting index offset.
   * @return {Integer}       Consonant index, or the end of the string.
   */
  Token.prototype.nextConsonantIndex = function (start) {
    var index = (start >= 0 && start < this.string.length) ? start : this.string.length;
    while (index < this.string.length && this.hasVowelAtIndex(index)) {
      index++;
    }
    return index;
  };

  /**
   * Determines whether the token has the provided suffix.
   * @param  {String}  suffix Suffix to match.
   * @return {Boolean}        Whether the token string ends in suffix.
   */
  Token.prototype.hasSuffix = function (suffix) {
    return this.string.slice(-suffix.length) === suffix;
  };

  /**
   * Determines whether the token has the provided suffix within the specified
   * region.
   *
   * @param  {String}  suffix Suffix to match.
   * @param  {String}  region Region name.
   * @return {Boolean}        Whether the token string ends in suffix.
   */
  Token.prototype.hasSuffixInRegion = function (suffix, region) {
    var regionStart = this.regions[region] || 0,
      suffixStart   = this.string.length - suffix.length;
    return this.hasSuffix(suffix) && suffixStart >= regionStart;
  };

  return Token;
})();


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tfidf\\tfidf.js":
/*!*************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tfidf/tfidf.js ***!
  \*************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer) {/*
Copyright (c) 2011, Rob Ellis, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._,
    Tokenizer = __webpack_require__(/*! ../tokenizers/regexp_tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\regexp_tokenizer.js").WordTokenizer,
    tokenizer = new Tokenizer(),
    stopwords = __webpack_require__(/*! ../util/stopwords */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords.js").words,
    fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");

function buildDocument(text, key) {
    var stopOut;

    if(typeof text === 'string') {
        text = tokenizer.tokenize(text.toLowerCase());
        stopOut = true;
    } else if(!_.isArray(text)) {
        stopOut = false;
        return text;
    }

    return text.reduce(function(document, term) {
        // next line solves https://github.com/NaturalNode/natural/issues/119
        if(typeof document[term] === 'function') document[term] = 0;
        if(!stopOut || stopwords.indexOf(term) < 0)
            document[term] = (document[term] ? document[term] + 1 : 1);
        return document;
    }, {__key: key});
}

function tf(term, document) {
    return document[term] ? document[term]: 0;
}

function documentHasTerm(term, document) {
    return document[term] && document[term] > 0;
}

function TfIdf(deserialized) {
    if(deserialized)
        this.documents = deserialized.documents;
    else
        this.documents = [];

    this._idfCache = {};
}

// backwards compatibility for < node 0.10
function isEncoding(encoding) {
    if (typeof Buffer.isEncoding !== 'undefined')
        return Buffer.isEncoding(encoding);
    switch ((encoding + '').toLowerCase()) {
        case 'hex':
        case 'utf8':
        case 'utf-8':
        case 'ascii':
        case 'binary':
        case 'base64':
        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
        case 'raw':
            return true;
    }
    return false;
}

module.exports = TfIdf;
TfIdf.tf = tf;

TfIdf.prototype.idf = function(term, force) {

    // Lookup the term in the New term-IDF caching,
    // this will cut search times down exponentially on large document sets.
    if(this._idfCache[term] && this._idfCache.hasOwnProperty(term) && force !== true)
        return this._idfCache[term];

    var docsWithTerm = this.documents.reduce(function(count, document) {
        return count + (documentHasTerm(term, document) ? 1 : 0);
    }, 0);

    var idf = 1 + Math.log((this.documents.length) / ( 1 + docsWithTerm ));

    // Add the idf to the term cache and return it
    this._idfCache[term] = idf;
    return idf;
};

// If restoreCache is set to true, all terms idf scores currently cached will be recomputed.
// Otherwise, the cache will just be wiped clean
TfIdf.prototype.addDocument = function(document, key, restoreCache) {
    this.documents.push(buildDocument(document, key));

    // make sure the cache is invalidated when new documents arrive
    if(restoreCache === true) {
        for(var term in this._idfCache) {
            // invoking idf with the force option set will
            // force a recomputation of the idf, and it will
            // automatically refresh the cache value.
            this.idf(term, true);
        }
    }   else {
        this._idfCache = {};
    }
};

// If restoreCache is set to true, all terms idf scores currently cached will be recomputed.
// Otherwise, the cache will just be wiped clean
TfIdf.prototype.addFileSync = function(path, encoding, key, restoreCache) {
    if(!encoding)
        encoding = 'utf8';
    if(!isEncoding(encoding))
        throw new Error('Invalid encoding: ' + encoding);

    var document = fs.readFileSync(path, encoding);
    this.documents.push(buildDocument(document, key));

    // make sure the cache is invalidated when new documents arrive
    if(restoreCache === true) {
        for(var term in this._idfCache) {
            // invoking idf with the force option set will
            // force a recomputation of the idf, and it will
            // automatically refresh the cache value.
            this.idf(term, true);
        }
    }
    else {
        this._idfCache = {};
    }
};

TfIdf.prototype.tfidf = function(terms, d) {
    var _this = this;

    if(!_.isArray(terms)) {
        terms = tokenizer.tokenize(terms.toString().toLowerCase());
    }

    return terms.reduce(function(value, term) {
        var idf = _this.idf(term);
        idf = idf === Infinity ? 0 : idf;
        return value + (tf(term, _this.documents[d]) * idf);
    }, 0.0);
};

TfIdf.prototype.listTerms = function(d) {
    var terms = [];
    var _this = this;
    for(var term in this.documents[d]) {
      if (this.documents[d]) {
          if(term != '__key') {
              terms.push({"term": term, 
                          "tf": tf(term, _this.documents[d]),
                          "idf": _this.idf(term),
                          "tfidf": _this.tfidf(term, d)});
          }
      }
    }

    return terms.sort(function(x, y) { return y.tfidf - x.tfidf; });
};

TfIdf.prototype.tfidfs = function(terms, callback) {
    var tfidfs = new Array(this.documents.length);

    for(var i = 0; i < this.documents.length; i++) {
        tfidfs[i] = this.tfidf(terms, i);

        if(callback)
            callback(i, tfidfs[i], this.documents[i].__key);
    }

    return tfidfs;
};

// Define a tokenizer other than the default "WordTokenizer"
TfIdf.prototype.setTokenizer = function(t) {
    if(!_.isFunction(t.tokenize))
        throw new Error('Expected a valid Tokenizer');
    tokenizer = t;
};

// Define a stopwords other than the default
TfIdf.prototype.setStopwords = function(customStopwords) {
  
  if (!Array.isArray(customStopwords))
    return false;
  
  customStopwords.forEach(stopword => {
    if ((typeof stopword) != 'string')
      return false;
  });
  
  stopwords = customStopwords;
  return true;
  
}

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../../../webpack/node_modules/buffer/index.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\buffer\\index.js").Buffer))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer.js":
/*!*********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer.js ***!
  \*********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);    
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    return this.trim(text.split(/\W+/));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_es.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_es.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel,David Przybilla

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);    
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    return this.trim(text.split(/[^a-zA-Zá-úÁ-ÚñÑüÜ]+/));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_fa.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_fa.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel
Farsi Aggressive Tokenizer by Fardin Koochaki <me@fardinak.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);    
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.clearEmptyString = function(array) {
	return array.filter(function(a) {
		return a != '';
	});
};

AggressiveTokenizer.prototype.clearText = function(text) {
	return text.replace(new RegExp('\.\:\+\-\=\(\)\"\'\!\?\،\,\؛\;', 'g'), ' ');
};

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    text = this.clearText(text);
    return this.clearEmptyString(text.split(/\s+/));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_fr.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_fr.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);    
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    return this.trim(text.split(/[^a-z0-9äâàéèëêïîöôùüûœç]+/i));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_id.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_id.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2017, Alif Bhaskoro, Andy Librian, R. Kukuh (Reimplemented from https://github.com/sastrawi/sastrawi)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);    
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

// Remove all non alphanumeric characters except '-'
// Replace more than one space character to ' '
function normalizeText(text){
	result = text.replace(/[^a-z0-9 -]/g, ' ').replace(/( +)/g, ' ');
	return result;
}

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by space
    text = normalizeText(text);
    return this.trim(text.split(' '));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_it.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_it.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel,David Przybilla

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);    
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    return this.trim(text.split(/\W+/));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_nl.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_nl.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel, Martijn de Boer

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    return this.trim(text.split(/[^a-zA-Z0-9_']+/));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_no.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_no.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2014, Kristoffer Brabrand

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    normalizer = __webpack_require__(/*! ../normalizers/normalizer_no */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer_no.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.tokenize = function(text) {
    text = normalizer.remove_diacritics(text);

    // break a string up into an array of tokens by anything non-word
    return this.trim(text.split(/[^A-Za-z0-9_æøåÆØÅäÄöÖüÜ]+/));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_pl.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_pl.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2013, Paweł Łaskarzewski

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);
};

util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.withoutEmpty = function(array) {
	return array.filter(function(a) {return a;});
};

AggressiveTokenizer.prototype.clearText = function(text) {
	return text.replace(/[^a-zążśźęćńół0-9]/gi, ' ').replace(/[\s\n]+/g, ' ').trim();
};

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    return this.withoutEmpty(this.clearText(text).split(' '));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_pt.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_pt.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel,David Przybilla

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.withoutEmpty = function(array) {
	return array.filter(function(a) {return a;});
};

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    return this.withoutEmpty(this.trim(text.split(/[^a-zA-Zà-úÀ-Ú]/)));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_ru.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_ru.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);    
};

util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.withoutEmpty = function(array) {
	return array.filter(function(a) {return a;});
};

AggressiveTokenizer.prototype.clearText = function(text) {
	return text.replace(/[^a-zа-яё0-9]/gi, ' ').replace(/[\s\n]+/g, ' ').trim();
};

AggressiveTokenizer.prototype.tokenize = function(text) {
    // break a string up into an array of tokens by anything non-word
    return this.withoutEmpty(this.clearText(text).split(' '));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_sv.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_sv.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2017, Dogan Yazar

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    normalizer = __webpack_require__(/*! ../normalizers/normalizer_sv */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer_sv.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
    Tokenizer.call(this);
};
util.inherits(AggressiveTokenizer, Tokenizer);

module.exports = AggressiveTokenizer;

AggressiveTokenizer.prototype.tokenize = function(text) {
    text = normalizer.remove_diacritics(text);

    // break a string up into an array of tokens by anything non-word
    // Ü is not part of swedish alphabet but there are words using it like müsli and München 
    return this.trim(text.split(/[^A-Za-z0-9_åÅäÄöÖüÜ\-]+/));
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\aggressive_tokenizer_vi.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_vi.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2018, Javis1205 (Github account name)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var AggressiveTokenizer = function() {
  Tokenizer.call(this);
};

util.inherits(AggressiveTokenizer, Tokenizer);

// break a string up into an array of tokens by anything non-word
AggressiveTokenizer.prototype.tokenize = function(text) {
  return this.trim(text.split(/[^a-z0-9àáảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệíìỉĩịóòỏõọôốồổỗộơớờởỡợúùủũụưứừửữựýỳỷỹỵđ]+/i));
};

module.exports = AggressiveTokenizer;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\orthography_matchers.js":
/*!*********************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/orthography_matchers.js ***!
  \*********************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/


/***
 * RegExp definitions for tokenizing text in a specific language based
 * on its alphabet. Each language is keyed by the two-letter code per
 * ISO 639-1, and defines a RegExp that excludes alphabetic characters.
 */
var matchers = {
  fi: /[^A-Za-zÅåÄäÖö]/
};

module.exports = matchers;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\regexp_tokenizer.js":
/*!*****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/regexp_tokenizer.js ***!
  \*****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Rob Ellis, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._;

// Base Class for RegExp Matching
var RegexpTokenizer = function(options) {
    var options = options || {};
    this._pattern = options.pattern || this._pattern;
    this.discardEmpty = options.discardEmpty || true;

    // Match and split on GAPS not the actual WORDS
    this._gaps = options.gaps;

    if (this._gaps === undefined) {
        this._gaps = true;
    }
};

util.inherits(RegexpTokenizer, Tokenizer);

RegexpTokenizer.prototype.tokenize = function(s) {
    var results;

    if (this._gaps) {
        results = s.split(this._pattern);
        return (this.discardEmpty) ? _.without(results,'',' ') : results;
    } else {
        return s.match(this._pattern);
    }
};

exports.RegexpTokenizer = RegexpTokenizer;

var orthographyMatchers = __webpack_require__(/*! ./orthography_matchers */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\orthography_matchers.js");

/***
 * A tokenizer that accepts an alphabet definition.
 * @param {string} options.language ISO 639-1 for the language, e.g. 'en'
 */
var OrthographyTokenizer = function(options) {
    var pattern = orthographyMatchers[options.language];
    if (!pattern) {
        WordTokenizer.call(this, options);
    } else {
        this._pattern = pattern;
        RegexpTokenizer.call(this, options);
    }
};

util.inherits(OrthographyTokenizer, RegexpTokenizer);

exports.OrthographyTokenizer = OrthographyTokenizer;

/***
 * A tokenizer that divides a text into sequences of alphabetic and
 * non-alphabetic characters.  E.g.:
 *
 *      >>> WordTokenizer().tokenize("She said 'hello'.")
 *      ['She', 'said', 'hello']
 *
 */
var WordTokenizer = function(options) {
    this._pattern = /[^A-Za-zА-Яа-я0-9_]+/;
    RegexpTokenizer.call(this,options)
};

util.inherits(WordTokenizer, RegexpTokenizer);
exports.WordTokenizer = WordTokenizer;

/***
 * A tokenizer that divides a text into sequences of alphabetic and
 * non-alphabetic characters.  E.g.:
 *
 *      >>> WordPunctTokenizer().tokenize("She said 'hello'.")
 *      ["She","said","'","hello","'","."]
 *
 */
var WordPunctTokenizer = function(options) {
    this._pattern = new RegExp(/([A-zÀ-ÿ-]+|[0-9._]+|.|!|\?|'|"|:|;|,|-)/i);
    RegexpTokenizer.call(this,options)
};

util.inherits(WordPunctTokenizer, RegexpTokenizer);
exports.WordPunctTokenizer = WordPunctTokenizer;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\sentence_tokenizer.js":
/*!*******************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/sentence_tokenizer.js ***!
  \*******************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

var SentenceTokenizer = function() {
    Tokenizer.call(this);
};
util.inherits(SentenceTokenizer, Tokenizer);

SentenceTokenizer.prototype.tokenize = function(text) {
    // break string up in to sentences based on punctation and quotation marks
    var tokens = text.match(/([\"\'\‘\“\'\"\[\(\{\⟨][^\.\?\!]+[\.\?\!][\"\'\’\”\'\"\]\)\}\⟩]|[^\.\?\!]+[\.\?\!\s]+)\s?/g);

    // remove unecessary white space
    tokens = tokens.map(Function.prototype.call, String.prototype.trim);

    return this.trim(tokens);
};

module.exports = SentenceTokenizer;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js":
/*!**********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/tokenizer.js ***!
  \**********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

/**
 * \@todo Use .bind() in Tokenizer.prototype.attach().
 */

var Tokenizer = function() {
};

Tokenizer.prototype.trim = function(array) {
  while (array[array.length - 1] == '')
    array.pop();

  while (array[0] == '')
    array.shift();

  return array;
};

// Expose an attach function that will patch String with new methods.
Tokenizer.prototype.attach = function() {
  var self = this;

  String.prototype.tokenize = function() {
    return self.tokenize(this);
  }
};

Tokenizer.prototype.tokenize = function() {};

module.exports = Tokenizer;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer_case.js":
/*!***************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/tokenizer_case.js ***!
  \***************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
 Copyright (c) 2011, Chris Umbel, Alex Langberg

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
  util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
  CaseTokenizer = function() {
    Tokenizer.call(this);
  };

util.inherits(CaseTokenizer, Tokenizer);

CaseTokenizer.prototype.attach = function() {
  var self = this;

  String.prototype.tokenize = function(preserveApostrophe) {
    return self.tokenize(this, preserveApostrophe);
  }
};

// Idea from Seagull: http://stackoverflow.com/a/26482650
CaseTokenizer.prototype.tokenize = function(text, preserveApostrophe) {
  var whitelist = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'];
  var lower = text.toLowerCase();
  var upper = text.toUpperCase();
  var result = '';
  var i;

  for (i = 0; i < lower.length; ++i) {
    if (lower[i] !== upper[i] || whitelist.indexOf(lower[i]) > -1 || (text[i] === '\'' && preserveApostrophe)) {
      result += text[i];
    } else {
      result += ' ';
    }
  }

  return this.trim(result.replace(/\s+/g, ' ').split(' '));
};

module.exports = CaseTokenizer;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer_ja.js":
/*!*************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/tokenizer_ja.js ***!
  \*************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// Original copyright:
/*
 Copyright (c) 2008, Taku Kudo

 All rights reserved.

 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are met:

 * Redistributions of source code must retain the above copyright notice,
 this list of conditions and the following disclaimer.
 * Redistributions in binary form must reproduce the above copyright
 notice, this list of conditions and the following disclaimer in the
 documentation and/or other materials provided with the distribution.
 * Neither the name of the <ORGANIZATION> nor the names of its
 contributors may be used to endorse or promote products derived from this
 software without specific prior written permission.

 THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
 LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
 A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
 CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// This version:
/*
 Copyright (c) 2012, Guillaume Marty

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

// TinySegmenter 0.1 -- Super compact Japanese tokenizer in Javascript
// (c) 2008 Taku Kudo <taku@chasen.org>
// TinySegmenter is freely distributable under the terms of a new BSD licence.
// For details, see http://chasen.org/~taku/software/TinySegmenter/LICENCE.txt

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    normalize = __webpack_require__(/*! ../normalizers/normalizer_ja */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\normalizers\\normalizer_ja.js").normalize_ja,
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");



/**
 * @constructor
 */
var TokenizerJa = function() {
  this.chartype_ = [
    [/[〇一二三四五六七八九十百千万億兆]/, 'M'],
    [/[一-鿌〆]/, 'H'],
    [/[ぁ-ゟ]/, 'I'],
    [/[゠-ヿ]/, 'K'],
    [/[a-zA-Z]/, 'A'],
    [/[0-9]/, 'N']
  ];

  this.BIAS__ = -332;
  this.BC1__ = {'HH': 6, 'II': 2461, 'KH': 406, 'OH': -1378};
  this.BC2__ = {'AA': -3267, 'AI': 2744, 'AN': -878, 'HH': -4070, 'HM': -1711, 'HN': 4012, 'HO': 3761, 'IA': 1327, 'IH': -1184, 'II': -1332, 'IK': 1721, 'IO': 5492, 'KI': 3831, 'KK': -8741, 'MH': -3132, 'MK': 3334, 'OO': -2920};
  this.BC3__ = {'HH': 996, 'HI': 626, 'HK': -721, 'HN': -1307, 'HO': -836, 'IH': -301, 'KK': 2762, 'MK': 1079, 'MM': 4034, 'OA': -1652, 'OH': 266};
  this.BP1__ = {'BB': 295, 'OB': 304, 'OO': -125, 'UB': 352};
  this.BP2__ = {'BO': 60, 'OO': -1762};
  this.BQ1__ = {'BHH': 1150, 'BHM': 1521, 'BII': -1158, 'BIM': 886, 'BMH': 1208, 'BNH': 449, 'BOH': -91, 'BOO': -2597, 'OHI': 451, 'OIH': -296, 'OKA': 1851, 'OKH': -1020, 'OKK': 904, 'OOO': 2965};
  this.BQ2__ = {'BHH': 118, 'BHI': -1159, 'BHM': 466, 'BIH': -919, 'BKK': -1720, 'BKO': 864, 'OHH': -1139, 'OHM': -181, 'OIH': 153, 'UHI': -1146};
  this.BQ3__ = {'BHH': -792, 'BHI': 2664, 'BII': -299, 'BKI': 419, 'BMH': 937, 'BMM': 8335, 'BNN': 998, 'BOH': 775, 'OHH': 2174, 'OHM': 439, 'OII': 280, 'OKH': 1798, 'OKI': -793, 'OKO': -2242, 'OMH': -2402, 'OOO': 11699};
  this.BQ4__ = {'BHH': -3895, 'BIH': 3761, 'BII': -4654, 'BIK': 1348, 'BKK': -1806, 'BMI': -3385, 'BOO': -12396, 'OAH': 926, 'OHH': 266, 'OHK': -2036, 'ONN': -973};
  this.BW1__ = {'，と': 660, '，同': 727, 'B1あ': 1404, 'B1同': 542, '、と': 660, '、同': 727, '｣と': 1682, 'あっ': 1505, 'いう': 1743, 'いっ': -2055, 'いる': 672, 'うし': -4817, 'うん': 665, 'から': 3472, 'がら': 600, 'こう': -790, 'こと': 2083, 'こん': -1262, 'さら': -4143, 'さん': 4573, 'した': 2641, 'して': 1104, 'すで': -3399, 'そこ': 1977, 'それ': -871, 'たち': 1122, 'ため': 601, 'った': 3463, 'つい': -802, 'てい': 805, 'てき': 1249, 'でき': 1127, 'です': 3445, 'では': 844, 'とい': -4915, 'とみ': 1922, 'どこ': 3887, 'ない': 5713, 'なっ': 3015, 'など': 7379, 'なん': -1113, 'にし': 2468, 'には': 1498, 'にも': 1671, 'に対': -912, 'の一': -501, 'の中': 741, 'ませ': 2448, 'まで': 1711, 'まま': 2600, 'まる': -2155, 'やむ': -1947, 'よっ': -2565, 'れた': 2369, 'れで': -913, 'をし': 1860, 'を見': 731, '亡く': -1886, '京都': 2558, '取り': -2784, '大き': -2604, '大阪': 1497, '平方': -2314, '引き': -1336, '日本': -195, '本当': -2423, '毎日': -2113, '目指': -724};
  this.BW2__ = {'11': -669, '．．': -11822, '――': -5730, '−−': -13175, 'いう': -1609, 'うか': 2490, 'かし': -1350, 'かも': -602, 'から': -7194, 'かれ': 4612, 'がい': 853, 'がら': -3198, 'きた': 1941, 'くな': -1597, 'こと': -8392, 'この': -4193, 'させ': 4533, 'され': 13168, 'さん': -3977, 'しい': -1819, 'しか': -545, 'した': 5078, 'して': 972, 'しな': 939, 'その': -3744, 'たい': -1253, 'たた': -662, 'ただ': -3857, 'たち': -786, 'たと': 1224, 'たは': -939, 'った': 4589, 'って': 1647, 'っと': -2094, 'てい': 6144, 'てき': 3640, 'てく': 2551, 'ては': -3110, 'ても': -3065, 'でい': 2666, 'でき': -1528, 'でし': -3828, 'です': -4761, 'でも': -4203, 'とい': 1890, 'とこ': -1746, 'とと': -2279, 'との': 720, 'とみ': 5168, 'とも': -3941, 'ない': -2488, 'なが': -1313, 'など': -6509, 'なの': 2614, 'なん': 3099, 'にお': -1615, 'にし': 2748, 'にな': 2454, 'によ': -7236, 'に対': -14943, 'に従': -4688, 'に関': -11388, 'のか': 2093, 'ので': -7059, 'のに': -6041, 'のの': -6125, 'はい': 1073, 'はが': -1033, 'はず': -2532, 'ばれ': 1813, 'まし': -1316, 'まで': -6621, 'まれ': 5409, 'めて': -3153, 'もい': 2230, 'もの': -10713, 'らか': -944, 'らし': -1611, 'らに': -1897, 'りし': 651, 'りま': 1620, 'れた': 4270, 'れて': 849, 'れば': 4114, 'ろう': 6067, 'われ': 7901, 'を通': -11877, 'んだ': 728, 'んな': -4115, '一人': 602, '一方': -1375, '一日': 970, '一部': -1051, '上が': -4479, '会社': -1116, '出て': 2163, '分の': -7758, '同党': 970, '同日': -913, '大阪': -2471, '委員': -1250, '少な': -1050, '年度': -8669, '年間': -1626, '府県': -2363, '手権': -1982, '新聞': -4066, '日新': -722, '日本': -7068, '日米': 3372, '曜日': -601, '朝鮮': -2355, '本人': -2697, '東京': -1543, '然と': -1384, '社会': -1276, '立て': -990, '第に': -1612, '米国': -4268};
  this.BW3__ = {'あた': -2194, 'あり': 719, 'ある': 3846, 'い．': -1185, 'い。': -1185, 'いい': 5308, 'いえ': 2079, 'いく': 3029, 'いた': 2056, 'いっ': 1883, 'いる': 5600, 'いわ': 1527, 'うち': 1117, 'うと': 4798, 'えと': 1454, 'か．': 2857, 'か。': 2857, 'かけ': -743, 'かっ': -4098, 'かに': -669, 'から': 6520, 'かり': -2670, 'が，': 1816, 'が、': 1816, 'がき': -4855, 'がけ': -1127, 'がっ': -913, 'がら': -4977, 'がり': -2064, 'きた': 1645, 'けど': 1374, 'こと': 7397, 'この': 1542, 'ころ': -2757, 'さい': -714, 'さを': 976, 'し，': 1557, 'し、': 1557, 'しい': -3714, 'した': 3562, 'して': 1449, 'しな': 2608, 'しま': 1200, 'す．': -1310, 'す。': -1310, 'する': 6521, 'ず，': 3426, 'ず、': 3426, 'ずに': 841, 'そう': 428, 'た．': 8875, 'た。': 8875, 'たい': -594, 'たの': 812, 'たり': -1183, 'たる': -853, 'だ．': 4098, 'だ。': 4098, 'だっ': 1004, 'った': -4748, 'って': 300, 'てい': 6240, 'てお': 855, 'ても': 302, 'です': 1437, 'でに': -1482, 'では': 2295, 'とう': -1387, 'とし': 2266, 'との': 541, 'とも': -3543, 'どう': 4664, 'ない': 1796, 'なく': -903, 'など': 2135, 'に，': -1021, 'に、': -1021, 'にし': 1771, 'にな': 1906, 'には': 2644, 'の，': -724, 'の、': -724, 'の子': -1000, 'は，': 1337, 'は、': 1337, 'べき': 2181, 'まし': 1113, 'ます': 6943, 'まっ': -1549, 'まで': 6154, 'まれ': -793, 'らし': 1479, 'られ': 6820, 'るる': 3818, 'れ，': 854, 'れ、': 854, 'れた': 1850, 'れて': 1375, 'れば': -3246, 'れる': 1091, 'われ': -605, 'んだ': 606, 'んで': 798, 'カ月': 990, '会議': 860, '入り': 1232, '大会': 2217, '始め': 1681, '市': 965, '新聞': -5055, '日，': 974, '日、': 974, '社会': 2024};
  this.TC1__ = {'AAA': 1093, 'HHH': 1029, 'HHM': 580, 'HII': 998, 'HOH': -390, 'HOM': -331, 'IHI': 1169, 'IOH': -142, 'IOI': -1015, 'IOM': 467, 'MMH': 187, 'OOI': -1832};
  this.TC2__ = {'HHO': 2088, 'HII': -1023, 'HMM': -1154, 'IHI': -1965, 'KKH': 703, 'OII': -2649};
  this.TC3__ = {'AAA': -294, 'HHH': 346, 'HHI': -341, 'HII': -1088, 'HIK': 731, 'HOH': -1486, 'IHH': 128, 'IHI': -3041, 'IHO': -1935, 'IIH': -825, 'IIM': -1035, 'IOI': -542, 'KHH': -1216, 'KKA': 491, 'KKH': -1217, 'KOK': -1009, 'MHH': -2694, 'MHM': -457, 'MHO': 123, 'MMH': -471, 'NNH': -1689, 'NNO': 662, 'OHO': -3393};
  this.TC4__ = {'HHH': -203, 'HHI': 1344, 'HHK': 365, 'HHM': -122, 'HHN': 182, 'HHO': 669, 'HIH': 804, 'HII': 679, 'HOH': 446, 'IHH': 695, 'IHO': -2324, 'IIH': 321, 'III': 1497, 'IIO': 656, 'IOO': 54, 'KAK': 4845, 'KKA': 3386, 'KKK': 3065, 'MHH': -405, 'MHI': 201, 'MMH': -241, 'MMM': 661, 'MOM': 841};
  this.TQ1__ = {'BHHH': -227, 'BHHI': 316, 'BHIH': -132, 'BIHH': 60, 'BIII': 1595, 'BNHH': -744, 'BOHH': 225, 'BOOO': -908, 'OAKK': 482, 'OHHH': 281, 'OHIH': 249, 'OIHI': 200, 'OIIH': -68};
  this.TQ2__ = {'BIHH': -1401, 'BIII': -1033, 'BKAK': -543, 'BOOO': -5591};
  this.TQ3__ = {'BHHH': 478, 'BHHM': -1073, 'BHIH': 222, 'BHII': -504, 'BIIH': -116, 'BIII': -105, 'BMHI': -863, 'BMHM': -464, 'BOMH': 620, 'OHHH': 346, 'OHHI': 1729, 'OHII': 997, 'OHMH': 481, 'OIHH': 623, 'OIIH': 1344, 'OKAK': 2792, 'OKHH': 587, 'OKKA': 679, 'OOHH': 110, 'OOII': -685};
  this.TQ4__ = {'BHHH': -721, 'BHHM': -3604, 'BHII': -966, 'BIIH': -607, 'BIII': -2181, 'OAAA': -2763, 'OAKK': 180, 'OHHH': -294, 'OHHI': 2446, 'OHHO': 480, 'OHIH': -1573, 'OIHH': 1935, 'OIHI': -493, 'OIIH': 626, 'OIII': -4007, 'OKAK': -8156};
  this.TW1__ = {'につい': -4681, '東京都': 2026};
  this.TW2__ = {'ある程': -2049, 'いった': -1256, 'ころが': -2434, 'しょう': 3873, 'その後': -4430, 'だって': -1049, 'ていた': 1833, 'として': -4657, 'ともに': -4517, 'もので': 1882, '一気に': -792, '初めて': -1512, '同時に': -8097, '大きな': -1255, '対して': -2721, '社会党': -3216};
  this.TW3__ = {'いただ': -1734, 'してい': 1314, 'として': -4314, 'につい': -5483, 'にとっ': -5989, 'に当た': -6247, 'ので，': -727, 'ので、': -727, 'のもの': -600, 'れから': -3752, '十二月': -2287};
  this.TW4__ = {'いう．': 8576, 'いう。': 8576, 'からな': -2348, 'してい': 2958, 'たが，': 1516, 'たが、': 1516, 'ている': 1538, 'という': 1349, 'ました': 5543, 'ません': 1097, 'ようと': -4258, 'よると': 5865};
  this.UC1__ = {'A': 484, 'K': 93, 'M': 645, 'O': -505};
  this.UC2__ = {'A': 819, 'H': 1059, 'I': 409, 'M': 3987, 'N': 5775, 'O': 646};
  this.UC3__ = {'A': -1370, 'I': 2311};
  this.UC4__ = {'A': -2643, 'H': 1809, 'I': -1032, 'K': -3450, 'M': 3565, 'N': 3876, 'O': 6646};
  this.UC5__ = {'H': 313, 'I': -1238, 'K': -799, 'M': 539, 'O': -831};
  this.UC6__ = {'H': -506, 'I': -253, 'K': 87, 'M': 247, 'O': -387};
  this.UP1__ = {'O': -214};
  this.UP2__ = {'B': 69, 'O': 935};
  this.UP3__ = {'B': 189};
  this.UQ1__ = {'BH': 21, 'BI': -12, 'BK': -99, 'BN': 142, 'BO': -56, 'OH': -95, 'OI': 477, 'OK': 410, 'OO': -2422};
  this.UQ2__ = {'BH': 216, 'BI': 113, 'OK': 1759};
  this.UQ3__ = {'BA': -479, 'BH': 42, 'BI': 1913, 'BK': -7198, 'BM': 3160, 'BN': 6427, 'BO': 14761, 'OI': -827, 'ON': -3212};
  this.UW1__ = {'，': 156, '、': 156, '｢': -463, 'あ': -941, 'う': -127, 'が': -553, 'き': 121, 'こ': 505, 'で': -201, 'と': -547, 'ど': -123, 'に': -789, 'の': -185, 'は': -847, 'も': -466, 'や': -470, 'よ': 182, 'ら': -292, 'り': 208, 'れ': 169, 'を': -446, 'ん': -137, '・': -135, '主': -402, '京': -268, '区': -912, '午': 871, '国': -460, '大': 561, '委': 729, '市': -411, '日': -141, '理': 361, '生': -408, '県': -386, '都': -718};
  this.UW2__ = {'，': -829, '、': -829, '〇': 892, '｢': -645, '｣': 3145, 'あ': -538, 'い': 505, 'う': 134, 'お': -502, 'か': 1454, 'が': -856, 'く': -412, 'こ': 1141, 'さ': 878, 'ざ': 540, 'し': 1529, 'す': -675, 'せ': 300, 'そ': -1011, 'た': 188, 'だ': 1837, 'つ': -949, 'て': -291, 'で': -268, 'と': -981, 'ど': 1273, 'な': 1063, 'に': -1764, 'の': 130, 'は': -409, 'ひ': -1273, 'べ': 1261, 'ま': 600, 'も': -1263, 'や': -402, 'よ': 1639, 'り': -579, 'る': -694, 'れ': 571, 'を': -2516, 'ん': 2095, 'ア': -587, 'カ': 306, 'キ': 568, 'ッ': 831, '三': -758, '不': -2150, '世': -302, '中': -968, '主': -861, '事': 492, '人': -123, '会': 978, '保': 362, '入': 548, '初': -3025, '副': -1566, '北': -3414, '区': -422, '大': -1769, '天': -865, '太': -483, '子': -1519, '学': 760, '実': 1023, '小': -2009, '市': -813, '年': -1060, '強': 1067, '手': -1519, '揺': -1033, '政': 1522, '文': -1355, '新': -1682, '日': -1815, '明': -1462, '最': -630, '朝': -1843, '本': -1650, '東': -931, '果': -665, '次': -2378, '民': -180, '気': -1740, '理': 752, '発': 529, '目': -1584, '相': -242, '県': -1165, '立': -763, '第': 810, '米': 509, '自': -1353, '行': 838, '西': -744, '見': -3874, '調': 1010, '議': 1198, '込': 3041, '開': 1758, '間': -1257};
  this.UW3__ = {'1': -800, '，': 4889, '−': -1723, '、': 4889, '々': -2311, '〇': 5827, '｣': 2670, '〓': -3573, 'あ': -2696, 'い': 1006, 'う': 2342, 'え': 1983, 'お': -4864, 'か': -1163, 'が': 3271, 'く': 1004, 'け': 388, 'げ': 401, 'こ': -3552, 'ご': -3116, 'さ': -1058, 'し': -395, 'す': 584, 'せ': 3685, 'そ': -5228, 'た': 842, 'ち': -521, 'っ': -1444, 'つ': -1081, 'て': 6167, 'で': 2318, 'と': 1691, 'ど': -899, 'な': -2788, 'に': 2745, 'の': 4056, 'は': 4555, 'ひ': -2171, 'ふ': -1798, 'へ': 1199, 'ほ': -5516, 'ま': -4384, 'み': -120, 'め': 1205, 'も': 2323, 'や': -788, 'よ': -202, 'ら': 727, 'り': 649, 'る': 5905, 'れ': 2773, 'わ': -1207, 'を': 6620, 'ん': -518, 'ア': 551, 'グ': 1319, 'ス': 874, 'ッ': -1350, 'ト': 521, 'ム': 1109, 'ル': 1591, 'ロ': 2201, 'ン': 278, '・': -3794, '一': -1619, '下': -1759, '世': -2087, '両': 3815, '中': 653, '主': -758, '予': -1193, '二': 974, '人': 2742, '今': 792, '他': 1889, '以': -1368, '低': 811, '何': 4265, '作': -361, '保': -2439, '元': 4858, '党': 3593, '全': 1574, '公': -3030, '六': 755, '共': -1880, '円': 5807, '再': 3095, '分': 457, '初': 2475, '別': 1129, '前': 2286, '副': 4437, '力': 365, '動': -949, '務': -1872, '化': 1327, '北': -1038, '区': 4646, '千': -2309, '午': -783, '協': -1006, '口': 483, '右': 1233, '各': 3588, '合': -241, '同': 3906, '和': -837, '員': 4513, '国': 642, '型': 1389, '場': 1219, '外': -241, '妻': 2016, '学': -1356, '安': -423, '実': -1008, '家': 1078, '小': -513, '少': -3102, '州': 1155, '市': 3197, '平': -1804, '年': 2416, '広': -1030, '府': 1605, '度': 1452, '建': -2352, '当': -3885, '得': 1905, '思': -1291, '性': 1822, '戸': -488, '指': -3973, '政': -2013, '教': -1479, '数': 3222, '文': -1489, '新': 1764, '日': 2099, '旧': 5792, '昨': -661, '時': -1248, '曜': -951, '最': -937, '月': 4125, '期': 360, '李': 3094, '村': 364, '東': -805, '核': 5156, '森': 2438, '業': 484, '氏': 2613, '民': -1694, '決': -1073, '法': 1868, '海': -495, '無': 979, '物': 461, '特': -3850, '生': -273, '用': 914, '町': 1215, '的': 7313, '直': -1835, '省': 792, '県': 6293, '知': -1528, '私': 4231, '税': 401, '立': -960, '第': 1201, '米': 7767, '系': 3066, '約': 3663, '級': 1384, '統': -4229, '総': 1163, '線': 1255, '者': 6457, '能': 725, '自': -2869, '英': 785, '見': 1044, '調': -562, '財': -733, '費': 1777, '車': 1835, '軍': 1375, '込': -1504, '通': -1136, '選': -681, '郎': 1026, '郡': 4404, '部': 1200, '金': 2163, '長': 421, '開': -1432, '間': 1302, '関': -1282, '雨': 2009, '電': -1045, '非': 2066, '駅': 1620};
  this.UW4__ = {'，': 3930, '．': 3508, '―': -4841, '、': 3930, '。': 3508, '〇': 4999, '｢': 1895, '｣': 3798, '〓': -5156, 'あ': 4752, 'い': -3435, 'う': -640, 'え': -2514, 'お': 2405, 'か': 530, 'が': 6006, 'き': -4482, 'ぎ': -3821, 'く': -3788, 'け': -4376, 'げ': -4734, 'こ': 2255, 'ご': 1979, 'さ': 2864, 'し': -843, 'じ': -2506, 'す': -731, 'ず': 1251, 'せ': 181, 'そ': 4091, 'た': 5034, 'だ': 5408, 'ち': -3654, 'っ': -5882, 'つ': -1659, 'て': 3994, 'で': 7410, 'と': 4547, 'な': 5433, 'に': 6499, 'ぬ': 1853, 'ね': 1413, 'の': 7396, 'は': 8578, 'ば': 1940, 'ひ': 4249, 'び': -4134, 'ふ': 1345, 'へ': 6665, 'べ': -744, 'ほ': 1464, 'ま': 1051, 'み': -2082, 'む': -882, 'め': -5046, 'も': 4169, 'ゃ': -2666, 'や': 2795, 'ょ': -1544, 'よ': 3351, 'ら': -2922, 'り': -9726, 'る': -14896, 'れ': -2613, 'ろ': -4570, 'わ': -1783, 'を': 13150, 'ん': -2352, 'カ': 2145, 'コ': 1789, 'セ': 1287, 'ッ': -724, 'ト': -403, 'メ': -1635, 'ラ': -881, 'リ': -541, 'ル': -856, 'ン': -3637, '・': -4371, 'ー': -11870, '一': -2069, '中': 2210, '予': 782, '事': -190, '井': -1768, '人': 1036, '以': 544, '会': 950, '体': -1286, '作': 530, '側': 4292, '先': 601, '党': -2006, '共': -1212, '内': 584, '円': 788, '初': 1347, '前': 1623, '副': 3879, '力': -302, '動': -740, '務': -2715, '化': 776, '区': 4517, '協': 1013, '参': 1555, '合': -1834, '和': -681, '員': -910, '器': -851, '回': 1500, '国': -619, '園': -1200, '地': 866, '場': -1410, '塁': -2094, '士': -1413, '多': 1067, '大': 571, '子': -4802, '学': -1397, '定': -1057, '寺': -809, '小': 1910, '屋': -1328, '山': -1500, '島': -2056, '川': -2667, '市': 2771, '年': 374, '庁': -4556, '後': 456, '性': 553, '感': 916, '所': -1566, '支': 856, '改': 787, '政': 2182, '教': 704, '文': 522, '方': -856, '日': 1798, '時': 1829, '最': 845, '月': -9066, '木': -485, '来': -442, '校': -360, '業': -1043, '氏': 5388, '民': -2716, '気': -910, '沢': -939, '済': -543, '物': -735, '率': 672, '球': -1267, '生': -1286, '産': -1101, '田': -2900, '町': 1826, '的': 2586, '目': 922, '省': -3485, '県': 2997, '空': -867, '立': -2112, '第': 788, '米': 2937, '系': 786, '約': 2171, '経': 1146, '統': -1169, '総': 940, '線': -994, '署': 749, '者': 2145, '能': -730, '般': -852, '行': -792, '規': 792, '警': -1184, '議': -244, '谷': -1000, '賞': 730, '車': -1481, '軍': 1158, '輪': -1433, '込': -3370, '近': 929, '道': -1291, '選': 2596, '郎': -4866, '都': 1192, '野': -1100, '銀': -2213, '長': 357, '間': -2344, '院': -2297, '際': -2604, '電': -878, '領': -1659, '題': -792, '館': -1984, '首': 1749, '高': 2120};
  this.UW5__ = {'1': -514, '，': 465, '．': -299, 'E2': -32768, '］': -2762, '、': 465, '。': -299, '｢': 363, 'あ': 1655, 'い': 331, 'う': -503, 'え': 1199, 'お': 527, 'か': 647, 'が': -421, 'き': 1624, 'ぎ': 1971, 'く': 312, 'げ': -983, 'さ': -1537, 'し': -1371, 'す': -852, 'だ': -1186, 'ち': 1093, 'っ': 52, 'つ': 921, 'て': -18, 'で': -850, 'と': -127, 'ど': 1682, 'な': -787, 'に': -1224, 'の': -635, 'は': -578, 'べ': 1001, 'み': 502, 'め': 865, 'ゃ': 3350, 'ょ': 854, 'り': -208, 'る': 429, 'れ': 504, 'わ': 419, 'を': -1264, 'ん': 327, 'イ': 241, 'ル': 451, 'ン': -343, '中': -871, '京': 722, '会': -1153, '党': -654, '務': 3519, '区': -901, '告': 848, '員': 2104, '大': -1296, '学': -548, '定': 1785, '嵐': -1304, '市': -2991, '席': 921, '年': 1763, '思': 872, '所': -814, '挙': 1618, '新': -1682, '日': 218, '月': -4353, '査': 932, '格': 1356, '機': -1508, '氏': -1347, '田': 240, '町': -3912, '的': -3149, '相': 1319, '省': -1052, '県': -4003, '研': -997, '社': -278, '空': -813, '統': 1955, '者': -2233, '表': 663, '語': -1073, '議': 1219, '選': -1018, '郎': -368, '長': 786, '間': 1191, '題': 2368, '館': -689};
  this.UW6__ = {'1': -270, '，': 227, '．': 808, 'E1': 306, '、': 227, '。': 808, 'あ': -307, 'う': 189, 'か': 241, 'が': -73, 'く': -121, 'こ': -200, 'じ': 1782, 'す': 383, 'た': -428, 'っ': 573, 'て': -1014, 'で': 101, 'と': -105, 'な': -253, 'に': -149, 'の': -417, 'は': -236, 'も': -206, 'り': 187, 'る': -135, 'を': 195, 'ル': -673, 'ン': -496, '一': -277, '中': 201, '件': -800, '会': 624, '前': 302, '区': 1792, '員': -1212, '委': 798, '学': -960, '市': 887, '広': -695, '後': 535, '業': -697, '相': 753, '社': -507, '福': 974, '空': -822, '者': 1811, '連': 463, '郎': 1082};

  return this;
};

util.inherits(TokenizerJa, Tokenizer);


/**
 * @param {string} str
 * @return {string}
 * @private
 */
TokenizerJa.prototype.ctype_ = function(str) {
  for (var i = 0, length = this.chartype_.length; i < length; i++) {
    if (str.match(this.chartype_[i][0])) {
      return this.chartype_[i][1];
    }
  }
  return 'O';
};


/**
 * @param {string} v
 * @return {number}
 * @private
 */
TokenizerJa.prototype.ts_ = function(v) {
  if (v) { return v; }
  return 0;
};


/**
 * Remove punctuations signs from tokens.
 *
 * @param {Array.<string>} tokens An array of tokens.
 * @return {Array.<string>} An array of tokens.
 * @private
 */
TokenizerJa.prototype.removePuncTokens = function(tokens) {
  return tokens
      .map(function(token) {
        return token.replace(/[＿－・，、；：！？．。（）［］｛｝｢｣＠＊＼／＆＃％｀＾＋＜＝＞｜～≪≫─＄＂_\-･,､;:!?.｡()[\]{}「」@*\/&#%`^+<=>|~«»$"\s]+/g, '');
      })
      .filter(function(token) {
        return token != '';
      });
};


/**
 * @param {string} text
 * @return {Array.<string>}
 */
TokenizerJa.prototype.tokenize = function(text) {
  if (text == null || text == undefined || text == '') {
    return [];
  }
  text = normalize(text);
  var result = [];
  var seg = ['B3', 'B2', 'B1'];
  var ctype = ['O', 'O', 'O'];
  var o = text.split('');
  var i;
  var length;
  for (i = 0, length = o.length; i < length; ++i) {
    seg.push(o[i]);
    ctype.push(this.ctype_(o[i]));
  }
  seg.push('E1');
  seg.push('E2');
  seg.push('E3');
  ctype.push('O');
  ctype.push('O');
  ctype.push('O');
  var word = seg[3];
  var p1 = 'U';
  var p2 = 'U';
  var p3 = 'U';
  for (i = 4, length = seg.length - 3; i < length; ++i) {
    var score = this.BIAS__;
    var w1 = seg[i - 3];
    var w2 = seg[i - 2];
    var w3 = seg[i - 1];
    var w4 = seg[i];
    var w5 = seg[i + 1];
    var w6 = seg[i + 2];
    var c1 = ctype[i - 3];
    var c2 = ctype[i - 2];
    var c3 = ctype[i - 1];
    var c4 = ctype[i];
    var c5 = ctype[i + 1];
    var c6 = ctype[i + 2];
    score += this.ts_(this.UP1__[p1]);
    score += this.ts_(this.UP2__[p2]);
    score += this.ts_(this.UP3__[p3]);
    score += this.ts_(this.BP1__[p1 + p2]);
    score += this.ts_(this.BP2__[p2 + p3]);
    score += this.ts_(this.UW1__[w1]);
    score += this.ts_(this.UW2__[w2]);
    score += this.ts_(this.UW3__[w3]);
    score += this.ts_(this.UW4__[w4]);
    score += this.ts_(this.UW5__[w5]);
    score += this.ts_(this.UW6__[w6]);
    score += this.ts_(this.BW1__[w2 + w3]);
    score += this.ts_(this.BW2__[w3 + w4]);
    score += this.ts_(this.BW3__[w4 + w5]);
    score += this.ts_(this.TW1__[w1 + w2 + w3]);
    score += this.ts_(this.TW2__[w2 + w3 + w4]);
    score += this.ts_(this.TW3__[w3 + w4 + w5]);
    score += this.ts_(this.TW4__[w4 + w5 + w6]);
    score += this.ts_(this.UC1__[c1]);
    score += this.ts_(this.UC2__[c2]);
    score += this.ts_(this.UC3__[c3]);
    score += this.ts_(this.UC4__[c4]);
    score += this.ts_(this.UC5__[c5]);
    score += this.ts_(this.UC6__[c6]);
    score += this.ts_(this.BC1__[c2 + c3]);
    score += this.ts_(this.BC2__[c3 + c4]);
    score += this.ts_(this.BC3__[c4 + c5]);
    score += this.ts_(this.TC1__[c1 + c2 + c3]);
    score += this.ts_(this.TC2__[c2 + c3 + c4]);
    score += this.ts_(this.TC3__[c3 + c4 + c5]);
    score += this.ts_(this.TC4__[c4 + c5 + c6]);
    //score += this.ts_(this.TC5__[c4 + c5 + c6]);
    score += this.ts_(this.UQ1__[p1 + c1]);
    score += this.ts_(this.UQ2__[p2 + c2]);
    score += this.ts_(this.UQ3__[p3 + c3]);
    score += this.ts_(this.BQ1__[p2 + c2 + c3]);
    score += this.ts_(this.BQ2__[p2 + c3 + c4]);
    score += this.ts_(this.BQ3__[p3 + c2 + c3]);
    score += this.ts_(this.BQ4__[p3 + c3 + c4]);
    score += this.ts_(this.TQ1__[p2 + c1 + c2 + c3]);
    score += this.ts_(this.TQ2__[p2 + c2 + c3 + c4]);
    score += this.ts_(this.TQ3__[p3 + c1 + c2 + c3]);
    score += this.ts_(this.TQ4__[p3 + c2 + c3 + c4]);
    var p = 'O';
    if (score > 0) {
      result.push(word);
      word = '';
      p = 'B';
    }
    p1 = p2;
    p2 = p3;
    p3 = p;
    word += seg[i];
  }
  result.push(word);

  result = this.removePuncTokens(result);

  return result;
};

module.exports = TokenizerJa;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\treebank_word_tokenizer.js":
/*!************************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/tokenizers/treebank_word_tokenizer.js ***!
  \************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Rob Ellis, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var Tokenizer = __webpack_require__(/*! ./tokenizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\tokenizers\\tokenizer.js"),
    util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._;

var contractions2 = [
    /(.)('ll|'re|'ve|n't|'s|'m|'d)\b/ig,
    /\b(can)(not)\b/ig,
    /\b(D)('ye)\b/ig,
    /\b(Gim)(me)\b/ig,
    /\b(Gon)(na)\b/ig,
    /\b(Got)(ta)\b/ig,
    /\b(Lem)(me)\b/ig,
    /\b(Mor)('n)\b/ig,
    /\b(T)(is)\b/ig,
    /\b(T)(was)\b/ig,
    /\b(Wan)(na)\b/ig];

var contractions3 = [
    /\b(Whad)(dd)(ya)\b/ig,
    /\b(Wha)(t)(cha)\b/ig
];

var TreebankWordTokenizer = function() {
};

util.inherits(TreebankWordTokenizer, Tokenizer);

TreebankWordTokenizer.prototype.tokenize = function(text) {
    contractions2.forEach(function(regexp) {
	text = text.replace(regexp,"$1 $2");
    });
    
    contractions3.forEach(function(regexp) {
	text = text.replace(regexp,"$1 $2 $3");
    });

    // most punctuation
    text = text.replace(/([^\w\.\'\-\/\+\<\>,&])/g, " $1 ");

    // commas if followed by space
    text = text.replace(/(,\s)/g, " $1");

    // single quotes if followed by a space
    text = text.replace(/('\s)/g, " $1");

    // periods before newline or end of string
    text = text.replace(/\. *(\n|$)/g, " . ");
    
    return  _.without(text.split(/\s+/), '');	
};

module.exports = TreebankWordTokenizer;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\transliterators\\ja\\index.js":
/*!**************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/transliterators/ja/index.js ***!
  \**************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
 Copyright (c) 2012, Guillaume Marty

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

/**
 * A transliteration of Katakana & Hiragana to roman characters using the
 * modified Hepburn system.
 * Rules based on CLDR transform rule set `Katakana-Latin-BGN.xml` but with
 * several bugs fixed:
 *  * Missing ū
 *  * Missing tsu + voiced kana
 *  * typos on my~ transliterations
 *  * support for long vowel sign
 *  * support for final small tsu
 *  * support for u + small vowels
 *  * support for su/shi/ji + small vowels
 *  * support for tchi/tsu/te/to + small vowels
 *  * support for fu + small vowels
 *  * support for katakana middle dot
 *
 * \@todo Take iteration marks into account.
 */

var replacer = __webpack_require__(/*! ../../util/utils */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\utils.js").replacer;

var transliterationTable1 = {
  'ウァ': 'wa', // KATAKANA LETTER U + SMALL A
  'ウィ': 'wi', // KATAKANA LETTER U + SMALL I
  'ウェ': 'we', // KATAKANA LETTER U + SMALL E
  'ウォ': 'wo', // KATAKANA LETTER U + SMALL O
  'ウー': 'ū', // KATAKANA LETTER VU + PROLONGED SOUND MARK

  'ヴァ': 'va', // KATAKANA LETTER VU + SMALL A
  'ヴィ': 'vi', // KATAKANA LETTER VU + SMALL I
  'ヴェ': 've', // KATAKANA LETTER VU + SMALL E
  'ヴォ': 'vo', // KATAKANA LETTER VU + SMALL O
  'ヴュ': 'vyu', // KATAKANA LETTER VU + SMALL YU

  'うぁ': 'wa', // HIRAGANA LETTER U + SMALL A
  'うぃ': 'wi', // HIRAGANA LETTER U + SMALL I
  'うぇ': 'we', // HIRAGANA LETTER U + SMALL E
  'うぉ': 'wo', // HIRAGANA LETTER U + SMALL O
  'うー': 'ū', // HIRAGANA LETTER VU + PROLONGED SOUND MARK

  'ゔぁ': 'va', // HIRAGANA LETTER VU + SMALL A
  'ゔぃ': 'vi', // HIRAGANA LETTER VU + SMALL I
  'ゔぇ': 've', // HIRAGANA LETTER VU + SMALL E
  'ゔぉ': 'vo', // HIRAGANA LETTER VU + SMALL O
  'ゔゅ': 'vyu' // HIRAGANA LETTER VU + SMALL YU
};

var transliterationTable2 = {
  'イェ': 'ye', // KATAKANA LETTER I + SMALL E

  'ア': 'a', // KATAKANA LETTER A
  'イ': 'i', // KATAKANA LETTER I
  'ウウ': 'ū', // KATAKANA LETTER U + U
  'ウ': 'u', // KATAKANA LETTER U
  'エ': 'e', // KATAKANA LETTER E
  'オウ': 'ō', // KATAKANA LETTER O + U
  'オ': 'o', // KATAKANA LETTER O

  'クァ': 'kwa', // KATAKANA LETTER KU + SMALL A
  'クィ': 'kwi', // KATAKANA LETTER KU + SMALL I
  'クェ': 'kwe', // KATAKANA LETTER KU + SMALL E
  'クォ': 'kwo', // KATAKANA LETTER KU + SMALL O

  'カ': 'ka', // KATAKANA LETTER KA
  'キョウ': 'kyō', // KATAKANA LETTER KI + SMALL YO + U
  'キュウ': 'kyū', // KATAKANA LETTER KI + SMALL YU + U
  'キャ': 'kya', // KATAKANA LETTER KI + SMALL YA
  'キョ': 'kyo', // KATAKANA LETTER KI + SMALL YO
  'キュ': 'kyu', // KATAKANA LETTER KI + SMALL YU
  'キ': 'ki', // KATAKANA LETTER KI
  'ク': 'ku', // KATAKANA LETTER KU
  'ケ': 'ke', // KATAKANA LETTER KE
  'コウ': 'kō', // KATAKANA LETTER KO + U
  'コ': 'ko', // KATAKANA LETTER KO

  'シェ': 'she', // KATAKANA LETTER SI + SMALL E
  'スィ': 'si', // KATAKANA LETTER SU + SMALL I

  'サ': 'sa', // KATAKANA LETTER SA
  'ショウ': 'shō', // KATAKANA LETTER SI + SMALL YO + U
  'シュウ': 'shū', // KATAKANA LETTER SI + SMALL YU + U
  'シャ': 'sha', // KATAKANA LETTER SI + SMALL YA
  'ショ': 'sho', // KATAKANA LETTER SI + SMALL YO
  'シュ': 'shu', // KATAKANA LETTER SI + SMALL YU
  'シ': 'shi', // KATAKANA LETTER SI
  'スウ': 'sū', // KATAKANA LETTER SU + U
  'ス': 'su', // KATAKANA LETTER SU
  'セ': 'se', // KATAKANA LETTER SE
  'ソウ': 'sō', // KATAKANA LETTER SO + U
  'ソ': 'so', // KATAKANA LETTER SO

  'チェ': 'che', // KATAKANA LETTER TI + SMALL E
  'ツァ': 'tsa', // KATAKANA LETTER TU + SMALL A
  'ツィ': 'tsi', // KATAKANA LETTER TU + SMALL I
  'ツェ': 'tse', // KATAKANA LETTER TU + SMALL E
  'ツォ': 'tso', // KATAKANA LETTER TU + SMALL O
  'ティ': 'ti', // KATAKANA LETTER TE + SMALL I
  'ディ': 'di', // KATAKANA LETTER DE + SMALL I
  'テュ': 'tyu', // KATAKANA LETTER TE + SMALL YU
  'デュ': 'dyu', // KATAKANA LETTER DE + SMALL YU
  'トィ': 'twi', // KATAKANA LETTER TO + SMALL I
  'トゥ': 'tu', // KATAKANA LETTER TO + SMALL U
  'ドィ': 'dwi', // KATAKANA LETTER DO + SMALL I
  'ドゥ': 'du', // KATAKANA LETTER DO + SMALL U

  'タ': 'ta', // KATAKANA LETTER TA
  'チョウ': 'chō', // KATAKANA LETTER TI + SMALL YO + U
  'チュウ': 'chū', // KATAKANA LETTER TI + SMALL YU + U
  'チャ': 'cha', // KATAKANA LETTER TI + SMALL YA
  'チョ': 'cho', // KATAKANA LETTER TI + SMALL YO
  'チュ': 'chu', // KATAKANA LETTER TI + SMALL YU
  'チ': 'chi', // KATAKANA LETTER TI
  'ツウ': 'tsū', // KATAKANA LETTER TU + U
  'ツ': 'tsu', // KATAKANA LETTER TU
  'テ': 'te', // KATAKANA LETTER TE
  'トウ': 'tō', // KATAKANA LETTER TO + U
  'ト': 'to', // KATAKANA LETTER TO

  'ナ': 'na', // KATAKANA LETTER NA
  'ニョウ': 'nyō', // KATAKANA LETTER NI + SMALL YO + U
  'ニュウ': 'nyū', // KATAKANA LETTER NI + SMALL YU + U
  'ニャ': 'nya', // KATAKANA LETTER NI + SMALL YA
  'ニョ': 'nyo', // KATAKANA LETTER NI + SMALL YO
  'ニュ': 'nyu', // KATAKANA LETTER NI + SMALL YU
  'ニ': 'ni', // KATAKANA LETTER NI
  'ヌウ': 'nū', // KATAKANA LETTER NU + U
  'ヌ': 'nu', // KATAKANA LETTER NU
  'ネ': 'ne', // KATAKANA LETTER NE
  'ノウ': 'nō', // KATAKANA LETTER NO + U
  'ノ': 'no', // KATAKANA LETTER NO

  'ファ': 'fa', // KATAKANA LETTER HU + SMALL A
  'フィ': 'fi', // KATAKANA LETTER HU + SMALL I
  //'フゥ': 'fu', // KATAKANA LETTER HU + SMALL U
  'フェ': 'fe', // KATAKANA LETTER HU + SMALL E
  'フォ': 'fo', // KATAKANA LETTER HU + SMALL O
  'フュ': 'fyu', // KATAKANA LETTER HU + SMALL YU
  'ホェ': 'hwe', // KATAKANA LETTER HO + SMALL E

  'ハ': 'ha', // KATAKANA LETTER HA
  'ヒョウ': 'hyō', // KATAKANA LETTER HI + SMALL YO + U
  'ヒュウ': 'hyū', // KATAKANA LETTER HI + SMALL YU + U
  'ヒャ': 'hya', // KATAKANA LETTER HI + SMALL YA
  'ヒョ': 'hyo', // KATAKANA LETTER HI + SMALL YO
  'ヒュ': 'hyu', // KATAKANA LETTER HI + SMALL YU
  'ヒ': 'hi', // KATAKANA LETTER HI
  'フウ': 'fū', // KATAKANA LETTER HU + U
  'フ': 'fu', // KATAKANA LETTER HU
  'ヘ': 'he', // KATAKANA LETTER HE
  'ホウ': 'hō', // KATAKANA LETTER HO + U
  'ホ': 'ho', // KATAKANA LETTER HO

  'マ': 'ma', // KATAKANA LETTER MA
  'ミョウ': 'myō', // KATAKANA LETTER MI + SMALL YO + U
  'ミュウ': 'myū', // KATAKANA LETTER MI + SMALL YU + U
  'ミャ': 'mya', // KATAKANA LETTER MI + SMALL YA
  'ミョ': 'myo', // KATAKANA LETTER MI + SMALL YO
  'ミュ': 'myu', // KATAKANA LETTER MI + SMALL YU
  'ミ': 'mi', // KATAKANA LETTER MI
  'ムウ': 'mū', // KATAKANA LETTER MU + U
  'ム': 'mu', // KATAKANA LETTER MU
  'メ': 'me', // KATAKANA LETTER ME
  'モウ': 'mō', // KATAKANA LETTER MO + U
  'モ': 'mo', // KATAKANA LETTER MO

  'ヤ': 'ya', // KATAKANA LETTER YA
  'ユウ': 'yū', // KATAKANA LETTER YU + U
  'ユ': 'yu', // KATAKANA LETTER YU
  'ヨウ': 'yō', // KATAKANA LETTER YO + U
  'ヨ': 'yo', // KATAKANA LETTER YO

  'リェ': 'rye', // KATAKANA LETTER RI + SMALL E

  'ラ': 'ra', // KATAKANA LETTER RA
  'リョウ': 'ryō', // KATAKANA LETTER RI + SMALL YO + U
  'リュウ': 'ryū', // KATAKANA LETTER RI + SMALL YU + U
  'リャ': 'rya', // KATAKANA LETTER RI + SMALL YA
  'リョ': 'ryo', // KATAKANA LETTER RI + SMALL YO
  'リュ': 'ryu', // KATAKANA LETTER RI + SMALL YU
  'リ': 'ri', // KATAKANA LETTER RI
  'ルウ': 'rū', // KATAKANA LETTER RU + U
  'ル': 'ru', // KATAKANA LETTER RU
  'レ': 're', // KATAKANA LETTER RE
  'ロウ': 'rō', // KATAKANA LETTER RO + U
  'ロ': 'ro', // KATAKANA LETTER RO

  'ワ': 'wa', // KATAKANA LETTER WA
  'ヰ': 'i', // KATAKANA LETTER WI
  'ヱ': 'e', // KATAKANA LETTER WE
  'ヲ': 'o', // KATAKANA LETTER WO

  'ン': 'n', // KATAKANA LETTER N

  'グァ': 'gwa', // KATAKANA LETTER GU + SMALL A
  'グィ': 'gwi', // KATAKANA LETTER GU + SMALL I
  'グェ': 'gwe', // KATAKANA LETTER GU + SMALL E
  'グォ': 'gwo', // KATAKANA LETTER GU + SMALL O

  'ガ': 'ga', // KATAKANA LETTER GA
  'ギョウ': 'gyō', // KATAKANA LETTER GI + SMALL YO + U
  'ギュウ': 'gyū', // KATAKANA LETTER GI + SMALL YU + U
  'ギャ': 'gya', // KATAKANA LETTER GI + SMALL YA
  'ギョ': 'gyo', // KATAKANA LETTER GI + SMALL YO
  'ギュ': 'gyu', // KATAKANA LETTER GI + SMALL YU
  'ギ': 'gi', // KATAKANA LETTER GI
  'グウ': 'gū', // KATAKANA LETTER GU + U
  'グ': 'gu', // KATAKANA LETTER GU
  'ゲ': 'ge', // KATAKANA LETTER GE
  'ゴウ': 'gō', // KATAKANA LETTER GO + U
  'ゴ': 'go', // KATAKANA LETTER GO

  'ジェ': 'je', // KATAKANA LETTER ZI + SMALL E
  'ズィ': 'zi', // KATAKANA LETTER ZU + SMALL I

  'ザ': 'za', // KATAKANA LETTER ZA
  'ジョウ': 'jō', // KATAKANA LETTER ZI + SMALL YO + U
  'ジュウ': 'jū', // KATAKANA LETTER ZI + SMALL YU + U
  'ジャ': 'ja', // KATAKANA LETTER ZI + SMALL YA
  'ジョ': 'jo', // KATAKANA LETTER ZI + SMALL YO
  'ジュ': 'ju', // KATAKANA LETTER ZI + SMALL YU
  'ジ': 'ji', // KATAKANA LETTER ZI
  'ズウ': 'zū', // KATAKANA LETTER ZU + U
  'ズ': 'zu', // KATAKANA LETTER ZU
  'ゼ': 'ze', // KATAKANA LETTER ZE
  'ゾウ': 'zō', // KATAKANA LETTER ZO + U
  'ゾ': 'zo', // KATAKANA LETTER ZO

  'ダ': 'da', // KATAKANA LETTER DA
  'ヂ': 'ji', // KATAKANA LETTER DI
  'ヅウ': 'zū', // KATAKANA LETTER DU + U
  'ヅ': 'zu', // KATAKANA LETTER DU
  'デ': 'de', // KATAKANA LETTER DE
  'ドウ': 'dō', // KATAKANA LETTER DO + U
  'ド': 'do', // KATAKANA LETTER DO

  'ブュ': 'byu', // KATAKANA LETTER BU + SMALL YU

  'バ': 'ba', // KATAKANA LETTER BA
  'ビョウ': 'byō', // KATAKANA LETTER BI + SMALL YO + U
  'ビュウ': 'byū', // KATAKANA LETTER BI + SMALL YU + U
  'ビャ': 'bya', // KATAKANA LETTER BI + SMALL YA
  'ビョ': 'byo', // KATAKANA LETTER BI + SMALL YO
  'ビュ': 'byu', // KATAKANA LETTER BI + SMALL YU
  'ビ': 'bi', // KATAKANA LETTER BI
  'ブウ': 'bū', // KATAKANA LETTER BU + U
  'ブ': 'bu', // KATAKANA LETTER BU
  'ベ': 'be', // KATAKANA LETTER BE
  'ボウ': 'bō', // KATAKANA LETTER BO + U
  'ボ': 'bo', // KATAKANA LETTER BO

  'パ': 'pa', // KATAKANA LETTER PA
  'ピョウ': 'pyō', // KATAKANA LETTER PI + SMALL YO + U
  'ピュウ': 'pyū', // KATAKANA LETTER PI + SMALL YU + U
  'ピャ': 'pya', // KATAKANA LETTER PI + SMALL YA
  'ピョ': 'pyo', // KATAKANA LETTER PI + SMALL YO
  'ピュ': 'pyu', // KATAKANA LETTER PI + SMALL YU
  'ピ': 'pi', // KATAKANA LETTER PI
  'プウ': 'pū', // KATAKANA LETTER PU + U
  'プ': 'pu', // KATAKANA LETTER PU
  'ペ': 'pe', // KATAKANA LETTER PE
  'ポウ': 'pō', // KATAKANA LETTER PO + U
  'ポ': 'po', // KATAKANA LETTER PO

  'ヴ': 'v', // KATAKANA LETTER VU

  '・': ' ', // KATAKANA MIDDLE DOT

  'いぇ': 'ye', // HIRAGANA LETTER I + SMALL E

  'あ': 'a', // HIRAGANA LETTER A
  'い': 'i', // HIRAGANA LETTER I
  'うう': 'ū', // HIRAGANA LETTER U + U
  'う': 'u', // HIRAGANA LETTER U
  'え': 'e', // HIRAGANA LETTER E
  'おう': 'ō', // HIRAGANA LETTER O + U
  'お': 'o', // HIRAGANA LETTER O

  'くぁ': 'kwa', // HIRAGANA LETTER KU + SMALL A
  'くぃ': 'kwi', // HIRAGANA LETTER KU + SMALL I
  'くぇ': 'kwe', // HIRAGANA LETTER KU + SMALL E
  'くぉ': 'kwo', // HIRAGANA LETTER KU + SMALL O

  'か': 'ka', // HIRAGANA LETTER KA
  'きょう': 'kyō', // HIRAGANA LETTER KI + SMALL YO + U
  'きゅう': 'kyū', // HIRAGANA LETTER KI + SMALL YU + U
  'きゃ': 'kya', // HIRAGANA LETTER KI + SMALL YA
  'きょ': 'kyo', // HIRAGANA LETTER KI + SMALL YO
  'きゅ': 'kyu', // HIRAGANA LETTER KI + SMALL YU
  'き': 'ki', // HIRAGANA LETTER KI
  'くう': 'kū', // HIRAGANA LETTER KU + U
  'く': 'ku', // HIRAGANA LETTER KU
  'け': 'ke', // HIRAGANA LETTER KE
  'こう': 'kō', // HIRAGANA LETTER KO + U
  'こ': 'ko', // HIRAGANA LETTER KO

  'しぇ': 'she', // HIRAGANA LETTER SI + SMALL E
  'すぃ': 'si', // HIRAGANA LETTER SU + SMALL I

  'さ': 'sa', // HIRAGANA LETTER SA
  'しょう': 'shō', // HIRAGANA LETTER SI + SMALL YO + U
  'しゅう': 'shū', // HIRAGANA LETTER SI + SMALL YU + U
  'しゃ': 'sha', // HIRAGANA LETTER SI + SMALL YA
  'しょ': 'sho', // HIRAGANA LETTER SI + SMALL YO
  'しゅ': 'shu', // HIRAGANA LETTER SI + SMALL YU
  'し': 'shi', // HIRAGANA LETTER SI
  'すう': 'sū', // HIRAGANA LETTER SU + U
  'す': 'su', // HIRAGANA LETTER SU
  'せ': 'se', // HIRAGANA LETTER SE
  'そう': 'sō', // HIRAGANA LETTER SO + U
  'そ': 'so', // HIRAGANA LETTER SO

  'ちぇ': 'che', // HIRAGANA LETTER TI + SMALL E
  'つぁ': 'tsa', // HIRAGANA LETTER TU + SMALL A
  'つぃ': 'tsi', // HIRAGANA LETTER TU + SMALL I
  'つぇ': 'tse', // HIRAGANA LETTER TU + SMALL E
  'つぉ': 'tso', // HIRAGANA LETTER TU + SMALL O
  'てぃ': 'ti', // HIRAGANA LETTER TE + SMALL I
  'でぃ': 'di', // HIRAGANA LETTER DE + SMALL I
  'てゅ': 'tyu', // HIRAGANA LETTER TE + SMALL YU
  'でゅ': 'dyu', // HIRAGANA LETTER DE + SMALL YU
  'とぃ': 'twi', // HIRAGANA LETTER TO + SMALL I
  'とぅ': 'tu', // HIRAGANA LETTER TO + SMALL U
  'どぃ': 'dwi', // HIRAGANA LETTER DO + SMALL I
  'どぅ': 'du', // HIRAGANA LETTER DO + SMALL U

  'た': 'ta', // HIRAGANA LETTER TA
  'ちょう': 'chō', // HIRAGANA LETTER TI + SMALL YO + U
  'ちゅう': 'chū', // HIRAGANA LETTER TI + SMALL YU + U
  'ちゃ': 'cha', // HIRAGANA LETTER TI + SMALL YA
  'ちょ': 'cho', // HIRAGANA LETTER TI + SMALL YO
  'ちゅ': 'chu', // HIRAGANA LETTER TI + SMALL YU
  'ち': 'chi', // HIRAGANA LETTER TI
  'つう': 'tsū', // HIRAGANA LETTER TU + U
  'つ': 'tsu', // HIRAGANA LETTER TU
  'て': 'te', // HIRAGANA LETTER TE
  'とう': 'tō', // HIRAGANA LETTER TO + U
  'と': 'to', // HIRAGANA LETTER TO

  'な': 'na', // HIRAGANA LETTER NA
  'にょう': 'nyō', // HIRAGANA LETTER NI + SMALL YO + U
  'にゅう': 'nyū', // HIRAGANA LETTER NI + SMALL YU + U
  'にゃ': 'nya', // HIRAGANA LETTER NI + SMALL YA
  'にょ': 'nyo', // HIRAGANA LETTER NI + SMALL YO
  'にゅ': 'nyu', // HIRAGANA LETTER NI + SMALL YU
  'に': 'ni', // HIRAGANA LETTER NI
  'ぬう': 'nū', // HIRAGANA LETTER NU + U
  'ぬ': 'nu', // HIRAGANA LETTER NU
  'ね': 'ne', // HIRAGANA LETTER NE
  'のう': 'nō', // HIRAGANA LETTER NO + U
  'の': 'no', // HIRAGANA LETTER NO

  'ふぁ': 'fa', // HIRAGANA LETTER HU + SMALL A
  'ふぃ': 'fi', // HIRAGANA LETTER HU + SMALL I
  //'ふぅ': 'fu', // HIRAGANA LETTER HU + SMALL U
  'ふぇ': 'fe', // HIRAGANA LETTER HU + SMALL E
  'ふぉ': 'fo', // HIRAGANA LETTER HU + SMALL O
  'ふゅ': 'fyu', // HIRAGANA LETTER HU + SMALL YU
  'ほぇ': 'hwe', // HIRAGANA LETTER HO + SMALL E

  'は': 'ha', // HIRAGANA LETTER HA
  'ひょう': 'hyō', // HIRAGANA LETTER HI + SMALL YO + U
  'ひゅう': 'hyū', // HIRAGANA LETTER HI + SMALL YU + U
  'ひゃ': 'hya', // HIRAGANA LETTER HI + SMALL YA
  'ひょ': 'hyo', // HIRAGANA LETTER HI + SMALL YO
  'ひゅ': 'hyu', // HIRAGANA LETTER HI + SMALL YU
  'ひ': 'hi', // HIRAGANA LETTER HI
  'ふう': 'fū', // HIRAGANA LETTER HU + U
  'ふ': 'fu', // HIRAGANA LETTER HU
  'へ': 'he', // HIRAGANA LETTER HE
  'ほう': 'hō', // HIRAGANA LETTER HO + U
  'ほ': 'ho', // HIRAGANA LETTER HO

  'ま': 'ma', // HIRAGANA LETTER MA
  'みょう': 'myō', // HIRAGANA LETTER MI + SMALL YO + U
  'みゅう': 'myū', // HIRAGANA LETTER MI + SMALL YU + U
  'みゃ': 'mya', // HIRAGANA LETTER MI + SMALL YA
  'みょ': 'myo', // HIRAGANA LETTER MI + SMALL YO
  'みゅ': 'myu', // HIRAGANA LETTER MI + SMALL YU
  'み': 'mi', // HIRAGANA LETTER MI
  'むう': 'mū', // HIRAGANA LETTER MU + U
  'む': 'mu', // HIRAGANA LETTER MU
  'め': 'me', // HIRAGANA LETTER ME
  'もう': 'mō', // HIRAGANA LETTER MO + U
  'も': 'mo', // HIRAGANA LETTER MO

  'や': 'ya', // HIRAGANA LETTER YA
  'ゆう': 'yū', // HIRAGANA LETTER YU + U
  'ゆ': 'yu', // HIRAGANA LETTER YU
  'よう': 'yō', // HIRAGANA LETTER YO + U
  'よ': 'yo', // HIRAGANA LETTER YO

  'りぇ': 'rye', // HIRAGANA LETTER RI + SMALL E

  'ら': 'ra', // HIRAGANA LETTER RA
  'りょう': 'ryō', // HIRAGANA LETTER RI + SMALL YO + U
  'りゅう': 'ryū', // HIRAGANA LETTER RI + SMALL YU + U
  'りゃ': 'rya', // HIRAGANA LETTER RI + SMALL YA
  'りょ': 'ryo', // HIRAGANA LETTER RI + SMALL YO
  'りゅ': 'ryu', // HIRAGANA LETTER RI + SMALL YU
  'り': 'ri', // HIRAGANA LETTER RI
  'るう': 'rū', // HIRAGANA LETTER RU + U
  'る': 'ru', // HIRAGANA LETTER RU
  'れ': 're', // HIRAGANA LETTER RE
  'ろう': 'rō', // HIRAGANA LETTER RO + U
  'ろ': 'ro', // HIRAGANA LETTER RO

  'わ': 'wa', // HIRAGANA LETTER WA
  'ゐ': 'i', // HIRAGANA LETTER WI
  'ゑ': 'e', // HIRAGANA LETTER WE
  'を': 'o', // HIRAGANA LETTER WO

  'ん': 'n', // HIRAGANA LETTER N

  'ぐぁ': 'gwa', // HIRAGANA LETTER GU + SMALL A
  'ぐぃ': 'gwi', // HIRAGANA LETTER GU + SMALL I
  'ぐぇ': 'gwe', // HIRAGANA LETTER GU + SMALL E
  'ぐぉ': 'gwo', // HIRAGANA LETTER GU + SMALL O

  'が': 'ga', // HIRAGANA LETTER GA
  'ぎょう': 'gyō', // HIRAGANA LETTER GI + SMALL YO + U
  'ぎゅう': 'gyū', // HIRAGANA LETTER GI + SMALL YU + U
  'ぎゃ': 'gya', // HIRAGANA LETTER GI + SMALL YA
  'ぎょ': 'gyo', // HIRAGANA LETTER GI + SMALL YO
  'ぎゅ': 'gyu', // HIRAGANA LETTER GI + SMALL YU
  'ぎ': 'gi', // HIRAGANA LETTER GI
  'ぐう': 'gū', // HIRAGANA LETTER GU + U
  'ぐ': 'gu', // HIRAGANA LETTER GU
  'げ': 'ge', // HIRAGANA LETTER GE
  'ごう': 'gō', // HIRAGANA LETTER GO + U
  'ご': 'go', // HIRAGANA LETTER GO

  'じぇ': 'je', // HIRAGANA LETTER ZI + SMALL E
  'ずぃ': 'zi', // HIRAGANA LETTER ZU + SMALL I

  'ざ': 'za', // HIRAGANA LETTER ZA
  'じょう': 'jō', // HIRAGANA LETTER ZI + SMALL YO + U
  'じゅう': 'jū', // HIRAGANA LETTER ZI + SMALL YU + U
  'じゃ': 'ja', // HIRAGANA LETTER ZI + SMALL YA
  'じょ': 'jo', // HIRAGANA LETTER ZI + SMALL YO
  'じゅ': 'ju', // HIRAGANA LETTER ZI + SMALL YU
  'じ': 'ji', // HIRAGANA LETTER ZI
  'ずう': 'zū', // HIRAGANA LETTER ZU + U
  'ず': 'zu', // HIRAGANA LETTER ZU
  'ぜ': 'ze', // HIRAGANA LETTER ZE
  'ぞう': 'zō', // HIRAGANA LETTER ZO + U
  'ぞ': 'zo', // HIRAGANA LETTER ZO

  'だ': 'da', // HIRAGANA LETTER DA
  'ぢ': 'ji', // HIRAGANA LETTER DI
  'づう': 'zū', // HIRAGANA LETTER DU + U
  'づ': 'zu', // HIRAGANA LETTER DU
  'で': 'de', // HIRAGANA LETTER DE
  'どう': 'dō', // HIRAGANA LETTER DO + U
  'ど': 'do', // HIRAGANA LETTER DO

  'ぶゅ': 'byu', // HIRAGANA LETTER BU + SMALL YU

  'ば': 'ba', // HIRAGANA LETTER BA
  'びょう': 'byō', // HIRAGANA LETTER BI + SMALL YO + U
  'びゅう': 'byū', // HIRAGANA LETTER BI + SMALL YU + U
  'びゃ': 'bya', // HIRAGANA LETTER BI + SMALL YA
  'びょ': 'byo', // HIRAGANA LETTER BI + SMALL YO
  'びゅ': 'byu', // HIRAGANA LETTER BI + SMALL YU
  'び': 'bi', // HIRAGANA LETTER BI
  'ぶう': 'bū', // HIRAGANA LETTER BU + U
  'ぶ': 'bu', // HIRAGANA LETTER BU
  'べ': 'be', // HIRAGANA LETTER BE
  'ぼう': 'bō', // HIRAGANA LETTER BO + U
  'ぼ': 'bo', // HIRAGANA LETTER BO

  'ぱ': 'pa', // HIRAGANA LETTER PA
  'ぴょう': 'pyō', // HIRAGANA LETTER PI + SMALL YO + U
  'ぴゅう': 'pyū', // HIRAGANA LETTER PI + SMALL YU + U
  'ぴゃ': 'pya', // HIRAGANA LETTER PI + SMALL YA
  'ぴょ': 'pyo', // HIRAGANA LETTER PI + SMALL YO
  'ぴゅ': 'pyu', // HIRAGANA LETTER PI + SMALL YU
  'ぴ': 'pi', // HIRAGANA LETTER PI
  'ぷう': 'pū', // HIRAGANA LETTER PU + U
  'ぷ': 'pu', // HIRAGANA LETTER PU
  'ぺ': 'pe', // HIRAGANA LETTER PE
  'ぽう': 'pō', // HIRAGANA LETTER PO + U
  'ぽ': 'po', // HIRAGANA LETTER PO

  'ゔ': 'v' // HIRAGANA LETTER VU
};

var transliterationTable3 = {
  'aァ': 'ā',
  'aぁ': 'ā',
  'iィー': 'ī',
  'iィ': 'ī',
  'iぃー': 'ī',
  'iぃ': 'ī',
  'aー': 'ā',
  'iー': 'ī',
  'uー': 'ū',
  'eー': 'ē',
  'oー': 'ō',

  // Fallback for small vowels
  'ァ': 'a',
  'ィ': 'i',
  'ゥ': 'u',
  'ェ': 'e',
  'ォ': 'o',
  'ぁ': 'a',
  'ぃ': 'i',
  'ぅ': 'u',
  'ぇ': 'e',
  'ぉ': 'o'
};

var replace1 = replacer(transliterationTable1);
var replace2 = replacer(transliterationTable2);
var replace3 = replacer(transliterationTable3);

module.exports = function(str) {
  str = replace1(str);

  str = str
    .replace(/ッ(?=[ン])/g, 'n')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[ん])/g, 'n')// HIRAGANA LETTER SMALL TU
    .replace(/ン(?=[バビブベボパピプペポマミムメモ])/g, 'm')// KATAKANA LETTER N
    .replace(/ん(?=[ばびぶべぼぱぴぷぺぽまみむめも])/g, 'm')// HIRAGANA LETTER N
    .replace(/ン(?=[ヤユヨアイウエオ])/g, "n'")// KATAKANA LETTER N
    .replace(/ん(?=[やゆよあいうえお])/g, "n'");// HIRAGANA LETTER N
  str = str
    .replace(/ッ(?=[カキクケコ])/g, 'k')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[かきくけこ])/g, 'k')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[ガギグゲゴ])/g, 'g')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[がぎぐげご])/g, 'g')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[サシスセソ])/g, 's')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[さしすせそ])/g, 's')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[ザズゼゾ])/g, 'z')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[ざずぜぞ])/g, 'z')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[ジ])/g, 'j')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[じ])/g, 'j')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[タチツテト])/g, 't')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[たちつてと])/g, 't')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[ダヂヅデド])/g, 't')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[だぢづでど])/g, 't')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[ハヒヘホ])/g, 'h')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[はひへほ])/g, 'h')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[フ])/g, 'f')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[ふ])/g, 'f')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[バビブベボ])/g, 'b')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[ばびぶべぼ])/g, 'b')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[パピプペポ])/g, 'p')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[ぱぴぷぺぽ])/g, 'p')// HIRAGANA LETTER SMALL TU
    .replace(/ッ(?=[ラリルレロ])/g, 'r')// KATAKANA LETTER SMALL TU
    .replace(/っ(?=[らりるれろ])/g, 'r');// HIRAGANA LETTER SMALL TU

  str = replace2(str);
  str = replace3(str);

  str = str
    .replace(/(ッ|っ)\B/g, 't');// FINAL KATAKANA LETTER SMALL TU

  return str;
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\trie\\trie.js":
/*!***********************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/trie/trie.js ***!
  \***********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2014 Ken Koch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

/** 
 * The basis of the TRIE structure.
 **/
function Trie(caseSensitive) {
	this.dictionary = {};
	this.$ = false;

	if(typeof caseSensitive === "undefined") {
		caseSensitive = true;
	}

	this.cs = caseSensitive;
}

/**
 * Add a single string to the TRIE, returns true if the word was already in the 
 * trie.
 **/
Trie.prototype.addString = function(string) {
	if(this.cs === false) {
		string = string.toLowerCase();
	}

	// If the string has only one letter, mark this as a word.
	if(string.length === 0) {
		var wasWord = this.$;
		this.$ = true;
		return wasWord;
	}

	// Make sure theres a Trie node in our dictionary
	var next = this.dictionary[string[0]];

	if(!next) {
		this.dictionary[string[0]] = new Trie(this.cs);
		next = this.dictionary[string[0]];
	}

	// Continue adding the string
	return next.addString(string.substring(1));
};

/**
 * Add multiple strings to the TRIE
 **/
Trie.prototype.addStrings = function(list) {
	for(var i in list) {
		this.addString(list[i]);
	}
};

/**
 * A function to search the TRIE and return an array of
 * words which have same prefix <prefix>
 * for example if we had the following words in our database:
 * a, ab, bc, cd, abc, abd
 * and we search the string: a
 * we will get :
 * [a, ab, abc, abd]
 **/
Trie.prototype.keysWithPrefix = function(prefix) {
    if(this.caseSensitive === false) {
        prefix = prefix.toLowerCase();
    }

    function isEmpty (object) {
        for (var key in object) if (object.hasOwnProperty(key)) return false;
        return true;
    }

    function get (node, word) {
        if(!node) return null;
        if(word.length == 0) return node;
        return get(node.dictionary[word[0]], word.substring(1));
    }

    function recurse ( node, stringAgg, resultsAgg) {
        if (!node) return;

        // Check if this is a word
        if (node.$) {
            resultsAgg.push(stringAgg);
        }

        if (isEmpty(node.dictionary)) {
            return ;
        }

        for (var c in node.dictionary) {
            recurse (node.dictionary[c],stringAgg + c, resultsAgg);
        }
    }

    var results = [];
    recurse (get(this, prefix), prefix, results);
    return results;
};

/** 
 * A function to search the given string and return true if it lands
 * on on a word. Essentially testing if the word exists in the database.
 **/
Trie.prototype.contains = function(string) {
	if(this.cs === false) {
		string = string.toLowerCase();
	}

	if(string.length === 0) {
		return this.$;
	}

	// Otherwise, we need to continue searching
	var firstLetter = string[0];
	var next = this.dictionary[firstLetter];		

	// If we don't have a node, this isn't a word
	if(!next) {
		return false;
	}

	// Otherwise continue the search at the next node
	return next.contains(string.substring(1));
}

/**
 * A function to search the TRIE and return an array of words which were encountered along the way.
 * This will only return words with full prefix matches.
 * for example if we had the following words in our database:
 * a, ab, bc, cd, abc
 * and we searched the string: abcd
 * we would get only:
 * [a, ab, abc]
 **/
Trie.prototype.findMatchesOnPath = function(search) {
	if(this.cs === false) {
		search = search.toLowerCase();
	}

	function recurse(node, search, stringAgg, resultsAgg) {
		// Check if this is a word.
		if(node.$) {
			resultsAgg.push(stringAgg);
		}

		// Check if the have completed the seearch
		if(search.length === 0) {
			return resultsAgg;
		}

		// Otherwise, continue searching
		var next = node.dictionary[search[0]];
		if(!next) {
			return resultsAgg;
		}
		return recurse(next, search.substring(1), stringAgg + search[0], resultsAgg);
	};

	return recurse(this, search, "", []);
};

/**
 * Returns the longest match and the remaining part that could not be matched.
 * inspired by [NLTK containers.trie.find_prefix](http://nltk.googlecode.com/svn-/trunk/doc/api/nltk.containers.Trie-class.html).
 **/
Trie.prototype.findPrefix = function(search) {
	if(this.cs === false) {
		search = search.toLowerCase();
	}
	
	function recurse(node, search, stringAgg, lastWord) {
		// Check if this is a word
		if(node.$) {
			lastWord = stringAgg;
		}

		// Check if we have no more to search
		if(search.length === 0) {
			return [lastWord, search];
		}

		// Continue searching
		var next = node.dictionary[search[0]];
		if(!next) {
			return [lastWord, search];
		}
		return recurse(next, search.substring(1), stringAgg + search[0], lastWord);
	};

	return recurse(this, search, "", null);
};

/**
 * Computes the number of actual nodes from this node to the end.
 * Note: This involves traversing the entire structure and may not be
 * good for frequent use.
 **/
Trie.prototype.getSize = function() { 
	var total = 1;
	for(var c in this.dictionary) {
		total += this.dictionary[c].getSize();
	}
	return total;
};

/**
 * EXPORT THE TRIE
 **/
module.exports = Trie;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\bag.js":
/*!**********************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/bag.js ***!
  \**********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*
 Copyright (c) 2014, Lee Wenzhu

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */


function Bag() {
    this.dictionary = [];
    this.nElement = 0;
};

Bag.prototype.add = function(element) {
    this.dictionary.push(element);
    this.nElement++;
    return this;
};

Bag.prototype.isEmpty = function() {
    return this.nElement > 0;
};

Bag.prototype.contains = function(item) {
    return this.dictionary.indexOf(item) >= 0;
};

/**
 * unpack the bag , and get all items
 */
Bag.prototype.unpack = function() {
    // return a copy is better than original
    return this.dictionary.slice();
};

module.exports = Bag;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\edge_weighted_digraph.js":
/*!****************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/edge_weighted_digraph.js ***!
  \****************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*
 Copyright (c) 2014, Lee Wenzhu

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */


var util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
    Bag = __webpack_require__(/*! ./bag */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\bag.js");

var DirectedEdge = function(start, end, weight) {
    this.start = start;
    this.end = end;
    this.weight = weight;
};

DirectedEdge.prototype.weight = function() {
    return this.weight;
};

DirectedEdge.prototype.from = function() {
    return this.start;
};

DirectedEdge.prototype.to = function() {
    return this.end;
};

DirectedEdge.prototype.toString = function() {
    return util.format('%s -> %s, %s', this.start, this.end, this.weight);
};

var EdgeWeightedDigraph = function() {
    this.edgesNum = 0;
    this.adj = []; // adjacency list
};

/**
 * the number of vertexs saved.
 */
EdgeWeightedDigraph.prototype.v = function() {
    return this.adj.length;
};

/**
 * the number of edges saved.
 */
EdgeWeightedDigraph.prototype.e = function() {
    return this.edgesNum;
};

EdgeWeightedDigraph.prototype.add = function(start, end, weight) {
    var e = new DirectedEdge(start, end, weight);
    this.addEdge(e);
};

EdgeWeightedDigraph.prototype.addEdge = function(e) {
    if(!this.adj[e.from()]) {
        this.adj[e.from()] = new Bag();
    }
    this.adj[e.from()].add(e);
    this.edgesNum++;
};

/**
 * use callback on all edges from v.
 */
EdgeWeightedDigraph.prototype.getAdj = function(v) {
    if(!this.adj[v]) return [];
    return this.adj[v].unpack();
};

/**
 * use callback on all edges.
 */
EdgeWeightedDigraph.prototype.edges = function() {
    var adj = this.adj;
    var list = new Bag();
    for(var i in adj) {
        adj[i].unpack().forEach(function(item) {
            list.add(item);
        });
    }
    return list.unpack();
};

EdgeWeightedDigraph.prototype.toString = function() {
    var result = [];
    var list = this.edges();
    list.forEach(function(edge) {
        result.push(edge.toString());
    });
    return result.join('\n');
};

module.exports = EdgeWeightedDigraph;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\longest_path_tree.js":
/*!************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/longest_path_tree.js ***!
  \************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*
 Copyright (c) 2014, Lee Wenzhu

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */


var EdgeWeightedDigraph = __webpack_require__(/*! ./edge_weighted_digraph */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\edge_weighted_digraph.js"),
    Topological = __webpack_require__(/*! ./topological */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\topological.js");

/**
  *  The LongestPathTree represents a data type for solving the
  *  single-source longest paths problem in edge-weighted directed
  *  acyclic graphs (DAGs). The edge weights can be positive, negative, or zero.
  *  This implementation uses a topological-sort based algorithm.
  *  the distTo() and hasPathTo() methods take
  *  constant time and the pathTo() method takes time proportional to the
  *  number of edges in the longest path returned.
  */
var LongestPathTree = function(digraph, start) {
    var _this = this;
    this.edgeTo = [];
    this.distTo = [];
    this.distTo[start] = 0.0;
    this.start = start;
    this.top = new Topological(digraph);
    this.top.order().forEach(function(vertex){
        _this.relaxVertex(digraph, vertex, _this);
    });
};

LongestPathTree.prototype.relaxEdge = function(e) {
    var distTo = this.distTo,
        edgeTo = this.edgeTo;
    var v = e.from(), w = e.to();
    if (distTo[w] < distTo[v] + e.weight) {
        distTo[w] = distTo[v] + e.weight;
        edgeTo[w] = e;
    }
};

/**
 * relax a vertex v in the specified digraph g
 * @param {EdgeWeightedDigraph} the apecified digraph
 * @param {Vertex} v vertex to be relaxed
 */
LongestPathTree.prototype.relaxVertex = function(digraph, vertex, tree) {
    var distTo = tree.distTo;
    var edgeTo = tree.edgeTo;

    digraph.getAdj(vertex).forEach(function(edge){
        var w = edge.to();
        distTo[w] = distTo[w] || 0.0;
        distTo[vertex] = distTo[vertex] || 0.0;
        if (distTo[w] < distTo[vertex] + edge.weight) {
            // in case of the result of 0.28+0.34 is 0.62000001
            distTo[w] = parseFloat((distTo[vertex] + edge.weight).toFixed(2));
            edgeTo[w] = edge;
        }
    });

};

LongestPathTree.prototype.getDistTo = function(v) {
    return this.distTo[v];
};

LongestPathTree.prototype.hasPathTo = function(v) {
    return !!this.distTo[v];
};

LongestPathTree.prototype.pathTo = function(v) {
    if (!this.hasPathTo(v)) return [];
    var path = [];
    var edgeTo = this.edgeTo;
    for (var e = edgeTo[v]; !!e; e = edgeTo[e.from()]) {
        path.push(e.to());
    }
    path.push(this.start);
    return path.reverse();
};

module.exports = LongestPathTree;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\shortest_path_tree.js":
/*!*************************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/shortest_path_tree.js ***!
  \*************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*
 Copyright (c) 2014, Lee Wenzhu

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */


var EdgeWeightedDigraph = __webpack_require__(/*! ./edge_weighted_digraph */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\edge_weighted_digraph.js"),
    Topological = __webpack_require__(/*! ./topological */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\topological.js");

/**
  *  The ShortestPathTree represents a data type for solving the
  *  single-source shortest paths problem in edge-weighted directed
  *  acyclic graphs (DAGs). The edge weights can be positive, negative, or zero.
  *  This implementation uses a topological-sort based algorithm.
  *  the distTo() and hasPathTo() methods take
  *  constant time and the pathTo() method takes time proportional to the
  *  number of edges in the longest path returned.
  */
var ShortestPathTree = function(digraph, start) {
    var _this = this;
    this.edgeTo = [];
    this.distTo = [];
    this.distTo[start] = 0.0;
    this.start = start;
    this.top = new Topological(digraph);
    this.top.order().forEach(function(vertex){
        _this.relaxVertex(digraph, vertex, _this);
    });
};

ShortestPathTree.prototype.relaxEdge = function(e) {
    var distTo = this.distTo,
        edgeTo = this.edgeTo;
    var v = e.from(), w = e.to();
    if (distTo[w] > distTo[v] + e.weight) {
        distTo[w] = distTo[v] + e.weight;
        edgeTo[w] = e;
    }
};

/**
 * relax a vertex v in the specified digraph g
 * @param {EdgeWeightedDigraph} the apecified digraph
 * @param {Vertex} v vertex to be relaxed
 */
ShortestPathTree.prototype.relaxVertex = function(digraph, vertex, tree) {
    var distTo = tree.distTo;
    var edgeTo = tree.edgeTo;
    digraph.getAdj(vertex).forEach(function(edge){
        var w = edge.to();
        distTo[w] = /\d/.test(distTo[w]) ? distTo[w] : Number.MAX_VALUE;
        distTo[vertex] = distTo[vertex] || 0;
        if (distTo[w] > distTo[vertex] + edge.weight) {
            // in case of the result of 0.28+0.34 is 0.62000001
            distTo[w] = parseFloat((distTo[vertex] + edge.weight).toFixed(2));
            edgeTo[w] = edge;
        }
    });

};

ShortestPathTree.prototype.getDistTo = function(v) {
    return this.distTo[v];
};

ShortestPathTree.prototype.hasPathTo = function(v) {
    var dist = this.distTo[v];
    if(v == this.start) return false;
    return /\d/.test(dist) ? dist != Number.MAX_VALUE : false;
};

ShortestPathTree.prototype.pathTo = function(v) {
    if (!this.hasPathTo(v) || v == this.start) return [];
    var path = [];
    var edgeTo = this.edgeTo;
    for (var e = edgeTo[v]; !!e; e = edgeTo[e.from()]) {
        path.push(e.to());
    }
    path.push(this.start);
    return path.reverse();
};

module.exports = ShortestPathTree;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords.js":
/*!****************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords.js ***!
  \****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = [
    'about', 'above', 'after', 'again', 'all', 'also', 'am', 'an', 'and', 'another',
    'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below',
    'between', 'both', 'but', 'by', 'came', 'can', 'cannot', 'come', 'could', 'did',
    'do', 'does', 'doing', 'during', 'each', 'few', 'for', 'from', 'further', 'get',
    'got', 'has', 'had', 'he', 'have', 'her', 'here', 'him', 'himself', 'his', 'how',
    'if', 'in', 'into', 'is', 'it', 'its', 'itself', 'like', 'make', 'many', 'me',
    'might', 'more', 'most', 'much', 'must', 'my', 'myself', 'never', 'now', 'of', 'on',
    'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own',
    'said', 'same', 'see', 'should', 'since', 'so', 'some', 'still', 'such', 'take', 'than',
    'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they',
    'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was',
    'way', 'we', 'well', 'were', 'what', 'where', 'when', 'which', 'while', 'who',
    'whom', 'with', 'would', 'why', 'you', 'your', 'yours', 'yourself',
    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',
    'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '$', '1',
    '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];

// tell the world about the noise words.
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_es.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_es.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, David Przybilla, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = [
    'a','un','el','ella','y','sobre','de','la','que','en',
    'los','del','se','las','por','un','para','con','no',
    'una','su','al','lo','como','más','pero','sus','le',
    'ya','o','porque','cuando','muy','sin','sobre','también',
    'me','hasta','donde','quien','desde','nos','durante','uno',
    'ni','contra','ese','eso','mí','qué','otro','él','cual',
    'poco','mi','tú','te','ti','sí',
     '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];
    
// tell the world about the noise words.    
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_fa.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_fa.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel
Farsi Stop Words by Fardin Koochaki <me@fardinak.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = [
    // Words
    'از', 'با', 'یه', 'برای', 'و', 'باید', 'شاید',

    // Symbols
    '؟', '!', '٪', '.', '،', '؛', ':', ';', ',',
    
    // Numbers
    '۱', '۲', '۳', '۴', '۵', '۶', '۷', '۸', '۹', '۰'
];
    
// tell the world about the noise words.    
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_fr.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_fr.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
 Copyright (c) 2014, Ismaël Héry

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */

// A list of commonly used french words that have little meaning and can be excluded
// from analysis.

var words = ['être', 'avoir', 'faire',
    'a',
    'au',
    'aux',
    'avec',
    'ce',
    'ces',
    'dans',
    'de',
    'des',
    'du',
    'elle',
    'en',
    'et',
    'eux',
    'il',
    'je',
    'la',
    'le',
    'leur',
    'lui',
    'ma',
    'mais',
    'me',
    'même',
    'mes',
    'moi',
    'mon',
    'ne',
    'nos',
    'notre',
    'nous',
    'on',
    'ou',
    'où',
    'par',
    'pas',
    'pour',
    'qu',
    'que',
    'qui',
    'sa',
    'se',
    'ses',
    'son',
    'sur',
    'ta',
    'te',
    'tes',
    'toi',
    'ton',
    'tu',
    'un',
    'une',
    'vos',
    'votre',
    'vous',
    'c',
    'd',
    'j',
    'l',
    'à',
    'm',
    'n',
    's',
    't',
    'y',
    'été',
    'étée',
    'étées',
    'étés',
    'étant',
    'suis',
    'es',
    'est',
    'sommes',
    'êtes',
    'sont',
    'serai',
    'seras',
    'sera',
    'serons',
    'serez',
    'seront',
    'serais',
    'serait',
    'serions',
    'seriez',
    'seraient',
    'étais',
    'était',
    'étions',
    'étiez',
    'étaient',
    'fus',
    'fut',
    'fûmes',
    'fûtes',
    'furent',
    'sois',
    'soit',
    'soyons',
    'soyez',
    'soient',
    'fusse',
    'fusses',
    'fût',
    'fussions',
    'fussiez',
    'fussent',
    'ayant',
    'eu',
    'eue',
    'eues',
    'eus',
    'ai',
    'as',
    'avons',
    'avez',
    'ont',
    'aurai',
    'auras',
    'aura',
    'aurons',
    'aurez',
    'auront',
    'aurais',
    'aurait',
    'aurions',
    'auriez',
    'auraient',
    'avais',
    'avait',
    'avions',
    'aviez',
    'avaient',
    'eut',
    'eûmes',
    'eûtes',
    'eurent',
    'aie',
    'aies',
    'ait',
    'ayons',
    'ayez',
    'aient',
    'eusse',
    'eusses',
    'eût',
    'eussions',
    'eussiez',
    'eussent',
    'ceci',
    'cela',
    'cet',
    'cette',
    'ici',
    'ils',
    'les',
    'leurs',
    'quel',
    'quels',
    'quelle',
    'quelles',
    'sans',
    'soi'
];

exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_id.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_id.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2017, Alif Bhaskoro, Andy Librian, R. Kukuh (Reimplemented from https://github.com/sastrawi/sastrawi)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = 
	['a','ada','adalah','adanya','adapun','agak','agaknya','agar','akan','akankah','akhir',
    'akhiri','akhirnya','aku','akulah','amat','amatlah','anda','andalah','antar','antara',
    'antaranya','apa','apaan','apabila','apakah','apalagi','apatah','arti','artinya','asal',
    'asalkan','atas','atau','ataukah','ataupun','awal','awalnya','b','bagai','bagaikan',
    'bagaimana','bagaimanakah','bagaimanapun','bagainamakah','bagi','bagian','bahkan','bahwa',
    'bahwasannya','bahwasanya','baik','baiklah','bakal','bakalan','balik','banyak','bapak',
    'baru','bawah','beberapa','begini','beginian','beginikah','beginilah','begitu','begitukah',
    'begitulah','begitupun','bekerja','belakang','belakangan','belum','belumlah','benar',
    'benarkah','benarlah','berada','berakhir','berakhirlah','berakhirnya','berapa','berapakah',
    'berapalah','berapapun','berarti','berawal','berbagai','berdatangan','beri','berikan',
    'berikut','berikutnya','berjumlah','berkali-kali','berkata','berkehendak','berkeinginan',
    'berkenaan','berlainan','berlalu','berlangsung','berlebihan','bermacam','bermacam-macam',
    'bermaksud','bermula','bersama','bersama-sama','bersiap','bersiap-siap','bertanya',
    'bertanya-tanya','berturut','berturut-turut','bertutur','berujar','berupa','besar',
    'betul','betulkah','biasa','biasanya','bila','bilakah','bisa','bisakah','boleh','bolehkah',
    'bolehlah','buat','bukan','bukankah','bukanlah','bukannya','bulan','bung','c','cara',
    'caranya','cukup','cukupkah','cukuplah','cuma','d','dahulu','dalam','dan','dapat','dari',
    'daripada','datang','dekat','demi','demikian','demikianlah','dengan','depan','di','dia',
    'diakhiri','diakhirinya','dialah','diantara','diantaranya','diberi','diberikan','diberikannya',
    'dibuat','dibuatnya','didapat','didatangkan','digunakan','diibaratkan','diibaratkannya',
    'diingat','diingatkan','diinginkan','dijawab','dijelaskan','dijelaskannya','dikarenakan',
    'dikatakan','dikatakannya','dikerjakan','diketahui','diketahuinya','dikira','dilakukan',
    'dilalui','dilihat','dimaksud','dimaksudkan','dimaksudkannya','dimaksudnya','diminta',
    'dimintai','dimisalkan','dimulai','dimulailah','dimulainya','dimungkinkan','dini','dipastikan',
    'diperbuat','diperbuatnya','dipergunakan','diperkirakan','diperlihatkan','diperlukan',
    'diperlukannya','dipersoalkan','dipertanyakan','dipunyai','diri','dirinya','disampaikan',
    'disebut','disebutkan','disebutkannya','disini','disinilah','ditambahkan','ditandaskan',
    'ditanya','ditanyai','ditanyakan','ditegaskan','ditujukan','ditunjuk','ditunjuki','ditunjukkan',
    'ditunjukkannya','ditunjuknya','dituturkan','dituturkannya','diucapkan','diucapkannya',
    'diungkapkan','dong','dua','dulu','e','empat','enak','enggak','enggaknya','entah','entahlah',
    'f','g','guna','gunakan','h','hadap','hai','hal','halo','hallo','hampir','hanya','hanyalah',
    'hari','harus','haruslah','harusnya','helo','hello','hendak','hendaklah','hendaknya','hingga',
    'i','ia','ialah','ibarat','ibaratkan','ibaratnya','ibu','ikut','ingat','ingat-ingat','ingin',
    'inginkah','inginkan','ini','inikah','inilah','itu','itukah','itulah','j','jadi','jadilah',
    'jadinya','jangan','jangankan','janganlah','jauh','jawab','jawaban','jawabnya','jelas',
    'jelaskan','jelaslah','jelasnya','jika','jikalau','juga','jumlah','jumlahnya','justru',
    'k','kadar','kala','kalau','kalaulah','kalaupun','kali','kalian','kami','kamilah','kamu',
    'kamulah','kan','kapan','kapankah','kapanpun','karena','karenanya','kasus','kata','katakan',
    'katakanlah','katanya','ke','keadaan','kebetulan','kecil','kedua','keduanya','keinginan',
    'kelamaan','kelihatan','kelihatannya','kelima','keluar','kembali','kemudian','kemungkinan',
    'kemungkinannya','kena','kenapa','kepada','kepadanya','kerja','kesampaian','keseluruhan',
    'keseluruhannya','keterlaluan','ketika','khusus','khususnya','kini','kinilah','kira',
    'kira-kira','kiranya','kita','kitalah','kok','kurang','l','lagi','lagian','lah','lain',
    'lainnya','laku','lalu','lama','lamanya','langsung','lanjut','lanjutnya','lebih','lewat',
    'lihat','lima','luar','m','macam','maka','makanya','makin','maksud','malah','malahan',
    'mampu','mampukah','mana','manakala','manalagi','masa','masalah','masalahnya','masih',
    'masihkah','masing','masing-masing','masuk','mata','mau','maupun','melainkan','melakukan',
    'melalui','melihat','melihatnya','memang','memastikan','memberi','memberikan','membuat',
    'memerlukan','memihak','meminta','memintakan','memisalkan','memperbuat','mempergunakan',
    'memperkirakan','memperlihatkan','mempersiapkan','mempersoalkan','mempertanyakan','mempunyai',
    'memulai','memungkinkan','menaiki','menambahkan','menandaskan','menanti','menanti-nanti',
    'menantikan','menanya','menanyai','menanyakan','mendapat','mendapatkan','mendatang','mendatangi',
    'mendatangkan','menegaskan','mengakhiri','mengapa','mengatakan','mengatakannya','mengenai',
    'mengerjakan','mengetahui','menggunakan','menghendaki','mengibaratkan','mengibaratkannya',
    'mengingat','mengingatkan','menginginkan','mengira','mengucapkan','mengucapkannya','mengungkapkan',
    'menjadi','menjawab','menjelaskan','menuju','menunjuk','menunjuki','menunjukkan','menunjuknya',
    'menurut','menuturkan','menyampaikan','menyangkut','menyatakan','menyebutkan','menyeluruh',
    'menyiapkan','merasa','mereka','merekalah','merupakan','meski','meskipun','meyakini','meyakinkan',
    'minta','mirip','misal','misalkan','misalnya','mohon','mula','mulai','mulailah','mulanya','mungkin',
    'mungkinkah','n','nah','naik','namun','nanti','nantinya','nya','nyaris','nyata','nyatanya',
    'o','oleh','olehnya','orang','p','pada','padahal','padanya','pak','paling','panjang','pantas',
    'para','pasti','pastilah','penting','pentingnya','per','percuma','perlu','perlukah','perlunya',
    'pernah','persoalan','pertama','pertama-tama','pertanyaan','pertanyakan','pihak','pihaknya',
    'pukul','pula','pun','punya','q','r','rasa','rasanya','rupa','rupanya','s','saat','saatnya','saja',
    'sajalah','salam','saling','sama','sama-sama','sambil','sampai','sampai-sampai','sampaikan','sana',
    'sangat','sangatlah','sangkut','satu','saya','sayalah','se','sebab','sebabnya','sebagai',
    'sebagaimana','sebagainya','sebagian','sebaik','sebaik-baiknya','sebaiknya','sebaliknya',
    'sebanyak','sebegini','sebegitu','sebelum','sebelumnya','sebenarnya','seberapa','sebesar',
    'sebetulnya','sebisanya','sebuah','sebut','sebutlah','sebutnya','secara','secukupnya','sedang',
    'sedangkan','sedemikian','sedikit','sedikitnya','seenaknya','segala','segalanya','segera',
    'seharusnya','sehingga','seingat','sejak','sejauh','sejenak','sejumlah','sekadar','sekadarnya',
    'sekali','sekali-kali','sekalian','sekaligus','sekalipun','sekarang','sekaranglah','sekecil',
    'seketika','sekiranya','sekitar','sekitarnya','sekurang-kurangnya','sekurangnya','sela','selain',
    'selaku','selalu','selama','selama-lamanya','selamanya','selanjutnya','seluruh','seluruhnya',
    'semacam','semakin','semampu','semampunya','semasa','semasih','semata','semata-mata','semaunya',
    'sementara','semisal','semisalnya','sempat','semua','semuanya','semula','sendiri','sendirian',
    'sendirinya','seolah','seolah-olah','seorang','sepanjang','sepantasnya','sepantasnyalah',
    'seperlunya','seperti','sepertinya','sepihak','sering','seringnya','serta','serupa','sesaat',
    'sesama','sesampai','sesegera','sesekali','seseorang','sesuatu','sesuatunya','sesudah',
    'sesudahnya','setelah','setempat','setengah','seterusnya','setiap','setiba','setibanya',
    'setidak-tidaknya','setidaknya','setinggi','seusai','sewaktu','siap','siapa','siapakah',
    'siapapun','sini','sinilah','soal','soalnya','suatu','sudah','sudahkah','sudahlah','supaya',
    't','tadi','tadinya','tahu','tak','tambah','tambahnya','tampak','tampaknya','tandas','tandasnya',
    'tanpa','tanya','tanyakan','tanyanya','tapi','tegas','tegasnya','telah','tempat','tentang','tentu',
    'tentulah','tentunya','tepat','terakhir','terasa','terbanyak','terdahulu','terdapat','terdiri',
    'terhadap','terhadapnya','teringat','teringat-ingat','terjadi','terjadilah','terjadinya','terkira',
    'terlalu','terlebih','terlihat','termasuk','ternyata','tersampaikan','tersebut','tersebutlah',
    'tertentu','tertuju','terus','terutama','tetap','tetapi','tiap','tiba','tiba-tiba','tidak',
    'tidakkah','tidaklah','tiga','toh','tuju','tunjuk','turut','tutur','tuturnya','u','ucap','ucapnya',
    'ujar','ujarnya','umumnya','ungkap','ungkapnya','untuk','usah','usai','v','w','waduh','wah','wahai',
    'waktunya','walau','walaupun','wong','x','y','ya','yaitu','yakin','yakni','yang','z'];

// tell the world about the noise words.
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_it.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_it.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, David Przybilla, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = [
    'ad','al','allo','ai','agli','all','agl','alla','alle','con','col','coi','da','dal','dallo',
    'dai','dagli','dall','dagl','dalla','dalle','di','del','dello','dei','degli','dell','degl',
    'della','delle','in','nel','nello','nei','negli','nell','negl','nella','nelle','su','sul',
    'sullo','sui','sugli','sull','sugl','sulla','sulle','per','tra','contro','io','tu','lui',
    'lei','noi','voi','loro','mio','mia','miei','mie','tuo','tua','tuoi','tue','suo','sua','suoi',
    'sue','nostro','nostra','nostri','nostre','vostro','vostra','vostri','vostre','mi','ti','ci',
    'vi','lo','la','li','le','gli','ne','il','un','uno','una','ma','ed','se','perché','anche','come',
    'dov','dove','che','chi','cui','non','più','quale','quanto','quanti','quanta','quante','quello',
    'quelli','quella','quelle','questo','questi','questa','queste','si','tutto','tutti','a','c','e',
    'i','l','o','ho','hai','ha','abbiamo','avete','hanno','abbia','abbiate','abbiano','avrò','avrai',
    'avrà','avremo','avrete','avranno','avrei','avresti','avrebbe','avremmo','avreste','avrebbero',
    'avevo','avevi','aveva','avevamo','avevate','avevano','ebbi','avesti','ebbe','avemmo','aveste',
    'ebbero','avessi','avesse','avessimo','avessero','avendo','avuto','avuta','avuti','avute','sono',
    'sei','è','siamo','siete','sia','siate','siano','sarò','sarai','sarà','saremo','sarete','saranno',
    'sarei','saresti','sarebbe','saremmo','sareste','sarebbero','ero','eri','era','eravamo','eravate',
    'erano','fui','fosti','fu','fummo','foste','furono','fossi','fosse','fossimo','fossero','essendo',
    'faccio','fai','facciamo','fanno','faccia','facciate','facciano','farò','farai','farà','faremo',
    'farete','faranno','farei','faresti','farebbe','faremmo','fareste','farebbero','facevo','facevi',
    'faceva','facevamo','facevate','facevano','feci','facesti','fece','facemmo','faceste','fecero',
    'facessi','facesse','facessimo','facessero','facendo','sto','stai','sta','stiamo','stanno','stia',
    'stiate','stiano','starò','starai','starà','staremo','starete','staranno','starei','staresti',
    'starebbe','staremmo','stareste','starebbero','stavo','stavi','stava','stavamo','stavate','stavano',
    'stetti','stesti','stette','stemmo','steste','stettero','stessi','stesse','stessimo','stessero','stando',
     '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];
    
// tell the world about the noise words.    
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_ja.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_ja.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Original copyright:
/*
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

 http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
*/

// This version:
/*
Copyright (c) 2012, Guillaume Marty

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
// Original location:
// http://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/stopwords.txt
var words = ['の', 'に', 'は', 'を', 'た', 'が', 'で', 'て', 'と', 'し', 'れ', 'さ',
  'ある', 'いる', 'も', 'する', 'から', 'な', 'こと', 'として', 'い', 'や', 'れる',
  'など', 'なっ', 'ない', 'この', 'ため', 'その', 'あっ', 'よう', 'また', 'もの',
  'という', 'あり', 'まで', 'られ', 'なる', 'へ', 'か', 'だ', 'これ', 'によって',
  'により', 'おり', 'より', 'による', 'ず', 'なり', 'られる', 'において', 'ば', 'なかっ',
  'なく', 'しかし', 'について', 'せ', 'だっ', 'その後', 'できる', 'それ', 'う', 'ので',
  'なお', 'のみ', 'でき', 'き', 'つ', 'における', 'および', 'いう', 'さらに', 'でも',
  'ら', 'たり', 'その他', 'に関する', 'たち', 'ます', 'ん', 'なら', 'に対して', '特に',
  'せる', '及び', 'これら', 'とき', 'では', 'にて', 'ほか', 'ながら', 'うち', 'そして',
  'とともに', 'ただし', 'かつて', 'それぞれ', 'または', 'お', 'ほど', 'ものの', 'に対する',
  'ほとんど', 'と共に', 'といった', 'です', 'とも', 'ところ', 'ここ'];

// tell the world about the noise words.
module.exports = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_nl.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_nl.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel, Martijn de Boer, Damien van Holten

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
// This dutch wordlist has been parsed from a list created by Damien van Holten
// source: http://www.damienvanholten.com/blog/dutch-stop-words/
var words = [
    'aan', 'af', 'al', 'alles', 'als', 'altijd', 'andere', 'ben', 'bij', 'daar',
    'dan', 'dat', 'de', 'der', 'deze', 'die', 'dit', 'doch', 'doen', 'door', 'dus',
    'een', 'eens', 'en', 'er', 'ge', 'geen', 'geweest', 'haar', 'had', 'heb',
    'hebben', 'heeft', 'hem', 'het', 'hier', 'hij', 'hoe', 'hun', 'iemand', 'iets',
    'ik', 'in', 'is', 'ja', 'je ', 'kan', 'kon', 'kunnen', 'maar', 'me', 'meer',
    'men', 'met', 'mij', 'mijn', 'moet', 'na', 'naar', 'niet', 'niets', 'nog', 'nu',
    'of', 'om', 'omdat', 'ons', 'ook', 'op', 'over', 'reeds', 'te', 'tegen', 'toch',
    'toen', 'tot', 'u', 'uit', 'uw', 'van', 'veel', 'voor', 'want', 'waren', 'was',
    'wat', 'we', 'wel', 'werd', 'wezen', 'wie', 'wij', 'wil', 'worden', 'zal', 'ze',
    'zei', 'zelf', 'zich', 'zij', 'zijn', 'zo', 'zonder', 'zou',
    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',
    'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '$', '1',
    '2', '3', '4', '5', '6', '7', '8', '9', '0', '_', '-'];

// tell the world about the noise words.
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_no.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_no.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2014, Kristoffer Brabrand

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = [
    'og','i','jeg','det','at','en','et','den','til','er','som',
    'på','de','med','han','av','ikke','der','så','var','meg',
    'seg','men','ett','har','om','vi','min','mitt','ha','hadde',
    'hun','nå','over','da','ved','fra','du','ut','sin','dem',
    'oss','opp','man','kan','hans','hvor','eller','hva','skal',
    'selv','sjøl','her','alle','vil','bli','ble','blitt','kunne',
    'inn','når','være','kom','noen','noe','ville','dere','som',
    'deres','kun','ja','etter','ned','skulle','denne','for','deg',
    'si','sine','sitt','mot','å','meget','hvorfor','dette','disse',
    'uten','hvordan','ingen','din','ditt','blir','samme','hvilken',
    'hvilke','sånn','inni','mellom','vår','hver','hvem','vors',
    'hvis','både','bare','enn','fordi','før','mange','også','slik',
    'vært','være','begge','siden','henne','hennar','hennes',
    '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];

// tell the world about the noise words.
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_pt.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_pt.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Luís Rodrigues

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = [
  'a',
  'à',
  'ao',
  'aos',
  'aquela',
  'aquelas',
  'aquele',
  'aqueles',
  'aquilo',
  'as',
  'às',
  'até',
  'com',
  'como',
  'da',
  'das',
  'de',
  'dela',
  'delas',
  'dele',
  'deles',
  'depois',
  'do',
  'dos',
  'e',
  'ela',
  'elas',
  'ele',
  'eles',
  'em',
  'entre',
  'essa',
  'essas',
  'esse',
  'esses',
  'esta',
  'estas',
  'este',
  'estes',
  'eu',
  'isso',
  'isto',
  'já',
  'lhe',
  'lhes',
  'mais',
  'mas',
  'me',
  'mesmo',
  'meu',
  'meus',
  'minha',
  'minhas',
  'muito',
  'muitos',
  'na',
  'não',
  'nas',
  'nem',
  'no',
  'nos',
  'nós',
  'nossa',
  'nossas',
  'nosso',
  'nossos',
  'num',
  'nuns',
  'numa',
  'numas',
  'o',
  'os',
  'ou',
  'para',
  'pela',
  'pelas',
  'pelo',
  'pelos',
  'por',
  'quais',
  'qual',
  'quando',
  'que',
  'quem',
  'se',
  'sem',
  'seu',
  'seus',
  'só',
  'sua',
  'suas',
  'também',
  'te',
  'teu',
  'teus',
  'tu',
  'tua',
  'tuas',
  'um',
  'uma',
  'umas',
  'você',
  'vocês',
  'vos',
  'vosso',
  'vossos',
  '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'
];

// tell the world about the noise words.
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_ru.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_ru.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Polyakov Vladimir, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = [
    'о', 'после', 'все', 'также', 'и', 'другие', 'все', 'как', 'во', 'быть',
    'потому', 'был', 'до', 'являюсь', 'между', 'все', 'но', 'от', 'иди', 'могу',
    'подойди', 'мог', 'делал', 'делаю', 'каждый', 'для', 'откуда', 'иметь', 'имел',
    'он', 'имеет', 'её', 'здесь', 'его', 'как', 'если', 'в', 'оно', 'за',
    'делать', 'много', 'я', 'может быть', 'более', 'самый', 'должен',
    'мой', 'никогда', 'сейчас', 'из', 'на', 'только', 'или', 'другой', 'другая',
    'другое', 'наше', 'вне', 'конец', 'сказал', 'сказала', 'также', 'видел', 'c',
    'немного', 'все еще', 'так', 'затем', 'тот', 'их', 'там', 'этот', 'они', 'те',
    'через', 'тоже', 'под', 'над', 'очень', 'был', 'путь', 'мы', 'хорошо',
    'что', 'где', 'который', 'пока', 'кто', 'с кем', 'хотел бы', 'ты', 'твои',
    'а', 'б', 'в', 'г', 'д', 'е', 'ё', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н',
    'o', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь',
    'э', 'ю', 'я','$', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];
    
// tell the world about the noise words.    
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\stopwords_sv.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/stopwords_sv.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2017, Dogan Yazar

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
const words = ["aderton","adertonde","adjö","aldrig","alla","allas","allt","alltid",
"alltså","andra","andras","annan","annat","artonde","artonn","att","av","bakom",
"bara","behöva","behövas","behövde","behövt","beslut","beslutat","beslutit","bland",
"blev","bli","blir","blivit","bort","borta","bra","bäst","bättre","båda","bådas",
"dag","dagar","dagarna","dagen","de","del","delen","dem","den","denna","deras",
"dess","dessa","det","detta","dig","din","dina","dit","ditt","dock","dom","du",
"där","därför","då","e","efter","eftersom","ej","elfte","eller","elva","emot","en",
"enkel","enkelt","enkla","enligt","ens","er","era","ers","ert","ett","ettusen",
"fanns","fem","femte","femtio","femtionde","femton","femtonde","fick","fin",
"finnas","finns","fjorton","fjortonde","fjärde","fler","flera","flesta","fram",
"framför","från","fyra","fyrtio","fyrtionde","få","får","fått","följande","för",
"före","förlåt","förra","första","genast","genom","gick","gjorde","gjort","god",
"goda","godare","godast","gott","gälla","gäller","gällt","gärna","gå","går","gått",
"gör","göra","ha","hade","haft","han","hans","har","heller","hellre","helst","helt",
"henne","hennes","hit","hon","honom","hundra","hundraen","hundraett","hur","här",
"hög","höger","högre","högst","i","ibland","icke","idag","igen","igår","imorgon",
"in","inför","inga","ingen","ingenting","inget","innan","inne","inom","inte",
"inuti","ja","jag","jo","ju","just","jämfört","kan","kanske","knappast","kom",
"komma","kommer","kommit","kr","kunde","kunna","kunnat","kvar","legat","ligga",
"ligger","lika","likställd","likställda","lilla","lite","liten","litet","länge",
"längre","längst","lätt","lättare","lättast","långsam","långsammare","långsammast",
"långsamt","långt","låt","man","med","mej","mellan","men","mer","mera","mest","mig",
"min","mina","mindre","minst","mitt","mittemot","mot","mycket","många","måste",
"möjlig","möjligen","möjligt","möjligtvis","ned","nederst","nedersta","nedre",
"nej","ner","ni","nio","nionde","nittio","nittionde","nitton","nittonde","nog",
"noll","nr","nu","nummer","när","nästa","någon","någonting","något","några","nån",
"nånting","nåt","nödvändig","nödvändiga","nödvändigt","nödvändigtvis","och","också",
"ofta","oftast","olika","olikt","om","oss","på","rakt","redan","rätt","sa","sade",
"sagt","samma","sedan","senare","senast","sent","sex","sextio","sextionde","sexton",
"sextonde","sig","sin","sina","sist","sista","siste","sitt","sitta","sju","sjunde",
"sjuttio","sjuttionde","sjutton","sjuttonde","själv","sjätte","ska","skall","skulle",
"slutligen","små","smått","snart","som","stor","stora","stort","större","störst",
"säga","säger","sämre","sämst","så","sådan","sådana","sådant","ta","tack","tar",
"tidig","tidigare","tidigast","tidigt","till","tills","tillsammans","tio","tionde",
"tjugo","tjugoen","tjugoett","tjugonde","tjugotre","tjugotvå","tjungo","tolfte",
"tolv","tre","tredje","trettio","trettionde","tretton","trettonde","två","tvåhundra",
"under","upp","ur","ursäkt","ut","utan","utanför","ute","va","vad","var","vara",
"varför","varifrån","varit","varje","varken","vars","varsågod","vart","vem","vems",
"verkligen","vi","vid","vidare","viktig","viktigare","viktigast","viktigt","vilka",
"vilkas","vilken","vilket","vill","väl","vänster","vänstra","värre","vår","våra",
"vårt","än","ännu","är","även","åt","åtminstone","åtta","åttio","åttionde",
"åttonde","över","övermorgon","överst","övre", "1", "2", "3", "4", "5", "6", "7",
"8", "9", "0"]

// tell the world about the noise words.
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\topological.js":
/*!******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/topological.js ***!
  \******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*
 Copyright (c) 2014, Lee Wenzhu

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */


/**
 * a topo sort for a digraph
 * @param {Digraph}
 */
var Topological = function(g) {
    this.isDag = true;
    this.sorted = topoSort(uniqueVertexs(g.edges()), g.edges());
};

Topological.prototype.isDAG = function() {
    return this.isDag;
};

/**
 * get ordered vertexs of digraph
 */
Topological.prototype.order = function() {
    return this.sorted.slice();
};

/**
 * @param {Array} all vertex in digraph
 * @param {Object} all edges in the digraph
 */
function topoSort(vertexs, edges) {
    var sorted = [];
    var cursor = vertexs.length,
        visited = {},
        i = cursor;
    while (i--) {
        if (!visited[i]) visit(vertexs[i], i, []);
    }

    return sorted.reverse();

    function visit(vertex, i, predecessors) {
        if(predecessors.indexOf(vertex) >= 0) {
            throw new Error('Cyclic dependency:' + JSON.stringify(vertex));
        }

        if(visited[i]) return;
        visited[i] = true;

        var outgoing = edges.filter(function(edge) {
            return edge.to() === vertex;
        });

        var preds = [];
        if(outgoing.length > 0) {
            preds = predecessors.concat(vertex);
        }
        var from;
        outgoing.forEach(function(edge) {
            from = edge.from();
            visit(from, vertexs.indexOf(from), preds);
        });

        sorted[--cursor] = vertex;
    };
};


function uniqueVertexs(edges) {
    var vertexs = [];
    var from, to;
    edges.forEach(function(edge) {
        from = edge.from();
        to = edge.to();
        if (vertexs.indexOf(from) < 0) vertexs.push(from);
        if (vertexs.indexOf(to) < 0) vertexs.push(to);
    });
    return vertexs;
};

module.exports = Topological;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\util\\utils.js":
/*!************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/util/utils.js ***!
  \************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
 Copyright (c) 2012, Guillaume Marty

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 */


/**
 * Generate a replacing function given a table of patterns. Inspired by:
 * http://code.google.com/p/jslibs/wiki/JavascriptTips#String_converter
 * The order of elements is significant. Longer elements should be listed first.
 * @see Speed test http://jsperf.com/build-a-regexp-table
 *
 * @param {Object.<string, string>} translationTable The translation table of key value.
 * @return {function(string): string} A translating function.
 */
function replacer(translationTable) {
  /**
   * An array of translationTable keys.
   * @type {Array.<string>}
   */
  var pattern = [];

  /**
   * The regular expression doing the replacement job.
   * @type {RegExp}
   */
  var regExp;

  /**
   * Used to iterate over translationTable.
   * @type {string}
   */
  var key;

  for (key in translationTable) {
    // Escaping regexp special chars.
    // @see Speed test for type casting to string http://jsperf.com/string-type-casting/2
    // @see http://closure-library.googlecode.com/svn/docs/closure_goog_string_string.js.source.html#line956
    key = ('' + key).replace(/([-()\[\]{}+?*.$\^|,:#<!\\\/])/g, '\\$1').
      replace(/\x08/g, '\\x08');

    pattern.push(key);
  }

  regExp = new RegExp(pattern.join('|'), 'g');

  /**
   * @param {string} str Input string.
   * @return {string} The string replaced.
   */
  return function(str) {
    return str.replace(regExp, function(str) {
      return translationTable[str];
    });
  };
}


/**
 * Exchanges all keys with their associated values in an object.
 *
 * @param {Object.<string, string>} obj An object of strings.
 * @return {Object.<string, string>} An object of strings.
 */
function flip(obj) {
  var newObj = Object.create(null),
      key;

  for (key in obj) {
    newObj[obj[key]] = key;
  }

  return newObj;
}


/**
 * Merge several objects. Properties from earlier objects are overwritten by
 * laters's in case of conflict.
 *
 * @param {...Object.<string, string>} var_args One or more objects of strings.
 * @return {!Object.<string, string>} An object of strings.
 */
function merge(var_args) {
  var args = [].slice.call(arguments),
      newObj = Object.create(null),
      id = 0, key;

  while (args[id]) {
    for (key in args[id]) {
      newObj[key] = args[id][key];
    }

    id++;
  }

  return newObj;
}

exports.replacer = replacer;
exports.flip = flip;
exports.merge = merge;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\data_file.js":
/*!*******************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/wordnet/data_file.js ***!
  \*******************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer) {/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var WordNetFile = __webpack_require__(/*! ./wordnet_file */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\wordnet_file.js"),
  fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js"),
  util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

function get(location, callback) {
  var buff = new Buffer(4096);

  this.open(function(err, fd, done) {
    WordNetFile.appendLineChar(fd, location, 0, buff, function(line) {
      done();
      var data = line.split('| ');
      var tokens = data[0].split(/\s+/);
      var ptrs = [];
      var wCnt = parseInt(tokens[3], 16);
      var synonyms = [];

      for(var i = 0; i < wCnt; i++) {
        synonyms.push(tokens[4 + i * 2]);
      }

      var ptrOffset = (wCnt - 1) * 2 + 6;
      for(var i = 0; i < parseInt(tokens[ptrOffset], 10); i++) {
        ptrs.push({
          pointerSymbol: tokens[ptrOffset + 1 + i * 4],
          synsetOffset: parseInt(tokens[ptrOffset + 2 + i * 4], 10),
          pos: tokens[ptrOffset + 3 + i * 4],
          sourceTarget: tokens[ptrOffset + 4 + i * 4]
        });
      }

      // break "gloss" into definition vs. examples
      var glossArray = data[1].split("; ");
      var definition = glossArray[0];
      var examples = glossArray.slice(1);    

      for (var k=0; k < examples.length; k++) {
        examples[k] = examples[k].replace(/\"/g,'').replace(/\s\s+/g,'');
      }
      
      callback({
        synsetOffset: parseInt(tokens[0], 10),
        lexFilenum: parseInt(tokens[1], 10),
        pos: tokens[2],
        wCnt: wCnt,
        lemma: tokens[4],
        synonyms: synonyms,
        lexId: tokens[5],
        ptrs: ptrs,
        gloss: data[1],
        def: definition,
        exp: examples
      });
    });
  });
}

var DataFile = function(dataDir, name) {
  WordNetFile.call(this, dataDir, 'data.' + name);
};

util.inherits(DataFile, WordNetFile);
DataFile.prototype.get = get;

module.exports = DataFile;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../../../webpack/node_modules/buffer/index.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\buffer\\index.js").Buffer))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\index_file.js":
/*!********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/wordnet/index_file.js ***!
  \********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer) {/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var WordNetFile = __webpack_require__(/*! ./wordnet_file */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\wordnet_file.js"),
  fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js"),
  util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");

function getFileSize(path) {
  var stat = fs.statSync(path);
  return stat.size;
}

function findPrevEOL(fd, pos, callback) {
  var buff = new Buffer(1024);
  if(pos == 0)
    callback(0);
  else {
    fs.read(fd, buff, 0, 1, pos, function(err, count) {
      if(buff[0] == 10)
        callback(pos + 1);
      else
        findPrevEOL(fd, pos - 1, callback);
    });
  }
}

function readLine(fd, pos, callback) {
  var buff = new Buffer(1024);
  findPrevEOL(fd, pos, function(pos) {
    WordNetFile.appendLineChar(fd, pos, 0, buff, callback);
  });
}

function miss(callback) {
  callback({status: 'miss'});
}

function findAt(fd, size, pos, lastPos, adjustment, searchKey, callback, lastKey) {
  if (lastPos == pos || pos >= size) {
    miss(callback);
  } else {
    readLine(fd, pos, function(line) {
      var tokens = line.split(/\s+/);
      var key = tokens[0];

    if(key == searchKey) {
        callback({status: 'hit', key: key, 'line': line, tokens: tokens});
      } else if(adjustment == 1 || key == lastKey)  {
        miss(callback);
      } else {
        adjustment = Math.ceil(adjustment * 0.5);

        if (key < searchKey) {
          findAt(fd, size, pos + adjustment, pos, adjustment, searchKey, callback, key);
        } else {
          findAt(fd, size, pos - adjustment, pos, adjustment, searchKey, callback, key);
        }
      }
    });
  }
}

function find(searchKey, callback) {
  var indexFile = this;

  indexFile.open(function(err, fd, done) {
    if(err) {
      console.log(err);
    } else {
      var size = getFileSize(indexFile.filePath) - 1;
      var pos = Math.ceil(size / 2);
      findAt(fd, size, pos, null, pos, searchKey,
        function(result) { callback(result); done(); });
    }
  });
}

function lookupFromFile(word, callback) {
  this.find(word, function(record) {
    var indexRecord = null;

    if(record.status == 'hit') {
      var ptrs = [], offsets = [];

      for(var i = 0; i < parseInt(record.tokens[3]); i++)
        ptrs.push(record.tokens[i]);

      for(var i = 0; i < parseInt(record.tokens[2]); i++)
        offsets.push(parseInt(record.tokens[ptrs.length + 6 + i], 10));

      indexRecord = {
        lemma: record.tokens[0],
        pos: record.tokens[1],
        ptrSymbol: ptrs,
        senseCnt:  parseInt(record.tokens[ptrs.length + 4], 10),
        tagsenseCnt:  parseInt(record.tokens[ptrs.length + 5], 10),
        synsetOffset:  offsets
      };
    }

    callback(indexRecord);
  });
}

function lookup(word, callback) {
  this.lookupFromFile(word, callback);
}

var IndexFile = function(dataDir, name) {
  WordNetFile.call(this, dataDir, 'index.' + name);
};

util.inherits(IndexFile, WordNetFile);

IndexFile.prototype.lookupFromFile = lookupFromFile;
IndexFile.prototype.lookup = lookup;
IndexFile.prototype.find = find;

IndexFile.prototype._findAt = findAt;

module.exports = IndexFile;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../../../webpack/node_modules/buffer/index.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\buffer\\index.js").Buffer))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\wordnet.js":
/*!*****************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/wordnet/wordnet.js ***!
  \*****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var IndexFile = __webpack_require__(/*! ./index_file */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\index_file.js"),
  DataFile = __webpack_require__(/*! ./data_file */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\data_file.js");

function pushResults(data, results, offsets, callback) {
  var wordnet = this;

  if(offsets.length == 0) {
    callback(results);
  } else {
    data.get(offsets.pop(), function(record) {
      results.push(record);
      wordnet.pushResults(data, results, offsets, callback);
    });
  }
}

function lookupFromFiles(files, results, word, callback) {
  var wordnet = this;

  if(files.length == 0)
    callback(results);
  else {
    var file = files.pop();

    file.index.lookup(word, function(record) {
      if(record) {
        wordnet.pushResults(file.data, results, record.synsetOffset, function() {
          wordnet.lookupFromFiles(files, results, word, callback);
        });
      } else {
        wordnet.lookupFromFiles(files, results, word, callback);
      }
    });
  }
}

function lookup(word, callback) {
  word = word.toLowerCase().replace(/\s+/g, '_');

  this.lookupFromFiles([
    {index: this.nounIndex, data: this.nounData},
    {index: this.verbIndex, data: this.verbData},
    {index: this.adjIndex, data: this.adjData},
    {index: this.advIndex, data: this.advData},
  ], [], word, callback);
}

function get(synsetOffset, pos, callback) {
  var dataFile = this.getDataFile(pos);
  var wordnet = this;

  dataFile.get(synsetOffset, function(result) {
    callback(result);
  });
}

function getDataFile(pos) {
    switch(pos) {
      case 'n':
        return this.nounData;
      case 'v':
        return this.verbData;
      case 'a': case 's':
        return this.adjData;
      case 'r':
        return this.advData;
    }
}

function loadSynonyms(synonyms, results, ptrs, callback) {
  var wordnet = this;

  if(ptrs.length > 0) {
    var ptr = ptrs.pop();

    this.get(ptr.synsetOffset, ptr.pos, function(result) {
      synonyms.push(result);
      wordnet.loadSynonyms(synonyms, results, ptrs, callback);
    });
  } else {
    wordnet.loadResultSynonyms(synonyms, results, callback);
  }
}

function loadResultSynonyms(synonyms, results, callback) {
  var wordnet = this;

  if(results.length > 0) {
    var result = results.pop();
    wordnet.loadSynonyms(synonyms, results, result.ptrs, callback);
  } else
    callback(synonyms);
}

function lookupSynonyms(word, callback) {
  var wordnet = this;

  wordnet.lookup(word, function(results) {
    wordnet.loadResultSynonyms([], results, callback);
  });
}

function getSynonyms() {
  var wordnet = this;
  var callback = arguments[2] ? arguments[2] : arguments[1];
  var pos = arguments[0].pos ? arguments[0].pos : arguments[1];
  var synsetOffset = arguments[0].synsetOffset ? arguments[0].synsetOffset : arguments[0];

  this.get(synsetOffset, pos, function(result) {
    wordnet.loadSynonyms([], [], result.ptrs, callback);
  });
}

function WordNet(dataDir) {

  if (!dataDir) {
    try {
      var WNdb = __webpack_require__(/*! wordnet-db */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordnet-db\\index.js");
    } catch(e) {
      console.error("Please 'npm install wordnet-db' before using WordNet module or specify a dict directory.");
      throw e;
    }
    dataDir = WNdb.path;
  }

  this.nounIndex = new IndexFile(dataDir, 'noun');
  this.verbIndex = new IndexFile(dataDir, 'verb');
  this.adjIndex = new IndexFile(dataDir, 'adj');
  this.advIndex = new IndexFile(dataDir, 'adv');

  this.nounData = new DataFile(dataDir, 'noun');
  this.verbData = new DataFile(dataDir, 'verb');
  this.adjData = new DataFile(dataDir, 'adj');
  this.advData = new DataFile(dataDir, 'adv');

  this.get = get;
  this.lookup = lookup;
  this.lookupFromFiles = lookupFromFiles;
  this.pushResults = pushResults;
  this.loadResultSynonyms = loadResultSynonyms;
  this.loadSynonyms = loadSynonyms;
  this.lookupSynonyms = lookupSynonyms;
  this.getSynonyms = getSynonyms;
  this.getDataFile = getDataFile;
}

module.exports = WordNet;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\wordnet\\wordnet_file.js":
/*!**********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/natural/lib/natural/wordnet/wordnet_file.js ***!
  \**********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer) {/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

var  fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js"),
  path = __webpack_require__(/*! path */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\path-browserify\\index.js"),
  util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js");


function appendLineChar(fd, pos, buffPos, buff, callback) {
  if(buffPos >= buff.length) {
    var newBuff = new Buffer(buff.length * 2);
    buff.copy(newBuff, 0, 0, buff.length);
    buff = newBuff;
  }

  fs.read(fd, buff, buffPos, 1, pos, function(err, count) {
    if(err)
      console.log(err);
    else {
      if(buff[buffPos] == 10 || buffPos == buff.length)
        callback(buff.slice(0, buffPos).toString('UTF-8'));
      else {
        appendLineChar(fd, pos + 1, buffPos + 1, buff, callback);
      }
    }
  });
}

function open(callback) {
  var filePath = this.filePath;

  fs.open(filePath, 'r', null, function(err, fd) {
    if (err) {
        console.log('Unable to open %s', filePath);
        return;
    }
    callback(err, fd, function() {
      fs.close(fd, function(error) {
        if (error) {
          throw error;
        }
      })
    });
  });
}

var WordNetFile = function(dataDir, fileName) {
  this.dataDir = dataDir;
  this.fileName = fileName;
  this.filePath = __webpack_require__(/*! path */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\path-browserify\\index.js").join(this.dataDir, this.fileName);
};

WordNetFile.prototype.open = open;
WordNetFile.appendLineChar = appendLineChar;

module.exports = WordNetFile;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../../../webpack/node_modules/buffer/index.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\buffer\\index.js").Buffer))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\index.js":
/*!****************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/sylvester/lib/node-sylvester/index.js ***!
  \****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global) {// Copyright (c) 2011, Chris Umbel

exports.Vector = __webpack_require__(/*! ./vector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\vector.js");
global.$V = exports.Vector.create;
exports.Matrix = __webpack_require__(/*! ./matrix */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\matrix.js");
global.$M = exports.Matrix.create;
exports.Line = __webpack_require__(/*! ./line */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\line.js");
global.$L = exports.Line.create;
exports.Plane = __webpack_require__(/*! ./plane */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\plane.js");
global.$P = exports.Plane.create;
exports.Line.Segment = __webpack_require__(/*! ./line.segment */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\line.segment.js");
exports.Sylvester = __webpack_require__(/*! ./sylvester */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\sylvester.js");

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../../webpack/buildin/global.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\buildin\\global.js")))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\line.js":
/*!***************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/sylvester/lib/node-sylvester/line.js ***!
  \***************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// Copyright (c) 2011, Chris Umbel, James Coglan
var Vector = __webpack_require__(/*! ./vector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\vector.js");
var Matrix = __webpack_require__(/*! ./matrix */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\matrix.js");
var Plane = __webpack_require__(/*! ./plane */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\plane.js");
var Sylvester = __webpack_require__(/*! ./sylvester */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\sylvester.js");

// Line class - depends on Vector, and some methods require Matrix and Plane.

function Line() {}
Line.prototype = {

  // Returns true if the argument occupies the same space as the line
  eql: function(line) {
    return (this.isParallelTo(line) && this.contains(line.anchor));
  },

  // Returns a copy of the line
  dup: function() {
    return Line.create(this.anchor, this.direction);
  },

  // Returns the result of translating the line by the given vector/array
  translate: function(vector) {
    var V = vector.elements || vector;
    return Line.create([
      this.anchor.elements[0] + V[0],
      this.anchor.elements[1] + V[1],
      this.anchor.elements[2] + (V[2] || 0)
    ], this.direction);
  },

  // Returns true if the line is parallel to the argument. Here, 'parallel to'
  // means that the argument's direction is either parallel or antiparallel to
  // the line's own direction. A line is parallel to a plane if the two do not
  // have a unique intersection.
  isParallelTo: function(obj) {
    if (obj.normal || (obj.start && obj.end)) { return obj.isParallelTo(this); }
    var theta = this.direction.angleFrom(obj.direction);
    return (Math.abs(theta) <= Sylvester.precision || Math.abs(theta - Math.PI) <= Sylvester.precision);
  },

  // Returns the line's perpendicular distance from the argument,
  // which can be a point, a line or a plane
  distanceFrom: function(obj) {
    if (obj.normal || (obj.start && obj.end)) { return obj.distanceFrom(this); }
    if (obj.direction) {
      // obj is a line
      if (this.isParallelTo(obj)) { return this.distanceFrom(obj.anchor); }
      var N = this.direction.cross(obj.direction).toUnitVector().elements;
      var A = this.anchor.elements, B = obj.anchor.elements;
      return Math.abs((A[0] - B[0]) * N[0] + (A[1] - B[1]) * N[1] + (A[2] - B[2]) * N[2]);
    } else {
      // obj is a point
      var P = obj.elements || obj;
      var A = this.anchor.elements, D = this.direction.elements;
      var PA1 = P[0] - A[0], PA2 = P[1] - A[1], PA3 = (P[2] || 0) - A[2];
      var modPA = Math.sqrt(PA1*PA1 + PA2*PA2 + PA3*PA3);
      if (modPA === 0) return 0;
      // Assumes direction vector is normalized
      var cosTheta = (PA1 * D[0] + PA2 * D[1] + PA3 * D[2]) / modPA;
      var sin2 = 1 - cosTheta*cosTheta;
      return Math.abs(modPA * Math.sqrt(sin2 < 0 ? 0 : sin2));
    }
  },

  // Returns true iff the argument is a point on the line, or if the argument
  // is a line segment lying within the receiver
  contains: function(obj) {
    if (obj.start && obj.end) { return this.contains(obj.start) && this.contains(obj.end); }
    var dist = this.distanceFrom(obj);
    return (dist !== null && dist <= Sylvester.precision);
  },

  // Returns the distance from the anchor of the given point. Negative values are
  // returned for points that are in the opposite direction to the line's direction from
  // the line's anchor point.
  positionOf: function(point) {
    if (!this.contains(point)) { return null; }
    var P = point.elements || point;
    var A = this.anchor.elements, D = this.direction.elements;
    return (P[0] - A[0]) * D[0] + (P[1] - A[1]) * D[1] + ((P[2] || 0) - A[2]) * D[2];
  },

  // Returns true iff the line lies in the given plane
  liesIn: function(plane) {
    return plane.contains(this);
  },

  // Returns true iff the line has a unique point of intersection with the argument
  intersects: function(obj) {
    if (obj.normal) { return obj.intersects(this); }
    return (!this.isParallelTo(obj) && this.distanceFrom(obj) <= Sylvester.precision);
  },

  // Returns the unique intersection point with the argument, if one exists
  intersectionWith: function(obj) {
    if (obj.normal || (obj.start && obj.end)) { return obj.intersectionWith(this); }
    if (!this.intersects(obj)) { return null; }
    var P = this.anchor.elements, X = this.direction.elements,
        Q = obj.anchor.elements, Y = obj.direction.elements;
    var X1 = X[0], X2 = X[1], X3 = X[2], Y1 = Y[0], Y2 = Y[1], Y3 = Y[2];
    var PsubQ1 = P[0] - Q[0], PsubQ2 = P[1] - Q[1], PsubQ3 = P[2] - Q[2];
    var XdotQsubP = - X1*PsubQ1 - X2*PsubQ2 - X3*PsubQ3;
    var YdotPsubQ = Y1*PsubQ1 + Y2*PsubQ2 + Y3*PsubQ3;
    var XdotX = X1*X1 + X2*X2 + X3*X3;
    var YdotY = Y1*Y1 + Y2*Y2 + Y3*Y3;
    var XdotY = X1*Y1 + X2*Y2 + X3*Y3;
    var k = (XdotQsubP * YdotY / XdotX + XdotY * YdotPsubQ) / (YdotY - XdotY * XdotY);
    return Vector.create([P[0] + k*X1, P[1] + k*X2, P[2] + k*X3]);
  },

  // Returns the point on the line that is closest to the given point or line/line segment
  pointClosestTo: function(obj) {
    if (obj.start && obj.end) {
      // obj is a line segment
      var P = obj.pointClosestTo(this);
      return (P === null) ? null : this.pointClosestTo(P);
    } else if (obj.direction) {
      // obj is a line
      if (this.intersects(obj)) { return this.intersectionWith(obj); }
      if (this.isParallelTo(obj)) { return null; }
      var D = this.direction.elements, E = obj.direction.elements;
      var D1 = D[0], D2 = D[1], D3 = D[2], E1 = E[0], E2 = E[1], E3 = E[2];
      // Create plane containing obj and the shared normal and intersect this with it
      // Thank you: http://www.cgafaq.info/wiki/Line-line_distance
      var x = (D3 * E1 - D1 * E3), y = (D1 * E2 - D2 * E1), z = (D2 * E3 - D3 * E2);
      var N = [x * E3 - y * E2, y * E1 - z * E3, z * E2 - x * E1];
      var P = Plane.create(obj.anchor, N);
      return P.intersectionWith(this);
    } else {
      // obj is a point
      var P = obj.elements || obj;
      if (this.contains(P)) { return Vector.create(P); }
      var A = this.anchor.elements, D = this.direction.elements;
      var D1 = D[0], D2 = D[1], D3 = D[2], A1 = A[0], A2 = A[1], A3 = A[2];
      var x = D1 * (P[1]-A2) - D2 * (P[0]-A1), y = D2 * ((P[2] || 0) - A3) - D3 * (P[1]-A2),
          z = D3 * (P[0]-A1) - D1 * ((P[2] || 0) - A3);
      var V = Vector.create([D2 * x - D3 * z, D3 * y - D1 * x, D1 * z - D2 * y]);
      var k = this.distanceFrom(P) / V.modulus();
      return Vector.create([
        P[0] + V.elements[0] * k,
        P[1] + V.elements[1] * k,
        (P[2] || 0) + V.elements[2] * k
      ]);
    }
  },

  // Returns a copy of the line rotated by t radians about the given line. Works by
  // finding the argument's closest point to this line's anchor point (call this C) and
  // rotating the anchor about C. Also rotates the line's direction about the argument's.
  // Be careful with this - the rotation axis' direction affects the outcome!
  rotate: function(t, line) {
    // If we're working in 2D
    if (typeof(line.direction) == 'undefined') { line = Line.create(line.to3D(), Vector.k); }
    var R = Matrix.Rotation(t, line.direction).elements;
    var C = line.pointClosestTo(this.anchor).elements;
    var A = this.anchor.elements, D = this.direction.elements;
    var C1 = C[0], C2 = C[1], C3 = C[2], A1 = A[0], A2 = A[1], A3 = A[2];
    var x = A1 - C1, y = A2 - C2, z = A3 - C3;
    return Line.create([
      C1 + R[0][0] * x + R[0][1] * y + R[0][2] * z,
      C2 + R[1][0] * x + R[1][1] * y + R[1][2] * z,
      C3 + R[2][0] * x + R[2][1] * y + R[2][2] * z
    ], [
      R[0][0] * D[0] + R[0][1] * D[1] + R[0][2] * D[2],
      R[1][0] * D[0] + R[1][1] * D[1] + R[1][2] * D[2],
      R[2][0] * D[0] + R[2][1] * D[1] + R[2][2] * D[2]
    ]);
  },

  // Returns a copy of the line with its direction vector reversed.
  // Useful when using lines for rotations.
  reverse: function() {
    return Line.create(this.anchor, this.direction.x(-1));
  },

  // Returns the line's reflection in the given point or line
  reflectionIn: function(obj) {
    if (obj.normal) {
      // obj is a plane
      var A = this.anchor.elements, D = this.direction.elements;
      var A1 = A[0], A2 = A[1], A3 = A[2], D1 = D[0], D2 = D[1], D3 = D[2];
      var newA = this.anchor.reflectionIn(obj).elements;
      // Add the line's direction vector to its anchor, then mirror that in the plane
      var AD1 = A1 + D1, AD2 = A2 + D2, AD3 = A3 + D3;
      var Q = obj.pointClosestTo([AD1, AD2, AD3]).elements;
      var newD = [Q[0] + (Q[0] - AD1) - newA[0], Q[1] + (Q[1] - AD2) - newA[1], Q[2] + (Q[2] - AD3) - newA[2]];
      return Line.create(newA, newD);
    } else if (obj.direction) {
      // obj is a line - reflection obtained by rotating PI radians about obj
      return this.rotate(Math.PI, obj);
    } else {
      // obj is a point - just reflect the line's anchor in it
      var P = obj.elements || obj;
      return Line.create(this.anchor.reflectionIn([P[0], P[1], (P[2] || 0)]), this.direction);
    }
  },

  // Set the line's anchor point and direction.
  setVectors: function(anchor, direction) {
    // Need to do this so that line's properties are not
    // references to the arguments passed in
    anchor = Vector.create(anchor);
    direction = Vector.create(direction);
    if (anchor.elements.length == 2) {anchor.elements.push(0); }
    if (direction.elements.length == 2) { direction.elements.push(0); }
    if (anchor.elements.length > 3 || direction.elements.length > 3) { return null; }
    var mod = direction.modulus();
    if (mod === 0) { return null; }
    this.anchor = anchor;
    this.direction = Vector.create([
      direction.elements[0] / mod,
      direction.elements[1] / mod,
      direction.elements[2] / mod
    ]);
    return this;
  }
};

// Constructor function
Line.create = function(anchor, direction) {
  var L = new Line();
  return L.setVectors(anchor, direction);
};

// Axes
Line.X = Line.create(Vector.Zero(3), Vector.i);
Line.Y = Line.create(Vector.Zero(3), Vector.j);
Line.Z = Line.create(Vector.Zero(3), Vector.k);

module.exports = Line;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\line.segment.js":
/*!***********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/sylvester/lib/node-sylvester/line.segment.js ***!
  \***********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// Copyright (c) 2011, Chris Umbel, James Coglan
// Line.Segment class - depends on Line and its dependencies.

var Line = __webpack_require__(/*! ./line */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\line.js");
var Vector = __webpack_require__(/*! ./vector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\vector.js");

Line.Segment = function() {};
Line.Segment.prototype = {

  // Returns true iff the line segment is equal to the argument
  eql: function(segment) {
    return (this.start.eql(segment.start) && this.end.eql(segment.end)) ||
        (this.start.eql(segment.end) && this.end.eql(segment.start));
  },

  // Returns a copy of the line segment
  dup: function() {
    return Line.Segment.create(this.start, this.end);
  },

  // Returns the length of the line segment
  length: function() {
    var A = this.start.elements, B = this.end.elements;
    var C1 = B[0] - A[0], C2 = B[1] - A[1], C3 = B[2] - A[2];
    return Math.sqrt(C1*C1 + C2*C2 + C3*C3);
  },

  // Returns the line segment as a vector equal to its
  // end point relative to its endpoint
  toVector: function() {
    var A = this.start.elements, B = this.end.elements;
    return Vector.create([B[0] - A[0], B[1] - A[1], B[2] - A[2]]);
  },

  // Returns the segment's midpoint as a vector
  midpoint: function() {
    var A = this.start.elements, B = this.end.elements;
    return Vector.create([(B[0] + A[0])/2, (B[1] + A[1])/2, (B[2] + A[2])/2]);
  },

  // Returns the plane that bisects the segment
  bisectingPlane: function() {
    return Plane.create(this.midpoint(), this.toVector());
  },

  // Returns the result of translating the line by the given vector/array
  translate: function(vector) {
    var V = vector.elements || vector;
    var S = this.start.elements, E = this.end.elements;
    return Line.Segment.create(
      [S[0] + V[0], S[1] + V[1], S[2] + (V[2] || 0)],
      [E[0] + V[0], E[1] + V[1], E[2] + (V[2] || 0)]
    );
  },

  // Returns true iff the line segment is parallel to the argument. It simply forwards
  // the method call onto its line property.
  isParallelTo: function(obj) {
    return this.line.isParallelTo(obj);
  },

  // Returns the distance between the argument and the line segment's closest point to the argument
  distanceFrom: function(obj) {
    var P = this.pointClosestTo(obj);
    return (P === null) ? null : P.distanceFrom(obj);
  },

  // Returns true iff the given point lies on the segment
  contains: function(obj) {
    if (obj.start && obj.end) { return this.contains(obj.start) && this.contains(obj.end); }
    var P = (obj.elements || obj).slice();
    if (P.length == 2) { P.push(0); }
    if (this.start.eql(P)) { return true; }
    var S = this.start.elements;
    var V = Vector.create([S[0] - P[0], S[1] - P[1], S[2] - (P[2] || 0)]);
    var vect = this.toVector();
    return V.isAntiparallelTo(vect) && V.modulus() <= vect.modulus();
  },

  // Returns true iff the line segment intersects the argument
  intersects: function(obj) {
    return (this.intersectionWith(obj) !== null);
  },

  // Returns the unique point of intersection with the argument
  intersectionWith: function(obj) {
    if (!this.line.intersects(obj)) { return null; }
    var P = this.line.intersectionWith(obj);
    return (this.contains(P) ? P : null);
  },

  // Returns the point on the line segment closest to the given object
  pointClosestTo: function(obj) {
    if (obj.normal) {
      // obj is a plane
      var V = this.line.intersectionWith(obj);
      if (V === null) { return null; }
      return this.pointClosestTo(V);
    } else {
      // obj is a line (segment) or point
      var P = this.line.pointClosestTo(obj);
      if (P === null) { return null; }
      if (this.contains(P)) { return P; }
      return (this.line.positionOf(P) < 0 ? this.start : this.end).dup();
    }
  },

  // Set the start and end-points of the segment
  setPoints: function(startPoint, endPoint) {
    startPoint = Vector.create(startPoint).to3D();
    endPoint = Vector.create(endPoint).to3D();
    if (startPoint === null || endPoint === null) { return null; }
    this.line = Line.create(startPoint, endPoint.subtract(startPoint));
    this.start = startPoint;
    this.end = endPoint;
    return this;
  }
};

// Constructor function
Line.Segment.create = function(v1, v2) {
  var S = new Line.Segment();
  return S.setPoints(v1, v2);
};

module.exports = Line.Segment;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\matrix.js":
/*!*****************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/sylvester/lib/node-sylvester/matrix.js ***!
  \*****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// Copyright (c) 2011, Chris Umbel, James Coglan
// Matrix class - depends on Vector.

var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");
var Sylvester = __webpack_require__(/*! ./sylvester */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\sylvester.js");
var Vector = __webpack_require__(/*! ./vector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\vector.js");

// augment a matrix M with identity rows/cols
function identSize(M, m, n, k) {
    var e = M.elements;
    var i = k - 1;

    while(i--) {
	var row = [];
	
	for(var j = 0; j < n; j++)
	    row.push(j == i ? 1 : 0);
	
        e.unshift(row);
    }
    
    for(var i = k - 1; i < m; i++) {
        while(e[i].length < n)
            e[i].unshift(0);
    }

    return $M(e);
}

function pca(X) {
    var Sigma = X.transpose().x(X).x(1 / X.rows());
    var svd = Sigma.svd();
    return {U: svd.U, S: svd.S};
}

function Matrix() {}
Matrix.prototype = {
    pcaProject: function(k, U) {
	var U = U || pca(this).U;
	var Ureduce= U.slice(1, U.rows(), 1, k);
	return {Z: this.x(Ureduce), U: U};
    },

    pcaRecover: function(U) {
	var k = this.cols();
	var Ureduce = U.slice(1, U.rows(), 1, k);
	return this.x(Ureduce.transpose());
    },    

    triu: function(k) {
	if(!k)
	    k = 0;
	
	return this.map(function(x, i, j) {
	    return j - i >= k ? x : 0;
	});
    },

    svd: function() {
	var A = this;
	var U = Matrix.I(A.rows());
	var S = A.transpose();
	var V = Matrix.I(A.cols());
	var err = Number.MAX_VALUE;
	var i = 0;
	var maxLoop = 100;

	while(err > 2.2737e-13 && i < maxLoop) {
	    var qr = S.transpose().qr();
	    S = qr.R;
	    U = U.x(qr.Q);
	    qr = S.transpose().qr();
	    V = V.x(qr.Q);
	    S = qr.R;

	    var e = S.triu(1).unroll().norm();
	    var f = S.diagonal().norm();

	    if(f == 0)
		f = 1;

	    err = e / f;

	    i++;
	}

	var ss = S.diagonal();
	var s = [];

	for(var i = 1; i <= ss.cols(); i++) {
	    var ssn = ss.e(i);
	    s.push(Math.abs(ssn));

	    if(ssn < 0) {
		for(var j = 0; j < U.rows(); j++) {
		    U.elements[j][i - 1] = -(U.elements[j][i - 1]);
		}
	    }
	}

	return {U: U, S: $V(s).toDiagonalMatrix(), V: V};
    },

    unroll: function() {
	var v = [];
	
	for(var i = 1; i <= this.cols(); i++) {
	    for(var j = 1; j <= this.rows(); j++) {
		v.push(this.e(j, i));
	    }
	}

	return $V(v);
    },

    qr: function() {
	var m = this.rows();
	var n = this.cols();
	var Q = Matrix.I(m);
	var A = this;
	
	for(var k = 1; k < Math.min(m, n); k++) {
	    var ak = A.slice(k, 0, k, k).col(1);
	    var oneZero = [1];
	    
	    while(oneZero.length <=  m - k)
		oneZero.push(0);
	    
	    oneZero = $V(oneZero);
	    var vk = ak.add(oneZero.x(ak.norm() * Math.sign(ak.e(1))));
	    var Vk = $M(vk);
	    var Hk = Matrix.I(m - k + 1).subtract(Vk.x(2).x(Vk.transpose()).div(Vk.transpose().x(Vk).e(1, 1)));
	    var Qk = identSize(Hk, m, n, k);
	    A = Qk.x(A);
	    Q = Q.x(Qk);
	}

	return {Q: Q, R: A};
    },


    slice: function(startRow, endRow, startCol, endCol) {
	var x = [];
	
	if(endRow == 0)
	    endRow = this.rows();
	
	if(endCol == 0)
	    endCol = this.cols();

	for(i = startRow; i <= endRow; i++) {
	    var row = [];

	    for(j = startCol; j <= endCol; j++) {
		row.push(this.e(i, j));
	    }

	    x.push(row);
	}

	return $M(x);
    },

    // Returns element (i,j) of the matrix
    e: function(i,j) {
	if (i < 1 || i > this.elements.length || j < 1 || j > this.elements[0].length) { return null; }
	return this.elements[i - 1][j - 1];
    },

    // Returns row k of the matrix as a vector
    row: function(i) {
	if (i > this.elements.length) { return null; }
	return $V(this.elements[i - 1]);
    },

    // Returns column k of the matrix as a vector
    col: function(j) {
	if (j > this.elements[0].length) { return null; }
	var col = [], n = this.elements.length;
	for (var i = 0; i < n; i++) { col.push(this.elements[i][j - 1]); }
	return $V(col);
    },

    // Returns the number of rows/columns the matrix has
    dimensions: function() {
	return {rows: this.elements.length, cols: this.elements[0].length};
    },

    // Returns the number of rows in the matrix
    rows: function() {
	return this.elements.length;
    },

    // Returns the number of columns in the matrix
    cols: function() {
	return this.elements[0].length;
    },

    // Returns true iff the matrix is equal to the argument. You can supply
    // a vector as the argument, in which case the receiver must be a
    // one-column matrix equal to the vector.
    eql: function(matrix) {
	var M = matrix.elements || matrix;
	if (typeof(M[0][0]) == 'undefined') { M = Matrix.create(M).elements; }
	if (this.elements.length != M.length ||
            this.elements[0].length != M[0].length) { return false; }
	var i = this.elements.length, nj = this.elements[0].length, j;
	while (i--) { j = nj;
		      while (j--) {
			  if (Math.abs(this.elements[i][j] - M[i][j]) > Sylvester.precision) { return false; }
		      }
		    }
	return true;
    },

    // Returns a copy of the matrix
    dup: function() {
	return Matrix.create(this.elements);
    },

    // Maps the matrix to another matrix (of the same dimensions) according to the given function
    map: function(fn) {
    var els = [], i = this.elements.length, nj = this.elements[0].length, j;
	while (i--) { j = nj;
		      els[i] = [];
		      while (j--) {
			  els[i][j] = fn(this.elements[i][j], i + 1, j + 1);
		      }
		    }
	return Matrix.create(els);
    },

    // Returns true iff the argument has the same dimensions as the matrix
    isSameSizeAs: function(matrix) {
	var M = matrix.elements || matrix;
	if (typeof(M[0][0]) == 'undefined') { M = Matrix.create(M).elements; }
	return (this.elements.length == M.length &&
		this.elements[0].length == M[0].length);
    },

    // Returns the result of adding the argument to the matrix
    add: function(matrix) {
	if(typeof(matrix) == 'number') {
	    return this.map(function(x, i, j) { return x + matrix});
	} else {
	    var M = matrix.elements || matrix;
	    if (typeof(M[0][0]) == 'undefined') { M = Matrix.create(M).elements; }
	    if (!this.isSameSizeAs(M)) { return null; }
	    return this.map(function(x, i, j) { return x + M[i - 1][j - 1]; });
	}
    },

    // Returns the result of subtracting the argument from the matrix
    subtract: function(matrix) {
	if(typeof(matrix) == 'number') {
	    return this.map(function(x, i, j) { return x - matrix});
	} else {
	    var M = matrix.elements || matrix;
	    if (typeof(M[0][0]) == 'undefined') { M = Matrix.create(M).elements; }
	    if (!this.isSameSizeAs(M)) { return null; }
	    return this.map(function(x, i, j) { return x - M[i - 1][j - 1]; });
	}
    },

    // Returns true iff the matrix can multiply the argument from the left
    canMultiplyFromLeft: function(matrix) {
	var M = matrix.elements || matrix;
	if (typeof(M[0][0]) == 'undefined') { M = Matrix.create(M).elements; }
	// this.columns should equal matrix.rows
	return (this.elements[0].length == M.length);
    },

    // Returns the result of a multiplication-style operation the matrix from the right by the argument.
    // If the argument is a scalar then just operate on all the elements. If the argument is
    // a vector, a vector is returned, which saves you having to remember calling
    // col(1) on the result.
    mulOp: function(matrix, op) {
	if (!matrix.elements) {
	    return this.map(function(x) { return op(x, matrix); });
	}

	var returnVector = matrix.modulus ? true : false;
	var M = matrix.elements || matrix;
	if (typeof(M[0][0]) == 'undefined') 
	    M = Matrix.create(M).elements;
	if (!this.canMultiplyFromLeft(M)) 
	    return null; 
	var e = this.elements, rowThis, rowElem, elements = [],
        sum, m = e.length, n = M[0].length, o = e[0].length, i = m, j, k;

	while (i--) {
            rowElem = [];
            rowThis = e[i];
            j = n;

            while (j--) {
		sum = 0;
		k = o;

		while (k--) {
                    sum += op(rowThis[k], M[k][j]);
		}

		rowElem[j] = sum;
            }

            elements[i] = rowElem;
	}

	var M = Matrix.create(elements);
	return returnVector ? M.col(1) : M;
    },

    // Returns the result of dividing the matrix from the right by the argument.
    // If the argument is a scalar then just divide all the elements. If the argument is
    // a vector, a vector is returned, which saves you having to remember calling
    // col(1) on the result.
    div: function(matrix) {
	return this.mulOp(matrix, function(x, y) { return x / y});
    },

    // Returns the result of multiplying the matrix from the right by the argument.
    // If the argument is a scalar then just multiply all the elements. If the argument is
    // a vector, a vector is returned, which saves you having to remember calling
    // col(1) on the result.
    multiply: function(matrix) {
	return this.mulOp(matrix, function(x, y) { return x * y});
    },

    x: function(matrix) { return this.multiply(matrix); },

    elementMultiply: function(v) {
        return this.map(function(k, i, j) {
            return v.e(i, j) * k;
        });
    },

    sum: function() {
        var sum = 0;

        this.map(function(x) { sum += x;});

        return sum;
    },

    // Returns a Vector of each colum averaged.
    mean: function() {
      var dim = this.dimensions();
      var r = [];
      for (var i = 1; i <= dim.cols; i++) {
        r.push(this.col(i).sum() / dim.rows);
      }
      return $V(r);
    },

    column: function(n) {
	return this.col(n);
    },

    log: function() {
	return this.map(function(x) { return Math.log(x); });
    },

    // Returns a submatrix taken from the matrix
    // Argument order is: start row, start col, nrows, ncols
    // Element selection wraps if the required index is outside the matrix's bounds, so you could
    // use this to perform row/column cycling or copy-augmenting.
    minor: function(a, b, c, d) {
	var elements = [], ni = c, i, nj, j;
	var rows = this.elements.length, cols = this.elements[0].length;
	while (ni--) {
	    i = c - ni - 1;
	    elements[i] = [];
	    nj = d;
	    while (nj--) {
		j = d - nj - 1;
		elements[i][j] = this.elements[(a + i - 1) % rows][(b + j - 1) % cols];
	    }
	}
	return Matrix.create(elements);
    },

    // Returns the transpose of the matrix
    transpose: function() {
    var rows = this.elements.length, i, cols = this.elements[0].length, j;
	var elements = [], i = cols;
	while (i--) {
	    j = rows;
	    elements[i] = [];
	    while (j--) {
		elements[i][j] = this.elements[j][i];
	    }
	}
	return Matrix.create(elements);
    },

    // Returns true iff the matrix is square
    isSquare: function() {
	return (this.elements.length == this.elements[0].length);
    },

    // Returns the (absolute) largest element of the matrix
    max: function() {
	var m = 0, i = this.elements.length, nj = this.elements[0].length, j;
	while (i--) {
	    j = nj;
	    while (j--) {
		if (Math.abs(this.elements[i][j]) > Math.abs(m)) { m = this.elements[i][j]; }
	    }
	}
	return m;
    },

    // Returns the indeces of the first match found by reading row-by-row from left to right
    indexOf: function(x) {
	var index = null, ni = this.elements.length, i, nj = this.elements[0].length, j;
	for (i = 0; i < ni; i++) {
	    for (j = 0; j < nj; j++) {
		if (this.elements[i][j] == x) { return {i: i + 1, j: j + 1}; }
	    }
	}
	return null;
    },

    // If the matrix is square, returns the diagonal elements as a vector.
    // Otherwise, returns null.
    diagonal: function() {
	if (!this.isSquare) { return null; }
	var els = [], n = this.elements.length;
	for (var i = 0; i < n; i++) {
	    els.push(this.elements[i][i]);
	}
	return $V(els);
    },

    // Make the matrix upper (right) triangular by Gaussian elimination.
    // This method only adds multiples of rows to other rows. No rows are
    // scaled up or switched, and the determinant is preserved.
    toRightTriangular: function() {
	var M = this.dup(), els;
	var n = this.elements.length, i, j, np = this.elements[0].length, p;
	for (i = 0; i < n; i++) {
	    if (M.elements[i][i] == 0) {
		for (j = i + 1; j < n; j++) {
		    if (M.elements[j][i] != 0) {
			els = [];
			for (p = 0; p < np; p++) { els.push(M.elements[i][p] + M.elements[j][p]); }
			M.elements[i] = els;
			break;
		    }
		}
	    }
	    if (M.elements[i][i] != 0) {
		for (j = i + 1; j < n; j++) {
		    var multiplier = M.elements[j][i] / M.elements[i][i];
		    els = [];
		    for (p = 0; p < np; p++) {
			// Elements with column numbers up to an including the number
			// of the row that we're subtracting can safely be set straight to
			// zero, since that's the point of this routine and it avoids having
			// to loop over and correct rounding errors later
			els.push(p <= i ? 0 : M.elements[j][p] - M.elements[i][p] * multiplier);
		    }
		    M.elements[j] = els;
		}
	    }
	}
	return M;
    },

    toUpperTriangular: function() { return this.toRightTriangular(); },

    // Returns the determinant for square matrices
    determinant: function() {
	if (!this.isSquare()) { return null; }
	if (this.cols == 1 && this.rows == 1) { return this.row(1); }
	if (this.cols == 0 && this.rows == 0) { return 1; }
	var M = this.toRightTriangular();
	var det = M.elements[0][0], n = M.elements.length;
	for (var i = 1; i < n; i++) {
	    det = det * M.elements[i][i];
	}
	return det;
    },
    det: function() { return this.determinant(); },

    // Returns true iff the matrix is singular
    isSingular: function() {
	return (this.isSquare() && this.determinant() === 0);
    },

    // Returns the trace for square matrices
    trace: function() {
	if (!this.isSquare()) { return null; }
	var tr = this.elements[0][0], n = this.elements.length;
	for (var i = 1; i < n; i++) {
	    tr += this.elements[i][i];
	}
	return tr;
    },

    tr: function() { return this.trace(); },

    // Returns the rank of the matrix
    rank: function() {
	var M = this.toRightTriangular(), rank = 0;
	var i = this.elements.length, nj = this.elements[0].length, j;
	while (i--) {
	    j = nj;
	    while (j--) {
		if (Math.abs(M.elements[i][j]) > Sylvester.precision) { rank++; break; }
	    }
	}
	return rank;
    },

    rk: function() { return this.rank(); },

    // Returns the result of attaching the given argument to the right-hand side of the matrix
    augment: function(matrix) {
	var M = matrix.elements || matrix;
	if (typeof(M[0][0]) == 'undefined') { M = Matrix.create(M).elements; }
	var T = this.dup(), cols = T.elements[0].length;
	var i = T.elements.length, nj = M[0].length, j;
	if (i != M.length) { return null; }
	while (i--) {
	    j = nj;
	    while (j--) {
		T.elements[i][cols + j] = M[i][j];
	    }
	}
	return T;
    },

    // Returns the inverse (if one exists) using Gauss-Jordan
    inverse: function() {
	if (!this.isSquare() || this.isSingular()) { return null; }
	var n = this.elements.length, i = n, j;
	var M = this.augment(Matrix.I(n)).toRightTriangular();
	var np = M.elements[0].length, p, els, divisor;
	var inverse_elements = [], new_element;
	// Matrix is non-singular so there will be no zeros on the diagonal
	// Cycle through rows from last to first
	while (i--) {
	    // First, normalise diagonal elements to 1
	    els = [];
	    inverse_elements[i] = [];
	    divisor = M.elements[i][i];
	    for (p = 0; p < np; p++) {
        new_element = M.elements[i][p] / divisor;
		els.push(new_element);
		// Shuffle off the current row of the right hand side into the results
		// array as it will not be modified by later runs through this loop
		if (p >= n) { inverse_elements[i].push(new_element); }
	    }
	    M.elements[i] = els;
	    // Then, subtract this row from those above it to
	    // give the identity matrix on the left hand side
	    j = i;
	    while (j--) {
		els = [];
		for (p = 0; p < np; p++) {
		    els.push(M.elements[j][p] - M.elements[i][p] * M.elements[j][i]);
		}
		M.elements[j] = els;
	    }
	}
	return Matrix.create(inverse_elements);
    },

    inv: function() { return this.inverse(); },

    // Returns the result of rounding all the elements
    round: function() {
	return this.map(function(x) { return Math.round(x); });
    },

    // Returns a copy of the matrix with elements set to the given value if they
    // differ from it by less than Sylvester.precision
    snapTo: function(x) {
	return this.map(function(p) {
	    return (Math.abs(p - x) <= Sylvester.precision) ? x : p;
	});
    },

    // Returns a string representation of the matrix
    inspect: function() {
	var matrix_rows = [];
	var n = this.elements.length;
	for (var i = 0; i < n; i++) {
	    matrix_rows.push($V(this.elements[i]).inspect());
	}
	return matrix_rows.join('\n');
    },

    // Returns a array representation of the matrix
    toArray: function() {
    	var matrix_rows = [];
    	var n = this.elements.length;
    	for (var i = 0; i < n; i++) {
        matrix_rows.push(this.elements[i]);
    	}
      return matrix_rows;
    },


    // Set the matrix's elements from an array. If the argument passed
    // is a vector, the resulting matrix will be a single column.
    setElements: function(els) {
	var i, j, elements = els.elements || els;
	if (typeof(elements[0][0]) != 'undefined') {
	    i = elements.length;
	    this.elements = [];
	    while (i--) {
		j = elements[i].length;
		this.elements[i] = [];
		while (j--) {
		    this.elements[i][j] = elements[i][j];
		}
	    }
	    return this;
	}
	var n = elements.length;
	this.elements = [];
	for (i = 0; i < n; i++) {
	    this.elements.push([elements[i]]);
	}
	return this;
    },

    maxColumnIndexes: function() {
	var maxes = [];

	for(var i = 1; i <= this.rows(); i++) {
	    var max = null;
	    var maxIndex = -1;

	    for(var j = 1; j <= this.cols(); j++) {
		if(max === null || this.e(i, j) > max) {
		    max = this.e(i, j);
		    maxIndex = j;
		}
	    }

	    maxes.push(maxIndex);
	}

	return $V(maxes);
    },

    maxColumns: function() {
	var maxes = [];

	for(var i = 1; i <= this.rows(); i++) {
	    var max = null;

	    for(var j = 1; j <= this.cols(); j++) {
		if(max === null || this.e(i, j) > max) {
		    max = this.e(i, j);
		}
	    }

	    maxes.push(max);
	}

	return $V(maxes);
    },

    minColumnIndexes: function() {
	var mins = [];

	for(var i = 1; i <= this.rows(); i++) {
	    var min = null;
	    var minIndex = -1;

	    for(var j = 1; j <= this.cols(); j++) {
		if(min === null || this.e(i, j) < min) {
		    min = this.e(i, j);
		    minIndex = j;
		}
	    }

	    mins.push(minIndex);
	}

	return $V(mins);
    },

    minColumns: function() {
	var mins = [];

	for(var i = 1; i <= this.rows(); i++) {
	    var min = null;

	    for(var j = 1; j <= this.cols(); j++) {
		if(min === null || this.e(i, j) < min) {
		    min = this.e(i, j);
		}
	    }

	    mins.push(min);
	}

	return $V(mins);
    }
};

// Constructor function
Matrix.create = function(elements) {
    var M = new Matrix();
    return M.setElements(elements);
};

// Identity matrix of size n
Matrix.I = function(n) {
    var els = [], i = n, j;
    while (i--) {
	j = n;
	els[i] = [];
	while (j--) {
	    els[i][j] = (i == j) ? 1 : 0;
	}
    }
    return Matrix.create(els);
};

Matrix.loadFile = function(file) {
    var contents = fs.readFileSync(file, 'utf-8');
    var matrix = [];

    var rowArray = contents.split('\n');
    for (var i = 0; i < rowArray.length; i++) {
	var d = rowArray[i].split(',');
	if (d.length > 1) {
	    matrix.push(d);
	}
    }

    var M = new Matrix();
    return M.setElements(matrix);
};

// Diagonal matrix - all off-diagonal elements are zero
Matrix.Diagonal = function(elements) {
    var i = elements.length;
    var M = Matrix.I(i);
    while (i--) {
	M.elements[i][i] = elements[i];
    }
    return M;
};

// Rotation matrix about some axis. If no axis is
// supplied, assume we're after a 2D transform
Matrix.Rotation = function(theta, a) {
    if (!a) {
	return Matrix.create([
	    [Math.cos(theta), -Math.sin(theta)],
	    [Math.sin(theta), Math.cos(theta)]
	]);
  }
    var axis = a.dup();
    if (axis.elements.length != 3) { return null; }
    var mod = axis.modulus();
    var x = axis.elements[0] / mod, y = axis.elements[1] / mod, z = axis.elements[2] / mod;
    var s = Math.sin(theta), c = Math.cos(theta), t = 1 - c;
    // Formula derived here: http://www.gamedev.net/reference/articles/article1199.asp
    // That proof rotates the co-ordinate system so theta
    // becomes -theta and sin becomes -sin here.
    return Matrix.create([
	[t * x * x + c, t * x * y - s * z, t * x * z + s * y],
	[t * x * y + s * z, t * y * y + c, t * y * z - s * x],
	[t * x * z - s * y, t * y * z + s * x, t * z * z + c]
    ]);
};

// Special case rotations
Matrix.RotationX = function(t) {
    var c = Math.cos(t), s = Math.sin(t);
    return Matrix.create([
	[1, 0, 0],
	[0, c, -s],
	[0, s, c]
    ]);
};

Matrix.RotationY = function(t) {
    var c = Math.cos(t), s = Math.sin(t);
    return Matrix.create([
	[c, 0, s],
	[0, 1, 0],
	[-s, 0, c]
    ]);
};

Matrix.RotationZ = function(t) {
    var c = Math.cos(t), s = Math.sin(t);
    return Matrix.create([
	[c, -s, 0],
	[s, c, 0],
	[0, 0, 1]
    ]);
};

// Random matrix of n rows, m columns
Matrix.Random = function(n, m) {
    if (arguments.length === 1) m = n;
    return Matrix.Zero(n, m).map(
	function() { return Math.random(); }
  );
};

Matrix.Fill = function(n, m, v) {
    if (arguments.length === 2) {
	v = m;
	m = n;
    }

    var els = [], i = n, j;

    while (i--) {
	j = m;
	els[i] = [];

	while (j--) {
	    els[i][j] = v;
	}
    }

    return Matrix.create(els);
};

// Matrix filled with zeros
Matrix.Zero = function(n, m) {
    return Matrix.Fill(n, m, 0);
};

// Matrix filled with zeros
Matrix.Zeros = function(n, m) {
    return Matrix.Zero(n, m);
};

// Matrix filled with ones
Matrix.One = function(n, m) {
    return Matrix.Fill(n, m, 1);
};

// Matrix filled with ones
Matrix.Ones = function(n, m) {
    return Matrix.One(n, m);
};

module.exports = Matrix;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\plane.js":
/*!****************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/sylvester/lib/node-sylvester/plane.js ***!
  \****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// Copyright (c) 2011, Chris Umbel, James Coglan
// Plane class - depends on Vector. Some methods require Matrix and Line.
var Vector = __webpack_require__(/*! ./vector */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\vector.js");
var Matrix = __webpack_require__(/*! ./matrix */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\matrix.js");
var Line = __webpack_require__(/*! ./line */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\line.js");

var Sylvester = __webpack_require__(/*! ./sylvester */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\sylvester.js");

function Plane() {}
Plane.prototype = {

  // Returns true iff the plane occupies the same space as the argument
  eql: function(plane) {
    return (this.contains(plane.anchor) && this.isParallelTo(plane));
  },

  // Returns a copy of the plane
  dup: function() {
    return Plane.create(this.anchor, this.normal);
  },

  // Returns the result of translating the plane by the given vector
  translate: function(vector) {
    var V = vector.elements || vector;
    return Plane.create([
      this.anchor.elements[0] + V[0],
      this.anchor.elements[1] + V[1],
      this.anchor.elements[2] + (V[2] || 0)
    ], this.normal);
  },

  // Returns true iff the plane is parallel to the argument. Will return true
  // if the planes are equal, or if you give a line and it lies in the plane.
  isParallelTo: function(obj) {
    var theta;
    if (obj.normal) {
      // obj is a plane
      theta = this.normal.angleFrom(obj.normal);
      return (Math.abs(theta) <= Sylvester.precision || Math.abs(Math.PI - theta) <= Sylvester.precision);
    } else if (obj.direction) {
      // obj is a line
      return this.normal.isPerpendicularTo(obj.direction);
    }
    return null;
  },

  // Returns true iff the receiver is perpendicular to the argument
  isPerpendicularTo: function(plane) {
    var theta = this.normal.angleFrom(plane.normal);
    return (Math.abs(Math.PI/2 - theta) <= Sylvester.precision);
  },

  // Returns the plane's distance from the given object (point, line or plane)
  distanceFrom: function(obj) {
    if (this.intersects(obj) || this.contains(obj)) { return 0; }
    if (obj.anchor) {
      // obj is a plane or line
      var A = this.anchor.elements, B = obj.anchor.elements, N = this.normal.elements;
      return Math.abs((A[0] - B[0]) * N[0] + (A[1] - B[1]) * N[1] + (A[2] - B[2]) * N[2]);
    } else {
      // obj is a point
      var P = obj.elements || obj;
      var A = this.anchor.elements, N = this.normal.elements;
      return Math.abs((A[0] - P[0]) * N[0] + (A[1] - P[1]) * N[1] + (A[2] - (P[2] || 0)) * N[2]);
    }
  },

  // Returns true iff the plane contains the given point or line
  contains: function(obj) {
    if (obj.normal) { return null; }
    if (obj.direction) {
      return (this.contains(obj.anchor) && this.contains(obj.anchor.add(obj.direction)));
    } else {
      var P = obj.elements || obj;
      var A = this.anchor.elements, N = this.normal.elements;
      var diff = Math.abs(N[0]*(A[0] - P[0]) + N[1]*(A[1] - P[1]) + N[2]*(A[2] - (P[2] || 0)));
      return (diff <= Sylvester.precision);
    }
  },

  // Returns true iff the plane has a unique point/line of intersection with the argument
  intersects: function(obj) {
    if (typeof(obj.direction) == 'undefined' && typeof(obj.normal) == 'undefined') { return null; }
    return !this.isParallelTo(obj);
  },

  // Returns the unique intersection with the argument, if one exists. The result
  // will be a vector if a line is supplied, and a line if a plane is supplied.
  intersectionWith: function(obj) {
    if (!this.intersects(obj)) { return null; }
    if (obj.direction) {
      // obj is a line
      var A = obj.anchor.elements, D = obj.direction.elements,
          P = this.anchor.elements, N = this.normal.elements;
      var multiplier = (N[0]*(P[0]-A[0]) + N[1]*(P[1]-A[1]) + N[2]*(P[2]-A[2])) / (N[0]*D[0] + N[1]*D[1] + N[2]*D[2]);
      return Vector.create([A[0] + D[0]*multiplier, A[1] + D[1]*multiplier, A[2] + D[2]*multiplier]);
    } else if (obj.normal) {
      // obj is a plane
      var direction = this.normal.cross(obj.normal).toUnitVector();
      // To find an anchor point, we find one co-ordinate that has a value
      // of zero somewhere on the intersection, and remember which one we picked
      var N = this.normal.elements, A = this.anchor.elements,
          O = obj.normal.elements, B = obj.anchor.elements;
      var solver = Matrix.Zero(2,2), i = 0;
      while (solver.isSingular()) {
        i++;
        solver = Matrix.create([
          [ N[i%3], N[(i+1)%3] ],
          [ O[i%3], O[(i+1)%3]  ]
        ]);
      }
      // Then we solve the simultaneous equations in the remaining dimensions
      var inverse = solver.inverse().elements;
      var x = N[0]*A[0] + N[1]*A[1] + N[2]*A[2];
      var y = O[0]*B[0] + O[1]*B[1] + O[2]*B[2];
      var intersection = [
        inverse[0][0] * x + inverse[0][1] * y,
        inverse[1][0] * x + inverse[1][1] * y
      ];
      var anchor = [];
      for (var j = 1; j <= 3; j++) {
        // This formula picks the right element from intersection by
        // cycling depending on which element we set to zero above
        anchor.push((i == j) ? 0 : intersection[(j + (5 - i)%3)%3]);
      }
      return Line.create(anchor, direction);
    }
  },

  // Returns the point in the plane closest to the given point
  pointClosestTo: function(point) {
    var P = point.elements || point;
    var A = this.anchor.elements, N = this.normal.elements;
    var dot = (A[0] - P[0]) * N[0] + (A[1] - P[1]) * N[1] + (A[2] - (P[2] || 0)) * N[2];
    return Vector.create([P[0] + N[0] * dot, P[1] + N[1] * dot, (P[2] || 0) + N[2] * dot]);
  },

  // Returns a copy of the plane, rotated by t radians about the given line
  // See notes on Line#rotate.
  rotate: function(t, line) {
    var R = t.determinant ? t.elements : Matrix.Rotation(t, line.direction).elements;
    var C = line.pointClosestTo(this.anchor).elements;
    var A = this.anchor.elements, N = this.normal.elements;
    var C1 = C[0], C2 = C[1], C3 = C[2], A1 = A[0], A2 = A[1], A3 = A[2];
    var x = A1 - C1, y = A2 - C2, z = A3 - C3;
    return Plane.create([
      C1 + R[0][0] * x + R[0][1] * y + R[0][2] * z,
      C2 + R[1][0] * x + R[1][1] * y + R[1][2] * z,
      C3 + R[2][0] * x + R[2][1] * y + R[2][2] * z
    ], [
      R[0][0] * N[0] + R[0][1] * N[1] + R[0][2] * N[2],
      R[1][0] * N[0] + R[1][1] * N[1] + R[1][2] * N[2],
      R[2][0] * N[0] + R[2][1] * N[1] + R[2][2] * N[2]
    ]);
  },

  // Returns the reflection of the plane in the given point, line or plane.
  reflectionIn: function(obj) {
    if (obj.normal) {
      // obj is a plane
      var A = this.anchor.elements, N = this.normal.elements;
      var A1 = A[0], A2 = A[1], A3 = A[2], N1 = N[0], N2 = N[1], N3 = N[2];
      var newA = this.anchor.reflectionIn(obj).elements;
      // Add the plane's normal to its anchor, then mirror that in the other plane
      var AN1 = A1 + N1, AN2 = A2 + N2, AN3 = A3 + N3;
      var Q = obj.pointClosestTo([AN1, AN2, AN3]).elements;
      var newN = [Q[0] + (Q[0] - AN1) - newA[0], Q[1] + (Q[1] - AN2) - newA[1], Q[2] + (Q[2] - AN3) - newA[2]];
      return Plane.create(newA, newN);
    } else if (obj.direction) {
      // obj is a line
      return this.rotate(Math.PI, obj);
    } else {
      // obj is a point
      var P = obj.elements || obj;
      return Plane.create(this.anchor.reflectionIn([P[0], P[1], (P[2] || 0)]), this.normal);
    }
  },

  // Sets the anchor point and normal to the plane. If three arguments are specified,
  // the normal is calculated by assuming the three points should lie in the same plane.
  // If only two are sepcified, the second is taken to be the normal. Normal vector is
  // normalised before storage.
  setVectors: function(anchor, v1, v2) {
    anchor = Vector.create(anchor);
    anchor = anchor.to3D(); if (anchor === null) { return null; }
    v1 = Vector.create(v1);
    v1 = v1.to3D(); if (v1 === null) { return null; }
    if (typeof(v2) == 'undefined') {
      v2 = null;
    } else {
      v2 = Vector.create(v2);
      v2 = v2.to3D(); if (v2 === null) { return null; }
    }
    var A1 = anchor.elements[0], A2 = anchor.elements[1], A3 = anchor.elements[2];
    var v11 = v1.elements[0], v12 = v1.elements[1], v13 = v1.elements[2];
    var normal, mod;
    if (v2 !== null) {
      var v21 = v2.elements[0], v22 = v2.elements[1], v23 = v2.elements[2];
      normal = Vector.create([
        (v12 - A2) * (v23 - A3) - (v13 - A3) * (v22 - A2),
        (v13 - A3) * (v21 - A1) - (v11 - A1) * (v23 - A3),
        (v11 - A1) * (v22 - A2) - (v12 - A2) * (v21 - A1)
      ]);
      mod = normal.modulus();
      if (mod === 0) { return null; }
      normal = Vector.create([normal.elements[0] / mod, normal.elements[1] / mod, normal.elements[2] / mod]);
    } else {
      mod = Math.sqrt(v11*v11 + v12*v12 + v13*v13);
      if (mod === 0) { return null; }
      normal = Vector.create([v1.elements[0] / mod, v1.elements[1] / mod, v1.elements[2] / mod]);
    }
    this.anchor = anchor;
    this.normal = normal;
    return this;
  }
};

// Constructor function
Plane.create = function(anchor, v1, v2) {
  var P = new Plane();
  return P.setVectors(anchor, v1, v2);
};

// X-Y-Z planes
Plane.XY = Plane.create(Vector.Zero(3), Vector.k);
Plane.YZ = Plane.create(Vector.Zero(3), Vector.i);
Plane.ZX = Plane.create(Vector.Zero(3), Vector.j);
Plane.YX = Plane.XY; Plane.ZY = Plane.YZ; Plane.XZ = Plane.ZX;

// Returns the plane containing the given points (can be arrays as
// well as vectors). If the points are not coplanar, returns null.
Plane.fromPoints = function(points) {
  var np = points.length, list = [], i, P, n, N, A, B, C, D, theta, prevN, totalN = Vector.Zero(3);
  for (i = 0; i < np; i++) {
    P = Vector.create(points[i]).to3D();
    if (P === null) { return null; }
    list.push(P);
    n = list.length;
    if (n > 2) {
      // Compute plane normal for the latest three points
      A = list[n-1].elements; B = list[n-2].elements; C = list[n-3].elements;
      N = Vector.create([
        (A[1] - B[1]) * (C[2] - B[2]) - (A[2] - B[2]) * (C[1] - B[1]),
        (A[2] - B[2]) * (C[0] - B[0]) - (A[0] - B[0]) * (C[2] - B[2]),
        (A[0] - B[0]) * (C[1] - B[1]) - (A[1] - B[1]) * (C[0] - B[0])
      ]).toUnitVector();
      if (n > 3) {
        // If the latest normal is not (anti)parallel to the previous one, we've strayed off the plane.
        // This might be a slightly long-winded way of doing things, but we need the sum of all the normals
        // to find which way the plane normal should point so that the points form an anticlockwise list.
        theta = N.angleFrom(prevN);
        if (theta !== null) {
          if (!(Math.abs(theta) <= Sylvester.precision || Math.abs(theta - Math.PI) <= Sylvester.precision)) { return null; }
        }
      }
      totalN = totalN.add(N);
      prevN = N;
    }
  }
  // We need to add in the normals at the start and end points, which the above misses out
  A = list[1].elements; B = list[0].elements; C = list[n-1].elements; D = list[n-2].elements;
  totalN = totalN.add(Vector.create([
    (A[1] - B[1]) * (C[2] - B[2]) - (A[2] - B[2]) * (C[1] - B[1]),
    (A[2] - B[2]) * (C[0] - B[0]) - (A[0] - B[0]) * (C[2] - B[2]),
    (A[0] - B[0]) * (C[1] - B[1]) - (A[1] - B[1]) * (C[0] - B[0])
  ]).toUnitVector()).add(Vector.create([
    (B[1] - C[1]) * (D[2] - C[2]) - (B[2] - C[2]) * (D[1] - C[1]),
    (B[2] - C[2]) * (D[0] - C[0]) - (B[0] - C[0]) * (D[2] - C[2]),
    (B[0] - C[0]) * (D[1] - C[1]) - (B[1] - C[1]) * (D[0] - C[0])
  ]).toUnitVector());
  return Plane.create(list[0], totalN);
};

module.exports = Plane;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\sylvester.js":
/*!********************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/sylvester/lib/node-sylvester/sylvester.js ***!
  \********************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) 2011, Chris Umbel, James Coglan
// This file is required in order for any other classes to work. Some Vector methods work with the
// other Sylvester classes and are useless unless they are included. Other classes such as Line and
// Plane will not function at all without Vector being loaded first.           

Math.sign = function(x) {
    return x < 0 ? -1: 1;
}
                                              
var Sylvester = {
    precision: 1e-6
};

module.exports = Sylvester;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\vector.js":
/*!*****************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/sylvester/lib/node-sylvester/vector.js ***!
  \*****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// Copyright (c) 2011, Chris Umbel, James Coglan
// This file is required in order for any other classes to work. Some Vector methods work with the
// other Sylvester classes and are useless unless they are included. Other classes such as Line and
// Plane will not function at all without Vector being loaded first.

var Sylvester = __webpack_require__(/*! ./sylvester */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\sylvester.js"),
Matrix = __webpack_require__(/*! ./matrix */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\sylvester\\lib\\node-sylvester\\matrix.js");

function Vector() {}
Vector.prototype = {

    norm: function() {
	var n = this.elements.length;
	var sum = 0;

	while (n--) {
	    sum += Math.pow(this.elements[n], 2);
	}

	return Math.sqrt(sum);
    },

    // Returns element i of the vector
    e: function(i) {
      return (i < 1 || i > this.elements.length) ? null : this.elements[i - 1];
    },

    // Returns the number of rows/columns the vector has
    dimensions: function() {
      return {rows: 1, cols: this.elements.length};
    },

    // Returns the number of rows in the vector
    rows: function() {
      return 1;
    },

    // Returns the number of columns in the vector
    cols: function() {
      return this.elements.length;
    },

    // Returns the modulus ('length') of the vector
    modulus: function() {
      return Math.sqrt(this.dot(this));
    },

    // Returns true iff the vector is equal to the argument
    eql: function(vector) {
    	var n = this.elements.length;
    	var V = vector.elements || vector;
    	if (n != V.length) { return false; }
    	while (n--) {
    	    if (Math.abs(this.elements[n] - V[n]) > Sylvester.precision) { return false; }
    	}
    	return true;
    },

    // Returns a copy of the vector
    dup: function() {
	    return Vector.create(this.elements);
    },

    // Maps the vector to another vector according to the given function
    map: function(fn) {
	var elements = [];
	this.each(function(x, i) {
	    elements.push(fn(x, i));
	});
	return Vector.create(elements);
    },

    // Calls the iterator for each element of the vector in turn
    each: function(fn) {
	var n = this.elements.length;
	for (var i = 0; i < n; i++) {
	    fn(this.elements[i], i + 1);
	}
    },

    // Returns a new vector created by normalizing the receiver
    toUnitVector: function() {
	var r = this.modulus();
	if (r === 0) { return this.dup(); }
	return this.map(function(x) { return x / r; });
    },

    // Returns the angle between the vector and the argument (also a vector)
    angleFrom: function(vector) {
	var V = vector.elements || vector;
	var n = this.elements.length, k = n, i;
	if (n != V.length) { return null; }
	var dot = 0, mod1 = 0, mod2 = 0;
	// Work things out in parallel to save time
	this.each(function(x, i) {
	    dot += x * V[i - 1];
	    mod1 += x * x;
	    mod2 += V[i - 1] * V[i - 1];
	});
	mod1 = Math.sqrt(mod1); mod2 = Math.sqrt(mod2);
	if (mod1 * mod2 === 0) { return null; }
	var theta = dot / (mod1 * mod2);
	if (theta < -1) { theta = -1; }
	if (theta > 1) { theta = 1; }
	return Math.acos(theta);
    },

    // Returns true iff the vector is parallel to the argument
    isParallelTo: function(vector) {
	var angle = this.angleFrom(vector);
	return (angle === null) ? null : (angle <= Sylvester.precision);
    },

    // Returns true iff the vector is antiparallel to the argument
    isAntiparallelTo: function(vector) {
	var angle = this.angleFrom(vector);
	return (angle === null) ? null : (Math.abs(angle - Math.PI) <= Sylvester.precision);
    },

    // Returns true iff the vector is perpendicular to the argument
    isPerpendicularTo: function(vector) {
	var dot = this.dot(vector);
	return (dot === null) ? null : (Math.abs(dot) <= Sylvester.precision);
    },

    // Returns the result of adding the argument to the vector
    add: function(value) {
	var V = value.elements || value;

	if (this.elements.length != V.length) 
	    return this.map(function(v) { return v + value });
	else
	    return this.map(function(x, i) { return x + V[i - 1]; });
    },

    // Returns the result of subtracting the argument from the vector
    subtract: function(v) {
	if (typeof(v) == 'number')
	    return this.map(function(k) { return k - v; });

	var V = v.elements || v;
	if (this.elements.length != V.length) { return null; }
	return this.map(function(x, i) { return x - V[i - 1]; });
    },

    // Returns the result of multiplying the elements of the vector by the argument
    multiply: function(k) {
	return this.map(function(x) { return x * k; });
    },

    elementMultiply: function(v) {
	return this.map(function(k, i) {
	    return v.e(i) * k;
	});
    },

    sum: function() {
	var sum = 0;
	this.map(function(x) { sum += x;});
	return sum;
    },

    chomp: function(n) {
	var elements = [];

	for (var i = n; i < this.elements.length; i++) {
	    elements.push(this.elements[i]);
	}

	return Vector.create(elements);
    },

    top: function(n) {
	var elements = [];

	for (var i = 0; i < n; i++) {
	    elements.push(this.elements[i]);
	}

	return Vector.create(elements);
    },

    augment: function(elements) {
	var newElements = this.elements;

	for (var i = 0; i < elements.length; i++) {
	    newElements.push(elements[i]);
	}

	return Vector.create(newElements);
    },

    x: function(k) { return this.multiply(k); },

    log: function() {
	return Vector.log(this);
    },

    elementDivide: function(vector) {
	return this.map(function(v, i) {
	    return v / vector.e(i);
	});
    },

    product: function() {
	var p = 1;

	this.map(function(v) {
	    p *= v;
	});

	return p;
    },

    // Returns the scalar product of the vector with the argument
    // Both vectors must have equal dimensionality
    dot: function(vector) {
	var V = vector.elements || vector;
	var i, product = 0, n = this.elements.length;	
	if (n != V.length) { return null; }
	while (n--) { product += this.elements[n] * V[n]; }
	return product;
    },

    // Returns the vector product of the vector with the argument
    // Both vectors must have dimensionality 3
    cross: function(vector) {
	var B = vector.elements || vector;
	if (this.elements.length != 3 || B.length != 3) { return null; }
	var A = this.elements;
	return Vector.create([
	    (A[1] * B[2]) - (A[2] * B[1]),
	    (A[2] * B[0]) - (A[0] * B[2]),
	    (A[0] * B[1]) - (A[1] * B[0])
	]);
    },

    // Returns the (absolute) largest element of the vector
    max: function() {
	var m = 0, i = this.elements.length;
	while (i--) {
	    if (Math.abs(this.elements[i]) > Math.abs(m)) { m = this.elements[i]; }
	}
	return m;
    },


    maxIndex: function() {
	var m = 0, i = this.elements.length;
	var maxIndex = -1;

	while (i--) {
	    if (Math.abs(this.elements[i]) > Math.abs(m)) { 
		m = this.elements[i]; 
		maxIndex = i + 1;
	    }
	}

	return maxIndex;
    },


    // Returns the index of the first match found
    indexOf: function(x) {
	var index = null, n = this.elements.length;
	for (var i = 0; i < n; i++) {
	    if (index === null && this.elements[i] == x) {
		index = i + 1;
	    }
	}
	return index;
    },

    // Returns a diagonal matrix with the vector's elements as its diagonal elements
    toDiagonalMatrix: function() {
	return Matrix.Diagonal(this.elements);
    },

    // Returns the result of rounding the elements of the vector
    round: function() {
	return this.map(function(x) { return Math.round(x); });
    },

    // Transpose a Vector, return a 1xn Matrix
    transpose: function() {
	var rows = this.elements.length;
	var elements = [];

	for (var i = 0; i < rows; i++) {
	    elements.push([this.elements[i]]);
	}
	return Matrix.create(elements);
    },

    // Returns a copy of the vector with elements set to the given value if they
    // differ from it by less than Sylvester.precision
    snapTo: function(x) {
	return this.map(function(y) {
	    return (Math.abs(y - x) <= Sylvester.precision) ? x : y;
	});
    },

    // Returns the vector's distance from the argument, when considered as a point in space
    distanceFrom: function(obj) {
	if (obj.anchor || (obj.start && obj.end)) { return obj.distanceFrom(this); }
	var V = obj.elements || obj;
	if (V.length != this.elements.length) { return null; }
	var sum = 0, part;
	this.each(function(x, i) {
	    part = x - V[i - 1];
	    sum += part * part;
	});
	return Math.sqrt(sum);
    },

    // Returns true if the vector is point on the given line
    liesOn: function(line) {
	return line.contains(this);
    },

    // Return true iff the vector is a point in the given plane
    liesIn: function(plane) {
	return plane.contains(this);
    },

    // Rotates the vector about the given object. The object should be a
    // point if the vector is 2D, and a line if it is 3D. Be careful with line directions!
    rotate: function(t, obj) {
	var V, R = null, x, y, z;
	if (t.determinant) { R = t.elements; }
	switch (this.elements.length) {
	case 2:
            V = obj.elements || obj;
            if (V.length != 2) { return null; }
            if (!R) { R = Matrix.Rotation(t).elements; }
            x = this.elements[0] - V[0];
            y = this.elements[1] - V[1];
            return Vector.create([
		V[0] + R[0][0] * x + R[0][1] * y,
		V[1] + R[1][0] * x + R[1][1] * y
            ]);
            break;
	case 3:
            if (!obj.direction) { return null; }
            var C = obj.pointClosestTo(this).elements;
            if (!R) { R = Matrix.Rotation(t, obj.direction).elements; }
            x = this.elements[0] - C[0];
            y = this.elements[1] - C[1];
            z = this.elements[2] - C[2];
            return Vector.create([
		C[0] + R[0][0] * x + R[0][1] * y + R[0][2] * z,
		C[1] + R[1][0] * x + R[1][1] * y + R[1][2] * z,
		C[2] + R[2][0] * x + R[2][1] * y + R[2][2] * z
            ]);
            break;
	default:
            return null;
	}
    },

    // Returns the result of reflecting the point in the given point, line or plane
    reflectionIn: function(obj) {
	if (obj.anchor) {
	    // obj is a plane or line
	    var P = this.elements.slice();
	    var C = obj.pointClosestTo(P).elements;
	    return Vector.create([C[0] + (C[0] - P[0]), C[1] + (C[1] - P[1]), C[2] + (C[2] - (P[2] || 0))]);
	} else {
	    // obj is a point
	    var Q = obj.elements || obj;
	    if (this.elements.length != Q.length) { return null; }
	    return this.map(function(x, i) { return Q[i - 1] + (Q[i - 1] - x); });
	}
    },

    // Utility to make sure vectors are 3D. If they are 2D, a zero z-component is added
    to3D: function() {
	var V = this.dup();
	switch (V.elements.length) {
	case 3: break;
	case 2: V.elements.push(0); break;
	default: return null;
	}
	return V;
    },

    // Returns a string representation of the vector
    inspect: function() {
	return '[' + this.elements.join(', ') + ']';
    },

    // Set vector's elements from an array
    setElements: function(els) {
	this.elements = (els.elements || els).slice();
	return this;
    }
};

// Constructor function
Vector.create = function(elements) {
    var V = new Vector();
    return V.setElements(elements);
};

// i, j, k unit vectors
Vector.i = Vector.create([1, 0, 0]);
Vector.j = Vector.create([0, 1, 0]);
Vector.k = Vector.create([0, 0, 1]);

// Random vector of size n
Vector.Random = function(n) {
    var elements = [];
    while (n--) { elements.push(Math.random()); }
    return Vector.create(elements);
};

Vector.Fill = function(n, v) {
    var elements = [];
    while (n--) { elements.push(v); }
    return Vector.create(elements);
};

// Vector filled with zeros
Vector.Zero = function(n) {
    return Vector.Fill(n, 0);
};

Vector.One = function(n) {
    return Vector.Fill(n, 1);
};

Vector.log = function(v) {
    return v.map(function(x) {
	return Math.log(x);
    });
};

module.exports = Vector;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js":
/*!***************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/underscore/underscore.js ***!
  \***************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global, module) {var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;//     Underscore.js 1.9.1
//     http://underscorejs.org
//     (c) 2009-2018 Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
//     Underscore may be freely distributed under the MIT license.

(function() {

  // Baseline setup
  // --------------

  // Establish the root object, `window` (`self`) in the browser, `global`
  // on the server, or `this` in some virtual machines. We use `self`
  // instead of `window` for `WebWorker` support.
  var root = typeof self == 'object' && self.self === self && self ||
            typeof global == 'object' && global.global === global && global ||
            this ||
            {};

  // Save the previous value of the `_` variable.
  var previousUnderscore = root._;

  // Save bytes in the minified (but not gzipped) version:
  var ArrayProto = Array.prototype, ObjProto = Object.prototype;
  var SymbolProto = typeof Symbol !== 'undefined' ? Symbol.prototype : null;

  // Create quick reference variables for speed access to core prototypes.
  var push = ArrayProto.push,
      slice = ArrayProto.slice,
      toString = ObjProto.toString,
      hasOwnProperty = ObjProto.hasOwnProperty;

  // All **ECMAScript 5** native function implementations that we hope to use
  // are declared here.
  var nativeIsArray = Array.isArray,
      nativeKeys = Object.keys,
      nativeCreate = Object.create;

  // Naked function reference for surrogate-prototype-swapping.
  var Ctor = function(){};

  // Create a safe reference to the Underscore object for use below.
  var _ = function(obj) {
    if (obj instanceof _) return obj;
    if (!(this instanceof _)) return new _(obj);
    this._wrapped = obj;
  };

  // Export the Underscore object for **Node.js**, with
  // backwards-compatibility for their old module API. If we're in
  // the browser, add `_` as a global object.
  // (`nodeType` is checked to ensure that `module`
  // and `exports` are not HTML elements.)
  if ( true && !exports.nodeType) {
    if ( true && !module.nodeType && module.exports) {
      exports = module.exports = _;
    }
    exports._ = _;
  } else {
    root._ = _;
  }

  // Current version.
  _.VERSION = '1.9.1';

  // Internal function that returns an efficient (for current engines) version
  // of the passed-in callback, to be repeatedly applied in other Underscore
  // functions.
  var optimizeCb = function(func, context, argCount) {
    if (context === void 0) return func;
    switch (argCount == null ? 3 : argCount) {
      case 1: return function(value) {
        return func.call(context, value);
      };
      // The 2-argument case is omitted because we’re not using it.
      case 3: return function(value, index, collection) {
        return func.call(context, value, index, collection);
      };
      case 4: return function(accumulator, value, index, collection) {
        return func.call(context, accumulator, value, index, collection);
      };
    }
    return function() {
      return func.apply(context, arguments);
    };
  };

  var builtinIteratee;

  // An internal function to generate callbacks that can be applied to each
  // element in a collection, returning the desired result — either `identity`,
  // an arbitrary callback, a property matcher, or a property accessor.
  var cb = function(value, context, argCount) {
    if (_.iteratee !== builtinIteratee) return _.iteratee(value, context);
    if (value == null) return _.identity;
    if (_.isFunction(value)) return optimizeCb(value, context, argCount);
    if (_.isObject(value) && !_.isArray(value)) return _.matcher(value);
    return _.property(value);
  };

  // External wrapper for our callback generator. Users may customize
  // `_.iteratee` if they want additional predicate/iteratee shorthand styles.
  // This abstraction hides the internal-only argCount argument.
  _.iteratee = builtinIteratee = function(value, context) {
    return cb(value, context, Infinity);
  };

  // Some functions take a variable number of arguments, or a few expected
  // arguments at the beginning and then a variable number of values to operate
  // on. This helper accumulates all remaining arguments past the function’s
  // argument length (or an explicit `startIndex`), into an array that becomes
  // the last argument. Similar to ES6’s "rest parameter".
  var restArguments = function(func, startIndex) {
    startIndex = startIndex == null ? func.length - 1 : +startIndex;
    return function() {
      var length = Math.max(arguments.length - startIndex, 0),
          rest = Array(length),
          index = 0;
      for (; index < length; index++) {
        rest[index] = arguments[index + startIndex];
      }
      switch (startIndex) {
        case 0: return func.call(this, rest);
        case 1: return func.call(this, arguments[0], rest);
        case 2: return func.call(this, arguments[0], arguments[1], rest);
      }
      var args = Array(startIndex + 1);
      for (index = 0; index < startIndex; index++) {
        args[index] = arguments[index];
      }
      args[startIndex] = rest;
      return func.apply(this, args);
    };
  };

  // An internal function for creating a new object that inherits from another.
  var baseCreate = function(prototype) {
    if (!_.isObject(prototype)) return {};
    if (nativeCreate) return nativeCreate(prototype);
    Ctor.prototype = prototype;
    var result = new Ctor;
    Ctor.prototype = null;
    return result;
  };

  var shallowProperty = function(key) {
    return function(obj) {
      return obj == null ? void 0 : obj[key];
    };
  };

  var has = function(obj, path) {
    return obj != null && hasOwnProperty.call(obj, path);
  }

  var deepGet = function(obj, path) {
    var length = path.length;
    for (var i = 0; i < length; i++) {
      if (obj == null) return void 0;
      obj = obj[path[i]];
    }
    return length ? obj : void 0;
  };

  // Helper for collection methods to determine whether a collection
  // should be iterated as an array or as an object.
  // Related: http://people.mozilla.org/~jorendorff/es6-draft.html#sec-tolength
  // Avoids a very nasty iOS 8 JIT bug on ARM-64. #2094
  var MAX_ARRAY_INDEX = Math.pow(2, 53) - 1;
  var getLength = shallowProperty('length');
  var isArrayLike = function(collection) {
    var length = getLength(collection);
    return typeof length == 'number' && length >= 0 && length <= MAX_ARRAY_INDEX;
  };

  // Collection Functions
  // --------------------

  // The cornerstone, an `each` implementation, aka `forEach`.
  // Handles raw objects in addition to array-likes. Treats all
  // sparse array-likes as if they were dense.
  _.each = _.forEach = function(obj, iteratee, context) {
    iteratee = optimizeCb(iteratee, context);
    var i, length;
    if (isArrayLike(obj)) {
      for (i = 0, length = obj.length; i < length; i++) {
        iteratee(obj[i], i, obj);
      }
    } else {
      var keys = _.keys(obj);
      for (i = 0, length = keys.length; i < length; i++) {
        iteratee(obj[keys[i]], keys[i], obj);
      }
    }
    return obj;
  };

  // Return the results of applying the iteratee to each element.
  _.map = _.collect = function(obj, iteratee, context) {
    iteratee = cb(iteratee, context);
    var keys = !isArrayLike(obj) && _.keys(obj),
        length = (keys || obj).length,
        results = Array(length);
    for (var index = 0; index < length; index++) {
      var currentKey = keys ? keys[index] : index;
      results[index] = iteratee(obj[currentKey], currentKey, obj);
    }
    return results;
  };

  // Create a reducing function iterating left or right.
  var createReduce = function(dir) {
    // Wrap code that reassigns argument variables in a separate function than
    // the one that accesses `arguments.length` to avoid a perf hit. (#1991)
    var reducer = function(obj, iteratee, memo, initial) {
      var keys = !isArrayLike(obj) && _.keys(obj),
          length = (keys || obj).length,
          index = dir > 0 ? 0 : length - 1;
      if (!initial) {
        memo = obj[keys ? keys[index] : index];
        index += dir;
      }
      for (; index >= 0 && index < length; index += dir) {
        var currentKey = keys ? keys[index] : index;
        memo = iteratee(memo, obj[currentKey], currentKey, obj);
      }
      return memo;
    };

    return function(obj, iteratee, memo, context) {
      var initial = arguments.length >= 3;
      return reducer(obj, optimizeCb(iteratee, context, 4), memo, initial);
    };
  };

  // **Reduce** builds up a single result from a list of values, aka `inject`,
  // or `foldl`.
  _.reduce = _.foldl = _.inject = createReduce(1);

  // The right-associative version of reduce, also known as `foldr`.
  _.reduceRight = _.foldr = createReduce(-1);

  // Return the first value which passes a truth test. Aliased as `detect`.
  _.find = _.detect = function(obj, predicate, context) {
    var keyFinder = isArrayLike(obj) ? _.findIndex : _.findKey;
    var key = keyFinder(obj, predicate, context);
    if (key !== void 0 && key !== -1) return obj[key];
  };

  // Return all the elements that pass a truth test.
  // Aliased as `select`.
  _.filter = _.select = function(obj, predicate, context) {
    var results = [];
    predicate = cb(predicate, context);
    _.each(obj, function(value, index, list) {
      if (predicate(value, index, list)) results.push(value);
    });
    return results;
  };

  // Return all the elements for which a truth test fails.
  _.reject = function(obj, predicate, context) {
    return _.filter(obj, _.negate(cb(predicate)), context);
  };

  // Determine whether all of the elements match a truth test.
  // Aliased as `all`.
  _.every = _.all = function(obj, predicate, context) {
    predicate = cb(predicate, context);
    var keys = !isArrayLike(obj) && _.keys(obj),
        length = (keys || obj).length;
    for (var index = 0; index < length; index++) {
      var currentKey = keys ? keys[index] : index;
      if (!predicate(obj[currentKey], currentKey, obj)) return false;
    }
    return true;
  };

  // Determine if at least one element in the object matches a truth test.
  // Aliased as `any`.
  _.some = _.any = function(obj, predicate, context) {
    predicate = cb(predicate, context);
    var keys = !isArrayLike(obj) && _.keys(obj),
        length = (keys || obj).length;
    for (var index = 0; index < length; index++) {
      var currentKey = keys ? keys[index] : index;
      if (predicate(obj[currentKey], currentKey, obj)) return true;
    }
    return false;
  };

  // Determine if the array or object contains a given item (using `===`).
  // Aliased as `includes` and `include`.
  _.contains = _.includes = _.include = function(obj, item, fromIndex, guard) {
    if (!isArrayLike(obj)) obj = _.values(obj);
    if (typeof fromIndex != 'number' || guard) fromIndex = 0;
    return _.indexOf(obj, item, fromIndex) >= 0;
  };

  // Invoke a method (with arguments) on every item in a collection.
  _.invoke = restArguments(function(obj, path, args) {
    var contextPath, func;
    if (_.isFunction(path)) {
      func = path;
    } else if (_.isArray(path)) {
      contextPath = path.slice(0, -1);
      path = path[path.length - 1];
    }
    return _.map(obj, function(context) {
      var method = func;
      if (!method) {
        if (contextPath && contextPath.length) {
          context = deepGet(context, contextPath);
        }
        if (context == null) return void 0;
        method = context[path];
      }
      return method == null ? method : method.apply(context, args);
    });
  });

  // Convenience version of a common use case of `map`: fetching a property.
  _.pluck = function(obj, key) {
    return _.map(obj, _.property(key));
  };

  // Convenience version of a common use case of `filter`: selecting only objects
  // containing specific `key:value` pairs.
  _.where = function(obj, attrs) {
    return _.filter(obj, _.matcher(attrs));
  };

  // Convenience version of a common use case of `find`: getting the first object
  // containing specific `key:value` pairs.
  _.findWhere = function(obj, attrs) {
    return _.find(obj, _.matcher(attrs));
  };

  // Return the maximum element (or element-based computation).
  _.max = function(obj, iteratee, context) {
    var result = -Infinity, lastComputed = -Infinity,
        value, computed;
    if (iteratee == null || typeof iteratee == 'number' && typeof obj[0] != 'object' && obj != null) {
      obj = isArrayLike(obj) ? obj : _.values(obj);
      for (var i = 0, length = obj.length; i < length; i++) {
        value = obj[i];
        if (value != null && value > result) {
          result = value;
        }
      }
    } else {
      iteratee = cb(iteratee, context);
      _.each(obj, function(v, index, list) {
        computed = iteratee(v, index, list);
        if (computed > lastComputed || computed === -Infinity && result === -Infinity) {
          result = v;
          lastComputed = computed;
        }
      });
    }
    return result;
  };

  // Return the minimum element (or element-based computation).
  _.min = function(obj, iteratee, context) {
    var result = Infinity, lastComputed = Infinity,
        value, computed;
    if (iteratee == null || typeof iteratee == 'number' && typeof obj[0] != 'object' && obj != null) {
      obj = isArrayLike(obj) ? obj : _.values(obj);
      for (var i = 0, length = obj.length; i < length; i++) {
        value = obj[i];
        if (value != null && value < result) {
          result = value;
        }
      }
    } else {
      iteratee = cb(iteratee, context);
      _.each(obj, function(v, index, list) {
        computed = iteratee(v, index, list);
        if (computed < lastComputed || computed === Infinity && result === Infinity) {
          result = v;
          lastComputed = computed;
        }
      });
    }
    return result;
  };

  // Shuffle a collection.
  _.shuffle = function(obj) {
    return _.sample(obj, Infinity);
  };

  // Sample **n** random values from a collection using the modern version of the
  // [Fisher-Yates shuffle](http://en.wikipedia.org/wiki/Fisher–Yates_shuffle).
  // If **n** is not specified, returns a single random element.
  // The internal `guard` argument allows it to work with `map`.
  _.sample = function(obj, n, guard) {
    if (n == null || guard) {
      if (!isArrayLike(obj)) obj = _.values(obj);
      return obj[_.random(obj.length - 1)];
    }
    var sample = isArrayLike(obj) ? _.clone(obj) : _.values(obj);
    var length = getLength(sample);
    n = Math.max(Math.min(n, length), 0);
    var last = length - 1;
    for (var index = 0; index < n; index++) {
      var rand = _.random(index, last);
      var temp = sample[index];
      sample[index] = sample[rand];
      sample[rand] = temp;
    }
    return sample.slice(0, n);
  };

  // Sort the object's values by a criterion produced by an iteratee.
  _.sortBy = function(obj, iteratee, context) {
    var index = 0;
    iteratee = cb(iteratee, context);
    return _.pluck(_.map(obj, function(value, key, list) {
      return {
        value: value,
        index: index++,
        criteria: iteratee(value, key, list)
      };
    }).sort(function(left, right) {
      var a = left.criteria;
      var b = right.criteria;
      if (a !== b) {
        if (a > b || a === void 0) return 1;
        if (a < b || b === void 0) return -1;
      }
      return left.index - right.index;
    }), 'value');
  };

  // An internal function used for aggregate "group by" operations.
  var group = function(behavior, partition) {
    return function(obj, iteratee, context) {
      var result = partition ? [[], []] : {};
      iteratee = cb(iteratee, context);
      _.each(obj, function(value, index) {
        var key = iteratee(value, index, obj);
        behavior(result, value, key);
      });
      return result;
    };
  };

  // Groups the object's values by a criterion. Pass either a string attribute
  // to group by, or a function that returns the criterion.
  _.groupBy = group(function(result, value, key) {
    if (has(result, key)) result[key].push(value); else result[key] = [value];
  });

  // Indexes the object's values by a criterion, similar to `groupBy`, but for
  // when you know that your index values will be unique.
  _.indexBy = group(function(result, value, key) {
    result[key] = value;
  });

  // Counts instances of an object that group by a certain criterion. Pass
  // either a string attribute to count by, or a function that returns the
  // criterion.
  _.countBy = group(function(result, value, key) {
    if (has(result, key)) result[key]++; else result[key] = 1;
  });

  var reStrSymbol = /[^\ud800-\udfff]|[\ud800-\udbff][\udc00-\udfff]|[\ud800-\udfff]/g;
  // Safely create a real, live array from anything iterable.
  _.toArray = function(obj) {
    if (!obj) return [];
    if (_.isArray(obj)) return slice.call(obj);
    if (_.isString(obj)) {
      // Keep surrogate pair characters together
      return obj.match(reStrSymbol);
    }
    if (isArrayLike(obj)) return _.map(obj, _.identity);
    return _.values(obj);
  };

  // Return the number of elements in an object.
  _.size = function(obj) {
    if (obj == null) return 0;
    return isArrayLike(obj) ? obj.length : _.keys(obj).length;
  };

  // Split a collection into two arrays: one whose elements all satisfy the given
  // predicate, and one whose elements all do not satisfy the predicate.
  _.partition = group(function(result, value, pass) {
    result[pass ? 0 : 1].push(value);
  }, true);

  // Array Functions
  // ---------------

  // Get the first element of an array. Passing **n** will return the first N
  // values in the array. Aliased as `head` and `take`. The **guard** check
  // allows it to work with `_.map`.
  _.first = _.head = _.take = function(array, n, guard) {
    if (array == null || array.length < 1) return n == null ? void 0 : [];
    if (n == null || guard) return array[0];
    return _.initial(array, array.length - n);
  };

  // Returns everything but the last entry of the array. Especially useful on
  // the arguments object. Passing **n** will return all the values in
  // the array, excluding the last N.
  _.initial = function(array, n, guard) {
    return slice.call(array, 0, Math.max(0, array.length - (n == null || guard ? 1 : n)));
  };

  // Get the last element of an array. Passing **n** will return the last N
  // values in the array.
  _.last = function(array, n, guard) {
    if (array == null || array.length < 1) return n == null ? void 0 : [];
    if (n == null || guard) return array[array.length - 1];
    return _.rest(array, Math.max(0, array.length - n));
  };

  // Returns everything but the first entry of the array. Aliased as `tail` and `drop`.
  // Especially useful on the arguments object. Passing an **n** will return
  // the rest N values in the array.
  _.rest = _.tail = _.drop = function(array, n, guard) {
    return slice.call(array, n == null || guard ? 1 : n);
  };

  // Trim out all falsy values from an array.
  _.compact = function(array) {
    return _.filter(array, Boolean);
  };

  // Internal implementation of a recursive `flatten` function.
  var flatten = function(input, shallow, strict, output) {
    output = output || [];
    var idx = output.length;
    for (var i = 0, length = getLength(input); i < length; i++) {
      var value = input[i];
      if (isArrayLike(value) && (_.isArray(value) || _.isArguments(value))) {
        // Flatten current level of array or arguments object.
        if (shallow) {
          var j = 0, len = value.length;
          while (j < len) output[idx++] = value[j++];
        } else {
          flatten(value, shallow, strict, output);
          idx = output.length;
        }
      } else if (!strict) {
        output[idx++] = value;
      }
    }
    return output;
  };

  // Flatten out an array, either recursively (by default), or just one level.
  _.flatten = function(array, shallow) {
    return flatten(array, shallow, false);
  };

  // Return a version of the array that does not contain the specified value(s).
  _.without = restArguments(function(array, otherArrays) {
    return _.difference(array, otherArrays);
  });

  // Produce a duplicate-free version of the array. If the array has already
  // been sorted, you have the option of using a faster algorithm.
  // The faster algorithm will not work with an iteratee if the iteratee
  // is not a one-to-one function, so providing an iteratee will disable
  // the faster algorithm.
  // Aliased as `unique`.
  _.uniq = _.unique = function(array, isSorted, iteratee, context) {
    if (!_.isBoolean(isSorted)) {
      context = iteratee;
      iteratee = isSorted;
      isSorted = false;
    }
    if (iteratee != null) iteratee = cb(iteratee, context);
    var result = [];
    var seen = [];
    for (var i = 0, length = getLength(array); i < length; i++) {
      var value = array[i],
          computed = iteratee ? iteratee(value, i, array) : value;
      if (isSorted && !iteratee) {
        if (!i || seen !== computed) result.push(value);
        seen = computed;
      } else if (iteratee) {
        if (!_.contains(seen, computed)) {
          seen.push(computed);
          result.push(value);
        }
      } else if (!_.contains(result, value)) {
        result.push(value);
      }
    }
    return result;
  };

  // Produce an array that contains the union: each distinct element from all of
  // the passed-in arrays.
  _.union = restArguments(function(arrays) {
    return _.uniq(flatten(arrays, true, true));
  });

  // Produce an array that contains every item shared between all the
  // passed-in arrays.
  _.intersection = function(array) {
    var result = [];
    var argsLength = arguments.length;
    for (var i = 0, length = getLength(array); i < length; i++) {
      var item = array[i];
      if (_.contains(result, item)) continue;
      var j;
      for (j = 1; j < argsLength; j++) {
        if (!_.contains(arguments[j], item)) break;
      }
      if (j === argsLength) result.push(item);
    }
    return result;
  };

  // Take the difference between one array and a number of other arrays.
  // Only the elements present in just the first array will remain.
  _.difference = restArguments(function(array, rest) {
    rest = flatten(rest, true, true);
    return _.filter(array, function(value){
      return !_.contains(rest, value);
    });
  });

  // Complement of _.zip. Unzip accepts an array of arrays and groups
  // each array's elements on shared indices.
  _.unzip = function(array) {
    var length = array && _.max(array, getLength).length || 0;
    var result = Array(length);

    for (var index = 0; index < length; index++) {
      result[index] = _.pluck(array, index);
    }
    return result;
  };

  // Zip together multiple lists into a single array -- elements that share
  // an index go together.
  _.zip = restArguments(_.unzip);

  // Converts lists into objects. Pass either a single array of `[key, value]`
  // pairs, or two parallel arrays of the same length -- one of keys, and one of
  // the corresponding values. Passing by pairs is the reverse of _.pairs.
  _.object = function(list, values) {
    var result = {};
    for (var i = 0, length = getLength(list); i < length; i++) {
      if (values) {
        result[list[i]] = values[i];
      } else {
        result[list[i][0]] = list[i][1];
      }
    }
    return result;
  };

  // Generator function to create the findIndex and findLastIndex functions.
  var createPredicateIndexFinder = function(dir) {
    return function(array, predicate, context) {
      predicate = cb(predicate, context);
      var length = getLength(array);
      var index = dir > 0 ? 0 : length - 1;
      for (; index >= 0 && index < length; index += dir) {
        if (predicate(array[index], index, array)) return index;
      }
      return -1;
    };
  };

  // Returns the first index on an array-like that passes a predicate test.
  _.findIndex = createPredicateIndexFinder(1);
  _.findLastIndex = createPredicateIndexFinder(-1);

  // Use a comparator function to figure out the smallest index at which
  // an object should be inserted so as to maintain order. Uses binary search.
  _.sortedIndex = function(array, obj, iteratee, context) {
    iteratee = cb(iteratee, context, 1);
    var value = iteratee(obj);
    var low = 0, high = getLength(array);
    while (low < high) {
      var mid = Math.floor((low + high) / 2);
      if (iteratee(array[mid]) < value) low = mid + 1; else high = mid;
    }
    return low;
  };

  // Generator function to create the indexOf and lastIndexOf functions.
  var createIndexFinder = function(dir, predicateFind, sortedIndex) {
    return function(array, item, idx) {
      var i = 0, length = getLength(array);
      if (typeof idx == 'number') {
        if (dir > 0) {
          i = idx >= 0 ? idx : Math.max(idx + length, i);
        } else {
          length = idx >= 0 ? Math.min(idx + 1, length) : idx + length + 1;
        }
      } else if (sortedIndex && idx && length) {
        idx = sortedIndex(array, item);
        return array[idx] === item ? idx : -1;
      }
      if (item !== item) {
        idx = predicateFind(slice.call(array, i, length), _.isNaN);
        return idx >= 0 ? idx + i : -1;
      }
      for (idx = dir > 0 ? i : length - 1; idx >= 0 && idx < length; idx += dir) {
        if (array[idx] === item) return idx;
      }
      return -1;
    };
  };

  // Return the position of the first occurrence of an item in an array,
  // or -1 if the item is not included in the array.
  // If the array is large and already in sort order, pass `true`
  // for **isSorted** to use binary search.
  _.indexOf = createIndexFinder(1, _.findIndex, _.sortedIndex);
  _.lastIndexOf = createIndexFinder(-1, _.findLastIndex);

  // Generate an integer Array containing an arithmetic progression. A port of
  // the native Python `range()` function. See
  // [the Python documentation](http://docs.python.org/library/functions.html#range).
  _.range = function(start, stop, step) {
    if (stop == null) {
      stop = start || 0;
      start = 0;
    }
    if (!step) {
      step = stop < start ? -1 : 1;
    }

    var length = Math.max(Math.ceil((stop - start) / step), 0);
    var range = Array(length);

    for (var idx = 0; idx < length; idx++, start += step) {
      range[idx] = start;
    }

    return range;
  };

  // Chunk a single array into multiple arrays, each containing `count` or fewer
  // items.
  _.chunk = function(array, count) {
    if (count == null || count < 1) return [];
    var result = [];
    var i = 0, length = array.length;
    while (i < length) {
      result.push(slice.call(array, i, i += count));
    }
    return result;
  };

  // Function (ahem) Functions
  // ------------------

  // Determines whether to execute a function as a constructor
  // or a normal function with the provided arguments.
  var executeBound = function(sourceFunc, boundFunc, context, callingContext, args) {
    if (!(callingContext instanceof boundFunc)) return sourceFunc.apply(context, args);
    var self = baseCreate(sourceFunc.prototype);
    var result = sourceFunc.apply(self, args);
    if (_.isObject(result)) return result;
    return self;
  };

  // Create a function bound to a given object (assigning `this`, and arguments,
  // optionally). Delegates to **ECMAScript 5**'s native `Function.bind` if
  // available.
  _.bind = restArguments(function(func, context, args) {
    if (!_.isFunction(func)) throw new TypeError('Bind must be called on a function');
    var bound = restArguments(function(callArgs) {
      return executeBound(func, bound, context, this, args.concat(callArgs));
    });
    return bound;
  });

  // Partially apply a function by creating a version that has had some of its
  // arguments pre-filled, without changing its dynamic `this` context. _ acts
  // as a placeholder by default, allowing any combination of arguments to be
  // pre-filled. Set `_.partial.placeholder` for a custom placeholder argument.
  _.partial = restArguments(function(func, boundArgs) {
    var placeholder = _.partial.placeholder;
    var bound = function() {
      var position = 0, length = boundArgs.length;
      var args = Array(length);
      for (var i = 0; i < length; i++) {
        args[i] = boundArgs[i] === placeholder ? arguments[position++] : boundArgs[i];
      }
      while (position < arguments.length) args.push(arguments[position++]);
      return executeBound(func, bound, this, this, args);
    };
    return bound;
  });

  _.partial.placeholder = _;

  // Bind a number of an object's methods to that object. Remaining arguments
  // are the method names to be bound. Useful for ensuring that all callbacks
  // defined on an object belong to it.
  _.bindAll = restArguments(function(obj, keys) {
    keys = flatten(keys, false, false);
    var index = keys.length;
    if (index < 1) throw new Error('bindAll must be passed function names');
    while (index--) {
      var key = keys[index];
      obj[key] = _.bind(obj[key], obj);
    }
  });

  // Memoize an expensive function by storing its results.
  _.memoize = function(func, hasher) {
    var memoize = function(key) {
      var cache = memoize.cache;
      var address = '' + (hasher ? hasher.apply(this, arguments) : key);
      if (!has(cache, address)) cache[address] = func.apply(this, arguments);
      return cache[address];
    };
    memoize.cache = {};
    return memoize;
  };

  // Delays a function for the given number of milliseconds, and then calls
  // it with the arguments supplied.
  _.delay = restArguments(function(func, wait, args) {
    return setTimeout(function() {
      return func.apply(null, args);
    }, wait);
  });

  // Defers a function, scheduling it to run after the current call stack has
  // cleared.
  _.defer = _.partial(_.delay, _, 1);

  // Returns a function, that, when invoked, will only be triggered at most once
  // during a given window of time. Normally, the throttled function will run
  // as much as it can, without ever going more than once per `wait` duration;
  // but if you'd like to disable the execution on the leading edge, pass
  // `{leading: false}`. To disable execution on the trailing edge, ditto.
  _.throttle = function(func, wait, options) {
    var timeout, context, args, result;
    var previous = 0;
    if (!options) options = {};

    var later = function() {
      previous = options.leading === false ? 0 : _.now();
      timeout = null;
      result = func.apply(context, args);
      if (!timeout) context = args = null;
    };

    var throttled = function() {
      var now = _.now();
      if (!previous && options.leading === false) previous = now;
      var remaining = wait - (now - previous);
      context = this;
      args = arguments;
      if (remaining <= 0 || remaining > wait) {
        if (timeout) {
          clearTimeout(timeout);
          timeout = null;
        }
        previous = now;
        result = func.apply(context, args);
        if (!timeout) context = args = null;
      } else if (!timeout && options.trailing !== false) {
        timeout = setTimeout(later, remaining);
      }
      return result;
    };

    throttled.cancel = function() {
      clearTimeout(timeout);
      previous = 0;
      timeout = context = args = null;
    };

    return throttled;
  };

  // Returns a function, that, as long as it continues to be invoked, will not
  // be triggered. The function will be called after it stops being called for
  // N milliseconds. If `immediate` is passed, trigger the function on the
  // leading edge, instead of the trailing.
  _.debounce = function(func, wait, immediate) {
    var timeout, result;

    var later = function(context, args) {
      timeout = null;
      if (args) result = func.apply(context, args);
    };

    var debounced = restArguments(function(args) {
      if (timeout) clearTimeout(timeout);
      if (immediate) {
        var callNow = !timeout;
        timeout = setTimeout(later, wait);
        if (callNow) result = func.apply(this, args);
      } else {
        timeout = _.delay(later, wait, this, args);
      }

      return result;
    });

    debounced.cancel = function() {
      clearTimeout(timeout);
      timeout = null;
    };

    return debounced;
  };

  // Returns the first function passed as an argument to the second,
  // allowing you to adjust arguments, run code before and after, and
  // conditionally execute the original function.
  _.wrap = function(func, wrapper) {
    return _.partial(wrapper, func);
  };

  // Returns a negated version of the passed-in predicate.
  _.negate = function(predicate) {
    return function() {
      return !predicate.apply(this, arguments);
    };
  };

  // Returns a function that is the composition of a list of functions, each
  // consuming the return value of the function that follows.
  _.compose = function() {
    var args = arguments;
    var start = args.length - 1;
    return function() {
      var i = start;
      var result = args[start].apply(this, arguments);
      while (i--) result = args[i].call(this, result);
      return result;
    };
  };

  // Returns a function that will only be executed on and after the Nth call.
  _.after = function(times, func) {
    return function() {
      if (--times < 1) {
        return func.apply(this, arguments);
      }
    };
  };

  // Returns a function that will only be executed up to (but not including) the Nth call.
  _.before = function(times, func) {
    var memo;
    return function() {
      if (--times > 0) {
        memo = func.apply(this, arguments);
      }
      if (times <= 1) func = null;
      return memo;
    };
  };

  // Returns a function that will be executed at most one time, no matter how
  // often you call it. Useful for lazy initialization.
  _.once = _.partial(_.before, 2);

  _.restArguments = restArguments;

  // Object Functions
  // ----------------

  // Keys in IE < 9 that won't be iterated by `for key in ...` and thus missed.
  var hasEnumBug = !{toString: null}.propertyIsEnumerable('toString');
  var nonEnumerableProps = ['valueOf', 'isPrototypeOf', 'toString',
    'propertyIsEnumerable', 'hasOwnProperty', 'toLocaleString'];

  var collectNonEnumProps = function(obj, keys) {
    var nonEnumIdx = nonEnumerableProps.length;
    var constructor = obj.constructor;
    var proto = _.isFunction(constructor) && constructor.prototype || ObjProto;

    // Constructor is a special case.
    var prop = 'constructor';
    if (has(obj, prop) && !_.contains(keys, prop)) keys.push(prop);

    while (nonEnumIdx--) {
      prop = nonEnumerableProps[nonEnumIdx];
      if (prop in obj && obj[prop] !== proto[prop] && !_.contains(keys, prop)) {
        keys.push(prop);
      }
    }
  };

  // Retrieve the names of an object's own properties.
  // Delegates to **ECMAScript 5**'s native `Object.keys`.
  _.keys = function(obj) {
    if (!_.isObject(obj)) return [];
    if (nativeKeys) return nativeKeys(obj);
    var keys = [];
    for (var key in obj) if (has(obj, key)) keys.push(key);
    // Ahem, IE < 9.
    if (hasEnumBug) collectNonEnumProps(obj, keys);
    return keys;
  };

  // Retrieve all the property names of an object.
  _.allKeys = function(obj) {
    if (!_.isObject(obj)) return [];
    var keys = [];
    for (var key in obj) keys.push(key);
    // Ahem, IE < 9.
    if (hasEnumBug) collectNonEnumProps(obj, keys);
    return keys;
  };

  // Retrieve the values of an object's properties.
  _.values = function(obj) {
    var keys = _.keys(obj);
    var length = keys.length;
    var values = Array(length);
    for (var i = 0; i < length; i++) {
      values[i] = obj[keys[i]];
    }
    return values;
  };

  // Returns the results of applying the iteratee to each element of the object.
  // In contrast to _.map it returns an object.
  _.mapObject = function(obj, iteratee, context) {
    iteratee = cb(iteratee, context);
    var keys = _.keys(obj),
        length = keys.length,
        results = {};
    for (var index = 0; index < length; index++) {
      var currentKey = keys[index];
      results[currentKey] = iteratee(obj[currentKey], currentKey, obj);
    }
    return results;
  };

  // Convert an object into a list of `[key, value]` pairs.
  // The opposite of _.object.
  _.pairs = function(obj) {
    var keys = _.keys(obj);
    var length = keys.length;
    var pairs = Array(length);
    for (var i = 0; i < length; i++) {
      pairs[i] = [keys[i], obj[keys[i]]];
    }
    return pairs;
  };

  // Invert the keys and values of an object. The values must be serializable.
  _.invert = function(obj) {
    var result = {};
    var keys = _.keys(obj);
    for (var i = 0, length = keys.length; i < length; i++) {
      result[obj[keys[i]]] = keys[i];
    }
    return result;
  };

  // Return a sorted list of the function names available on the object.
  // Aliased as `methods`.
  _.functions = _.methods = function(obj) {
    var names = [];
    for (var key in obj) {
      if (_.isFunction(obj[key])) names.push(key);
    }
    return names.sort();
  };

  // An internal function for creating assigner functions.
  var createAssigner = function(keysFunc, defaults) {
    return function(obj) {
      var length = arguments.length;
      if (defaults) obj = Object(obj);
      if (length < 2 || obj == null) return obj;
      for (var index = 1; index < length; index++) {
        var source = arguments[index],
            keys = keysFunc(source),
            l = keys.length;
        for (var i = 0; i < l; i++) {
          var key = keys[i];
          if (!defaults || obj[key] === void 0) obj[key] = source[key];
        }
      }
      return obj;
    };
  };

  // Extend a given object with all the properties in passed-in object(s).
  _.extend = createAssigner(_.allKeys);

  // Assigns a given object with all the own properties in the passed-in object(s).
  // (https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object/assign)
  _.extendOwn = _.assign = createAssigner(_.keys);

  // Returns the first key on an object that passes a predicate test.
  _.findKey = function(obj, predicate, context) {
    predicate = cb(predicate, context);
    var keys = _.keys(obj), key;
    for (var i = 0, length = keys.length; i < length; i++) {
      key = keys[i];
      if (predicate(obj[key], key, obj)) return key;
    }
  };

  // Internal pick helper function to determine if `obj` has key `key`.
  var keyInObj = function(value, key, obj) {
    return key in obj;
  };

  // Return a copy of the object only containing the whitelisted properties.
  _.pick = restArguments(function(obj, keys) {
    var result = {}, iteratee = keys[0];
    if (obj == null) return result;
    if (_.isFunction(iteratee)) {
      if (keys.length > 1) iteratee = optimizeCb(iteratee, keys[1]);
      keys = _.allKeys(obj);
    } else {
      iteratee = keyInObj;
      keys = flatten(keys, false, false);
      obj = Object(obj);
    }
    for (var i = 0, length = keys.length; i < length; i++) {
      var key = keys[i];
      var value = obj[key];
      if (iteratee(value, key, obj)) result[key] = value;
    }
    return result;
  });

  // Return a copy of the object without the blacklisted properties.
  _.omit = restArguments(function(obj, keys) {
    var iteratee = keys[0], context;
    if (_.isFunction(iteratee)) {
      iteratee = _.negate(iteratee);
      if (keys.length > 1) context = keys[1];
    } else {
      keys = _.map(flatten(keys, false, false), String);
      iteratee = function(value, key) {
        return !_.contains(keys, key);
      };
    }
    return _.pick(obj, iteratee, context);
  });

  // Fill in a given object with default properties.
  _.defaults = createAssigner(_.allKeys, true);

  // Creates an object that inherits from the given prototype object.
  // If additional properties are provided then they will be added to the
  // created object.
  _.create = function(prototype, props) {
    var result = baseCreate(prototype);
    if (props) _.extendOwn(result, props);
    return result;
  };

  // Create a (shallow-cloned) duplicate of an object.
  _.clone = function(obj) {
    if (!_.isObject(obj)) return obj;
    return _.isArray(obj) ? obj.slice() : _.extend({}, obj);
  };

  // Invokes interceptor with the obj, and then returns obj.
  // The primary purpose of this method is to "tap into" a method chain, in
  // order to perform operations on intermediate results within the chain.
  _.tap = function(obj, interceptor) {
    interceptor(obj);
    return obj;
  };

  // Returns whether an object has a given set of `key:value` pairs.
  _.isMatch = function(object, attrs) {
    var keys = _.keys(attrs), length = keys.length;
    if (object == null) return !length;
    var obj = Object(object);
    for (var i = 0; i < length; i++) {
      var key = keys[i];
      if (attrs[key] !== obj[key] || !(key in obj)) return false;
    }
    return true;
  };


  // Internal recursive comparison function for `isEqual`.
  var eq, deepEq;
  eq = function(a, b, aStack, bStack) {
    // Identical objects are equal. `0 === -0`, but they aren't identical.
    // See the [Harmony `egal` proposal](http://wiki.ecmascript.org/doku.php?id=harmony:egal).
    if (a === b) return a !== 0 || 1 / a === 1 / b;
    // `null` or `undefined` only equal to itself (strict comparison).
    if (a == null || b == null) return false;
    // `NaN`s are equivalent, but non-reflexive.
    if (a !== a) return b !== b;
    // Exhaust primitive checks
    var type = typeof a;
    if (type !== 'function' && type !== 'object' && typeof b != 'object') return false;
    return deepEq(a, b, aStack, bStack);
  };

  // Internal recursive comparison function for `isEqual`.
  deepEq = function(a, b, aStack, bStack) {
    // Unwrap any wrapped objects.
    if (a instanceof _) a = a._wrapped;
    if (b instanceof _) b = b._wrapped;
    // Compare `[[Class]]` names.
    var className = toString.call(a);
    if (className !== toString.call(b)) return false;
    switch (className) {
      // Strings, numbers, regular expressions, dates, and booleans are compared by value.
      case '[object RegExp]':
      // RegExps are coerced to strings for comparison (Note: '' + /a/i === '/a/i')
      case '[object String]':
        // Primitives and their corresponding object wrappers are equivalent; thus, `"5"` is
        // equivalent to `new String("5")`.
        return '' + a === '' + b;
      case '[object Number]':
        // `NaN`s are equivalent, but non-reflexive.
        // Object(NaN) is equivalent to NaN.
        if (+a !== +a) return +b !== +b;
        // An `egal` comparison is performed for other numeric values.
        return +a === 0 ? 1 / +a === 1 / b : +a === +b;
      case '[object Date]':
      case '[object Boolean]':
        // Coerce dates and booleans to numeric primitive values. Dates are compared by their
        // millisecond representations. Note that invalid dates with millisecond representations
        // of `NaN` are not equivalent.
        return +a === +b;
      case '[object Symbol]':
        return SymbolProto.valueOf.call(a) === SymbolProto.valueOf.call(b);
    }

    var areArrays = className === '[object Array]';
    if (!areArrays) {
      if (typeof a != 'object' || typeof b != 'object') return false;

      // Objects with different constructors are not equivalent, but `Object`s or `Array`s
      // from different frames are.
      var aCtor = a.constructor, bCtor = b.constructor;
      if (aCtor !== bCtor && !(_.isFunction(aCtor) && aCtor instanceof aCtor &&
                               _.isFunction(bCtor) && bCtor instanceof bCtor)
                          && ('constructor' in a && 'constructor' in b)) {
        return false;
      }
    }
    // Assume equality for cyclic structures. The algorithm for detecting cyclic
    // structures is adapted from ES 5.1 section 15.12.3, abstract operation `JO`.

    // Initializing stack of traversed objects.
    // It's done here since we only need them for objects and arrays comparison.
    aStack = aStack || [];
    bStack = bStack || [];
    var length = aStack.length;
    while (length--) {
      // Linear search. Performance is inversely proportional to the number of
      // unique nested structures.
      if (aStack[length] === a) return bStack[length] === b;
    }

    // Add the first object to the stack of traversed objects.
    aStack.push(a);
    bStack.push(b);

    // Recursively compare objects and arrays.
    if (areArrays) {
      // Compare array lengths to determine if a deep comparison is necessary.
      length = a.length;
      if (length !== b.length) return false;
      // Deep compare the contents, ignoring non-numeric properties.
      while (length--) {
        if (!eq(a[length], b[length], aStack, bStack)) return false;
      }
    } else {
      // Deep compare objects.
      var keys = _.keys(a), key;
      length = keys.length;
      // Ensure that both objects contain the same number of properties before comparing deep equality.
      if (_.keys(b).length !== length) return false;
      while (length--) {
        // Deep compare each member
        key = keys[length];
        if (!(has(b, key) && eq(a[key], b[key], aStack, bStack))) return false;
      }
    }
    // Remove the first object from the stack of traversed objects.
    aStack.pop();
    bStack.pop();
    return true;
  };

  // Perform a deep comparison to check if two objects are equal.
  _.isEqual = function(a, b) {
    return eq(a, b);
  };

  // Is a given array, string, or object empty?
  // An "empty" object has no enumerable own-properties.
  _.isEmpty = function(obj) {
    if (obj == null) return true;
    if (isArrayLike(obj) && (_.isArray(obj) || _.isString(obj) || _.isArguments(obj))) return obj.length === 0;
    return _.keys(obj).length === 0;
  };

  // Is a given value a DOM element?
  _.isElement = function(obj) {
    return !!(obj && obj.nodeType === 1);
  };

  // Is a given value an array?
  // Delegates to ECMA5's native Array.isArray
  _.isArray = nativeIsArray || function(obj) {
    return toString.call(obj) === '[object Array]';
  };

  // Is a given variable an object?
  _.isObject = function(obj) {
    var type = typeof obj;
    return type === 'function' || type === 'object' && !!obj;
  };

  // Add some isType methods: isArguments, isFunction, isString, isNumber, isDate, isRegExp, isError, isMap, isWeakMap, isSet, isWeakSet.
  _.each(['Arguments', 'Function', 'String', 'Number', 'Date', 'RegExp', 'Error', 'Symbol', 'Map', 'WeakMap', 'Set', 'WeakSet'], function(name) {
    _['is' + name] = function(obj) {
      return toString.call(obj) === '[object ' + name + ']';
    };
  });

  // Define a fallback version of the method in browsers (ahem, IE < 9), where
  // there isn't any inspectable "Arguments" type.
  if (!_.isArguments(arguments)) {
    _.isArguments = function(obj) {
      return has(obj, 'callee');
    };
  }

  // Optimize `isFunction` if appropriate. Work around some typeof bugs in old v8,
  // IE 11 (#1621), Safari 8 (#1929), and PhantomJS (#2236).
  var nodelist = root.document && root.document.childNodes;
  if ( true && typeof Int8Array != 'object' && typeof nodelist != 'function') {
    _.isFunction = function(obj) {
      return typeof obj == 'function' || false;
    };
  }

  // Is a given object a finite number?
  _.isFinite = function(obj) {
    return !_.isSymbol(obj) && isFinite(obj) && !isNaN(parseFloat(obj));
  };

  // Is the given value `NaN`?
  _.isNaN = function(obj) {
    return _.isNumber(obj) && isNaN(obj);
  };

  // Is a given value a boolean?
  _.isBoolean = function(obj) {
    return obj === true || obj === false || toString.call(obj) === '[object Boolean]';
  };

  // Is a given value equal to null?
  _.isNull = function(obj) {
    return obj === null;
  };

  // Is a given variable undefined?
  _.isUndefined = function(obj) {
    return obj === void 0;
  };

  // Shortcut function for checking if an object has a given property directly
  // on itself (in other words, not on a prototype).
  _.has = function(obj, path) {
    if (!_.isArray(path)) {
      return has(obj, path);
    }
    var length = path.length;
    for (var i = 0; i < length; i++) {
      var key = path[i];
      if (obj == null || !hasOwnProperty.call(obj, key)) {
        return false;
      }
      obj = obj[key];
    }
    return !!length;
  };

  // Utility Functions
  // -----------------

  // Run Underscore.js in *noConflict* mode, returning the `_` variable to its
  // previous owner. Returns a reference to the Underscore object.
  _.noConflict = function() {
    root._ = previousUnderscore;
    return this;
  };

  // Keep the identity function around for default iteratees.
  _.identity = function(value) {
    return value;
  };

  // Predicate-generating functions. Often useful outside of Underscore.
  _.constant = function(value) {
    return function() {
      return value;
    };
  };

  _.noop = function(){};

  // Creates a function that, when passed an object, will traverse that object’s
  // properties down the given `path`, specified as an array of keys or indexes.
  _.property = function(path) {
    if (!_.isArray(path)) {
      return shallowProperty(path);
    }
    return function(obj) {
      return deepGet(obj, path);
    };
  };

  // Generates a function for a given object that returns a given property.
  _.propertyOf = function(obj) {
    if (obj == null) {
      return function(){};
    }
    return function(path) {
      return !_.isArray(path) ? obj[path] : deepGet(obj, path);
    };
  };

  // Returns a predicate for checking whether an object has a given set of
  // `key:value` pairs.
  _.matcher = _.matches = function(attrs) {
    attrs = _.extendOwn({}, attrs);
    return function(obj) {
      return _.isMatch(obj, attrs);
    };
  };

  // Run a function **n** times.
  _.times = function(n, iteratee, context) {
    var accum = Array(Math.max(0, n));
    iteratee = optimizeCb(iteratee, context, 1);
    for (var i = 0; i < n; i++) accum[i] = iteratee(i);
    return accum;
  };

  // Return a random integer between min and max (inclusive).
  _.random = function(min, max) {
    if (max == null) {
      max = min;
      min = 0;
    }
    return min + Math.floor(Math.random() * (max - min + 1));
  };

  // A (possibly faster) way to get the current timestamp as an integer.
  _.now = Date.now || function() {
    return new Date().getTime();
  };

  // List of HTML entities for escaping.
  var escapeMap = {
    '&': '&amp;',
    '<': '&lt;',
    '>': '&gt;',
    '"': '&quot;',
    "'": '&#x27;',
    '`': '&#x60;'
  };
  var unescapeMap = _.invert(escapeMap);

  // Functions for escaping and unescaping strings to/from HTML interpolation.
  var createEscaper = function(map) {
    var escaper = function(match) {
      return map[match];
    };
    // Regexes for identifying a key that needs to be escaped.
    var source = '(?:' + _.keys(map).join('|') + ')';
    var testRegexp = RegExp(source);
    var replaceRegexp = RegExp(source, 'g');
    return function(string) {
      string = string == null ? '' : '' + string;
      return testRegexp.test(string) ? string.replace(replaceRegexp, escaper) : string;
    };
  };
  _.escape = createEscaper(escapeMap);
  _.unescape = createEscaper(unescapeMap);

  // Traverses the children of `obj` along `path`. If a child is a function, it
  // is invoked with its parent as context. Returns the value of the final
  // child, or `fallback` if any child is undefined.
  _.result = function(obj, path, fallback) {
    if (!_.isArray(path)) path = [path];
    var length = path.length;
    if (!length) {
      return _.isFunction(fallback) ? fallback.call(obj) : fallback;
    }
    for (var i = 0; i < length; i++) {
      var prop = obj == null ? void 0 : obj[path[i]];
      if (prop === void 0) {
        prop = fallback;
        i = length; // Ensure we don't continue iterating.
      }
      obj = _.isFunction(prop) ? prop.call(obj) : prop;
    }
    return obj;
  };

  // Generate a unique integer id (unique within the entire client session).
  // Useful for temporary DOM ids.
  var idCounter = 0;
  _.uniqueId = function(prefix) {
    var id = ++idCounter + '';
    return prefix ? prefix + id : id;
  };

  // By default, Underscore uses ERB-style template delimiters, change the
  // following template settings to use alternative delimiters.
  _.templateSettings = {
    evaluate: /<%([\s\S]+?)%>/g,
    interpolate: /<%=([\s\S]+?)%>/g,
    escape: /<%-([\s\S]+?)%>/g
  };

  // When customizing `templateSettings`, if you don't want to define an
  // interpolation, evaluation or escaping regex, we need one that is
  // guaranteed not to match.
  var noMatch = /(.)^/;

  // Certain characters need to be escaped so that they can be put into a
  // string literal.
  var escapes = {
    "'": "'",
    '\\': '\\',
    '\r': 'r',
    '\n': 'n',
    '\u2028': 'u2028',
    '\u2029': 'u2029'
  };

  var escapeRegExp = /\\|'|\r|\n|\u2028|\u2029/g;

  var escapeChar = function(match) {
    return '\\' + escapes[match];
  };

  // JavaScript micro-templating, similar to John Resig's implementation.
  // Underscore templating handles arbitrary delimiters, preserves whitespace,
  // and correctly escapes quotes within interpolated code.
  // NB: `oldSettings` only exists for backwards compatibility.
  _.template = function(text, settings, oldSettings) {
    if (!settings && oldSettings) settings = oldSettings;
    settings = _.defaults({}, settings, _.templateSettings);

    // Combine delimiters into one regular expression via alternation.
    var matcher = RegExp([
      (settings.escape || noMatch).source,
      (settings.interpolate || noMatch).source,
      (settings.evaluate || noMatch).source
    ].join('|') + '|$', 'g');

    // Compile the template source, escaping string literals appropriately.
    var index = 0;
    var source = "__p+='";
    text.replace(matcher, function(match, escape, interpolate, evaluate, offset) {
      source += text.slice(index, offset).replace(escapeRegExp, escapeChar);
      index = offset + match.length;

      if (escape) {
        source += "'+\n((__t=(" + escape + "))==null?'':_.escape(__t))+\n'";
      } else if (interpolate) {
        source += "'+\n((__t=(" + interpolate + "))==null?'':__t)+\n'";
      } else if (evaluate) {
        source += "';\n" + evaluate + "\n__p+='";
      }

      // Adobe VMs need the match returned to produce the correct offset.
      return match;
    });
    source += "';\n";

    // If a variable is not specified, place data values in local scope.
    if (!settings.variable) source = 'with(obj||{}){\n' + source + '}\n';

    source = "var __t,__p='',__j=Array.prototype.join," +
      "print=function(){__p+=__j.call(arguments,'');};\n" +
      source + 'return __p;\n';

    var render;
    try {
      render = new Function(settings.variable || 'obj', '_', source);
    } catch (e) {
      e.source = source;
      throw e;
    }

    var template = function(data) {
      return render.call(this, data, _);
    };

    // Provide the compiled source as a convenience for precompilation.
    var argument = settings.variable || 'obj';
    template.source = 'function(' + argument + '){\n' + source + '}';

    return template;
  };

  // Add a "chain" function. Start chaining a wrapped Underscore object.
  _.chain = function(obj) {
    var instance = _(obj);
    instance._chain = true;
    return instance;
  };

  // OOP
  // ---------------
  // If Underscore is called as a function, it returns a wrapped object that
  // can be used OO-style. This wrapper holds altered versions of all the
  // underscore functions. Wrapped objects may be chained.

  // Helper function to continue chaining intermediate results.
  var chainResult = function(instance, obj) {
    return instance._chain ? _(obj).chain() : obj;
  };

  // Add your own custom functions to the Underscore object.
  _.mixin = function(obj) {
    _.each(_.functions(obj), function(name) {
      var func = _[name] = obj[name];
      _.prototype[name] = function() {
        var args = [this._wrapped];
        push.apply(args, arguments);
        return chainResult(this, func.apply(_, args));
      };
    });
    return _;
  };

  // Add all of the Underscore functions to the wrapper object.
  _.mixin(_);

  // Add all mutator Array functions to the wrapper.
  _.each(['pop', 'push', 'reverse', 'shift', 'sort', 'splice', 'unshift'], function(name) {
    var method = ArrayProto[name];
    _.prototype[name] = function() {
      var obj = this._wrapped;
      method.apply(obj, arguments);
      if ((name === 'shift' || name === 'splice') && obj.length === 0) delete obj[0];
      return chainResult(this, obj);
    };
  });

  // Add all accessor Array functions to the wrapper.
  _.each(['concat', 'join', 'slice'], function(name) {
    var method = ArrayProto[name];
    _.prototype[name] = function() {
      return chainResult(this, method.apply(this._wrapped, arguments));
    };
  });

  // Extracts the result from a wrapped and chained object.
  _.prototype.value = function() {
    return this._wrapped;
  };

  // Provide unwrapping proxy for some methods used in engine operations
  // such as arithmetic and JSON stringification.
  _.prototype.valueOf = _.prototype.toJSON = _.prototype.value;

  _.prototype.toString = function() {
    return String(this._wrapped);
  };

  // AMD registration happens at the end for compatibility with AMD loaders
  // that may not enforce next-turn semantics on modules. Even though general
  // practice for AMD registration is to be anonymous, underscore registers
  // as a named module because, like jQuery, it is a base library that is
  // popular enough to be bundled in a third party lib, but not be part of
  // an AMD load request. Those cases could generate an error when an
  // anonymous define() is called outside of a loader request.
  if (true) {
    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function() {
      return _;
    }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),
				__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));
  }
}());

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../webpack/buildin/global.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\buildin\\global.js"), __webpack_require__(/*! ./../../../webpack/buildin/module.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\buildin\\module.js")(module)))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordnet-db\\index.js":
/*!**********************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/wordnet-db/index.js ***!
  \**********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(__dirname) {
exports.version = '3.1';	// this is the WordNet DB version
exports.path = __webpack_require__(/*! path */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\path-browserify\\index.js").join(__dirname, 'dict');
try{
exports.files = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js").readdirSync(exports.path);
} catch(e) {
  console.log(e.message);
}
/* WEBPACK VAR INJECTION */}.call(this, "/"))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\lib\\natural\\trie\\trie.js":
/*!***********************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/wordpos/lib/natural/trie/trie.js ***!
  \***********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2014 Ken Koch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

/** 
 * The basis of the TRIE structure.
 **/
function Trie(caseSensitive) {
	this.dictionary = {};
	this.$ = false;

	if(typeof caseSensitive === "undefined") {
		caseSensitive = true;
	}

	this.cs = caseSensitive;
}

/**
 * Add a single string to the TRIE, returns true if the word was already in the 
 * trie.
 **/
Trie.prototype.addString = function(string) {
	if(this.cs === false) {
		string = string.toLowerCase();
	}

	// If the string has only one letter, mark this as a word.
	if(string.length === 0) {
		var wasWord = this.$;
		this.$ = true;
		return wasWord;
	}

	// Make sure theres a Trie node in our dictionary
	var next = this.dictionary[string[0]];

	if(!next) {
		this.dictionary[string[0]] = new Trie(this.cs);
		next = this.dictionary[string[0]];
	}

	// Continue adding the string
	return next.addString(string.substring(1));
};

/**
 * Add multiple strings to the TRIE
 **/
Trie.prototype.addStrings = function(list) {
	for(var i in list) {
		this.addString(list[i]);
	}
};

/**
 * A function to search the TRIE and return an array of
 * words which have same prefix <prefix>
 * for example if we had the following words in our database:
 * a, ab, bc, cd, abc, abd
 * and we search the string: a
 * we will get :
 * [a, ab, abc, abd]
 **/
Trie.prototype.keysWithPrefix = function(prefix) {
    if(this.caseSensitive === false) {
        prefix = prefix.toLowerCase();
    }

    function isEmpty (object) {
        for (var key in object) if (object.hasOwnProperty(key)) return false;
        return true;
    }

    function get (node, word) {
        if(!node) return null;
        if(word.length == 0) return node;
        return get(node.dictionary[word[0]], word.substring(1));
    }

    function recurse ( node, stringAgg, resultsAgg) {
        if (!node) return;

        // Check if this is a word
        if (node.$) {
            resultsAgg.push(stringAgg);
        }

        if (isEmpty(node.dictionary)) {
            return ;
        }

        for (var c in node.dictionary) {
            recurse (node.dictionary[c],stringAgg + c, resultsAgg);
        }
    }

    var results = [];
    recurse (get(this, prefix), prefix, results);
    return results;
};

/** 
 * A function to search the given string and return true if it lands
 * on on a word. Essentially testing if the word exists in the database.
 **/
Trie.prototype.contains = function(string) {
	if(this.cs === false) {
		string = string.toLowerCase();
	}

	if(string.length === 0) {
		return this.$;
	}

	// Otherwise, we need to continue searching
	var firstLetter = string[0];
	var next = this.dictionary[firstLetter];		

	// If we don't have a node, this isn't a word
	if(!next) {
		return false;
	}

	// Otherwise continue the search at the next node
	return next.contains(string.substring(1));
}

/**
 * A function to search the TRIE and return an array of words which were encountered along the way.
 * This will only return words with full prefix matches.
 * for example if we had the following words in our database:
 * a, ab, bc, cd, abc
 * and we searched the string: abcd
 * we would get only:
 * [a, ab, abc]
 **/
Trie.prototype.findMatchesOnPath = function(search) {
	if(this.cs === false) {
		search = search.toLowerCase();
	}

	function recurse(node, search, stringAgg, resultsAgg) {
		// Check if this is a word.
		if(node.$) {
			resultsAgg.push(stringAgg);
		}

		// Check if the have completed the seearch
		if(search.length === 0) {
			return resultsAgg;
		}

		// Otherwise, continue searching
		var next = node.dictionary[search[0]];
		if(!next) {
			return resultsAgg;
		}
		return recurse(next, search.substring(1), stringAgg + search[0], resultsAgg);
	};

	return recurse(this, search, "", []);
};

/**
 * Returns the longest match and the remaining part that could not be matched.
 * inspired by [NLTK containers.trie.find_prefix](http://nltk.googlecode.com/svn-/trunk/doc/api/nltk.containers.Trie-class.html).
 **/
Trie.prototype.findPrefix = function(search) {
	if(this.cs === false) {
		search = search.toLowerCase();
	}
	
	function recurse(node, search, stringAgg, lastWord) {
		// Check if this is a word
		if(node.$) {
			lastWord = stringAgg;
		}

		// Check if we have no more to search
		if(search.length === 0) {
			return [lastWord, search];
		}

		// Continue searching
		var next = node.dictionary[search[0]];
		if(!next) {
			return [lastWord, search];
		}
		return recurse(next, search.substring(1), stringAgg + search[0], lastWord);
	};

	return recurse(this, search, "", null);
};

/**
 * Computes the number of actual nodes from this node to the end.
 * Note: This involves traversing the entire structure and may not be
 * good for frequent use.
 **/
Trie.prototype.getSize = function() { 
	var total = 1;
	for(var c in this.dictionary) {
		total += this.dictionary[c].getSize();
	}
	return total;
};

/**
 * EXPORT THE TRIE
 **/
module.exports = Trie;



/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\lib\\natural\\util\\stopwords.js":
/*!****************************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/wordpos/lib/natural/util/stopwords.js ***!
  \****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
Copyright (c) 2011, Chris Umbel

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// a list of commonly used words that have little meaning and can be excluded
// from analysis.
var words = [
    'about', 'after', 'all', 'also', 'am', 'an', 'and', 'another', 'any', 'are', 'as', 'at', 'be',
    'because', 'been', 'before', 'being', 'between', 'both', 'but', 'by', 'came', 'can',
    'come', 'could', 'did', 'do', 'each', 'for', 'from', 'get', 'got', 'has', 'had',
    'he', 'have', 'her', 'here', 'him', 'himself', 'his', 'how', 'if', 'in', 'into',
    'is', 'it', 'like', 'make', 'many', 'me', 'might', 'more', 'most', 'much', 'must',
    'my', 'never', 'now', 'of', 'on', 'only', 'or', 'other', 'our', 'out', 'over',
    'said', 'same', 'see', 'should', 'since', 'some', 'still', 'such', 'take', 'than',
    'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'this', 'those',
    'through', 'to', 'too', 'under', 'up', 'very', 'was', 'way', 'we', 'well', 'were',
    'what', 'where', 'which', 'while', 'who', 'with', 'would', 'you', 'your',
    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',
    'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '$', '1',
    '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];
    
// tell the world about the noise words.    
exports.words = words;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\dataFile.js":
/*!**************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/wordpos/src/dataFile.js ***!
  \**************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer) {/*!
 * dataFile.js
 *
 * Copyright (c) 2012-2018 mooster@42at.com
 * https://github.com/moos/wordpos
 *
 * Portions: Copyright (c) 2011, Chris Umbel
 *
 * Released under MIT license
 */

var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js"),
  path = __webpack_require__(/*! path */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\path-browserify\\index.js"),
  _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js");

/**
 * sanity check read data - line must start with zero-padded location
 *
 * @param line {string} - line data read
 * @return {boolean} true if line data is good
 */
function dataCheck(line, location) {
  var pad = '00000000', // 8 zeros
    padded = String(pad + location).slice( - pad.length);
  return line.indexOf(padded) === 0;
}

/**
 * parse a single data file line, returning data object
 *
 * @param line {string} - a single line from WordNet data file
 * @returns {object}
 *
 * Credit for this routine to https://github.com/NaturalNode/natural
 */
function lineDataToJSON(line, location) {
  if (!dataCheck(line, location)) return new Error('Bad data at location ' + location);

  var data = line.split('| '),
    tokens = data[0].split(/\s+/),
    ptrs = [],
    wCnt = parseInt(tokens[3], 16),
    synonyms = [],
    i;

  for(i = 0; i < wCnt; i++) {
    synonyms.push(tokens[4 + i * 2]);
  }

  var ptrOffset = (wCnt - 1) * 2 + 6;
  for(i = 0; i < parseInt(tokens[ptrOffset], 10); i++) {
    ptrs.push({
      pointerSymbol: tokens[ptrOffset + 1 + i * 4],
      synsetOffset: parseInt(tokens[ptrOffset + 2 + i * 4], 10),
      pos: tokens[ptrOffset + 3 + i * 4],
      sourceTarget: tokens[ptrOffset + 4 + i * 4]
    });
  }

  // break "gloss" into definition vs. examples
  var glossArray = data[1].split("; ");
  var definition = glossArray[0];
  var examples = glossArray.slice(1);
  var lexFilenum = parseInt(tokens[1], 10);

  for (var k = 0; k < examples.length; k++) {
    examples[k] = examples[k].replace(/\"/g,'').replace(/\s\s+/g,'');
  }

  return {
    synsetOffset: parseInt(tokens[0], 10),
    lexFilenum: lexFilenum,
    lexName: DataFile.LEX_NAMES[ lexFilenum ],
    pos: tokens[2],
    wCnt: wCnt,
    lemma: tokens[4],
    synonyms: synonyms,
    lexId: tokens[5],
    ptrs: ptrs,
    gloss: data[1],
    def: definition,
    exp: examples
  };
}

/**
 * read data file at location (bound to a data file).
 * Reads nominal length and checks for EOL.  Continue reading until EOL.
 *
 * @param location {Number} - seek location
 * @param callback {function} - callback function
 */
function readLocation(location, callback) {
  //console.log('## read location ', this.fileName, location);
  var
    file = this,
    str = '',
    len = file.nominalLineLength,
    buffer = new Buffer.alloc(len);

  readChunk(location, function(err, count) {
    if (err) {
      //console.log(err);
      callback(err);
      return;
    }
    //console.log('  read %d bytes at <%d>', count, location);
    callback(null, lineDataToJSON(str, location));
  });

  function readChunk(pos, cb) {
    var nonDataErr = new Error('no data at offset ' + pos);

    fs.read(file.fd, buffer, 0, len, pos, function (err, count) {
      if (!count) return cb(nonDataErr, count);

      str += buffer.toString('ascii');
      var eol = str.indexOf('\n');
      //console.log('  -- read %d bytes at <%d>', count, pos, eol);
      if (count && eol === -1 && len < file.maxLineLength) {
        // continue reading
        return readChunk(pos + count, cb);
      }

      str = str.substr(0, eol);
      if (str === '' && !err) err = nonDataErr;
      cb(err, count);
    });
  }
}

/**
 * main lookup function
 *
 * @param offsets {array} - array of offsets to lookup (obtained from index.find())
 * @param callback{function} (optional) - callback function
 * @returns {Promise}
 */
function lookup(offsets, callback) {
  var results = [],
    self = this,
    single = !_.isArray(offsets);

  if (single) offsets = [offsets];
  return new Promise(function(resolve, reject) {
    offsets
      .map(function (offset) {
        return _.partial(readLocation.bind(self), offset);
      })
      .map(promisifyInto(results))
      .reduce(serialize, openFile())
      .then(done)
      .catch(done);

    function done(lastResult) {
      closeFile();
      if (lastResult instanceof Error) {
        callback && callback(lastResult, single ? {} :[]);
        reject(lastResult);
      } else {
        if (single) results = results[0];
        callback && callback(null, results);
        resolve(results);
      }
    }
  });

  function serialize(prev, next) {
    return prev.then(next);
  }

  function openFile() {
    if (!self.fd) {
      // console.log(' ... opening', self.filePath);
      self.fd = fs.openSync(self.filePath, 'r');
    }
    // ref count so we know when to close the main index file
    ++self.refcount;
    return Promise.resolve();
  }

  function closeFile() {
    if (--self.refcount === 0) {
      // console.log(' ... closing', self.filePath);
      fs.closeSync(self.fd);
      self.fd = null;
    }
    return Promise.resolve();
  }
}

/**
 * turn ordinary function into a promising one!
 *
 * @param collect {Array} - used to collect results
 * @returns {Function}
 */
function promisifyInto(collect) {
  return function(fn) {
    return function() {
      return new Promise(function (resolve, reject) {
        fn(function (error, result) {   // Note: callback signature!
          if (error) {
            reject(error);
          }
          else {
            collect && collect.push(result);
            resolve(result);
          }
        });
      });
    };
  }
}


/**
 * DataFile class
 *
 * @param dictPath {string} - path to dict folder
 * @param name {string} - POS name
 * @constructor
 */
var DataFile = function(dictPath, name) {
  this.dictPath = dictPath;
  this.fileName = 'data.' + name;
  this.filePath = path.join(this.dictPath, this.fileName);

  this.maxLineLength = DataFile.MAX_LINE_LENGTH[ name ];
  this.nominalLineLength = MAX_SINGLE_READ_LENGTH;
  this.refcount = 0;
};

/**
 * maximum read length at a time
 * @type {Number}
 */
var MAX_SINGLE_READ_LENGTH = 512;

/**
 * lookup
 */
DataFile.prototype.lookup = lookup;


/**
 * maximum line length in each data file - used to optimize reads
 *
 * wc -L data.adv as of v3.1
 */
DataFile.MAX_LINE_LENGTH = {
  noun: 12972,
  verb: 7713,
  adj: 2794,
  adv: 638
};

/**
 * map of lexFilenum to lex names
 *
 * @see https://wordnet.princeton.edu/wordnet/man/lexnames.5WN.html
 * @type {string[]}
 */
DataFile.LEX_NAMES = [
  'adj.all',
  'adj.pert',
  'adv.all',
  'noun.Tops',
  'noun.act',
  'noun.animal',
  'noun.artifact',
  'noun.attribute',
  'noun.body',
  'noun.cognition',
  'noun.communication',
  'noun.event',
  'noun.feeling',
  'noun.food',
  'noun.group',
  'noun.location',
  'noun.motive',
  'noun.object',
  'noun.person',
  'noun.phenomenon',
  'noun.plant',
  'noun.possession',
  'noun.process',
  'noun.quantity',
  'noun.relation',
  'noun.shape',
  'noun.state',
  'noun.substance',
  'noun.time',
  'verb.body',
  'verb.change',
  'verb.cognition',
  'verb.communication',
  'verb.competition',
  'verb.consumption',
  'verb.contact',
  'verb.creation',
  'verb.emotion',
  'verb.motion',
  'verb.perception',
  'verb.possession',
  'verb.social',
  'verb.stative',
  'verb.weather',
  'adj.ppl'
];

module.exports = DataFile;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../webpack/node_modules/buffer/index.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\buffer\\index.js").Buffer))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\indexFile.js":
/*!***************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/wordpos/src/indexFile.js ***!
  \***************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer, process) {/*!
 * indexFile.js
 *
 * 		implements fast index lookup of WordNet's index files
 *
 * Copyright (c) 2012-2018 mooster@42at.com
 * https://github.com/moos/wordpos
 *
 * Portions: Copyright (c) 2011, Chris Umbel
 *
 * Released under MIT license
 */

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._,
  util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
  path = __webpack_require__(/*! path */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\path-browserify\\index.js"),
  fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js"),
  piper = __webpack_require__(/*! ./piper */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\piper.js"),
  KEY_LENGTH = 3;


/**
 * load fast index bucket data
 *
 * @param dir {string} - dir path of index files
 * @param name {string} - name of index file, eg, 'index.verb'
 * @returns {Object} - fast index data object
 */
function loadFastIndex(dir, name) {
  var jsonFile = path.join(dir, 'fast-' + name + '.json'),
    data = null;
  try{
    data = JSON.parse( fs.readFileSync(jsonFile,'utf8') );
    //console.log('loaded %d buckets for %s', data.stats.buckets, data.name);
  } catch(e) {
    console.error('Error with fast index file. Try reinstalling from npm!');
    throw e;
  }
  return data;
}

/**
 * read index file using fast index data at key
 *
 * @param key {string} - 3-char key into fast index
 * @param index {object} - index file object
 * @param callback {function} - function receives buffer of data read
 * @returns none
 */
function readIndexForKey(key, index, callback) {
  var data = index.fastIndex,
    offset = data.offsets[key][0],
    nextKey = data.offsets[key][1],
    nextOffset = data.offsets[nextKey][0],
    len = nextOffset - offset - 1,
    buffer = new Buffer.alloc(len);

  fs.read(index.fd, buffer, 0, len, offset, function(err, count){
     if (err) return console.log(err);
     //console.log('  read %d bytes for <%s>', count, key);
     callback(buffer);
  });
}


/**
 * read index file using fast index data at keyStart to keyEnd (inclusive)
 *
 * @param keyStart {string} - 3-char key into fast index to begin at
 * @param keyEnd {string|null} - 3-char key into fast index to end at.  If null, reads to next key.
 * @param index {object} - index file object
 * @param callback - function receives buffer of data read
 * @returns none
 */
function readIndexBetweenKeys(keyStart, keyEnd, index, callback) {
  var data = index.fastIndex,
    offset = data.offsets[keyStart][0],
    end = keyEnd || keyStart,
    nextKey = data.offsets[end][1],
    nextOffset = data.offsets[nextKey][0],
    len = nextOffset - offset - 1,
    buffer = new Buffer.alloc(len);

  //console.log('### readIndexBetweenKeys', keyStart, keyEnd, nextKey, len)
  fs.read(index.fd, buffer, 0, len, offset, function(err, count){
     if (err) return console.log(err);
     // console.log('  read %d bytes for <%s>', count, keyStart);
     callback(buffer);
  });
}

/**
 * find a search term in an index file (using fast index)
 *
 * Calls to same bucket are queued for callback using the piper.
 *
 * @param search {string} - word to search for
 * @param callback {function} - callback receives found line and tokens
 * @returns none
 */
function find(search, callback) {
  var self = this,
    data = this.fastIndex,
    readCallbacks = this.callbackQueue,
    miss = {status: 'miss'};

  var key = search.slice(0, KEY_LENGTH);
  if (!(key in data.offsets)) return process.nextTick(function(){ callback(miss) });

  // prepare the piper
  var task = 'find:' + key,
    args = [key, this],
    context = [search, callback]; // last arg MUST be callback

  // pay the piper
  this.piper(task, readIndexForKey, args, context, collector);

  function collector(_key, index, search, callback, buffer){
    var lines = buffer.toString().split('\n'),
      keys = lines.map(function(line){
        return line.substring(0,line.indexOf(' '));
      }),
      ind = _.indexOf(keys, search, /*isSorted*/ true);	// binary search!

    //console.log(' %s is %d', search, ind);
    if (ind === -1) return callback(miss);

    var tokens = lines[ind].split(/\s+/),
      key = tokens[0],
      result = {status: 'hit', key: key, 'line': lines[ind], tokens: tokens};

    callback(result);
  }
}

/**
 * find a word and prepare its lexical record
 *
 * @param word {string} - search word
 * @param callback {function} - callback function receives result
 * @returns none
 *
 * Credit for this routine to https://github.com/NaturalNode/natural
 */
function lookup(word, callback) {
  var self = this;

  return new Promise(function(resolve, reject){
    self.find(word, function (record) {
      var indexRecord = null,
        i;

      if (record.status == 'hit') {
        var ptrs = [], offsets = [];

        for (i = 0; i < parseInt(record.tokens[3]); i++)
          ptrs.push(record.tokens[i]);

        for (i = 0; i < parseInt(record.tokens[2]); i++)
          offsets.push(parseInt(record.tokens[ptrs.length + 6 + i], 10));

        indexRecord = {
          lemma       : record.tokens[0],
          pos         : record.tokens[1],
          ptrSymbol   : ptrs,
          senseCnt    : parseInt(record.tokens[ptrs.length + 4], 10),
          tagsenseCnt : parseInt(record.tokens[ptrs.length + 5], 10),
          synsetOffset: offsets
        };
      }

      callback && callback(indexRecord);
      resolve(indexRecord);
    });
  });
}


/**
 * loads fast index data and return fast index find function
 *
 * @param index {object} - the IndexFile instance
 */
function initIndex(index){
  var key = index.filePath,
    data;

  if (!(key in cache)) {
    data = loadFastIndex(index.dictPath, index.fileName);
    cache[key] = data;
  }

  // if no fast index data was found or was corrupt, throw
  if (!cache[key]) throw new Error('Unable to load fastIndex file: ' + index.filePath);

  index.fastIndex = cache[key];
  index.fastIndex.indexKeys = Object.keys(index.fastIndex.offsets);
  index.fastIndex.trie = null;  // calc on demand

  index.refcount = 0;
  index.callbackQueue = {};
  index.piper = _.bind(piper, index);
}

/**
 * IndexFile class
 *
 * @param dictPath {string} - WordNet db dict path
 * @param name {string} - name of index: noun, verb, adj, adv
 * @constructor
 */
var IndexFile = function(dictPath, name) {
  this.dictPath = dictPath;
  this.fileName = 'index.' + name;
  this.filePath = path.join(this.dictPath, this.fileName);
  initIndex(this);
};

IndexFile.prototype.lookup = lookup;
IndexFile.prototype.find = find;

/**
 * export static method
 * @type {readIndexBetweenKeys}
 */
IndexFile.readIndexBetweenKeys = readIndexBetweenKeys;

/**
 * cache of fast index data across instances of WordPOS class
 *
 * @type {object}
 */
var cache = {};



module.exports = IndexFile;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../webpack/node_modules/buffer/index.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\buffer\\index.js").Buffer, __webpack_require__(/*! ./../../../../webpack/node_modules/process/browser.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\process\\browser.js")))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\piper.js":
/*!***********************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/wordpos/src/piper.js ***!
  \***********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*!
 * piper.js
 *
 *     executes multiple async i/o tasks and pools similar callbacks,
 *     calling i/o open/close when all incoming tasks are done.
 *
 * Copyright (c) 2012-2016 mooster@42at.com
 * https://github.com/moos/wordpos
 *
 * Released under MIT license
 */

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._,
  util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
  fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js");

/**
 * run single 'task' method sharing callbacks.  Method MUST take callback as LAST arg.
 * piper is bound to an IndexFile.
 *
 * @param task {string} - task name unique to method!
 * @param method {function} - method to execute, gets (args, ... , callback)
 * @param args {Array} - args to pass to method
 * @param context {object} - other params to remember and sent to callback
 * @param callback {function} - result callback
 */
function piper(task, method, args, context, callback){
  var readCallbacks = this.callbackQueue,
    memoArgs = _.rest(arguments, 2),
    wrappedCallback;

   //console.log('piper', task, [method]);

  // queue up if already reading file for this task
  if (task in readCallbacks){
    readCallbacks[task].push(memoArgs);
    return;
  }
  readCallbacks[task] = [memoArgs];

  if (!this.fd) {
    //console.log(' ... opening', this.filePath);
    this.fd = fs.openSync(this.filePath, 'r');
  }

  // ref count so we know when to close the main index file
  ++this.refcount;

  wrappedCallback = _.partial(piper.wrapper, this, task);

  // call method -- replace original callback (last arg) with wrapped one
  method.apply(null, [].concat( args, wrappedCallback ));
}

// result is the *same* for same task
piper.wrapper = function(self, task /*, result...*/){
  var readCallbacks = self.callbackQueue,
    result = _.rest(arguments, 2),
    callback, args;

  // live access callbacks cache in case nested cb's
  // add to the array.
  while (args = readCallbacks[task].shift()) {
    callback = args.pop(); // last arg MUST be callback

//    console.log('>>>> pper wrapper', self.fastIndex.name, task, result.toString())
    callback.apply(null, [].concat(_.flatten(args, /*shallow*/true), result));
  }

  // now done - delete cb cache
  delete readCallbacks[task];

  if (--self.refcount === 0) {
    //console.log(' ... closing', self.filePath);
    fs.closeSync(self.fd);
    self.fd = null;
  }
};


module.exports = piper;



/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\rand.js":
/*!**********************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/wordpos/src/rand.js ***!
  \**********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*!
 * rand.js
 *
 * 		define rand() and randX() functions on wordpos
 *
 * Copyright (c) 2012-2016 mooster@42at.com
 * https://github.com/moos/wordpos
 *
 * Released under MIT license
 */

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._,
  util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
  Trie = __webpack_require__(/*! ../lib/natural/trie/trie */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\lib\\natural\\trie\\trie.js"),
  IndexFile = __webpack_require__(/*! ./indexFile */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\indexFile.js"),
  KEY_LENGTH = 3;


/**
 * factory function for randX()
 *
 * @param pos {string} - a,r,n,v
 * @returns {Function} - rand function bound to an index file
 */
function makeRandX(pos){
  return function(opts, callback, _noprofile) {
    // disable profiling when isX() used internally
    var profile = this.options.profile && !_noprofile,
      start = profile && new Date(),
      args = [],
      index = this.getFilesFor(pos).index,
      startsWith = opts && opts.startsWith || '',
      count = opts && opts.count || 1;

    if (typeof opts === 'function') {
      callback = opts;
    }

    return index.rand(startsWith, count, function (record) {
      args.push(record, startsWith);
      profile && args.push(new Date() - start);
      callback && callback.apply(null, args);
    });
  };
}

/**
 * rand function (bound to index)
 *
 * @param startsWith {string} - get random word(s) that start with this, or ''
 * @param num {number} - number of words to return
 * @param callback {function} - callback function, receives words array and startsWith
 * @returns Promise
 */
function rand(startsWith, num, callback){
  var self = this,
    nextKey = null,
    trie = this.fastIndex.trie,
    key, keys;

  return new Promise(function(resolve, reject) {

    //console.log('-- ', startsWith, num, self.fastIndex.indexKeys.length);
    if (startsWith) {
      key = startsWith.slice(0, KEY_LENGTH);

      /**
       * if key is 'a' or 'ab' (<3 chars), search for ALL keys starting with that.
       */
      if (key.length < KEY_LENGTH) {

        // calc trie if haven't done so yet
        if (!trie) {
          trie = new Trie();
          trie.addStrings(self.fastIndex.indexKeys);
          self.fastIndex.trie = trie;
          //console.log(' +++ Trie calc ');
        }

        try {
          // trie throws if not found!!!!!
          keys = trie.keysWithPrefix(startsWith);
        } catch (e) {
          keys = [];
        }

        // read all keys then select random word.
        // May be large disk read!
        key = keys[0];
        nextKey = _.last(keys);
      }

      if (!key || !(key in self.fastIndex.offsets))  {
        callback && callback([], startsWith);
        resolve([]);
      }

    } else {
      // no startWith given - random select among keys
      keys = _.sample(self.fastIndex.indexKeys, num);

      // if num > 1, run each key independently and collect results
      if (num > 1) {
        var results = [], ii = 0;
        _(keys).each(function (startsWith) {
          self.rand(startsWith, 1, function (result) {
            results.push(result[0]);
            if (++ii == num) {
              callback && callback(results, '');
              resolve(results);
            }
          });
        });
        return;
      }
      key = keys;
    }

    // prepare the piper
    var args = [key, nextKey, self],
      task = 'rand:' + key + nextKey,
      context = [startsWith, num, callback]; // last arg MUST be callback

    // pay the piper
    self.piper(task, IndexFile.readIndexBetweenKeys, args, context, collector);

    function collector(key, nextKey, index, startsWith, num, callback, buffer) {
      var lines = buffer.toString().split('\n'),
        matches = lines.map(function (line) {
          return line.substring(0, line.indexOf(' '));
        });
      //console.log(' got lines for key ', key, lines.length);

      // we got bunch of matches for key - now search within for startsWith
      if (startsWith !== key) {
        // binary search for startsWith within set of matches
        var ind = _.sortedIndex(matches, startsWith);
        if (ind >= lines.length || matches[ind].indexOf(startsWith) === -1) {
          callback && callback([], startsWith);
          resolve([]);
          return;
        }

        var trie = new Trie();
        trie.addStrings(matches);
        //console.log('Trie > ', trie.matchesWithPrefix( startsWith ));
        matches = trie.keysWithPrefix(startsWith);
      }

      var words = _.sample(matches, num);
      callback && callback(words, startsWith);
      resolve(words);
    }

  }); // Promise
}

// relative weight of each POS word count (DB 3.1 numbers)
var POS_factor = {
  Noun: 26,
  Verb: 3,
  Adjective: 5,
  Adverb: 1,
  Total: 37
};

/**
 * rand() - for all Index files
 * @returns Promise
 */
function randAll(opts, callback) {

  if (typeof opts === 'function') {
    callback = opts;
    opts = {};
  } else {
    opts = _.clone(opts || {});
  }

  var
    profile = this.options.profile,
    start = profile && new Date(),
    results = [],
    startsWith = opts && opts.startsWith || '',
    count = opts && opts.count || 1,
    args = [null, startsWith],
    parts = 'Noun Verb Adjective Adverb'.split(' '),
    self = this;



  return new Promise(function(resolve, reject) {
    // select at random a POS to look at
    var doParts = _.sample(parts, parts.length);
    tryPart();

    function tryPart() {
      var part = doParts.pop(),
        rand = 'rand' + part,
        factor = POS_factor[part],
        weight = factor / POS_factor.Total;

      // pick count according to relative weight
      opts.count = Math.ceil(count * weight * 1.1); // guard against dupes
      self[rand](opts, partCallback);
    }

    function partCallback(result) {
      if (result) {
        results = _.uniq(results.concat(result));  // make sure it's unique!
      }

      if (results.length < count && doParts.length) {
        return tryPart();
      }

      // final random and trim excess
      results = _.sample(results, count);
      done();
    }

    function done() {
      profile && (args.push(new Date() - start));
      args[0] = results;
      callback && callback.apply(null, args);
      resolve(results);
    }

  }); // Promise
}

/**
 * bind rand() to index
 *
 * @param index {object} - the IndexFile instance
 * @returns {function} - bound rand function for index
 */
function randomify(index){
  if (!index.fastIndex) throw 'rand requires fastIndex';
  return _.bind(rand, index);
}



module.exports = {

  init: function(wordposProto) {
    wordposProto.nounIndex.rand = randomify(wordposProto.nounIndex);
    wordposProto.verbIndex.rand = randomify(wordposProto.verbIndex);
    wordposProto.adjIndex.rand = randomify(wordposProto.adjIndex);
    wordposProto.advIndex.rand = randomify(wordposProto.advIndex);

    /**
     * define rand()
     */
    wordposProto.rand = randAll;

    /**
     * define randX()
     */
    wordposProto.randAdjective = makeRandX('a');
    wordposProto.randAdverb = makeRandX('r');
    wordposProto.randNoun = makeRandX('n');
    wordposProto.randVerb = makeRandX('v');
  }
};



/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\wordpos.js":
/*!*************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/node_modules/wordpos/src/wordpos.js ***!
  \*************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*!
* wordpos.js
*
*    Node.js part-of-speech utilities using WordNet database.
*
* Copyright (c) 2012-2016 mooster@42at.com
* https://github.com/moos/wordpos
*
* Released under MIT license
*/

var _ = __webpack_require__(/*! underscore */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\underscore\\underscore.js")._,
  util = __webpack_require__(/*! util */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js"),
  stopwords = __webpack_require__(/*! ../lib/natural/util/stopwords */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\lib\\natural\\util\\stopwords.js").words,
  stopwordsStr = makeStopwordString(stopwords),
  WNdb = __webpack_require__(/*! wordnet-db */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordnet-db\\index.js"),
  DataFile = __webpack_require__(/*! ./dataFile */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\dataFile.js"),
  IndexFile = __webpack_require__(/*! ./indexFile */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\indexFile.js");


function normalize(word) {
  return word.toLowerCase().replace(/\s+/g, '_');
}

function makeStopwordString(stopwords) {
  return ' '+ stopwords.join(' ') +' ';
}

function isStopword(stopwords, word) {
  return stopwords.indexOf(' '+word+' ') >= 0;
}

function tokenizer(str) {
  return str.split(/\W+/); //_.without(results,'',' ')
}

function prepText(text) {
  if (_.isArray(text)) return text;
  var deduped = _.uniq(tokenizer(text));
  if (!this.options.stopwords) return deduped;
  return _.reject(deduped, _.bind(isStopword, null,
    _.isString(this.options.stopwords) ? this.options.stopwords : stopwordsStr
  ));
}

/**
 * factory for main lookup function
 *
 * @param pos {string} - n/v/a/r
 * @returns {Function} - lookup function bound to POS
 */
function lookup(pos) {
  return function(word, callback) {
    var profile = this.options.profile,
      start = profile && new Date(),
      files = this.getFilesFor(pos),
      args = [];

    word = normalize(word);

    // lookup index
    return files.index.lookup(word)
      .then(function(result) {
        if (result) {
          // lookup data
          return files.data.lookup(result.synsetOffset).then(done);
        } else {
          // not found in index
          return done([]);
        }
      })
      .catch(done);

    function done(results) {
      if (results instanceof Error) {
        args.push([], word);
      } else {
        args.push(results, word);
      }
      //console.log(3333, args)
      profile && args.push(new Date() - start);
      nextTick(callback, args);
      return results;
    }
  };
}

/**
 * isX() factory function
 *
 * @param pos {string} - n/v/a/r
 * @returns {Function}
 */
function is(pos){
  return function(word, callback, _noprofile) {
    // disable profiling when isX() used internally
    var profile = this.options.profile && !_noprofile,
      start = profile && new Date(),
      args = [],
      index = this.getFilesFor(pos).index;
    word = normalize(word);

    return index
      .lookup(word)
      .then(function(record) {
        var result = !!record;
        args.push(result, word);
        profile && args.push(new Date() - start);
        nextTick(callback, args);
        return result;
      });
  };
}


/**
 * getX() factory function
 *
 * @param isFn {function} - an isX() function
 * @returns {Function}
 */
function get(isFn) {
  return function(text, callback, _noprofile) {
    var profile = this.options.profile && !_noprofile,
      start = profile && new Date(),
      words = this.parse(text),
      results = [],
      self = this;

    //if (!n) return (process.nextTick(done),0);
    return Promise
      .all(words.map(exec))
      .then(done);

    function exec(word) {
      return self[isFn]
        .call(self, word, null, /*_noprofile*/ true)
        .then(function collect(result) {
          result && results.push(word);
        });
    }

    function done(){
      var args = [results];
      profile && args.push(new Date() - start);
      nextTick(callback, args);
      return results;
    }
  };
}

// setImmediate executes callback AFTER promise handlers.
// Without it, exceptions in callback may be caught by Promise.
function nextTick(fn, args) {
  if (fn) {
    fn.apply(null, args);
  }
}


/**
 * @class WordPOS
 * @param options {object} -- @see WordPOS.defaults
 * @constructor
 */
var WordPOS = function(options) {
  var dictPath;

  this.options = _.defaults({}, _.isObject(options) && options || {}, {
    dictPath: WNdb.path
  }, WordPOS.defaults);

  dictPath = this.options.dictPath;

  this.nounIndex = new IndexFile(dictPath, 'noun');
  this.verbIndex = new IndexFile(dictPath, 'verb');
  this.adjIndex = new IndexFile(dictPath, 'adj');
  this.advIndex = new IndexFile(dictPath, 'adv');

  this.nounData = new DataFile(dictPath, 'noun');
  this.verbData = new DataFile(dictPath, 'verb');
  this.adjData = new DataFile(dictPath, 'adj');
  this.advData = new DataFile(dictPath, 'adv');

  // define randX() functions
  __webpack_require__(/*! ./rand */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\rand.js").init(this);

  if (_.isArray(this.options.stopwords)) {
    this.options.stopwords = makeStopwordString(this.options.stopwords);
  }
};


WordPOS.defaults = {
  /**
   * path to WordNet data (override only if not using wordnet-db)
   */
  dictPath: '',

  /**
   * enable profiling, time in msec returned as second argument in callback
   */
  profile: false,

  /**
   * if true, exclude standard stopwords.
   * if array, stopwords to exclude, eg, ['all','of','this',...]
   * if false, do not filter any stopwords.
   */
  stopwords: true
};

var wordposProto = WordPOS.prototype;

/**
 * lookup a word in all indexes
 *
 * @param word {string} - search word
 * @param callback {Function} (optional) - callback with (results, word) signature
 * @returns {Promise}
 */
wordposProto.lookup = function(word, callback) {
  var self = this,
    results = [],
    profile = this.options.profile,
    start = profile && new Date(),
    methods = ['lookupAdverb', 'lookupAdjective', 'lookupVerb', 'lookupNoun'];

  return Promise
    .all(methods.map(exec))
    .then(done)
    .catch(error);

  function exec(method) {
    return self[ method ]
      .call(self, word)
      .then(function collect(result){
        results = results.concat(result);
      });
  }

  function done() {
    var args = [results, word];
    profile && args.push(new Date() - start);
    nextTick(callback, args);
    return results;
  }

  function error(err) {
    nextTick(callback, [[], word]);
    throw err;
  }
};


/**
 * getPOS() - Find all POS for all words in given string
 *
 * @param text {string} - words to lookup for POS
 * @param callback {function} (optional) - receives object with words broken into POS or 'rest', ie,
 * 	    Object: {nouns:[], verbs:[], adjectives:[], adverbs:[], rest:[]}
 * @return Promise - resolve function receives data object
 */
wordposProto.getPOS = function(text, callback) {
  var self = this,
    data = {nouns:[], verbs:[], adjectives:[], adverbs:[], rest:[]},
    profile = this.options.profile,
    start = profile && new Date(),
    words = this.parse(text),
    methods = ['getAdverbs', 'getAdjectives', 'getVerbs', 'getNouns'];

  return Promise
    .all(methods.map(exec))
    .then(done)
    .catch(error);

  function exec(method) {
    return self[ method ]
      .call(self, text, null, true)
      .then(function collect(results) {
        // getAdjectives --> adjectives
        var pos = method.replace('get','').toLowerCase();
        data[ pos ] =  results;
      });
  }

  function done() {
    var matches = _(data).chain()
      .values()
      .flatten()
      .uniq()
      .value(),
      args = [data];

    data.rest =  _(words).difference(matches);

    profile && args.push(new Date() - start);
    nextTick(callback, args);
    return data;
  }

  function error(err) {
    nextTick(callback, []);
    throw err;
  }
};

/**
 * get index and data files for given pos
 *
 * @param pos {string} - n/v/a/r
 * @returns {object} - keys {index, data}
 */
wordposProto.getFilesFor = function (pos) {
  switch(pos) {
    case 'n':
      return {index: this.nounIndex, data: this.nounData};
    case 'v':
      return {index: this.verbIndex, data: this.verbData};
    case 'a': case 's':
    return {index: this.adjIndex, data: this.adjData};
    case 'r':
      return {index: this.advIndex, data: this.advData};
  }
  return {};
};


/**
 * lookupX() - Lookup word definition if already know POS
 * @see lookup
 */
wordposProto.lookupAdjective = lookup('a');
wordposProto.lookupAdverb = lookup('r');
wordposProto.lookupNoun = lookup('n');
wordposProto.lookupVerb = lookup('v');

/**
 * isX() - Test if word is given POS
 * @see is
 */
wordposProto.isAdjective = is('a');
wordposProto.isAdverb = is('r');
wordposProto.isNoun = is('n');
wordposProto.isVerb = is('v');

/**
 * getX() - Find all words in string that are given POS
 * @see get
 */
wordposProto.getAdjectives = get('isAdjective');
wordposProto.getAdverbs = get('isAdverb');
wordposProto.getNouns = get('isNoun');
wordposProto.getVerbs = get('isVerb');

/**
 * parse - get deduped, less stopwords
 *
 * @param text {string|array} - string of words to parse.  If array is given, it is left in tact.
 * @returns {array}
 */
wordposProto.parse = prepText;


/**
 * seek - get record at offset for pos
 *
 * @param offset {number} - synset offset
 * @param pos {string} - POS a/r/n/v
 * @param callback {function} - optional callback
 * @returns Promise
 */
wordposProto.seek = function(offset, pos, callback){
  offset = Number(offset);
  if (_.isNaN(offset) || offset <= 0) return error('offset must be valid positive number.');

  var data = this.getFilesFor(pos).data;
  if (!data) return error('Incorrect POS - 2nd argument must be a, r, n or v.');

  return data.lookup(offset, callback);

  function error(msg) {
    var err = new Error(msg);
    callback && callback(err, {});
    return Promise.reject(err);
  }
};


/**
 * access to WordNet DB
 * @type {object}
 */
WordPOS.WNdb = WNdb;

/**
 * access to stopwords
 * @type {Array}
 */
WordPOS.stopwords = stopwords;


module.exports = WordPOS;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\src\\Preprocesser.js":
/*!*********************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/src/Preprocesser.js ***!
  \*********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

const natural = __webpack_require__(/*! natural */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\index.js");
const WordPos = __webpack_require__(/*! wordpos */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\wordpos\\src\\wordpos.js");
const WeightedGraph = __webpack_require__(/*! ./WeightedGraph */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\src\\WeightedGraph.js").WeightedGraph;

class Preprocesser{
	constructor(){
		this.tokenizer = new natural.SentenceTokenizer(); 
	}

	//This method takes in a paragraph and returns a list of the sentences in the paragraph.
	paragraphToSentences(string_to_process){
		try{
			let result = this.tokenizer.tokenize(string_to_process);
			return result;
		}catch(err){
			return Error("Cannot toeknize the given string.");
		}
	}

	//Cleans the sentences by removing punctuation and lowercasing capital letters.
	cleanSentences(list_to_clean){
		let sentence_map = new Map();
		const regex = /[&\/\\#,+()$~%.'":*?<>{}]/g;
		for (let i = 0; i<list_to_clean.length; i++){
			let original_sentence = list_to_clean[i];
			list_to_clean[i] = list_to_clean[i].toLowerCase();
			list_to_clean[i] = list_to_clean[i].replace(regex, "");
			sentence_map.set(list_to_clean[i], original_sentence);
		}
		return [list_to_clean,sentence_map];
	}

	//Takes in a list of sentences and returns a list of all of the words in the sentences.
	tokenizeSentences(list_of_sentences){
		let new_array = new Array();
		new_array = list_of_sentences
		let result_list = [];
		for (let i = 0; i<new_array.length; i++){
			result_list = result_list.concat(new_array[i].split(" "));
		}
		return result_list;
	}

	//Takes in a list of words and calculates the frequencies of the words.
	//Returns a list. The first item is a map of word->frequency. The second is the max frequency.
	getFrequencyAndMax(list_of_words){
		let frequency_map = new Map();
		let max = 0
		for (let i = 0; i<list_of_words.length; i++){
			const word = list_of_words[i];
			if (frequency_map.has(word)){
				const new_val = frequency_map.get(word)+1;
				frequency_map.set(word, new_val);
				if (new_val>max){
					max = new_val;
				}
			}else{
				frequency_map.set(word, 1);
			}
		}
		return [frequency_map, max];
	}
	
	//Converts a frequency map into a map with "weights".
	getWeights(list_of_words){
		const frequencies_and_max = this.getFrequencyAndMax(list_of_words);
		const frequencies_map = frequencies_and_max[0];
		const max = frequencies_and_max[1];
		frequencies_map.forEach((value,key,map)=>{
			map.set(key, value/max);
		});
		return frequencies_map;
	}


	sentenceWeights(clean_sentences, weighted_map){
		let weight_of_sentence = 0;
		let sentence_weight_list = [];
		let sentence = "";
		for (let i = 0; i<clean_sentences.length; i++){
			sentence = clean_sentences[i];
			let word_list = sentence.split(" ");
			weight_of_sentence = 0;
			for (let j = 0; j<word_list.length; j++){
				weight_of_sentence += weighted_map.get(word_list[j]);
			}
			sentence_weight_list.push([weight_of_sentence/word_list.length, sentence]);
		}
		return sentence_weight_list;
	}

	//Takes a list of sentences and returns a map of the each sentence to its nouns and adjectives
	async nounsAndAdjectives(clean_sentences){
		let nouns_and_adjectives_map = new Map();
		let wordpos = new WordPos();
		try{
			for (let i = 0; i<clean_sentences.length; i++){
				let adjectives = await wordpos.getAdjectives(clean_sentences[i]);
				let nouns = await wordpos.getNouns(clean_sentences[i]);
				nouns_and_adjectives_map.set(clean_sentences[i],nouns.concat(adjectives));
			}

			return await nouns_and_adjectives_map;
		}catch(err){
			console.log(err)
			return
		}
	}

	//Used for the text rank summary. Takes two lists of words and gets the weight of the edge connecting the vertices.
	getEdgeWeights(list1, list2){
		let weight = 0;
		let intial = list1
		let other = list2
		if (list2.length >= list1.length){
			intial = list2
			other = list1
		}
		for(let i=0; i<intial.length; i++){
			if(other.includes(intial[i])){
				weight+=1;
			}
		}

		return weight
	}

	//Creates the graph for the textrank algorithm.
	createTextRankGraph(nouns_and_adjactive_map){
		let graph = new WeightedGraph();
		let key_list = [];
		let weight = 0
		nouns_and_adjactive_map.forEach((value,key,map)=>{
			key_list.push(key);
		})
		for(let i=0; i<key_list.length; i++){
			for(let j=i+1; j<key_list.length; j++){
				weight = this.getEdgeWeights(nouns_and_adjactive_map.get(key_list[i]), nouns_and_adjactive_map.get(key_list[j]));
				if(weight>0){
					graph.addEdge(key_list[i], key_list[j], weight);
				}
			}

		}
		return graph;
	}

	//TextRank algorithm.
	textRank(graph){
		let key_list = graph.getAllVertices();
		let text_rank_map = new Map();
		
		//random key to start with
		if (key_list.length == 0){
			return text_rank_map;
		}
		let key = key_list[Math.floor(Math.random()*key_list.length)];
		let vertex = graph.getVertex(key);
		let probability_list = [];
		//random walk 
		for (let i = 0; i < 10000; i++) {
			let full_weight = 0
		
			vertex.adjacent.forEach((value, key, map)=>{
				full_weight+=value;
			})
		
			vertex.adjacent.forEach((value, key, map)=>{
				for(let x = 0; x<value; x++){
					probability_list.push(key);
				}
			})
		

			let sentence = probability_list[Math.floor(Math.random()*probability_list.length)];
			if(text_rank_map.has(sentence)){
				text_rank_map.set(sentence, text_rank_map.get(sentence)+1)
			}else{
				text_rank_map.set(sentence, 1);
			}
			let last_vertex = vertex;
			vertex = graph.getVertex(sentence);
			probability_list = [];
		}
		return text_rank_map;
		
	}


}


module.exports.Preprocesser = Preprocesser

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\src\\Summarizer.js":
/*!*******************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/src/Summarizer.js ***!
  \*******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

const Preprocesser = __webpack_require__(/*! ./Preprocesser */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\src\\Preprocesser.js").Preprocesser;

class Summarizer{
	constructor(string_to_process, number_of_sentences){
		this.preprocesser = new Preprocesser();
		this.number_of_sentences = number_of_sentences;
		this.string_to_process = string_to_process;
		this.new_length = 0;
	}

	//Takes in a list of sentences and weights and sorts by weight.
	sortSentences(sentence_weights_list){
		sentence_weights_list.sort((a,b)=>{
			return b[0]-a[0];
		})
		return sentence_weights_list;
	}

	//Converts the textRank map into a list
	textRankMapToList(text_rank_map){
		let result_list = [];
		text_rank_map.forEach((value, key, map)=>{
			result_list.push([value,key]);
		})

		return result_list;
	}

	//Takes in a list of sorted sentences and a map of those sentences to the original sentences. 
	listToString(sorted_sentences, clean_sentences){
		const self = this;
		let result_string = "";
		let length_count = 0;
		let count = self.number_of_sentences;
		if(sorted_sentences.length < self.number_of_sentences){
			count = sorted_sentences.length;
		}
		for(var i=0; i<count; i++){
			length_count += sorted_sentences[i][1].split(" ").length;
			result_string+=clean_sentences[1].get(sorted_sentences[i][1]);
		}
		this.new_length = length_count;
		return result_string;
	}

	summarizeByFrequency(){
		const self = this
		const list_to_clean = self.preprocesser.paragraphToSentences(self.string_to_process);
		const clean_sentences = self.preprocesser.cleanSentences(list_to_clean);
		const tokenized = self.preprocesser.tokenizeSentences(clean_sentences[0]);
		const weighted_map = self.preprocesser.getWeights(tokenized);
		const sentence_weights_list = self.preprocesser.sentenceWeights(clean_sentences[0], weighted_map);
		const sorted_sentences = self.sortSentences(sentence_weights_list);
		
		return {
			summary: self.listToString(sorted_sentences, clean_sentences),
			sentence_list: list_to_clean,
			weighted_map: weighted_map,
			sorted_sentences: sorted_sentences
		}
	}

	async summarizeByRank(){
		const self = this;
		const list_to_clean = self.preprocesser.paragraphToSentences(self.string_to_process);
		const clean_sentences = self.preprocesser.cleanSentences(list_to_clean);
		try{
			const nouns_and_adjactive_map = await self.preprocesser.nounsAndAdjectives(clean_sentences[0]);
			let text_rank_graph = self.preprocesser.createTextRankGraph(nouns_and_adjactive_map);
			let text_rank_map = self.preprocesser.textRank(text_rank_graph);
			let text_rank_list = self.sortSentences(self.textRankMapToList(text_rank_map));
			//let list_to_pass_in = text_rank_list;
			return {
				summary: self.listToString(text_rank_list, clean_sentences),
				sentence_list: list_to_clean,
				nouns_and_adjactive_map: nouns_and_adjactive_map
			}
		}catch(err){
			console.log(err);
		}
	}
}

module.exports.Summarizer = Summarizer;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\src\\SummarizerManager.js":
/*!**************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/src/SummarizerManager.js ***!
  \**************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

const Summarizer = __webpack_require__(/*! ./Summarizer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\src\\Summarizer.js").Summarizer;
const natural = __webpack_require__(/*! natural */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\index.js");

class SummarizerManager{
	constructor(string, number_of_sentences){
		this.string = string;
		this.number_of_sentences = number_of_sentences;
		this.rank_summary = "";
		this.frequency_summary = "";
	}

	getSentiment(){
		let self = this;
		let Analyzer = __webpack_require__(/*! natural */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\index.js").SentimentAnalyzer;
		let stemmer = __webpack_require__(/*! natural */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\node_modules\\natural\\lib\\natural\\index.js").PorterStemmer;
		let analyzer = new Analyzer("English", stemmer, "afinn");
		return analyzer.getSentiment(self.string.split(" "));
		
	}
	getFrequencyReduction(){
		if (this.frequency_summary == ""){
			this.frequency_summary = this.getSummaryByFrequency().summary;
		}
		let dec = 1-(this.frequency_summary.length/this.string.length);
		let string_dec = String(dec);
		return {
			reduction: string_dec.slice(2,4)+"."+string_dec.slice(4,5)+"%",
			summary: this.frequency_summary
		};
	}

	async getRankReduction(){
		if (this.rank_summary == ""){
			await this.getSummaryByRank();	
		}
		let dec = 1-(this.rank_summary.length/this.string.length);
		let string_dec = String(dec);
		return {
			reduction: string_dec.slice(2,4)+"."+string_dec.slice(4,5)+"%",
			summary: this.rank_summary
		}

	}

	async getRankReductionAsDec(){
		if (this.rank_summary == ""){
			await this.getSummaryByRank();
		}
		let dec = 1-(this.rank_summary.length/this.string.length);
		return {
			dec_reduction: dec,
			summary: this.rank_summary
		}
	}

	getFrequencyReductionAsDec(){
		if (this.frequency_summary == ""){
			this.frequency_summary = this.getSummaryByFrequency().summary;
		}
		let dec = 1-(this.frequency_summary.length/this.string.length);
		return {
			dec_reduction: dec,
			summary: this.frequency_summary
		}
	}

	getSummaryByFrequency(){
		try{
			let summarizer = new Summarizer(this.string, this.number_of_sentences);
			const summary_obj = summarizer.summarizeByFrequency();
			this.frequency_summary = summary_obj.summary;
			if(summary_obj.summary == ''){
				summary_obj.summary = Error("Not Enough similarities to be summarized, or the sentence is invalid."),
				summary_obj.sentence_list = Error("Not enough similarities to be summarized, or the sentence is invalid.")
			}
			return summary_obj;
		}catch(err){
			return Error("An invalid sentence was entered");
		}

	}

	async getSummaryByRank(){
		try{
			let summarizer = new Summarizer(this.string, this.number_of_sentences);
			const summary_obj = await summarizer.summarizeByRank();
			if(typeof(summary_obj.summary) === 'undefined' || summary_obj.summary == ''){
				summary_obj.summary = Error("Not Enough similarities to be summarized, or the sentence is invalid."),
				summary_obj.sentence_list = Error("Not enough similarities to be summarized, or the sentence is invalid.")
			}
			this.rank_summary = summary_obj.summary;
			return summary_obj;
		}catch(err){
			return Error("An invalid sentence was entered");
		}
	}
}

module.exports = SummarizerManager;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\node-summarizer\\src\\WeightedGraph.js":
/*!**********************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/node-summarizer/src/WeightedGraph.js ***!
  \**********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

class Vertex{
	constructor(value){
		this.value = value;
		this.adjacent = new Map();
	}
}

class WeightedGraph{
	constructor(){
		this.vertices_map = new Map();
		this.size = 0;
	}

	addVertex(value){
		this.size+=1;
		let vertex_to_add = new Vertex(value);
		this.vertices_map.set(value, vertex_to_add);
		return vertex_to_add;
	}

	getVertex(value){
		if (this.vertices_map.has(value)){
			return this.vertices_map.get(value);
		}
		return 
	}

	addEdge(a, b, weight){
		if (!this.vertices_map.has(a)){
			this.addVertex(a);
		}
		if (!this.vertices_map.has(b)){
			this.addVertex(b);
		}
		this.vertices_map.get(a).adjacent.set(b, weight);
		this.vertices_map.get(b).adjacent.set(a, weight);
	}

	getAllVertices(){
		let result_list = []
		this.vertices_map.forEach((value, key, map)=>{
			result_list.push(key);
		})
		return result_list;
	}
}

module.exports.WeightedGraph = WeightedGraph;

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\buildin\\global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

var g;

// This works in non-strict mode
g = (function() {
	return this;
})();

try {
	// This works if eval is allowed (see CSP)
	g = g || new Function("return this")();
} catch (e) {
	// This works if the window reference is available
	if (typeof window === "object") g = window;
}

// g can still be undefined, but nothing to do about it...
// We return undefined, instead of nothing here, so it's
// easier to handle this case. if(!global) { ...}

module.exports = g;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\buildin\\module.js":
/*!***********************************!*\
  !*** (webpack)/buildin/module.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

module.exports = function(module) {
	if (!module.webpackPolyfill) {
		module.deprecate = function() {};
		module.paths = [];
		// module.parent = undefined by default
		if (!module.children) module.children = [];
		Object.defineProperty(module, "loaded", {
			enumerable: true,
			get: function() {
				return module.l;
			}
		});
		Object.defineProperty(module, "id", {
			enumerable: true,
			get: function() {
				return module.i;
			}
		});
		module.webpackPolyfill = 1;
	}
	return module;
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\base64-js\\index.js":
/*!*************************************************!*\
  !*** (webpack)/node_modules/base64-js/index.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


exports.byteLength = byteLength
exports.toByteArray = toByteArray
exports.fromByteArray = fromByteArray

var lookup = []
var revLookup = []
var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array

var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'
for (var i = 0, len = code.length; i < len; ++i) {
  lookup[i] = code[i]
  revLookup[code.charCodeAt(i)] = i
}

// Support decoding URL-safe base64 strings, as Node.js does.
// See: https://en.wikipedia.org/wiki/Base64#URL_applications
revLookup['-'.charCodeAt(0)] = 62
revLookup['_'.charCodeAt(0)] = 63

function getLens (b64) {
  var len = b64.length

  if (len % 4 > 0) {
    throw new Error('Invalid string. Length must be a multiple of 4')
  }

  // Trim off extra bytes after placeholder bytes are found
  // See: https://github.com/beatgammit/base64-js/issues/42
  var validLen = b64.indexOf('=')
  if (validLen === -1) validLen = len

  var placeHoldersLen = validLen === len
    ? 0
    : 4 - (validLen % 4)

  return [validLen, placeHoldersLen]
}

// base64 is 4/3 + up to two characters of the original data
function byteLength (b64) {
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function _byteLength (b64, validLen, placeHoldersLen) {
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function toByteArray (b64) {
  var tmp
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]

  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))

  var curByte = 0

  // if there are placeholders, only get up to the last complete 4 chars
  var len = placeHoldersLen > 0
    ? validLen - 4
    : validLen

  for (var i = 0; i < len; i += 4) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 18) |
      (revLookup[b64.charCodeAt(i + 1)] << 12) |
      (revLookup[b64.charCodeAt(i + 2)] << 6) |
      revLookup[b64.charCodeAt(i + 3)]
    arr[curByte++] = (tmp >> 16) & 0xFF
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 2) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 2) |
      (revLookup[b64.charCodeAt(i + 1)] >> 4)
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 1) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 10) |
      (revLookup[b64.charCodeAt(i + 1)] << 4) |
      (revLookup[b64.charCodeAt(i + 2)] >> 2)
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  return arr
}

function tripletToBase64 (num) {
  return lookup[num >> 18 & 0x3F] +
    lookup[num >> 12 & 0x3F] +
    lookup[num >> 6 & 0x3F] +
    lookup[num & 0x3F]
}

function encodeChunk (uint8, start, end) {
  var tmp
  var output = []
  for (var i = start; i < end; i += 3) {
    tmp =
      ((uint8[i] << 16) & 0xFF0000) +
      ((uint8[i + 1] << 8) & 0xFF00) +
      (uint8[i + 2] & 0xFF)
    output.push(tripletToBase64(tmp))
  }
  return output.join('')
}

function fromByteArray (uint8) {
  var tmp
  var len = uint8.length
  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes
  var parts = []
  var maxChunkLength = 16383 // must be multiple of 3

  // go through the array every three bytes, we'll deal with trailing stuff later
  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
    parts.push(encodeChunk(
      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)
    ))
  }

  // pad the end with zeros, but make sure to not forget the extra bytes
  if (extraBytes === 1) {
    tmp = uint8[len - 1]
    parts.push(
      lookup[tmp >> 2] +
      lookup[(tmp << 4) & 0x3F] +
      '=='
    )
  } else if (extraBytes === 2) {
    tmp = (uint8[len - 2] << 8) + uint8[len - 1]
    parts.push(
      lookup[tmp >> 10] +
      lookup[(tmp >> 4) & 0x3F] +
      lookup[(tmp << 2) & 0x3F] +
      '='
    )
  }

  return parts.join('')
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\buffer\\index.js":
/*!**********************************************!*\
  !*** (webpack)/node_modules/buffer/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/* WEBPACK VAR INJECTION */(function(global) {/*!
 * The buffer module from node.js, for the browser.
 *
 * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>
 * @license  MIT
 */
/* eslint-disable no-proto */



var base64 = __webpack_require__(/*! base64-js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\base64-js\\index.js")
var ieee754 = __webpack_require__(/*! ieee754 */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\ieee754\\index.js")
var isArray = __webpack_require__(/*! isarray */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\isarray\\index.js")

exports.Buffer = Buffer
exports.SlowBuffer = SlowBuffer
exports.INSPECT_MAX_BYTES = 50

/**
 * If `Buffer.TYPED_ARRAY_SUPPORT`:
 *   === true    Use Uint8Array implementation (fastest)
 *   === false   Use Object implementation (most compatible, even IE6)
 *
 * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,
 * Opera 11.6+, iOS 4.2+.
 *
 * Due to various browser bugs, sometimes the Object implementation will be used even
 * when the browser supports typed arrays.
 *
 * Note:
 *
 *   - Firefox 4-29 lacks support for adding new properties to `Uint8Array` instances,
 *     See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438.
 *
 *   - Chrome 9-10 is missing the `TypedArray.prototype.subarray` function.
 *
 *   - IE10 has a broken `TypedArray.prototype.subarray` function which returns arrays of
 *     incorrect length in some situations.

 * We detect these buggy browsers and set `Buffer.TYPED_ARRAY_SUPPORT` to `false` so they
 * get the Object implementation, which is slower but behaves correctly.
 */
Buffer.TYPED_ARRAY_SUPPORT = global.TYPED_ARRAY_SUPPORT !== undefined
  ? global.TYPED_ARRAY_SUPPORT
  : typedArraySupport()

/*
 * Export kMaxLength after typed array support is determined.
 */
exports.kMaxLength = kMaxLength()

function typedArraySupport () {
  try {
    var arr = new Uint8Array(1)
    arr.__proto__ = {__proto__: Uint8Array.prototype, foo: function () { return 42 }}
    return arr.foo() === 42 && // typed array instances can be augmented
        typeof arr.subarray === 'function' && // chrome 9-10 lack `subarray`
        arr.subarray(1, 1).byteLength === 0 // ie10 has broken `subarray`
  } catch (e) {
    return false
  }
}

function kMaxLength () {
  return Buffer.TYPED_ARRAY_SUPPORT
    ? 0x7fffffff
    : 0x3fffffff
}

function createBuffer (that, length) {
  if (kMaxLength() < length) {
    throw new RangeError('Invalid typed array length')
  }
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    // Return an augmented `Uint8Array` instance, for best performance
    that = new Uint8Array(length)
    that.__proto__ = Buffer.prototype
  } else {
    // Fallback: Return an object instance of the Buffer class
    if (that === null) {
      that = new Buffer(length)
    }
    that.length = length
  }

  return that
}

/**
 * The Buffer constructor returns instances of `Uint8Array` that have their
 * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of
 * `Uint8Array`, so the returned instances will have all the node `Buffer` methods
 * and the `Uint8Array` methods. Square bracket notation works as expected -- it
 * returns a single octet.
 *
 * The `Uint8Array` prototype remains unmodified.
 */

function Buffer (arg, encodingOrOffset, length) {
  if (!Buffer.TYPED_ARRAY_SUPPORT && !(this instanceof Buffer)) {
    return new Buffer(arg, encodingOrOffset, length)
  }

  // Common case.
  if (typeof arg === 'number') {
    if (typeof encodingOrOffset === 'string') {
      throw new Error(
        'If encoding is specified then the first argument must be a string'
      )
    }
    return allocUnsafe(this, arg)
  }
  return from(this, arg, encodingOrOffset, length)
}

Buffer.poolSize = 8192 // not used by this implementation

// TODO: Legacy, not needed anymore. Remove in next major version.
Buffer._augment = function (arr) {
  arr.__proto__ = Buffer.prototype
  return arr
}

function from (that, value, encodingOrOffset, length) {
  if (typeof value === 'number') {
    throw new TypeError('"value" argument must not be a number')
  }

  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {
    return fromArrayBuffer(that, value, encodingOrOffset, length)
  }

  if (typeof value === 'string') {
    return fromString(that, value, encodingOrOffset)
  }

  return fromObject(that, value)
}

/**
 * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError
 * if value is a number.
 * Buffer.from(str[, encoding])
 * Buffer.from(array)
 * Buffer.from(buffer)
 * Buffer.from(arrayBuffer[, byteOffset[, length]])
 **/
Buffer.from = function (value, encodingOrOffset, length) {
  return from(null, value, encodingOrOffset, length)
}

if (Buffer.TYPED_ARRAY_SUPPORT) {
  Buffer.prototype.__proto__ = Uint8Array.prototype
  Buffer.__proto__ = Uint8Array
  if (typeof Symbol !== 'undefined' && Symbol.species &&
      Buffer[Symbol.species] === Buffer) {
    // Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97
    Object.defineProperty(Buffer, Symbol.species, {
      value: null,
      configurable: true
    })
  }
}

function assertSize (size) {
  if (typeof size !== 'number') {
    throw new TypeError('"size" argument must be a number')
  } else if (size < 0) {
    throw new RangeError('"size" argument must not be negative')
  }
}

function alloc (that, size, fill, encoding) {
  assertSize(size)
  if (size <= 0) {
    return createBuffer(that, size)
  }
  if (fill !== undefined) {
    // Only pay attention to encoding if it's a string. This
    // prevents accidentally sending in a number that would
    // be interpretted as a start offset.
    return typeof encoding === 'string'
      ? createBuffer(that, size).fill(fill, encoding)
      : createBuffer(that, size).fill(fill)
  }
  return createBuffer(that, size)
}

/**
 * Creates a new filled Buffer instance.
 * alloc(size[, fill[, encoding]])
 **/
Buffer.alloc = function (size, fill, encoding) {
  return alloc(null, size, fill, encoding)
}

function allocUnsafe (that, size) {
  assertSize(size)
  that = createBuffer(that, size < 0 ? 0 : checked(size) | 0)
  if (!Buffer.TYPED_ARRAY_SUPPORT) {
    for (var i = 0; i < size; ++i) {
      that[i] = 0
    }
  }
  return that
}

/**
 * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.
 * */
Buffer.allocUnsafe = function (size) {
  return allocUnsafe(null, size)
}
/**
 * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.
 */
Buffer.allocUnsafeSlow = function (size) {
  return allocUnsafe(null, size)
}

function fromString (that, string, encoding) {
  if (typeof encoding !== 'string' || encoding === '') {
    encoding = 'utf8'
  }

  if (!Buffer.isEncoding(encoding)) {
    throw new TypeError('"encoding" must be a valid string encoding')
  }

  var length = byteLength(string, encoding) | 0
  that = createBuffer(that, length)

  var actual = that.write(string, encoding)

  if (actual !== length) {
    // Writing a hex string, for example, that contains invalid characters will
    // cause everything after the first invalid character to be ignored. (e.g.
    // 'abxxcd' will be treated as 'ab')
    that = that.slice(0, actual)
  }

  return that
}

function fromArrayLike (that, array) {
  var length = array.length < 0 ? 0 : checked(array.length) | 0
  that = createBuffer(that, length)
  for (var i = 0; i < length; i += 1) {
    that[i] = array[i] & 255
  }
  return that
}

function fromArrayBuffer (that, array, byteOffset, length) {
  array.byteLength // this throws if `array` is not a valid ArrayBuffer

  if (byteOffset < 0 || array.byteLength < byteOffset) {
    throw new RangeError('\'offset\' is out of bounds')
  }

  if (array.byteLength < byteOffset + (length || 0)) {
    throw new RangeError('\'length\' is out of bounds')
  }

  if (byteOffset === undefined && length === undefined) {
    array = new Uint8Array(array)
  } else if (length === undefined) {
    array = new Uint8Array(array, byteOffset)
  } else {
    array = new Uint8Array(array, byteOffset, length)
  }

  if (Buffer.TYPED_ARRAY_SUPPORT) {
    // Return an augmented `Uint8Array` instance, for best performance
    that = array
    that.__proto__ = Buffer.prototype
  } else {
    // Fallback: Return an object instance of the Buffer class
    that = fromArrayLike(that, array)
  }
  return that
}

function fromObject (that, obj) {
  if (Buffer.isBuffer(obj)) {
    var len = checked(obj.length) | 0
    that = createBuffer(that, len)

    if (that.length === 0) {
      return that
    }

    obj.copy(that, 0, 0, len)
    return that
  }

  if (obj) {
    if ((typeof ArrayBuffer !== 'undefined' &&
        obj.buffer instanceof ArrayBuffer) || 'length' in obj) {
      if (typeof obj.length !== 'number' || isnan(obj.length)) {
        return createBuffer(that, 0)
      }
      return fromArrayLike(that, obj)
    }

    if (obj.type === 'Buffer' && isArray(obj.data)) {
      return fromArrayLike(that, obj.data)
    }
  }

  throw new TypeError('First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.')
}

function checked (length) {
  // Note: cannot use `length < kMaxLength()` here because that fails when
  // length is NaN (which is otherwise coerced to zero.)
  if (length >= kMaxLength()) {
    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +
                         'size: 0x' + kMaxLength().toString(16) + ' bytes')
  }
  return length | 0
}

function SlowBuffer (length) {
  if (+length != length) { // eslint-disable-line eqeqeq
    length = 0
  }
  return Buffer.alloc(+length)
}

Buffer.isBuffer = function isBuffer (b) {
  return !!(b != null && b._isBuffer)
}

Buffer.compare = function compare (a, b) {
  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {
    throw new TypeError('Arguments must be Buffers')
  }

  if (a === b) return 0

  var x = a.length
  var y = b.length

  for (var i = 0, len = Math.min(x, y); i < len; ++i) {
    if (a[i] !== b[i]) {
      x = a[i]
      y = b[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

Buffer.isEncoding = function isEncoding (encoding) {
  switch (String(encoding).toLowerCase()) {
    case 'hex':
    case 'utf8':
    case 'utf-8':
    case 'ascii':
    case 'latin1':
    case 'binary':
    case 'base64':
    case 'ucs2':
    case 'ucs-2':
    case 'utf16le':
    case 'utf-16le':
      return true
    default:
      return false
  }
}

Buffer.concat = function concat (list, length) {
  if (!isArray(list)) {
    throw new TypeError('"list" argument must be an Array of Buffers')
  }

  if (list.length === 0) {
    return Buffer.alloc(0)
  }

  var i
  if (length === undefined) {
    length = 0
    for (i = 0; i < list.length; ++i) {
      length += list[i].length
    }
  }

  var buffer = Buffer.allocUnsafe(length)
  var pos = 0
  for (i = 0; i < list.length; ++i) {
    var buf = list[i]
    if (!Buffer.isBuffer(buf)) {
      throw new TypeError('"list" argument must be an Array of Buffers')
    }
    buf.copy(buffer, pos)
    pos += buf.length
  }
  return buffer
}

function byteLength (string, encoding) {
  if (Buffer.isBuffer(string)) {
    return string.length
  }
  if (typeof ArrayBuffer !== 'undefined' && typeof ArrayBuffer.isView === 'function' &&
      (ArrayBuffer.isView(string) || string instanceof ArrayBuffer)) {
    return string.byteLength
  }
  if (typeof string !== 'string') {
    string = '' + string
  }

  var len = string.length
  if (len === 0) return 0

  // Use a for loop to avoid recursion
  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'ascii':
      case 'latin1':
      case 'binary':
        return len
      case 'utf8':
      case 'utf-8':
      case undefined:
        return utf8ToBytes(string).length
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return len * 2
      case 'hex':
        return len >>> 1
      case 'base64':
        return base64ToBytes(string).length
      default:
        if (loweredCase) return utf8ToBytes(string).length // assume utf8
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}
Buffer.byteLength = byteLength

function slowToString (encoding, start, end) {
  var loweredCase = false

  // No need to verify that "this.length <= MAX_UINT32" since it's a read-only
  // property of a typed array.

  // This behaves neither like String nor Uint8Array in that we set start/end
  // to their upper/lower bounds if the value passed is out of range.
  // undefined is handled specially as per ECMA-262 6th Edition,
  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.
  if (start === undefined || start < 0) {
    start = 0
  }
  // Return early if start > this.length. Done here to prevent potential uint32
  // coercion fail below.
  if (start > this.length) {
    return ''
  }

  if (end === undefined || end > this.length) {
    end = this.length
  }

  if (end <= 0) {
    return ''
  }

  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.
  end >>>= 0
  start >>>= 0

  if (end <= start) {
    return ''
  }

  if (!encoding) encoding = 'utf8'

  while (true) {
    switch (encoding) {
      case 'hex':
        return hexSlice(this, start, end)

      case 'utf8':
      case 'utf-8':
        return utf8Slice(this, start, end)

      case 'ascii':
        return asciiSlice(this, start, end)

      case 'latin1':
      case 'binary':
        return latin1Slice(this, start, end)

      case 'base64':
        return base64Slice(this, start, end)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return utf16leSlice(this, start, end)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = (encoding + '').toLowerCase()
        loweredCase = true
    }
  }
}

// The property is used by `Buffer.isBuffer` and `is-buffer` (in Safari 5-7) to detect
// Buffer instances.
Buffer.prototype._isBuffer = true

function swap (b, n, m) {
  var i = b[n]
  b[n] = b[m]
  b[m] = i
}

Buffer.prototype.swap16 = function swap16 () {
  var len = this.length
  if (len % 2 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 16-bits')
  }
  for (var i = 0; i < len; i += 2) {
    swap(this, i, i + 1)
  }
  return this
}

Buffer.prototype.swap32 = function swap32 () {
  var len = this.length
  if (len % 4 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 32-bits')
  }
  for (var i = 0; i < len; i += 4) {
    swap(this, i, i + 3)
    swap(this, i + 1, i + 2)
  }
  return this
}

Buffer.prototype.swap64 = function swap64 () {
  var len = this.length
  if (len % 8 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 64-bits')
  }
  for (var i = 0; i < len; i += 8) {
    swap(this, i, i + 7)
    swap(this, i + 1, i + 6)
    swap(this, i + 2, i + 5)
    swap(this, i + 3, i + 4)
  }
  return this
}

Buffer.prototype.toString = function toString () {
  var length = this.length | 0
  if (length === 0) return ''
  if (arguments.length === 0) return utf8Slice(this, 0, length)
  return slowToString.apply(this, arguments)
}

Buffer.prototype.equals = function equals (b) {
  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')
  if (this === b) return true
  return Buffer.compare(this, b) === 0
}

Buffer.prototype.inspect = function inspect () {
  var str = ''
  var max = exports.INSPECT_MAX_BYTES
  if (this.length > 0) {
    str = this.toString('hex', 0, max).match(/.{2}/g).join(' ')
    if (this.length > max) str += ' ... '
  }
  return '<Buffer ' + str + '>'
}

Buffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {
  if (!Buffer.isBuffer(target)) {
    throw new TypeError('Argument must be a Buffer')
  }

  if (start === undefined) {
    start = 0
  }
  if (end === undefined) {
    end = target ? target.length : 0
  }
  if (thisStart === undefined) {
    thisStart = 0
  }
  if (thisEnd === undefined) {
    thisEnd = this.length
  }

  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {
    throw new RangeError('out of range index')
  }

  if (thisStart >= thisEnd && start >= end) {
    return 0
  }
  if (thisStart >= thisEnd) {
    return -1
  }
  if (start >= end) {
    return 1
  }

  start >>>= 0
  end >>>= 0
  thisStart >>>= 0
  thisEnd >>>= 0

  if (this === target) return 0

  var x = thisEnd - thisStart
  var y = end - start
  var len = Math.min(x, y)

  var thisCopy = this.slice(thisStart, thisEnd)
  var targetCopy = target.slice(start, end)

  for (var i = 0; i < len; ++i) {
    if (thisCopy[i] !== targetCopy[i]) {
      x = thisCopy[i]
      y = targetCopy[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,
// OR the last index of `val` in `buffer` at offset <= `byteOffset`.
//
// Arguments:
// - buffer - a Buffer to search
// - val - a string, Buffer, or number
// - byteOffset - an index into `buffer`; will be clamped to an int32
// - encoding - an optional encoding, relevant is val is a string
// - dir - true for indexOf, false for lastIndexOf
function bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {
  // Empty buffer means no match
  if (buffer.length === 0) return -1

  // Normalize byteOffset
  if (typeof byteOffset === 'string') {
    encoding = byteOffset
    byteOffset = 0
  } else if (byteOffset > 0x7fffffff) {
    byteOffset = 0x7fffffff
  } else if (byteOffset < -0x80000000) {
    byteOffset = -0x80000000
  }
  byteOffset = +byteOffset  // Coerce to Number.
  if (isNaN(byteOffset)) {
    // byteOffset: it it's undefined, null, NaN, "foo", etc, search whole buffer
    byteOffset = dir ? 0 : (buffer.length - 1)
  }

  // Normalize byteOffset: negative offsets start from the end of the buffer
  if (byteOffset < 0) byteOffset = buffer.length + byteOffset
  if (byteOffset >= buffer.length) {
    if (dir) return -1
    else byteOffset = buffer.length - 1
  } else if (byteOffset < 0) {
    if (dir) byteOffset = 0
    else return -1
  }

  // Normalize val
  if (typeof val === 'string') {
    val = Buffer.from(val, encoding)
  }

  // Finally, search either indexOf (if dir is true) or lastIndexOf
  if (Buffer.isBuffer(val)) {
    // Special case: looking for empty string/buffer always fails
    if (val.length === 0) {
      return -1
    }
    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)
  } else if (typeof val === 'number') {
    val = val & 0xFF // Search for a byte value [0-255]
    if (Buffer.TYPED_ARRAY_SUPPORT &&
        typeof Uint8Array.prototype.indexOf === 'function') {
      if (dir) {
        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)
      } else {
        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)
      }
    }
    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)
  }

  throw new TypeError('val must be string, number or Buffer')
}

function arrayIndexOf (arr, val, byteOffset, encoding, dir) {
  var indexSize = 1
  var arrLength = arr.length
  var valLength = val.length

  if (encoding !== undefined) {
    encoding = String(encoding).toLowerCase()
    if (encoding === 'ucs2' || encoding === 'ucs-2' ||
        encoding === 'utf16le' || encoding === 'utf-16le') {
      if (arr.length < 2 || val.length < 2) {
        return -1
      }
      indexSize = 2
      arrLength /= 2
      valLength /= 2
      byteOffset /= 2
    }
  }

  function read (buf, i) {
    if (indexSize === 1) {
      return buf[i]
    } else {
      return buf.readUInt16BE(i * indexSize)
    }
  }

  var i
  if (dir) {
    var foundIndex = -1
    for (i = byteOffset; i < arrLength; i++) {
      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
        if (foundIndex === -1) foundIndex = i
        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize
      } else {
        if (foundIndex !== -1) i -= i - foundIndex
        foundIndex = -1
      }
    }
  } else {
    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength
    for (i = byteOffset; i >= 0; i--) {
      var found = true
      for (var j = 0; j < valLength; j++) {
        if (read(arr, i + j) !== read(val, j)) {
          found = false
          break
        }
      }
      if (found) return i
    }
  }

  return -1
}

Buffer.prototype.includes = function includes (val, byteOffset, encoding) {
  return this.indexOf(val, byteOffset, encoding) !== -1
}

Buffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)
}

Buffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)
}

function hexWrite (buf, string, offset, length) {
  offset = Number(offset) || 0
  var remaining = buf.length - offset
  if (!length) {
    length = remaining
  } else {
    length = Number(length)
    if (length > remaining) {
      length = remaining
    }
  }

  // must be an even number of digits
  var strLen = string.length
  if (strLen % 2 !== 0) throw new TypeError('Invalid hex string')

  if (length > strLen / 2) {
    length = strLen / 2
  }
  for (var i = 0; i < length; ++i) {
    var parsed = parseInt(string.substr(i * 2, 2), 16)
    if (isNaN(parsed)) return i
    buf[offset + i] = parsed
  }
  return i
}

function utf8Write (buf, string, offset, length) {
  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)
}

function asciiWrite (buf, string, offset, length) {
  return blitBuffer(asciiToBytes(string), buf, offset, length)
}

function latin1Write (buf, string, offset, length) {
  return asciiWrite(buf, string, offset, length)
}

function base64Write (buf, string, offset, length) {
  return blitBuffer(base64ToBytes(string), buf, offset, length)
}

function ucs2Write (buf, string, offset, length) {
  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)
}

Buffer.prototype.write = function write (string, offset, length, encoding) {
  // Buffer#write(string)
  if (offset === undefined) {
    encoding = 'utf8'
    length = this.length
    offset = 0
  // Buffer#write(string, encoding)
  } else if (length === undefined && typeof offset === 'string') {
    encoding = offset
    length = this.length
    offset = 0
  // Buffer#write(string, offset[, length][, encoding])
  } else if (isFinite(offset)) {
    offset = offset | 0
    if (isFinite(length)) {
      length = length | 0
      if (encoding === undefined) encoding = 'utf8'
    } else {
      encoding = length
      length = undefined
    }
  // legacy write(string, encoding, offset, length) - remove in v0.13
  } else {
    throw new Error(
      'Buffer.write(string, encoding, offset[, length]) is no longer supported'
    )
  }

  var remaining = this.length - offset
  if (length === undefined || length > remaining) length = remaining

  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {
    throw new RangeError('Attempt to write outside buffer bounds')
  }

  if (!encoding) encoding = 'utf8'

  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'hex':
        return hexWrite(this, string, offset, length)

      case 'utf8':
      case 'utf-8':
        return utf8Write(this, string, offset, length)

      case 'ascii':
        return asciiWrite(this, string, offset, length)

      case 'latin1':
      case 'binary':
        return latin1Write(this, string, offset, length)

      case 'base64':
        // Warning: maxLength not taken into account in base64Write
        return base64Write(this, string, offset, length)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return ucs2Write(this, string, offset, length)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}

Buffer.prototype.toJSON = function toJSON () {
  return {
    type: 'Buffer',
    data: Array.prototype.slice.call(this._arr || this, 0)
  }
}

function base64Slice (buf, start, end) {
  if (start === 0 && end === buf.length) {
    return base64.fromByteArray(buf)
  } else {
    return base64.fromByteArray(buf.slice(start, end))
  }
}

function utf8Slice (buf, start, end) {
  end = Math.min(buf.length, end)
  var res = []

  var i = start
  while (i < end) {
    var firstByte = buf[i]
    var codePoint = null
    var bytesPerSequence = (firstByte > 0xEF) ? 4
      : (firstByte > 0xDF) ? 3
      : (firstByte > 0xBF) ? 2
      : 1

    if (i + bytesPerSequence <= end) {
      var secondByte, thirdByte, fourthByte, tempCodePoint

      switch (bytesPerSequence) {
        case 1:
          if (firstByte < 0x80) {
            codePoint = firstByte
          }
          break
        case 2:
          secondByte = buf[i + 1]
          if ((secondByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)
            if (tempCodePoint > 0x7F) {
              codePoint = tempCodePoint
            }
          }
          break
        case 3:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)
            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {
              codePoint = tempCodePoint
            }
          }
          break
        case 4:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          fourthByte = buf[i + 3]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)
            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {
              codePoint = tempCodePoint
            }
          }
      }
    }

    if (codePoint === null) {
      // we did not generate a valid codePoint so insert a
      // replacement char (U+FFFD) and advance only 1 byte
      codePoint = 0xFFFD
      bytesPerSequence = 1
    } else if (codePoint > 0xFFFF) {
      // encode to utf16 (surrogate pair dance)
      codePoint -= 0x10000
      res.push(codePoint >>> 10 & 0x3FF | 0xD800)
      codePoint = 0xDC00 | codePoint & 0x3FF
    }

    res.push(codePoint)
    i += bytesPerSequence
  }

  return decodeCodePointsArray(res)
}

// Based on http://stackoverflow.com/a/22747272/680742, the browser with
// the lowest limit is Chrome, with 0x10000 args.
// We go 1 magnitude less, for safety
var MAX_ARGUMENTS_LENGTH = 0x1000

function decodeCodePointsArray (codePoints) {
  var len = codePoints.length
  if (len <= MAX_ARGUMENTS_LENGTH) {
    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()
  }

  // Decode in chunks to avoid "call stack size exceeded".
  var res = ''
  var i = 0
  while (i < len) {
    res += String.fromCharCode.apply(
      String,
      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)
    )
  }
  return res
}

function asciiSlice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i] & 0x7F)
  }
  return ret
}

function latin1Slice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i])
  }
  return ret
}

function hexSlice (buf, start, end) {
  var len = buf.length

  if (!start || start < 0) start = 0
  if (!end || end < 0 || end > len) end = len

  var out = ''
  for (var i = start; i < end; ++i) {
    out += toHex(buf[i])
  }
  return out
}

function utf16leSlice (buf, start, end) {
  var bytes = buf.slice(start, end)
  var res = ''
  for (var i = 0; i < bytes.length; i += 2) {
    res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256)
  }
  return res
}

Buffer.prototype.slice = function slice (start, end) {
  var len = this.length
  start = ~~start
  end = end === undefined ? len : ~~end

  if (start < 0) {
    start += len
    if (start < 0) start = 0
  } else if (start > len) {
    start = len
  }

  if (end < 0) {
    end += len
    if (end < 0) end = 0
  } else if (end > len) {
    end = len
  }

  if (end < start) end = start

  var newBuf
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    newBuf = this.subarray(start, end)
    newBuf.__proto__ = Buffer.prototype
  } else {
    var sliceLen = end - start
    newBuf = new Buffer(sliceLen, undefined)
    for (var i = 0; i < sliceLen; ++i) {
      newBuf[i] = this[i + start]
    }
  }

  return newBuf
}

/*
 * Need to make sure that buffer isn't trying to write out of bounds.
 */
function checkOffset (offset, ext, length) {
  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')
  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')
}

Buffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {
  offset = offset | 0
  byteLength = byteLength | 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }

  return val
}

Buffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {
  offset = offset | 0
  byteLength = byteLength | 0
  if (!noAssert) {
    checkOffset(offset, byteLength, this.length)
  }

  var val = this[offset + --byteLength]
  var mul = 1
  while (byteLength > 0 && (mul *= 0x100)) {
    val += this[offset + --byteLength] * mul
  }

  return val
}

Buffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 1, this.length)
  return this[offset]
}

Buffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 2, this.length)
  return this[offset] | (this[offset + 1] << 8)
}

Buffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 2, this.length)
  return (this[offset] << 8) | this[offset + 1]
}

Buffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 4, this.length)

  return ((this[offset]) |
      (this[offset + 1] << 8) |
      (this[offset + 2] << 16)) +
      (this[offset + 3] * 0x1000000)
}

Buffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] * 0x1000000) +
    ((this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    this[offset + 3])
}

Buffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {
  offset = offset | 0
  byteLength = byteLength | 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {
  offset = offset | 0
  byteLength = byteLength | 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var i = byteLength
  var mul = 1
  var val = this[offset + --i]
  while (i > 0 && (mul *= 0x100)) {
    val += this[offset + --i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readInt8 = function readInt8 (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 1, this.length)
  if (!(this[offset] & 0x80)) return (this[offset])
  return ((0xff - this[offset] + 1) * -1)
}

Buffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset] | (this[offset + 1] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset + 1] | (this[offset] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset]) |
    (this[offset + 1] << 8) |
    (this[offset + 2] << 16) |
    (this[offset + 3] << 24)
}

Buffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] << 24) |
    (this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    (this[offset + 3])
}

Buffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, true, 23, 4)
}

Buffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, false, 23, 4)
}

Buffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, true, 52, 8)
}

Buffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, false, 52, 8)
}

function checkInt (buf, value, offset, ext, max, min) {
  if (!Buffer.isBuffer(buf)) throw new TypeError('"buffer" argument must be a Buffer instance')
  if (value > max || value < min) throw new RangeError('"value" argument is out of bounds')
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
}

Buffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset | 0
  byteLength = byteLength | 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var mul = 1
  var i = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset | 0
  byteLength = byteLength | 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var i = byteLength - 1
  var mul = 1
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)
  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)
  this[offset] = (value & 0xff)
  return offset + 1
}

function objectWriteUInt16 (buf, value, offset, littleEndian) {
  if (value < 0) value = 0xffff + value + 1
  for (var i = 0, j = Math.min(buf.length - offset, 2); i < j; ++i) {
    buf[offset + i] = (value & (0xff << (8 * (littleEndian ? i : 1 - i)))) >>>
      (littleEndian ? i : 1 - i) * 8
  }
}

Buffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    this[offset] = (value & 0xff)
    this[offset + 1] = (value >>> 8)
  } else {
    objectWriteUInt16(this, value, offset, true)
  }
  return offset + 2
}

Buffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    this[offset] = (value >>> 8)
    this[offset + 1] = (value & 0xff)
  } else {
    objectWriteUInt16(this, value, offset, false)
  }
  return offset + 2
}

function objectWriteUInt32 (buf, value, offset, littleEndian) {
  if (value < 0) value = 0xffffffff + value + 1
  for (var i = 0, j = Math.min(buf.length - offset, 4); i < j; ++i) {
    buf[offset + i] = (value >>> (littleEndian ? i : 3 - i) * 8) & 0xff
  }
}

Buffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    this[offset + 3] = (value >>> 24)
    this[offset + 2] = (value >>> 16)
    this[offset + 1] = (value >>> 8)
    this[offset] = (value & 0xff)
  } else {
    objectWriteUInt32(this, value, offset, true)
  }
  return offset + 4
}

Buffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    this[offset] = (value >>> 24)
    this[offset + 1] = (value >>> 16)
    this[offset + 2] = (value >>> 8)
    this[offset + 3] = (value & 0xff)
  } else {
    objectWriteUInt32(this, value, offset, false)
  }
  return offset + 4
}

Buffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) {
    var limit = Math.pow(2, 8 * byteLength - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = 0
  var mul = 1
  var sub = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) {
    var limit = Math.pow(2, 8 * byteLength - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = byteLength - 1
  var mul = 1
  var sub = 0
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)
  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)
  if (value < 0) value = 0xff + value + 1
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    this[offset] = (value & 0xff)
    this[offset + 1] = (value >>> 8)
  } else {
    objectWriteUInt16(this, value, offset, true)
  }
  return offset + 2
}

Buffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    this[offset] = (value >>> 8)
    this[offset + 1] = (value & 0xff)
  } else {
    objectWriteUInt16(this, value, offset, false)
  }
  return offset + 2
}

Buffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    this[offset] = (value & 0xff)
    this[offset + 1] = (value >>> 8)
    this[offset + 2] = (value >>> 16)
    this[offset + 3] = (value >>> 24)
  } else {
    objectWriteUInt32(this, value, offset, true)
  }
  return offset + 4
}

Buffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset | 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  if (value < 0) value = 0xffffffff + value + 1
  if (Buffer.TYPED_ARRAY_SUPPORT) {
    this[offset] = (value >>> 24)
    this[offset + 1] = (value >>> 16)
    this[offset + 2] = (value >>> 8)
    this[offset + 3] = (value & 0xff)
  } else {
    objectWriteUInt32(this, value, offset, false)
  }
  return offset + 4
}

function checkIEEE754 (buf, value, offset, ext, max, min) {
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
  if (offset < 0) throw new RangeError('Index out of range')
}

function writeFloat (buf, value, offset, littleEndian, noAssert) {
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)
  }
  ieee754.write(buf, value, offset, littleEndian, 23, 4)
  return offset + 4
}

Buffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {
  return writeFloat(this, value, offset, true, noAssert)
}

Buffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {
  return writeFloat(this, value, offset, false, noAssert)
}

function writeDouble (buf, value, offset, littleEndian, noAssert) {
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)
  }
  ieee754.write(buf, value, offset, littleEndian, 52, 8)
  return offset + 8
}

Buffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {
  return writeDouble(this, value, offset, true, noAssert)
}

Buffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {
  return writeDouble(this, value, offset, false, noAssert)
}

// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
Buffer.prototype.copy = function copy (target, targetStart, start, end) {
  if (!start) start = 0
  if (!end && end !== 0) end = this.length
  if (targetStart >= target.length) targetStart = target.length
  if (!targetStart) targetStart = 0
  if (end > 0 && end < start) end = start

  // Copy 0 bytes; we're done
  if (end === start) return 0
  if (target.length === 0 || this.length === 0) return 0

  // Fatal error conditions
  if (targetStart < 0) {
    throw new RangeError('targetStart out of bounds')
  }
  if (start < 0 || start >= this.length) throw new RangeError('sourceStart out of bounds')
  if (end < 0) throw new RangeError('sourceEnd out of bounds')

  // Are we oob?
  if (end > this.length) end = this.length
  if (target.length - targetStart < end - start) {
    end = target.length - targetStart + start
  }

  var len = end - start
  var i

  if (this === target && start < targetStart && targetStart < end) {
    // descending copy from end
    for (i = len - 1; i >= 0; --i) {
      target[i + targetStart] = this[i + start]
    }
  } else if (len < 1000 || !Buffer.TYPED_ARRAY_SUPPORT) {
    // ascending copy from start
    for (i = 0; i < len; ++i) {
      target[i + targetStart] = this[i + start]
    }
  } else {
    Uint8Array.prototype.set.call(
      target,
      this.subarray(start, start + len),
      targetStart
    )
  }

  return len
}

// Usage:
//    buffer.fill(number[, offset[, end]])
//    buffer.fill(buffer[, offset[, end]])
//    buffer.fill(string[, offset[, end]][, encoding])
Buffer.prototype.fill = function fill (val, start, end, encoding) {
  // Handle string cases:
  if (typeof val === 'string') {
    if (typeof start === 'string') {
      encoding = start
      start = 0
      end = this.length
    } else if (typeof end === 'string') {
      encoding = end
      end = this.length
    }
    if (val.length === 1) {
      var code = val.charCodeAt(0)
      if (code < 256) {
        val = code
      }
    }
    if (encoding !== undefined && typeof encoding !== 'string') {
      throw new TypeError('encoding must be a string')
    }
    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {
      throw new TypeError('Unknown encoding: ' + encoding)
    }
  } else if (typeof val === 'number') {
    val = val & 255
  }

  // Invalid ranges are not set to a default, so can range check early.
  if (start < 0 || this.length < start || this.length < end) {
    throw new RangeError('Out of range index')
  }

  if (end <= start) {
    return this
  }

  start = start >>> 0
  end = end === undefined ? this.length : end >>> 0

  if (!val) val = 0

  var i
  if (typeof val === 'number') {
    for (i = start; i < end; ++i) {
      this[i] = val
    }
  } else {
    var bytes = Buffer.isBuffer(val)
      ? val
      : utf8ToBytes(new Buffer(val, encoding).toString())
    var len = bytes.length
    for (i = 0; i < end - start; ++i) {
      this[i + start] = bytes[i % len]
    }
  }

  return this
}

// HELPER FUNCTIONS
// ================

var INVALID_BASE64_RE = /[^+\/0-9A-Za-z-_]/g

function base64clean (str) {
  // Node strips out invalid characters like \n and \t from the string, base64-js does not
  str = stringtrim(str).replace(INVALID_BASE64_RE, '')
  // Node converts strings with length < 2 to ''
  if (str.length < 2) return ''
  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not
  while (str.length % 4 !== 0) {
    str = str + '='
  }
  return str
}

function stringtrim (str) {
  if (str.trim) return str.trim()
  return str.replace(/^\s+|\s+$/g, '')
}

function toHex (n) {
  if (n < 16) return '0' + n.toString(16)
  return n.toString(16)
}

function utf8ToBytes (string, units) {
  units = units || Infinity
  var codePoint
  var length = string.length
  var leadSurrogate = null
  var bytes = []

  for (var i = 0; i < length; ++i) {
    codePoint = string.charCodeAt(i)

    // is surrogate component
    if (codePoint > 0xD7FF && codePoint < 0xE000) {
      // last char was a lead
      if (!leadSurrogate) {
        // no lead yet
        if (codePoint > 0xDBFF) {
          // unexpected trail
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        } else if (i + 1 === length) {
          // unpaired lead
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        }

        // valid lead
        leadSurrogate = codePoint

        continue
      }

      // 2 leads in a row
      if (codePoint < 0xDC00) {
        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
        leadSurrogate = codePoint
        continue
      }

      // valid surrogate pair
      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000
    } else if (leadSurrogate) {
      // valid bmp char, but last char was a lead
      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
    }

    leadSurrogate = null

    // encode utf8
    if (codePoint < 0x80) {
      if ((units -= 1) < 0) break
      bytes.push(codePoint)
    } else if (codePoint < 0x800) {
      if ((units -= 2) < 0) break
      bytes.push(
        codePoint >> 0x6 | 0xC0,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x10000) {
      if ((units -= 3) < 0) break
      bytes.push(
        codePoint >> 0xC | 0xE0,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x110000) {
      if ((units -= 4) < 0) break
      bytes.push(
        codePoint >> 0x12 | 0xF0,
        codePoint >> 0xC & 0x3F | 0x80,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else {
      throw new Error('Invalid code point')
    }
  }

  return bytes
}

function asciiToBytes (str) {
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    // Node's code seems to be doing this and not & 0x7F..
    byteArray.push(str.charCodeAt(i) & 0xFF)
  }
  return byteArray
}

function utf16leToBytes (str, units) {
  var c, hi, lo
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    if ((units -= 2) < 0) break

    c = str.charCodeAt(i)
    hi = c >> 8
    lo = c % 256
    byteArray.push(lo)
    byteArray.push(hi)
  }

  return byteArray
}

function base64ToBytes (str) {
  return base64.toByteArray(base64clean(str))
}

function blitBuffer (src, dst, offset, length) {
  for (var i = 0; i < length; ++i) {
    if ((i + offset >= dst.length) || (i >= src.length)) break
    dst[i + offset] = src[i]
  }
  return i
}

function isnan (val) {
  return val !== val // eslint-disable-line no-self-compare
}

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buildin/global.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\buildin\\global.js")))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\events\\events.js":
/*!***********************************************!*\
  !*** (webpack)/node_modules/events/events.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.



var R = typeof Reflect === 'object' ? Reflect : null
var ReflectApply = R && typeof R.apply === 'function'
  ? R.apply
  : function ReflectApply(target, receiver, args) {
    return Function.prototype.apply.call(target, receiver, args);
  }

var ReflectOwnKeys
if (R && typeof R.ownKeys === 'function') {
  ReflectOwnKeys = R.ownKeys
} else if (Object.getOwnPropertySymbols) {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target)
      .concat(Object.getOwnPropertySymbols(target));
  };
} else {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target);
  };
}

function ProcessEmitWarning(warning) {
  if (console && console.warn) console.warn(warning);
}

var NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {
  return value !== value;
}

function EventEmitter() {
  EventEmitter.init.call(this);
}
module.exports = EventEmitter;

// Backwards-compat with node 0.10.x
EventEmitter.EventEmitter = EventEmitter;

EventEmitter.prototype._events = undefined;
EventEmitter.prototype._eventsCount = 0;
EventEmitter.prototype._maxListeners = undefined;

// By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.
var defaultMaxListeners = 10;

Object.defineProperty(EventEmitter, 'defaultMaxListeners', {
  enumerable: true,
  get: function() {
    return defaultMaxListeners;
  },
  set: function(arg) {
    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {
      throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + '.');
    }
    defaultMaxListeners = arg;
  }
});

EventEmitter.init = function() {

  if (this._events === undefined ||
      this._events === Object.getPrototypeOf(this)._events) {
    this._events = Object.create(null);
    this._eventsCount = 0;
  }

  this._maxListeners = this._maxListeners || undefined;
};

// Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.
EventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {
  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {
    throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + '.');
  }
  this._maxListeners = n;
  return this;
};

function $getMaxListeners(that) {
  if (that._maxListeners === undefined)
    return EventEmitter.defaultMaxListeners;
  return that._maxListeners;
}

EventEmitter.prototype.getMaxListeners = function getMaxListeners() {
  return $getMaxListeners(this);
};

EventEmitter.prototype.emit = function emit(type) {
  var args = [];
  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);
  var doError = (type === 'error');

  var events = this._events;
  if (events !== undefined)
    doError = (doError && events.error === undefined);
  else if (!doError)
    return false;

  // If there is no 'error' event listener then throw.
  if (doError) {
    var er;
    if (args.length > 0)
      er = args[0];
    if (er instanceof Error) {
      // Note: The comments on the `throw` lines are intentional, they show
      // up in Node's output if this results in an unhandled exception.
      throw er; // Unhandled 'error' event
    }
    // At least give some kind of context to the user
    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));
    err.context = er;
    throw err; // Unhandled 'error' event
  }

  var handler = events[type];

  if (handler === undefined)
    return false;

  if (typeof handler === 'function') {
    ReflectApply(handler, this, args);
  } else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      ReflectApply(listeners[i], this, args);
  }

  return true;
};

function _addListener(target, type, listener, prepend) {
  var m;
  var events;
  var existing;

  if (typeof listener !== 'function') {
    throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
  }

  events = target._events;
  if (events === undefined) {
    events = target._events = Object.create(null);
    target._eventsCount = 0;
  } else {
    // To avoid recursion in the case that type === "newListener"! Before
    // adding it to the listeners, first emit "newListener".
    if (events.newListener !== undefined) {
      target.emit('newListener', type,
                  listener.listener ? listener.listener : listener);

      // Re-assign `events` because a newListener handler could have caused the
      // this._events to be assigned to a new object
      events = target._events;
    }
    existing = events[type];
  }

  if (existing === undefined) {
    // Optimize the case of one listener. Don't need the extra array object.
    existing = events[type] = listener;
    ++target._eventsCount;
  } else {
    if (typeof existing === 'function') {
      // Adding the second element, need to change to array.
      existing = events[type] =
        prepend ? [listener, existing] : [existing, listener];
      // If we've already got an array, just append.
    } else if (prepend) {
      existing.unshift(listener);
    } else {
      existing.push(listener);
    }

    // Check for listener leak
    m = $getMaxListeners(target);
    if (m > 0 && existing.length > m && !existing.warned) {
      existing.warned = true;
      // No error code for this since it is a Warning
      // eslint-disable-next-line no-restricted-syntax
      var w = new Error('Possible EventEmitter memory leak detected. ' +
                          existing.length + ' ' + String(type) + ' listeners ' +
                          'added. Use emitter.setMaxListeners() to ' +
                          'increase limit');
      w.name = 'MaxListenersExceededWarning';
      w.emitter = target;
      w.type = type;
      w.count = existing.length;
      ProcessEmitWarning(w);
    }
  }

  return target;
}

EventEmitter.prototype.addListener = function addListener(type, listener) {
  return _addListener(this, type, listener, false);
};

EventEmitter.prototype.on = EventEmitter.prototype.addListener;

EventEmitter.prototype.prependListener =
    function prependListener(type, listener) {
      return _addListener(this, type, listener, true);
    };

function onceWrapper() {
  var args = [];
  for (var i = 0; i < arguments.length; i++) args.push(arguments[i]);
  if (!this.fired) {
    this.target.removeListener(this.type, this.wrapFn);
    this.fired = true;
    ReflectApply(this.listener, this.target, args);
  }
}

function _onceWrap(target, type, listener) {
  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
  var wrapped = onceWrapper.bind(state);
  wrapped.listener = listener;
  state.wrapFn = wrapped;
  return wrapped;
}

EventEmitter.prototype.once = function once(type, listener) {
  if (typeof listener !== 'function') {
    throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
  }
  this.on(type, _onceWrap(this, type, listener));
  return this;
};

EventEmitter.prototype.prependOnceListener =
    function prependOnceListener(type, listener) {
      if (typeof listener !== 'function') {
        throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
      }
      this.prependListener(type, _onceWrap(this, type, listener));
      return this;
    };

// Emits a 'removeListener' event if and only if the listener was removed.
EventEmitter.prototype.removeListener =
    function removeListener(type, listener) {
      var list, events, position, i, originalListener;

      if (typeof listener !== 'function') {
        throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
      }

      events = this._events;
      if (events === undefined)
        return this;

      list = events[type];
      if (list === undefined)
        return this;

      if (list === listener || list.listener === listener) {
        if (--this._eventsCount === 0)
          this._events = Object.create(null);
        else {
          delete events[type];
          if (events.removeListener)
            this.emit('removeListener', type, list.listener || listener);
        }
      } else if (typeof list !== 'function') {
        position = -1;

        for (i = list.length - 1; i >= 0; i--) {
          if (list[i] === listener || list[i].listener === listener) {
            originalListener = list[i].listener;
            position = i;
            break;
          }
        }

        if (position < 0)
          return this;

        if (position === 0)
          list.shift();
        else {
          spliceOne(list, position);
        }

        if (list.length === 1)
          events[type] = list[0];

        if (events.removeListener !== undefined)
          this.emit('removeListener', type, originalListener || listener);
      }

      return this;
    };

EventEmitter.prototype.off = EventEmitter.prototype.removeListener;

EventEmitter.prototype.removeAllListeners =
    function removeAllListeners(type) {
      var listeners, events, i;

      events = this._events;
      if (events === undefined)
        return this;

      // not listening for removeListener, no need to emit
      if (events.removeListener === undefined) {
        if (arguments.length === 0) {
          this._events = Object.create(null);
          this._eventsCount = 0;
        } else if (events[type] !== undefined) {
          if (--this._eventsCount === 0)
            this._events = Object.create(null);
          else
            delete events[type];
        }
        return this;
      }

      // emit removeListener for all listeners on all events
      if (arguments.length === 0) {
        var keys = Object.keys(events);
        var key;
        for (i = 0; i < keys.length; ++i) {
          key = keys[i];
          if (key === 'removeListener') continue;
          this.removeAllListeners(key);
        }
        this.removeAllListeners('removeListener');
        this._events = Object.create(null);
        this._eventsCount = 0;
        return this;
      }

      listeners = events[type];

      if (typeof listeners === 'function') {
        this.removeListener(type, listeners);
      } else if (listeners !== undefined) {
        // LIFO order
        for (i = listeners.length - 1; i >= 0; i--) {
          this.removeListener(type, listeners[i]);
        }
      }

      return this;
    };

function _listeners(target, type, unwrap) {
  var events = target._events;

  if (events === undefined)
    return [];

  var evlistener = events[type];
  if (evlistener === undefined)
    return [];

  if (typeof evlistener === 'function')
    return unwrap ? [evlistener.listener || evlistener] : [evlistener];

  return unwrap ?
    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
}

EventEmitter.prototype.listeners = function listeners(type) {
  return _listeners(this, type, true);
};

EventEmitter.prototype.rawListeners = function rawListeners(type) {
  return _listeners(this, type, false);
};

EventEmitter.listenerCount = function(emitter, type) {
  if (typeof emitter.listenerCount === 'function') {
    return emitter.listenerCount(type);
  } else {
    return listenerCount.call(emitter, type);
  }
};

EventEmitter.prototype.listenerCount = listenerCount;
function listenerCount(type) {
  var events = this._events;

  if (events !== undefined) {
    var evlistener = events[type];

    if (typeof evlistener === 'function') {
      return 1;
    } else if (evlistener !== undefined) {
      return evlistener.length;
    }
  }

  return 0;
}

EventEmitter.prototype.eventNames = function eventNames() {
  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
};

function arrayClone(arr, n) {
  var copy = new Array(n);
  for (var i = 0; i < n; ++i)
    copy[i] = arr[i];
  return copy;
}

function spliceOne(list, index) {
  for (; index + 1 < list.length; index++)
    list[index] = list[index + 1];
  list.pop();
}

function unwrapListeners(arr) {
  var ret = new Array(arr.length);
  for (var i = 0; i < ret.length; ++i) {
    ret[i] = arr[i].listener || arr[i];
  }
  return ret;
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\ieee754\\index.js":
/*!***********************************************!*\
  !*** (webpack)/node_modules/ieee754/index.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

exports.read = function (buffer, offset, isLE, mLen, nBytes) {
  var e, m
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var nBits = -7
  var i = isLE ? (nBytes - 1) : 0
  var d = isLE ? -1 : 1
  var s = buffer[offset + i]

  i += d

  e = s & ((1 << (-nBits)) - 1)
  s >>= (-nBits)
  nBits += eLen
  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  m = e & ((1 << (-nBits)) - 1)
  e >>= (-nBits)
  nBits += mLen
  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  if (e === 0) {
    e = 1 - eBias
  } else if (e === eMax) {
    return m ? NaN : ((s ? -1 : 1) * Infinity)
  } else {
    m = m + Math.pow(2, mLen)
    e = e - eBias
  }
  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)
}

exports.write = function (buffer, value, offset, isLE, mLen, nBytes) {
  var e, m, c
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)
  var i = isLE ? 0 : (nBytes - 1)
  var d = isLE ? 1 : -1
  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0

  value = Math.abs(value)

  if (isNaN(value) || value === Infinity) {
    m = isNaN(value) ? 1 : 0
    e = eMax
  } else {
    e = Math.floor(Math.log(value) / Math.LN2)
    if (value * (c = Math.pow(2, -e)) < 1) {
      e--
      c *= 2
    }
    if (e + eBias >= 1) {
      value += rt / c
    } else {
      value += rt * Math.pow(2, 1 - eBias)
    }
    if (value * c >= 2) {
      e++
      c /= 2
    }

    if (e + eBias >= eMax) {
      m = 0
      e = eMax
    } else if (e + eBias >= 1) {
      m = ((value * c) - 1) * Math.pow(2, mLen)
      e = e + eBias
    } else {
      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)
      e = 0
    }
  }

  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}

  e = (e << mLen) | m
  eLen += mLen
  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}

  buffer[offset + i - d] |= s * 128
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\inherits\\inherits_browser.js":
/*!***********************************************************!*\
  !*** (webpack)/node_modules/inherits/inherits_browser.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    ctor.prototype = Object.create(superCtor.prototype, {
      constructor: {
        value: ctor,
        enumerable: false,
        writable: true,
        configurable: true
      }
    });
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    var TempCtor = function () {}
    TempCtor.prototype = superCtor.prototype
    ctor.prototype = new TempCtor()
    ctor.prototype.constructor = ctor
  }
}


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\isarray\\index.js":
/*!***********************************************!*\
  !*** (webpack)/node_modules/isarray/index.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

var toString = {}.toString;

module.exports = Array.isArray || function (arr) {
  return toString.call(arr) == '[object Array]';
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js":
/*!**************************************************************!*\
  !*** (webpack)/node_modules/node-libs-browser/mock/empty.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {



/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\os-browserify\\browser.js":
/*!*******************************************************!*\
  !*** (webpack)/node_modules/os-browserify/browser.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

exports.endianness = function () { return 'LE' };

exports.hostname = function () {
    if (typeof location !== 'undefined') {
        return location.hostname
    }
    else return '';
};

exports.loadavg = function () { return [] };

exports.uptime = function () { return 0 };

exports.freemem = function () {
    return Number.MAX_VALUE;
};

exports.totalmem = function () {
    return Number.MAX_VALUE;
};

exports.cpus = function () { return [] };

exports.type = function () { return 'Browser' };

exports.release = function () {
    if (typeof navigator !== 'undefined') {
        return navigator.appVersion;
    }
    return '';
};

exports.networkInterfaces
= exports.getNetworkInterfaces
= function () { return {} };

exports.arch = function () { return 'javascript' };

exports.platform = function () { return 'browser' };

exports.tmpdir = exports.tmpDir = function () {
    return '/tmp';
};

exports.EOL = '\n';

exports.homedir = function () {
	return '/'
};


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\path-browserify\\index.js":
/*!*******************************************************!*\
  !*** (webpack)/node_modules/path-browserify/index.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(process) {// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

// resolves . and .. elements in a path array with directory names there
// must be no slashes, empty elements, or device names (c:\) in the array
// (so also no leading and trailing slashes - it does not distinguish
// relative and absolute paths)
function normalizeArray(parts, allowAboveRoot) {
  // if the path tries to go above the root, `up` ends up > 0
  var up = 0;
  for (var i = parts.length - 1; i >= 0; i--) {
    var last = parts[i];
    if (last === '.') {
      parts.splice(i, 1);
    } else if (last === '..') {
      parts.splice(i, 1);
      up++;
    } else if (up) {
      parts.splice(i, 1);
      up--;
    }
  }

  // if the path is allowed to go above the root, restore leading ..s
  if (allowAboveRoot) {
    for (; up--; up) {
      parts.unshift('..');
    }
  }

  return parts;
}

// Split a filename into [root, dir, basename, ext], unix version
// 'root' is just a slash, or nothing.
var splitPathRe =
    /^(\/?|)([\s\S]*?)((?:\.{1,2}|[^\/]+?|)(\.[^.\/]*|))(?:[\/]*)$/;
var splitPath = function(filename) {
  return splitPathRe.exec(filename).slice(1);
};

// path.resolve([from ...], to)
// posix version
exports.resolve = function() {
  var resolvedPath = '',
      resolvedAbsolute = false;

  for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {
    var path = (i >= 0) ? arguments[i] : process.cwd();

    // Skip empty and invalid entries
    if (typeof path !== 'string') {
      throw new TypeError('Arguments to path.resolve must be strings');
    } else if (!path) {
      continue;
    }

    resolvedPath = path + '/' + resolvedPath;
    resolvedAbsolute = path.charAt(0) === '/';
  }

  // At this point the path should be resolved to a full absolute path, but
  // handle relative paths to be safe (might happen when process.cwd() fails)

  // Normalize the path
  resolvedPath = normalizeArray(filter(resolvedPath.split('/'), function(p) {
    return !!p;
  }), !resolvedAbsolute).join('/');

  return ((resolvedAbsolute ? '/' : '') + resolvedPath) || '.';
};

// path.normalize(path)
// posix version
exports.normalize = function(path) {
  var isAbsolute = exports.isAbsolute(path),
      trailingSlash = substr(path, -1) === '/';

  // Normalize the path
  path = normalizeArray(filter(path.split('/'), function(p) {
    return !!p;
  }), !isAbsolute).join('/');

  if (!path && !isAbsolute) {
    path = '.';
  }
  if (path && trailingSlash) {
    path += '/';
  }

  return (isAbsolute ? '/' : '') + path;
};

// posix version
exports.isAbsolute = function(path) {
  return path.charAt(0) === '/';
};

// posix version
exports.join = function() {
  var paths = Array.prototype.slice.call(arguments, 0);
  return exports.normalize(filter(paths, function(p, index) {
    if (typeof p !== 'string') {
      throw new TypeError('Arguments to path.join must be strings');
    }
    return p;
  }).join('/'));
};


// path.relative(from, to)
// posix version
exports.relative = function(from, to) {
  from = exports.resolve(from).substr(1);
  to = exports.resolve(to).substr(1);

  function trim(arr) {
    var start = 0;
    for (; start < arr.length; start++) {
      if (arr[start] !== '') break;
    }

    var end = arr.length - 1;
    for (; end >= 0; end--) {
      if (arr[end] !== '') break;
    }

    if (start > end) return [];
    return arr.slice(start, end - start + 1);
  }

  var fromParts = trim(from.split('/'));
  var toParts = trim(to.split('/'));

  var length = Math.min(fromParts.length, toParts.length);
  var samePartsLength = length;
  for (var i = 0; i < length; i++) {
    if (fromParts[i] !== toParts[i]) {
      samePartsLength = i;
      break;
    }
  }

  var outputParts = [];
  for (var i = samePartsLength; i < fromParts.length; i++) {
    outputParts.push('..');
  }

  outputParts = outputParts.concat(toParts.slice(samePartsLength));

  return outputParts.join('/');
};

exports.sep = '/';
exports.delimiter = ':';

exports.dirname = function(path) {
  var result = splitPath(path),
      root = result[0],
      dir = result[1];

  if (!root && !dir) {
    // No dirname whatsoever
    return '.';
  }

  if (dir) {
    // It has a dirname, strip trailing slash
    dir = dir.substr(0, dir.length - 1);
  }

  return root + dir;
};


exports.basename = function(path, ext) {
  var f = splitPath(path)[2];
  // TODO: make this comparison case-insensitive on windows?
  if (ext && f.substr(-1 * ext.length) === ext) {
    f = f.substr(0, f.length - ext.length);
  }
  return f;
};


exports.extname = function(path) {
  return splitPath(path)[3];
};

function filter (xs, f) {
    if (xs.filter) return xs.filter(f);
    var res = [];
    for (var i = 0; i < xs.length; i++) {
        if (f(xs[i], i, xs)) res.push(xs[i]);
    }
    return res;
}

// String.prototype.substr - negative index don't work in IE8
var substr = 'ab'.substr(-1) === 'b'
    ? function (str, start, len) { return str.substr(start, len) }
    : function (str, start, len) {
        if (start < 0) start = str.length + start;
        return str.substr(start, len);
    }
;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../process/browser.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\process\\browser.js")))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\process\\browser.js":
/*!*************************************************!*\
  !*** (webpack)/node_modules/process/browser.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// shim for using process in browser
var process = module.exports = {};

// cached from whatever global is present so that test runners that stub it
// don't break things.  But we need to wrap it in a try catch in case it is
// wrapped in strict mode code which doesn't define any globals.  It's inside a
// function because try/catches deoptimize in certain engines.

var cachedSetTimeout;
var cachedClearTimeout;

function defaultSetTimout() {
    throw new Error('setTimeout has not been defined');
}
function defaultClearTimeout () {
    throw new Error('clearTimeout has not been defined');
}
(function () {
    try {
        if (typeof setTimeout === 'function') {
            cachedSetTimeout = setTimeout;
        } else {
            cachedSetTimeout = defaultSetTimout;
        }
    } catch (e) {
        cachedSetTimeout = defaultSetTimout;
    }
    try {
        if (typeof clearTimeout === 'function') {
            cachedClearTimeout = clearTimeout;
        } else {
            cachedClearTimeout = defaultClearTimeout;
        }
    } catch (e) {
        cachedClearTimeout = defaultClearTimeout;
    }
} ())
function runTimeout(fun) {
    if (cachedSetTimeout === setTimeout) {
        //normal enviroments in sane situations
        return setTimeout(fun, 0);
    }
    // if setTimeout wasn't available but was latter defined
    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
        cachedSetTimeout = setTimeout;
        return setTimeout(fun, 0);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedSetTimeout(fun, 0);
    } catch(e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
            return cachedSetTimeout.call(null, fun, 0);
        } catch(e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
            return cachedSetTimeout.call(this, fun, 0);
        }
    }


}
function runClearTimeout(marker) {
    if (cachedClearTimeout === clearTimeout) {
        //normal enviroments in sane situations
        return clearTimeout(marker);
    }
    // if clearTimeout wasn't available but was latter defined
    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
        cachedClearTimeout = clearTimeout;
        return clearTimeout(marker);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedClearTimeout(marker);
    } catch (e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
            return cachedClearTimeout.call(null, marker);
        } catch (e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
            // Some versions of I.E. have different rules for clearTimeout vs setTimeout
            return cachedClearTimeout.call(this, marker);
        }
    }



}
var queue = [];
var draining = false;
var currentQueue;
var queueIndex = -1;

function cleanUpNextTick() {
    if (!draining || !currentQueue) {
        return;
    }
    draining = false;
    if (currentQueue.length) {
        queue = currentQueue.concat(queue);
    } else {
        queueIndex = -1;
    }
    if (queue.length) {
        drainQueue();
    }
}

function drainQueue() {
    if (draining) {
        return;
    }
    var timeout = runTimeout(cleanUpNextTick);
    draining = true;

    var len = queue.length;
    while(len) {
        currentQueue = queue;
        queue = [];
        while (++queueIndex < len) {
            if (currentQueue) {
                currentQueue[queueIndex].run();
            }
        }
        queueIndex = -1;
        len = queue.length;
    }
    currentQueue = null;
    draining = false;
    runClearTimeout(timeout);
}

process.nextTick = function (fun) {
    var args = new Array(arguments.length - 1);
    if (arguments.length > 1) {
        for (var i = 1; i < arguments.length; i++) {
            args[i - 1] = arguments[i];
        }
    }
    queue.push(new Item(fun, args));
    if (queue.length === 1 && !draining) {
        runTimeout(drainQueue);
    }
};

// v8 likes predictible objects
function Item(fun, array) {
    this.fun = fun;
    this.array = array;
}
Item.prototype.run = function () {
    this.fun.apply(null, this.array);
};
process.title = 'browser';
process.browser = true;
process.env = {};
process.argv = [];
process.version = ''; // empty string to avoid regexp issues
process.versions = {};

function noop() {}

process.on = noop;
process.addListener = noop;
process.once = noop;
process.off = noop;
process.removeListener = noop;
process.removeAllListeners = noop;
process.emit = noop;
process.prependListener = noop;
process.prependOnceListener = noop;

process.listeners = function (name) { return [] }

process.binding = function (name) {
    throw new Error('process.binding is not supported');
};

process.cwd = function () { return '/' };
process.chdir = function (dir) {
    throw new Error('process.chdir is not supported');
};
process.umask = function() { return 0; };


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\support\\isBufferBrowser.js":
/*!**************************************************************!*\
  !*** (webpack)/node_modules/util/support/isBufferBrowser.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

module.exports = function isBuffer(arg) {
  return arg && typeof arg === 'object'
    && typeof arg.copy === 'function'
    && typeof arg.fill === 'function'
    && typeof arg.readUInt8 === 'function';
}

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\util.js":
/*!*******************************************!*\
  !*** (webpack)/node_modules/util/util.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(process) {// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

var getOwnPropertyDescriptors = Object.getOwnPropertyDescriptors ||
  function getOwnPropertyDescriptors(obj) {
    var keys = Object.keys(obj);
    var descriptors = {};
    for (var i = 0; i < keys.length; i++) {
      descriptors[keys[i]] = Object.getOwnPropertyDescriptor(obj, keys[i]);
    }
    return descriptors;
  };

var formatRegExp = /%[sdj%]/g;
exports.format = function(f) {
  if (!isString(f)) {
    var objects = [];
    for (var i = 0; i < arguments.length; i++) {
      objects.push(inspect(arguments[i]));
    }
    return objects.join(' ');
  }

  var i = 1;
  var args = arguments;
  var len = args.length;
  var str = String(f).replace(formatRegExp, function(x) {
    if (x === '%%') return '%';
    if (i >= len) return x;
    switch (x) {
      case '%s': return String(args[i++]);
      case '%d': return Number(args[i++]);
      case '%j':
        try {
          return JSON.stringify(args[i++]);
        } catch (_) {
          return '[Circular]';
        }
      default:
        return x;
    }
  });
  for (var x = args[i]; i < len; x = args[++i]) {
    if (isNull(x) || !isObject(x)) {
      str += ' ' + x;
    } else {
      str += ' ' + inspect(x);
    }
  }
  return str;
};


// Mark that a method should not be used.
// Returns a modified function which warns once by default.
// If --no-deprecation is set, then it is a no-op.
exports.deprecate = function(fn, msg) {
  if (typeof process !== 'undefined' && process.noDeprecation === true) {
    return fn;
  }

  // Allow for deprecating things in the process of starting up.
  if (typeof process === 'undefined') {
    return function() {
      return exports.deprecate(fn, msg).apply(this, arguments);
    };
  }

  var warned = false;
  function deprecated() {
    if (!warned) {
      if (process.throwDeprecation) {
        throw new Error(msg);
      } else if (process.traceDeprecation) {
        console.trace(msg);
      } else {
        console.error(msg);
      }
      warned = true;
    }
    return fn.apply(this, arguments);
  }

  return deprecated;
};


var debugs = {};
var debugEnviron;
exports.debuglog = function(set) {
  if (isUndefined(debugEnviron))
    debugEnviron = process.env.NODE_DEBUG || '';
  set = set.toUpperCase();
  if (!debugs[set]) {
    if (new RegExp('\\b' + set + '\\b', 'i').test(debugEnviron)) {
      var pid = process.pid;
      debugs[set] = function() {
        var msg = exports.format.apply(exports, arguments);
        console.error('%s %d: %s', set, pid, msg);
      };
    } else {
      debugs[set] = function() {};
    }
  }
  return debugs[set];
};


/**
 * Echos the value of a value. Trys to print the value out
 * in the best way possible given the different types.
 *
 * @param {Object} obj The object to print out.
 * @param {Object} opts Optional options object that alters the output.
 */
/* legacy: obj, showHidden, depth, colors*/
function inspect(obj, opts) {
  // default options
  var ctx = {
    seen: [],
    stylize: stylizeNoColor
  };
  // legacy...
  if (arguments.length >= 3) ctx.depth = arguments[2];
  if (arguments.length >= 4) ctx.colors = arguments[3];
  if (isBoolean(opts)) {
    // legacy...
    ctx.showHidden = opts;
  } else if (opts) {
    // got an "options" object
    exports._extend(ctx, opts);
  }
  // set default options
  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;
  if (isUndefined(ctx.depth)) ctx.depth = 2;
  if (isUndefined(ctx.colors)) ctx.colors = false;
  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;
  if (ctx.colors) ctx.stylize = stylizeWithColor;
  return formatValue(ctx, obj, ctx.depth);
}
exports.inspect = inspect;


// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics
inspect.colors = {
  'bold' : [1, 22],
  'italic' : [3, 23],
  'underline' : [4, 24],
  'inverse' : [7, 27],
  'white' : [37, 39],
  'grey' : [90, 39],
  'black' : [30, 39],
  'blue' : [34, 39],
  'cyan' : [36, 39],
  'green' : [32, 39],
  'magenta' : [35, 39],
  'red' : [31, 39],
  'yellow' : [33, 39]
};

// Don't use 'blue' not visible on cmd.exe
inspect.styles = {
  'special': 'cyan',
  'number': 'yellow',
  'boolean': 'yellow',
  'undefined': 'grey',
  'null': 'bold',
  'string': 'green',
  'date': 'magenta',
  // "name": intentionally not styling
  'regexp': 'red'
};


function stylizeWithColor(str, styleType) {
  var style = inspect.styles[styleType];

  if (style) {
    return '\u001b[' + inspect.colors[style][0] + 'm' + str +
           '\u001b[' + inspect.colors[style][1] + 'm';
  } else {
    return str;
  }
}


function stylizeNoColor(str, styleType) {
  return str;
}


function arrayToHash(array) {
  var hash = {};

  array.forEach(function(val, idx) {
    hash[val] = true;
  });

  return hash;
}


function formatValue(ctx, value, recurseTimes) {
  // Provide a hook for user-specified inspect functions.
  // Check that value is an object with an inspect function on it
  if (ctx.customInspect &&
      value &&
      isFunction(value.inspect) &&
      // Filter out the util module, it's inspect function is special
      value.inspect !== exports.inspect &&
      // Also filter out any prototype objects using the circular check.
      !(value.constructor && value.constructor.prototype === value)) {
    var ret = value.inspect(recurseTimes, ctx);
    if (!isString(ret)) {
      ret = formatValue(ctx, ret, recurseTimes);
    }
    return ret;
  }

  // Primitive types cannot have properties
  var primitive = formatPrimitive(ctx, value);
  if (primitive) {
    return primitive;
  }

  // Look up the keys of the object.
  var keys = Object.keys(value);
  var visibleKeys = arrayToHash(keys);

  if (ctx.showHidden) {
    keys = Object.getOwnPropertyNames(value);
  }

  // IE doesn't make error fields non-enumerable
  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx
  if (isError(value)
      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {
    return formatError(value);
  }

  // Some type of object without properties can be shortcutted.
  if (keys.length === 0) {
    if (isFunction(value)) {
      var name = value.name ? ': ' + value.name : '';
      return ctx.stylize('[Function' + name + ']', 'special');
    }
    if (isRegExp(value)) {
      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');
    }
    if (isDate(value)) {
      return ctx.stylize(Date.prototype.toString.call(value), 'date');
    }
    if (isError(value)) {
      return formatError(value);
    }
  }

  var base = '', array = false, braces = ['{', '}'];

  // Make Array say that they are Array
  if (isArray(value)) {
    array = true;
    braces = ['[', ']'];
  }

  // Make functions say that they are functions
  if (isFunction(value)) {
    var n = value.name ? ': ' + value.name : '';
    base = ' [Function' + n + ']';
  }

  // Make RegExps say that they are RegExps
  if (isRegExp(value)) {
    base = ' ' + RegExp.prototype.toString.call(value);
  }

  // Make dates with properties first say the date
  if (isDate(value)) {
    base = ' ' + Date.prototype.toUTCString.call(value);
  }

  // Make error with message first say the error
  if (isError(value)) {
    base = ' ' + formatError(value);
  }

  if (keys.length === 0 && (!array || value.length == 0)) {
    return braces[0] + base + braces[1];
  }

  if (recurseTimes < 0) {
    if (isRegExp(value)) {
      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');
    } else {
      return ctx.stylize('[Object]', 'special');
    }
  }

  ctx.seen.push(value);

  var output;
  if (array) {
    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);
  } else {
    output = keys.map(function(key) {
      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);
    });
  }

  ctx.seen.pop();

  return reduceToSingleString(output, base, braces);
}


function formatPrimitive(ctx, value) {
  if (isUndefined(value))
    return ctx.stylize('undefined', 'undefined');
  if (isString(value)) {
    var simple = '\'' + JSON.stringify(value).replace(/^"|"$/g, '')
                                             .replace(/'/g, "\\'")
                                             .replace(/\\"/g, '"') + '\'';
    return ctx.stylize(simple, 'string');
  }
  if (isNumber(value))
    return ctx.stylize('' + value, 'number');
  if (isBoolean(value))
    return ctx.stylize('' + value, 'boolean');
  // For some reason typeof null is "object", so special case here.
  if (isNull(value))
    return ctx.stylize('null', 'null');
}


function formatError(value) {
  return '[' + Error.prototype.toString.call(value) + ']';
}


function formatArray(ctx, value, recurseTimes, visibleKeys, keys) {
  var output = [];
  for (var i = 0, l = value.length; i < l; ++i) {
    if (hasOwnProperty(value, String(i))) {
      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,
          String(i), true));
    } else {
      output.push('');
    }
  }
  keys.forEach(function(key) {
    if (!key.match(/^\d+$/)) {
      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,
          key, true));
    }
  });
  return output;
}


function formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {
  var name, str, desc;
  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };
  if (desc.get) {
    if (desc.set) {
      str = ctx.stylize('[Getter/Setter]', 'special');
    } else {
      str = ctx.stylize('[Getter]', 'special');
    }
  } else {
    if (desc.set) {
      str = ctx.stylize('[Setter]', 'special');
    }
  }
  if (!hasOwnProperty(visibleKeys, key)) {
    name = '[' + key + ']';
  }
  if (!str) {
    if (ctx.seen.indexOf(desc.value) < 0) {
      if (isNull(recurseTimes)) {
        str = formatValue(ctx, desc.value, null);
      } else {
        str = formatValue(ctx, desc.value, recurseTimes - 1);
      }
      if (str.indexOf('\n') > -1) {
        if (array) {
          str = str.split('\n').map(function(line) {
            return '  ' + line;
          }).join('\n').substr(2);
        } else {
          str = '\n' + str.split('\n').map(function(line) {
            return '   ' + line;
          }).join('\n');
        }
      }
    } else {
      str = ctx.stylize('[Circular]', 'special');
    }
  }
  if (isUndefined(name)) {
    if (array && key.match(/^\d+$/)) {
      return str;
    }
    name = JSON.stringify('' + key);
    if (name.match(/^"([a-zA-Z_][a-zA-Z_0-9]*)"$/)) {
      name = name.substr(1, name.length - 2);
      name = ctx.stylize(name, 'name');
    } else {
      name = name.replace(/'/g, "\\'")
                 .replace(/\\"/g, '"')
                 .replace(/(^"|"$)/g, "'");
      name = ctx.stylize(name, 'string');
    }
  }

  return name + ': ' + str;
}


function reduceToSingleString(output, base, braces) {
  var numLinesEst = 0;
  var length = output.reduce(function(prev, cur) {
    numLinesEst++;
    if (cur.indexOf('\n') >= 0) numLinesEst++;
    return prev + cur.replace(/\u001b\[\d\d?m/g, '').length + 1;
  }, 0);

  if (length > 60) {
    return braces[0] +
           (base === '' ? '' : base + '\n ') +
           ' ' +
           output.join(',\n  ') +
           ' ' +
           braces[1];
  }

  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];
}


// NOTE: These type checking functions intentionally don't use `instanceof`
// because it is fragile and can be easily faked with `Object.create()`.
function isArray(ar) {
  return Array.isArray(ar);
}
exports.isArray = isArray;

function isBoolean(arg) {
  return typeof arg === 'boolean';
}
exports.isBoolean = isBoolean;

function isNull(arg) {
  return arg === null;
}
exports.isNull = isNull;

function isNullOrUndefined(arg) {
  return arg == null;
}
exports.isNullOrUndefined = isNullOrUndefined;

function isNumber(arg) {
  return typeof arg === 'number';
}
exports.isNumber = isNumber;

function isString(arg) {
  return typeof arg === 'string';
}
exports.isString = isString;

function isSymbol(arg) {
  return typeof arg === 'symbol';
}
exports.isSymbol = isSymbol;

function isUndefined(arg) {
  return arg === void 0;
}
exports.isUndefined = isUndefined;

function isRegExp(re) {
  return isObject(re) && objectToString(re) === '[object RegExp]';
}
exports.isRegExp = isRegExp;

function isObject(arg) {
  return typeof arg === 'object' && arg !== null;
}
exports.isObject = isObject;

function isDate(d) {
  return isObject(d) && objectToString(d) === '[object Date]';
}
exports.isDate = isDate;

function isError(e) {
  return isObject(e) &&
      (objectToString(e) === '[object Error]' || e instanceof Error);
}
exports.isError = isError;

function isFunction(arg) {
  return typeof arg === 'function';
}
exports.isFunction = isFunction;

function isPrimitive(arg) {
  return arg === null ||
         typeof arg === 'boolean' ||
         typeof arg === 'number' ||
         typeof arg === 'string' ||
         typeof arg === 'symbol' ||  // ES6 symbol
         typeof arg === 'undefined';
}
exports.isPrimitive = isPrimitive;

exports.isBuffer = __webpack_require__(/*! ./support/isBuffer */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\util\\support\\isBufferBrowser.js");

function objectToString(o) {
  return Object.prototype.toString.call(o);
}


function pad(n) {
  return n < 10 ? '0' + n.toString(10) : n.toString(10);
}


var months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',
              'Oct', 'Nov', 'Dec'];

// 26 Feb 16:19:34
function timestamp() {
  var d = new Date();
  var time = [pad(d.getHours()),
              pad(d.getMinutes()),
              pad(d.getSeconds())].join(':');
  return [d.getDate(), months[d.getMonth()], time].join(' ');
}


// log is just a thin wrapper to console.log that prepends a timestamp
exports.log = function() {
  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));
};


/**
 * Inherit the prototype methods from one constructor into another.
 *
 * The Function.prototype.inherits from lang.js rewritten as a standalone
 * function (not on Function.prototype). NOTE: If this file is to be loaded
 * during bootstrapping this function needs to be rewritten using some native
 * functions as prototype setup using normal JavaScript does not work as
 * expected during bootstrapping (see mirror.js in r114903).
 *
 * @param {function} ctor Constructor function which needs to inherit the
 *     prototype.
 * @param {function} superCtor Constructor function to inherit prototype from.
 */
exports.inherits = __webpack_require__(/*! inherits */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\inherits\\inherits_browser.js");

exports._extend = function(origin, add) {
  // Don't do anything if add isn't an object
  if (!add || !isObject(add)) return origin;

  var keys = Object.keys(add);
  var i = keys.length;
  while (i--) {
    origin[keys[i]] = add[keys[i]];
  }
  return origin;
};

function hasOwnProperty(obj, prop) {
  return Object.prototype.hasOwnProperty.call(obj, prop);
}

var kCustomPromisifiedSymbol = typeof Symbol !== 'undefined' ? Symbol('util.promisify.custom') : undefined;

exports.promisify = function promisify(original) {
  if (typeof original !== 'function')
    throw new TypeError('The "original" argument must be of type Function');

  if (kCustomPromisifiedSymbol && original[kCustomPromisifiedSymbol]) {
    var fn = original[kCustomPromisifiedSymbol];
    if (typeof fn !== 'function') {
      throw new TypeError('The "util.promisify.custom" argument must be of type Function');
    }
    Object.defineProperty(fn, kCustomPromisifiedSymbol, {
      value: fn, enumerable: false, writable: false, configurable: true
    });
    return fn;
  }

  function fn() {
    var promiseResolve, promiseReject;
    var promise = new Promise(function (resolve, reject) {
      promiseResolve = resolve;
      promiseReject = reject;
    });

    var args = [];
    for (var i = 0; i < arguments.length; i++) {
      args.push(arguments[i]);
    }
    args.push(function (err, value) {
      if (err) {
        promiseReject(err);
      } else {
        promiseResolve(value);
      }
    });

    try {
      original.apply(this, args);
    } catch (err) {
      promiseReject(err);
    }

    return promise;
  }

  Object.setPrototypeOf(fn, Object.getPrototypeOf(original));

  if (kCustomPromisifiedSymbol) Object.defineProperty(fn, kCustomPromisifiedSymbol, {
    value: fn, enumerable: false, writable: false, configurable: true
  });
  return Object.defineProperties(
    fn,
    getOwnPropertyDescriptors(original)
  );
}

exports.promisify.custom = kCustomPromisifiedSymbol

function callbackifyOnRejected(reason, cb) {
  // `!reason` guard inspired by bluebird (Ref: https://goo.gl/t5IS6M).
  // Because `null` is a special error value in callbacks which means "no error
  // occurred", we error-wrap so the callback consumer can distinguish between
  // "the promise rejected with null" or "the promise fulfilled with undefined".
  if (!reason) {
    var newReason = new Error('Promise was rejected with a falsy value');
    newReason.reason = reason;
    reason = newReason;
  }
  return cb(reason);
}

function callbackify(original) {
  if (typeof original !== 'function') {
    throw new TypeError('The "original" argument must be of type Function');
  }

  // We DO NOT return the promise as it gives the user a false sense that
  // the promise is actually somehow related to the callback's execution
  // and that the callback throwing will reject the promise.
  function callbackified() {
    var args = [];
    for (var i = 0; i < arguments.length; i++) {
      args.push(arguments[i]);
    }

    var maybeCb = args.pop();
    if (typeof maybeCb !== 'function') {
      throw new TypeError('The last argument must be of type Function');
    }
    var self = this;
    var cb = function() {
      return maybeCb.apply(self, arguments);
    };
    // In true node style we process the callback on `nextTick` with all the
    // implications (stack, `uncaughtException`, `async_hooks`)
    original.apply(this, args)
      .then(function(ret) { process.nextTick(cb, null, ret) },
            function(rej) { process.nextTick(callbackifyOnRejected, rej, cb) });
  }

  Object.setPrototypeOf(callbackified, Object.getPrototypeOf(original));
  Object.defineProperties(callbackified,
                          getOwnPropertyDescriptors(original));
  return callbackified;
}
exports.callbackify = callbackify;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../process/browser.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\process\\browser.js")))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webworker-threads\\index.js":
/*!************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/webworker-threads/index.js ***!
  \************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var WebWorkerThreads = __webpack_require__(/*! bindings */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webworker-threads\\node_modules\\bindings\\bindings.js")('WebWorkerThreads');
 
module.exports = WebWorkerThreads;


/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webworker-threads\\node_modules\\bindings\\bindings.js":
/*!*************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/webworker-threads/node_modules/bindings/bindings.js ***!
  \*************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(process, __filename) {/**
 * Module dependencies.
 */

var fs = __webpack_require__(/*! fs */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\node-libs-browser\\mock\\empty.js"),
  path = __webpack_require__(/*! path */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\path-browserify\\index.js"),
  fileURLToPath = __webpack_require__(/*! file-uri-to-path */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webworker-threads\\node_modules\\file-uri-to-path\\index.js"),
  join = path.join,
  dirname = path.dirname,
  exists =
    (fs.accessSync &&
      function(path) {
        try {
          fs.accessSync(path);
        } catch (e) {
          return false;
        }
        return true;
      }) ||
    fs.existsSync ||
    path.existsSync,
  defaults = {
    arrow: process.env.NODE_BINDINGS_ARROW || ' → ',
    compiled: process.env.NODE_BINDINGS_COMPILED_DIR || 'compiled',
    platform: process.platform,
    arch: process.arch,
    nodePreGyp:
      'node-v' +
      process.versions.modules +
      '-' +
      process.platform +
      '-' +
      process.arch,
    version: process.versions.node,
    bindings: 'bindings.node',
    try: [
      // node-gyp's linked version in the "build" dir
      ['module_root', 'build', 'bindings'],
      // node-waf and gyp_addon (a.k.a node-gyp)
      ['module_root', 'build', 'Debug', 'bindings'],
      ['module_root', 'build', 'Release', 'bindings'],
      // Debug files, for development (legacy behavior, remove for node v0.9)
      ['module_root', 'out', 'Debug', 'bindings'],
      ['module_root', 'Debug', 'bindings'],
      // Release files, but manually compiled (legacy behavior, remove for node v0.9)
      ['module_root', 'out', 'Release', 'bindings'],
      ['module_root', 'Release', 'bindings'],
      // Legacy from node-waf, node <= 0.4.x
      ['module_root', 'build', 'default', 'bindings'],
      // Production "Release" buildtype binary (meh...)
      ['module_root', 'compiled', 'version', 'platform', 'arch', 'bindings'],
      // node-qbs builds
      ['module_root', 'addon-build', 'release', 'install-root', 'bindings'],
      ['module_root', 'addon-build', 'debug', 'install-root', 'bindings'],
      ['module_root', 'addon-build', 'default', 'install-root', 'bindings'],
      // node-pre-gyp path ./lib/binding/{node_abi}-{platform}-{arch}
      ['module_root', 'lib', 'binding', 'nodePreGyp', 'bindings']
    ]
  };

/**
 * The main `bindings()` function loads the compiled bindings for a given module.
 * It uses V8's Error API to determine the parent filename that this function is
 * being invoked from, which is then used to find the root directory.
 */

function bindings(opts) {
  // Argument surgery
  if (typeof opts == 'string') {
    opts = { bindings: opts };
  } else if (!opts) {
    opts = {};
  }

  // maps `defaults` onto `opts` object
  Object.keys(defaults).map(function(i) {
    if (!(i in opts)) opts[i] = defaults[i];
  });

  // Get the module root
  if (!opts.module_root) {
    opts.module_root = exports.getRoot(exports.getFileName());
  }

  // Ensure the given bindings name ends with .node
  if (path.extname(opts.bindings) != '.node') {
    opts.bindings += '.node';
  }

  // https://github.com/webpack/webpack/issues/4175#issuecomment-342931035
  var requireFunc =
     true
      ? require
      : undefined;

  var tries = [],
    i = 0,
    l = opts.try.length,
    n,
    b,
    err;

  for (; i < l; i++) {
    n = join.apply(
      null,
      opts.try[i].map(function(p) {
        return opts[p] || p;
      })
    );
    tries.push(n);
    try {
      b = opts.path ? requireFunc.resolve(n) : requireFunc(n);
      if (!opts.path) {
        b.path = n;
      }
      return b;
    } catch (e) {
      if (e.code !== 'MODULE_NOT_FOUND' &&
          e.code !== 'QUALIFIED_PATH_RESOLUTION_FAILED' &&
          !/not find/i.test(e.message)) {
        throw e;
      }
    }
  }

  err = new Error(
    'Could not locate the bindings file. Tried:\n' +
      tries
        .map(function(a) {
          return opts.arrow + a;
        })
        .join('\n')
  );
  err.tries = tries;
  throw err;
}
module.exports = exports = bindings;

/**
 * Gets the filename of the JavaScript file that invokes this function.
 * Used to help find the root directory of a module.
 * Optionally accepts an filename argument to skip when searching for the invoking filename
 */

exports.getFileName = function getFileName(calling_file) {
  var origPST = Error.prepareStackTrace,
    origSTL = Error.stackTraceLimit,
    dummy = {},
    fileName;

  Error.stackTraceLimit = 10;

  Error.prepareStackTrace = function(e, st) {
    for (var i = 0, l = st.length; i < l; i++) {
      fileName = st[i].getFileName();
      if (fileName !== __filename) {
        if (calling_file) {
          if (fileName !== calling_file) {
            return;
          }
        } else {
          return;
        }
      }
    }
  };

  // run the 'prepareStackTrace' function above
  Error.captureStackTrace(dummy);
  dummy.stack;

  // cleanup
  Error.prepareStackTrace = origPST;
  Error.stackTraceLimit = origSTL;

  // handle filename that starts with "file://"
  var fileSchema = 'file://';
  if (fileName.indexOf(fileSchema) === 0) {
    fileName = fileURLToPath(fileName);
  }

  return fileName;
};

/**
 * Gets the root directory of a module, given an arbitrary filename
 * somewhere in the module tree. The "root directory" is the directory
 * containing the `package.json` file.
 *
 *   In:  /home/nate/node-native-module/lib/index.js
 *   Out: /home/nate/node-native-module
 */

exports.getRoot = function getRoot(file) {
  var dir = dirname(file),
    prev;
  while (true) {
    if (dir === '.') {
      // Avoids an infinite loop in rare cases, like the REPL
      dir = process.cwd();
    }
    if (
      exists(join(dir, 'package.json')) ||
      exists(join(dir, 'node_modules'))
    ) {
      // Found the 'package.json' file or 'node_modules' dir; we're done
      return dir;
    }
    if (prev === dir) {
      // Got to the top
      throw new Error(
        'Could not find module root given file: "' +
          file +
          '". Do you have a `package.json` file? '
      );
    }
    // Try the parent dir next
    prev = dir;
    dir = join(dir, '..');
  }
};

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../webpack/node_modules/process/browser.js */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\process\\browser.js"), "/index.js"))

/***/ }),

/***/ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webworker-threads\\node_modules\\file-uri-to-path\\index.js":
/*!******************************************************************************************************************!*\
  !*** C:/Users/pudding/AppData/Roaming/npm/node_modules/webworker-threads/node_modules/file-uri-to-path/index.js ***!
  \******************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {


/**
 * Module dependencies.
 */

var sep = __webpack_require__(/*! path */ "C:\\Users\\pudding\\AppData\\Roaming\\npm\\node_modules\\webpack\\node_modules\\path-browserify\\index.js").sep || '/';

/**
 * Module exports.
 */

module.exports = fileUriToPath;

/**
 * File URI to Path function.
 *
 * @param {String} uri
 * @return {String} path
 * @api public
 */

function fileUriToPath (uri) {
  if ('string' != typeof uri ||
      uri.length <= 7 ||
      'file://' != uri.substring(0, 7)) {
    throw new TypeError('must pass in a file:// URI to convert to a file path');
  }

  var rest = decodeURI(uri.substring(7));
  var firstSlash = rest.indexOf('/');
  var host = rest.substring(0, firstSlash);
  var path = rest.substring(firstSlash + 1);

  // 2.  Scheme Definition
  // As a special case, <host> can be the string "localhost" or the empty
  // string; this is interpreted as "the machine from which the URL is
  // being interpreted".
  if ('localhost' == host) host = '';

  if (host) {
    host = sep + sep + host;
  }

  // 3.2  Drives, drive letters, mount points, file system root
  // Drive letters are mapped into the top of a file URI in various ways,
  // depending on the implementation; some applications substitute
  // vertical bar ("|") for the colon after the drive letter, yielding
  // "file:///c|/tmp/test.txt".  In some cases, the colon is left
  // unchanged, as in "file:///c:/tmp/test.txt".  In other cases, the
  // colon is simply omitted, as in "file:///c/tmp/test.txt".
  path = path.replace(/^(.+)\|/, '$1:');

  // for Windows, we need to invert the path separators from what a URI uses
  if (sep == '\\') {
    path = path.replace(/\//g, '\\');
  }

  if (/^.+\:/.test(path)) {
    // has Windows drive at beginning of path
  } else {
    // unix path…
    path = sep + path;
  }

  return host + path;
}


/***/ })

}]);
//# sourceMappingURL=vendors.min.js.map